{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c9a9a878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n",
      "2.0\n",
      "3.1622776601683795\n",
      "2.23606797749979\n",
      "1.4142135623730951\n",
      "1.7320508075688772\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#cite https://www.geeksforgeeks.org/calculate-the-euclidean-distance-using-numpy/\n",
    "point1 = np.array((0, 0, 0))\n",
    "point2 = np.array((0, 3, 0))\n",
    "\n",
    "dist = np.linalg.norm(point1-point2)\n",
    "print(dist)\n",
    "point2 = np.array((2, 0, 0))\n",
    "dist = np.linalg.norm(point1-point2)\n",
    "print(dist)\n",
    "point2 = np.array((0, 1, 3))\n",
    "dist = np.linalg.norm(point1-point2)\n",
    "print(dist)\n",
    "point2 = np.array((0, 1, 2))\n",
    "dist = np.linalg.norm(point1-point2)\n",
    "print(dist)\n",
    "point2 = np.array((-1, 0, 1))\n",
    "dist = np.linalg.norm(point1-point2)\n",
    "print(dist)\n",
    "point2 = np.array((1, 1, 1))\n",
    "dist = np.linalg.norm(point1-point2)\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "710d5402",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b2/8cn96b9x6qz0b7b79dn_n_1h0000gn/T/ipykernel_13453/1107571974.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({'FPR':FPR, 'TPR':TPR}, ignore_index = True)\n",
      "/var/folders/b2/8cn96b9x6qz0b7b79dn_n_1h0000gn/T/ipykernel_13453/1107571974.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({'FPR':FPR, 'TPR':TPR}, ignore_index = True)\n",
      "/var/folders/b2/8cn96b9x6qz0b7b79dn_n_1h0000gn/T/ipykernel_13453/1107571974.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({'FPR':FPR, 'TPR':TPR}, ignore_index = True)\n",
      "/var/folders/b2/8cn96b9x6qz0b7b79dn_n_1h0000gn/T/ipykernel_13453/1107571974.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({'FPR':FPR, 'TPR':TPR}, ignore_index = True)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#question 5 - make a ROC curve\n",
    "# credit to pseudocode provided in Lecture 6 of CS 760, Fall 2023\n",
    "df = {'c': [0.95, 0.85, 0.8, 0.7, 0.55, 0.45, 0.4, 0.3, 0.2, 0.1],\n",
    "     'class': [1, 1, 0, 1, 1, 0, 1, 1, 0, 0]}\n",
    "TP = 0\n",
    "FP = 0\n",
    "last_TP = 0\n",
    "m = 10\n",
    "df_pandas = pd.DataFrame(df)\n",
    "num_neg = len(df_pandas[(df_pandas['class']==0)]['class'])\n",
    "num_pos = len(df_pandas[(df_pandas['class']==1)]['class'])\n",
    "results = pd.DataFrame()\n",
    "\n",
    "for i in range(m):\n",
    "    if (i > 0) and df_pandas.loc[i, 'c']!=df_pandas.loc[i-1, 'c'] and df_pandas.loc[i, 'class']==0 and TP > last_TP:\n",
    "        FPR = FP/num_neg\n",
    "        TPR = TP/num_pos\n",
    "        results = results.append({'FPR':FPR, 'TPR':TPR}, ignore_index = True)\n",
    "        last_TP = TP\n",
    "    if df_pandas.loc[i, 'class']==1:\n",
    "        TP = TP + 1\n",
    "    else:\n",
    "        FP = FP + 1\n",
    "\n",
    "FPR = FP/num_neg\n",
    "TPR = TP/num_pos\n",
    "results = results.append({'FPR':FPR, 'TPR':TPR}, ignore_index = True)\n",
    "\n",
    "#cite https://stackoverflow.com/questions/20130227/matplotlib-connect-scatterplot-points-with-line-python\n",
    "#results.plot.line(x = 'FPR', y = 'TPR')\n",
    "plt.plot('FPR', 'TPR', data = results)\n",
    "plt.scatter('FPR', 'TPR', data = results)\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.savefig(\"./HW/HW3/ROC_curve.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "bb27b02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_KNN(train_data, test_data, k):\n",
    "    train_data = train_data.reset_index(drop=True)\n",
    "    test_data = test_data.reset_index(drop=True)\n",
    "    print(train_data.shape)\n",
    "    print(test_data.shape)\n",
    "    dist_matrix = pd.DataFrame(distance_matrix(train_data.iloc[:,0:(train_data.shape[1]-1)], test_data.iloc[:, 0:(test_data.shape[1]-1)]), index=train_data.index, columns=test_data.index)\n",
    "    test_data['pred'] = dist_matrix.apply(lambda col: np.argpartition(col,k),axis=0).iloc[:k]\\\n",
    "                .apply(lambda col: train_data.filter(items = col.values, axis = 0)['Prediction'].reset_index(drop=True), axis = 1)\\\n",
    "                 .mean(axis = 0)\n",
    "#     x = dist_matrix.apply(lambda col: np.argpartition(col,k),axis=0).iloc[:k]\n",
    "#     print(x)\n",
    "#     y = x.apply(lambda col: train_data.filter(items = col.values, axis = 0)['Prediction'].reset_index(drop=True).mean(axis = 0))\n",
    "#     print(y)\n",
    "    #z = y.mean(axis = 1)\n",
    "    #print(z)\n",
    "#     print(test_data)\n",
    "#     print(dist_matrix.apply(lambda col: np.argpartition(col,k),axis=0).iloc[:k]\\\n",
    "#                 .apply(lambda col: train_data.filter(items = col.values, axis = 0)[2].reset_index(drop = True), axis = 1)\\\n",
    "#                 .mode(axis = 0).iloc[0])\n",
    "    return test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "b8b6e327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 3)\n",
      "(1600, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#KNN\n",
    "#cite https://stackoverflow.com/questions/29481485/creating-a-distance-matrix\n",
    "from scipy.spatial import distance_matrix\n",
    "data = np.loadtxt(\"./HW/hw3Data/D2z.txt\")\n",
    "train_data = pd.DataFrame(data, columns = ['x1', 'x2', 'Prediction'])\n",
    "\n",
    "x = np.arange(-2,2,.1)\n",
    "y = np.arange(-2,2,.1)\n",
    "x1,x2=np.meshgrid(x,y)\n",
    "test_data = pd.DataFrame(zip(x1.flatten(),x2.flatten()))\n",
    "test_data['Prediction'] = 1\n",
    "\n",
    "\n",
    "one_kNN = predict_KNN(train_data, test_data, 1)\n",
    "ax = train_data.plot.scatter(0,1)\n",
    "one_kNN.plot.scatter(0, 1, ax = ax, c = 'pred')\n",
    "ax.set_ylabel('x2')\n",
    "ax.set_xlabel('x1')\n",
    "plt.savefig(\"./HW/KNN_q1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "edc2799e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 2 question 2. Spam filter\n",
    "spam = pd.read_csv(\"./HW/hw3Data/emails.csv\")\n",
    "spam = spam.drop(['Email No.'], axis = 1)\n",
    "#partition data into train and test sets\n",
    "all_index = np.arange(0, 5000, 1)\n",
    "fold_1_test = np.arange(0, 1000, 1)\n",
    "fold_2_test = np.arange(1000, 2000, 1)\n",
    "fold_3_test = np.arange(2000, 3000, 1)\n",
    "fold_4_test = np.arange(3000, 4000, 1)\n",
    "fold_5_test = np.arange(4000, 5000, 1)\n",
    "\n",
    "#results_five_foldCV = pd.DataFrame()\n",
    "\n",
    "def accuracy_precision_recall(df, fold_id):\n",
    "    df['true_label'] = spam['Prediction'].iloc[fold_id].reset_index(drop=True)\n",
    "    print(df)\n",
    "    TP_and_TN = np.sum(df['pred']==df['true_label'])\n",
    "    denomin = df.shape[0]\n",
    "    accuracy = TP_and_TN/denomin\n",
    "    TP = len(df.loc[(df['true_label']==1) & (df['pred']==df['true_label'])])\n",
    "#     TP = np.sum((df['true_label']==1) and (df['pred']==df['true_label']))\n",
    "    TP_and_FP = np.sum(df['pred']==1)\n",
    "    precision = TP/TP_and_FP\n",
    "    \n",
    "    TP_and_FN = np.sum(df['true_label']==1)\n",
    "    recall = TP/TP_and_FN\n",
    "    return [accuracy, precision, recall]\n",
    "    \n",
    "def run_one_fold(k, train_id, fold_id):\n",
    "    print(spam.iloc[fold_id])\n",
    "    print(spam.iloc[train_id])\n",
    "    test_pred_df = predict_KNN(spam.iloc[train_id], spam.iloc[fold_id], k)\n",
    "    res = accuracy_precision_recall(test_pred_df, fold_id)\n",
    "    print(res)\n",
    "    return pd.DataFrame.from_records([{'k':k, 'accuracy': res[0],\n",
    "                         'precision':res[1], 'recall':res[2]}]), test_pred_df\n",
    "\n",
    "def run_five_fold(k):\n",
    "    one = run_one_fold(k, np.delete(all_index, fold_1_test), fold_1_test)[0]\n",
    "    two = run_one_fold(k, np.delete(all_index, fold_2_test), fold_2_test)[0]\n",
    "    three = run_one_fold(k, np.delete(all_index, fold_3_test), fold_3_test)[0]\n",
    "    four = run_one_fold(k, np.delete(all_index, fold_4_test), fold_4_test)[0]\n",
    "    five = run_one_fold(k, np.delete(all_index, fold_5_test), fold_5_test)[0]\n",
    "#    t = run_one_fold(k, np.arange(41, 100, 1), np.arange(0, 40, 1))\n",
    "    final = pd.concat([one, two, three, four, five])\n",
    "    final['fold'] = [1, 2, 3, 4, 5]\n",
    "    \n",
    "    final_preds = pd.concat([one[1], two[1], three[1], four[1], five[1]])\n",
    "    return final, final_preds\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62727f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_nn = run_five_fold(1)\n",
    "one_nn.to_latex()\n",
    "# print(fold_1_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "b832d864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      "{} &  k &  accuracy &  precision &    recall &  fold \\\\\n",
      "\\midrule\n",
      "0 &  1 &     0.825 &   0.654494 &  0.817544 &     1 \\\\\n",
      "0 &  1 &     0.853 &   0.685714 &  0.866426 &     2 \\\\\n",
      "0 &  1 &     0.862 &   0.721212 &  0.838028 &     3 \\\\\n",
      "0 &  1 &     0.851 &   0.716418 &  0.816327 &     4 \\\\\n",
      "0 &  1 &     0.775 &   0.605744 &  0.758170 &     5 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b2/8cn96b9x6qz0b7b79dn_n_1h0000gn/T/ipykernel_13453/2539730384.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(one_nn.to_latex())\n"
     ]
    }
   ],
   "source": [
    "print(one_nn.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "1692372e",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 25)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m<tokenize>:25\u001b[0;36m\u001b[0m\n\u001b[0;31m    for epoch in range(num_epochs):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "#question 4 - build logistic regression model from scratch\n",
    "spam_matrix = spam.to_numpy()\n",
    "x_train = spam_matrix[:,0:(spam_matrix.shape[0]-1)]\n",
    "y_train = spam_matrix[:,-1]\n",
    "\n",
    "## Attribution: Hugh Liu's CS540 P1 Solution 2020, available online through summer 2023 CS 540 website\n",
    "def logistic_regression(test_id, train_id):\n",
    "    x = x_train[train_id]\n",
    "    y = y_train[train_id]\n",
    "    \n",
    "    x_test = x_train[test_id]\n",
    "    y_test = y_train[test_id]\n",
    "    \n",
    "    num_epochs = 5000\n",
    "\n",
    "    m = x.shape[1]\n",
    "\n",
    "    w = np.ones(m)\n",
    "    b = np.ones(1)\n",
    "    loss_previous = 10e10\n",
    "    lowest_loss = 1e6\n",
    "    for alpha in np.linspace(0.000001, 0.99, 40):\n",
    "            w = np.ones(m)\n",
    "            b = np.ones(1)\n",
    "        for epoch in range(num_epochs):\n",
    "            print(alpha, epoch)\n",
    "            a = x@w + b\n",
    "            a = (1/(1+np.exp(-a)))\n",
    "            # bound items in a to avoid log(0):\n",
    "            a = np.clip(a, .001, .999)\n",
    "\n",
    "            w -= alpha * (x.T)@(a-y)\n",
    "\n",
    "            b -= alpha * (a-y).sum()\n",
    "            loss = - np.sum(y*np.log(a) + (1-y)*np.log(1-a))\n",
    "            loss_reduction = loss_previous - loss\n",
    "            loss_previous = loss\n",
    "            if loss < lowest_loss:\n",
    "                w_best = w\n",
    "                b_best = b\n",
    "                alpha_best = alpha\n",
    "                lowest_loss = loss\n",
    "            accuracy = sum((a>0.5).astype(int) == y) / len(y)\n",
    "            \n",
    "\n",
    "#             print('alpha = ', alpha, 'b = ', b, 'epoch = ', epoch, ' loss = {:.7}'.format(loss), \\\n",
    "#                   ' loss reduction = {:.7}'.format(loss_reduction), \\\n",
    "#                   ' correctly classified = {:.4%}'.format(accuracy))\n",
    "            if abs(loss_reduction) < 0.001:\n",
    "                break\n",
    "    test_a = x_test@w_best + b_best \n",
    "    test_pred = 1/(1+np.exp(-test_a))\n",
    "    df = pd.DataFrame({'pred':test_pred})\n",
    "    return accuracy_precision_recall(df, test_id), test_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "0bae2f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.6 b =  -1695.571622420976 epoch =  0  loss = 19557.07  loss reduction = 9.999998e+10  correctly classified = 29.2250%\n",
      "alpha =  0.6 b =  -996.5716224209759 epoch =  1  loss = 8077.998  loss reduction = 11479.07  correctly classified = 70.7750%\n",
      "alpha =  0.6 b =  -297.5716224209759 epoch =  2  loss = 8077.998  loss reduction = 0.0  correctly classified = 70.7750%\n",
      "alpha =  0.6205263157894737 b =  -2051.799517157818 epoch =  0  loss = 19557.02  loss reduction = -11479.03  correctly classified = 29.2250%\n",
      "alpha =  0.6205263157894737 b =  -1328.8863592630814 epoch =  1  loss = 8077.998  loss reduction = 11479.03  correctly classified = 70.7750%\n",
      "alpha =  0.6205263157894737 b =  -605.9732013683446 epoch =  2  loss = 8077.998  loss reduction = 0.0  correctly classified = 70.7750%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b2/8cn96b9x6qz0b7b79dn_n_1h0000gn/T/ipykernel_13453/3879921196.py:25: RuntimeWarning: overflow encountered in exp\n",
      "  a = (1/(1+np.exp(-a)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.6410526315789473 b =  -2418.2289908420285 epoch =  0  loss = 19557.02  loss reduction = -11479.03  correctly classified = 29.2250%\n",
      "alpha =  0.6410526315789473 b =  -1671.402675052555 epoch =  1  loss = 8077.998  loss reduction = 11479.03  correctly classified = 70.7750%\n",
      "alpha =  0.6410526315789473 b =  -3031.3407024209755 epoch =  2  loss = 15668.52  loss reduction = -7590.524  correctly classified = 43.3000%\n",
      "alpha =  0.6410526315789473 b =  -2284.514386631502 epoch =  3  loss = 8077.998  loss reduction = 7590.524  correctly classified = 70.7750%\n",
      "alpha =  0.6410526315789473 b =  -1537.6880708420285 epoch =  4  loss = 8077.998  loss reduction = 0.0  correctly classified = 70.7750%\n",
      "alpha =  0.661578947368421 b =  -3407.9717550525547 epoch =  0  loss = 19557.02  loss reduction = -11479.03  correctly classified = 29.2250%\n",
      "alpha =  0.661578947368421 b =  -2637.232281368344 epoch =  1  loss = 8077.998  loss reduction = 11479.03  correctly classified = 70.7750%\n",
      "alpha =  0.661578947368421 b =  -2778.966308736765 epoch =  2  loss = 5646.821  loss reduction = 2431.178  correctly classified = 79.5750%\n",
      "alpha =  0.661578947368421 b =  -2008.2268350525542 epoch =  3  loss = 8077.998  loss reduction = -2431.178  correctly classified = 70.7750%\n",
      "alpha =  0.661578947368421 b =  -3869.266938210449 epoch =  4  loss = 19653.72  loss reduction = -11575.72  correctly classified = 28.8750%\n",
      "alpha =  0.661578947368421 b =  -3098.5274645262384 epoch =  5  loss = 8077.998  loss reduction = 11575.72  correctly classified = 70.7750%\n",
      "alpha =  0.661578947368421 b =  -3435.036949789396 epoch =  6  loss = 6537.792  loss reduction = 1540.206  correctly classified = 76.3500%\n",
      "alpha =  0.661578947368421 b =  -2664.2974761051855 epoch =  7  loss = 8077.998  loss reduction = -1540.206  correctly classified = 70.7750%\n",
      "alpha =  0.661578947368421 b =  -4522.036300315713 epoch =  8  loss = 19660.63  loss reduction = -11582.63  correctly classified = 28.8500%\n",
      "alpha =  0.661578947368421 b =  -3751.296826631502 epoch =  9  loss = 8077.998  loss reduction = 11582.63  correctly classified = 70.7750%\n",
      "alpha =  0.661578947368421 b =  -3182.5956245262387 epoch =  10  loss = 7014.358  loss reduction = 1063.64  correctly classified = 74.6250%\n",
      "alpha =  0.661578947368421 b =  -5042.315216105186 epoch =  11  loss = 19653.72  loss reduction = -12639.36  correctly classified = 28.8750%\n",
      "alpha =  0.661578947368421 b =  -4271.575742420975 epoch =  12  loss = 8077.998  loss reduction = 11575.72  correctly classified = 70.7750%\n",
      "alpha =  0.661578947368421 b =  -4769.847896105186 epoch =  13  loss = 7428.763  loss reduction = 649.2349  correctly classified = 73.1250%\n",
      "alpha =  0.661578947368421 b =  -3999.1084224209753 epoch =  14  loss = 8077.998  loss reduction = -649.2349  correctly classified = 70.7750%\n",
      "alpha =  0.661578947368421 b =  -5811.289597157818 epoch =  15  loss = 19322.2  loss reduction = -11244.2  correctly classified = 30.0750%\n",
      "alpha =  0.661578947368421 b =  -5040.5501234736075 epoch =  16  loss = 8077.998  loss reduction = 11244.2  correctly classified = 70.7750%\n",
      "alpha =  0.661578947368421 b =  -4382.714389789397 epoch =  17  loss = 7463.297  loss reduction = 614.7012  correctly classified = 73.0000%\n",
      "alpha =  0.661578947368421 b =  -6240.453213999923 epoch =  18  loss = 19660.63  loss reduction = -12197.33  correctly classified = 28.8500%\n",
      "alpha =  0.661578947368421 b =  -5469.713740315712 epoch =  19  loss = 8077.998  loss reduction = 11582.63  correctly classified = 70.7750%\n",
      "alpha =  0.661578947368421 b =  -6084.8511687367645 epoch =  20  loss = 8333.548  loss reduction = -255.5499  correctly classified = 69.8500%\n",
      "alpha =  0.661578947368421 b =  -5314.111695052554 epoch =  21  loss = 8077.998  loss reduction = 255.5499  correctly classified = 70.7750%\n",
      "alpha =  0.661578947368421 b =  -6814.6521371578165 epoch =  22  loss = 16476.61  loss reduction = -8398.614  correctly classified = 40.3750%\n",
      "alpha =  0.661578947368421 b =  -6043.912663473606 epoch =  23  loss = 8077.998  loss reduction = 8398.614  correctly classified = 70.7750%\n",
      "alpha =  0.661578947368421 b =  -5546.519086631501 epoch =  24  loss = 6696.647  loss reduction = 1381.351  correctly classified = 75.7750%\n",
      "alpha =  0.661578947368421 b =  -7266.9247066315 epoch =  25  loss = 18527.92  loss reduction = -11831.27  correctly classified = 32.9500%\n",
      "alpha =  0.661578947368421 b =  -6496.1852329472895 epoch =  26  loss = 8077.998  loss reduction = 10449.92  correctly classified = 70.7750%\n",
      "alpha =  0.661578947368421 b =  -6260.913204526237 epoch =  27  loss = 5501.779  loss reduction = 2576.22  correctly classified = 80.1000%\n",
      "alpha =  0.661578947368421 b =  -6569.6919466315 epoch =  28  loss = 6316.776  loss reduction = -814.9971  correctly classified = 77.1500%\n",
      "alpha =  0.661578947368421 b =  -5815.458867684132 epoch =  29  loss = 7919.143  loss reduction = -1602.367  correctly classified = 71.3500%\n",
      "alpha =  0.661578947368421 b =  -7545.108068736764 epoch =  30  loss = 18596.99  loss reduction = -10677.84  correctly classified = 32.7000%\n",
      "alpha =  0.661578947368421 b =  -6774.368595052553 epoch =  31  loss = 8077.998  loss reduction = 10518.99  correctly classified = 70.7750%\n",
      "alpha =  0.661578947368421 b =  -6720.666908736764 epoch =  32  loss = 5190.975  loss reduction = 2887.023  correctly classified = 81.2250%\n",
      "alpha =  0.661578947368421 b =  -6299.202747684132 epoch =  33  loss = 6192.454  loss reduction = -1001.479  correctly classified = 77.6000%\n",
      "alpha =  0.661578947368421 b =  -7584.499802420974 epoch =  34  loss = 14501.28  loss reduction = -8308.826  correctly classified = 47.5250%\n",
      "alpha =  0.661578947368421 b =  -6813.760328736764 epoch =  35  loss = 8077.998  loss reduction = 6423.282  correctly classified = 70.7750%\n",
      "alpha =  0.661578947368421 b =  -6806.936803473606 epoch =  36  loss = 5197.882  loss reduction = 2880.117  correctly classified = 81.2000%\n",
      "alpha =  0.661578947368421 b =  -6310.863738210448 epoch =  37  loss = 6627.58  loss reduction = -1429.698  correctly classified = 76.0250%\n",
      "alpha =  0.661578947368421 b =  -7850.359271894658 epoch =  38  loss = 16787.42  loss reduction = -10159.84  correctly classified = 39.2500%\n",
      "alpha =  0.661578947368421 b =  -7079.619798210448 epoch =  39  loss = 8077.998  loss reduction = 8709.418  correctly classified = 70.7750%\n",
      "alpha =  0.661578947368421 b =  -7020.6360655788685 epoch =  40  loss = 5121.907  loss reduction = 2956.091  correctly classified = 81.4750%\n",
      "alpha =  0.661578947368421 b =  -6642.088530842027 epoch =  41  loss = 5992.158  loss reduction = -870.2511  correctly classified = 78.3250%\n",
      "alpha =  0.661578947368421 b =  -7556.982087684131 epoch =  42  loss = 10889.05  loss reduction = -4896.889  correctly classified = 60.6000%\n",
      "alpha =  0.661578947368421 b =  -6786.242613999921 epoch =  43  loss = 8077.998  loss reduction = 2811.049  correctly classified = 70.7750%\n",
      "alpha =  0.661578947368421 b =  -7528.149153999921 epoch =  44  loss = 9272.867  loss reduction = -1194.869  correctly classified = 66.4500%\n",
      "alpha =  0.661578947368421 b =  -6763.351982420973 epoch =  45  loss = 8029.651  loss reduction = 1243.216  correctly classified = 70.9500%\n",
      "alpha =  0.661578947368421 b =  -7934.424785578868 epoch =  46  loss = 13347.85  loss reduction = -5318.201  correctly classified = 51.7000%\n",
      "alpha =  0.661578947368421 b =  -7163.685311894657 epoch =  47  loss = 8077.998  loss reduction = 5269.854  correctly classified = 70.7750%\n",
      "alpha =  0.661578947368421 b =  -7390.592336105184 epoch =  48  loss = 5750.422  loss reduction = 2327.576  correctly classified = 79.2000%\n",
      "alpha =  0.661578947368421 b =  -6712.288672947288 epoch =  49  loss = 7525.458  loss reduction = -1775.036  correctly classified = 72.7750%\n",
      "alpha =  0.661578947368421 b =  -8311.86812593364 epoch =  50  loss = 17373.81  loss reduction = -9848.354  correctly classified = 37.1250%\n",
      "alpha =  0.661578947368421 b =  -7541.12865224943 epoch =  51  loss = 8077.998  loss reduction = 9295.813  correctly classified = 70.7750%\n",
      "alpha =  0.661578947368421 b =  -7725.779305933641 epoch =  52  loss = 5626.1  loss reduction = 2451.898  correctly classified = 79.6500%\n",
      "alpha =  0.661578947368421 b =  -7074.546130144167 epoch =  53  loss = 7325.162  loss reduction = -1699.062  correctly classified = 73.5000%\n",
      "alpha =  0.661578947368421 b =  -8621.964733302062 epoch =  54  loss = 16856.48  loss reduction = -9531.322  correctly classified = 39.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.661578947368421 b =  -7851.885515407325 epoch =  55  loss = 8071.092  loss reduction = 8785.392  correctly classified = 70.8000%\n",
      "alpha =  0.661578947368421 b =  -8063.605049236454 epoch =  56  loss = 5688.264  loss reduction = 2382.828  correctly classified = 79.4250%\n",
      "alpha =  0.661578947368421 b =  -7424.256477657506 epoch =  57  loss = 7269.908  loss reduction = -1581.644  correctly classified = 73.7000%\n",
      "alpha =  0.661578947368421 b =  -8913.572571341716 epoch =  58  loss = 16317.76  loss reduction = -9047.849  correctly classified = 40.9500%\n",
      "alpha =  0.661578947368421 b =  -8146.134376604874 epoch =  59  loss = 8057.278  loss reduction = 8260.479  correctly classified = 70.8500%\n",
      "alpha =  0.661578947368421 b =  -8386.246516604873 epoch =  60  loss = 5833.303  loss reduction = 2223.975  correctly classified = 78.9000%\n",
      "alpha =  0.661578947368421 b =  -7751.519735552241 epoch =  61  loss = 7235.374  loss reduction = -1402.071  correctly classified = 73.8250%\n",
      "alpha =  0.661578947368421 b =  -9188.675621868031 epoch =  62  loss = 15841.19  loss reduction = -8605.816  correctly classified = 42.6750%\n",
      "alpha =  0.661578947368421 b =  -8421.897682920662 epoch =  63  loss = 8050.371  loss reduction = 7790.819  correctly classified = 70.8750%\n",
      "alpha =  0.661578947368421 b =  -8689.740566078557 epoch =  64  loss = 5971.438  loss reduction = 2078.933  correctly classified = 78.4000%\n",
      "alpha =  0.661578947368421 b =  -8043.129180815399 epoch =  65  loss = 7318.255  loss reduction = -1346.817  correctly classified = 73.5250%\n",
      "alpha =  0.661578947368421 b =  -9423.50306923645 epoch =  66  loss = 15288.65  loss reduction = -7970.395  correctly classified = 44.6750%\n",
      "alpha =  0.661578947368421 b =  -8658.04564186803 epoch =  67  loss = 8036.558  loss reduction = 7252.093  correctly classified = 70.9250%\n",
      "alpha =  0.661578947368421 b =  -8966.824383973293 epoch =  68  loss = 6123.387  loss reduction = 1913.171  correctly classified = 77.8500%\n",
      "alpha =  0.661578947368421 b =  -8324.174533446978 epoch =  69  loss = 7276.815  loss reduction = -1153.428  correctly classified = 73.6750%\n",
      "alpha =  0.661578947368421 b =  -9644.465145025924 epoch =  70  loss = 14743.02  loss reduction = -7466.202  correctly classified = 46.6500%\n",
      "alpha =  0.661578947368421 b =  -8882.969252394345 epoch =  71  loss = 7995.117  loss reduction = 6747.899  correctly classified = 71.0750%\n",
      "alpha =  0.661578947368421 b =  -9253.812038710133 epoch =  72  loss = 6399.657  loss reduction = 1595.46  correctly classified = 76.8500%\n",
      "alpha =  0.661578947368421 b =  -8618.425001868029 epoch =  73  loss = 7228.467  loss reduction = -828.8106  correctly classified = 73.8500%\n",
      "alpha =  0.661578947368421 b =  -9888.536173446975 epoch =  74  loss = 14314.8  loss reduction = -7086.33  correctly classified = 48.2000%\n",
      "alpha =  0.661578947368421 b =  -9128.360792394344 epoch =  75  loss = 7981.304  loss reduction = 6333.494  correctly classified = 71.1250%\n",
      "alpha =  0.661578947368421 b =  -9522.972787131186 epoch =  76  loss = 6537.792  loss reduction = 1443.512  correctly classified = 76.3500%\n",
      "alpha =  0.661578947368421 b =  -8897.489587131186 epoch =  77  loss = 7193.934  loss reduction = -656.1417  correctly classified = 73.9750%\n",
      "alpha =  0.661578947368421 b =  -10112.799528183818 epoch =  78  loss = 13741.54  loss reduction = -6547.604  correctly classified = 50.2750%\n",
      "alpha =  0.661578947368421 b =  -9356.585681868028 epoch =  79  loss = 7939.863  loss reduction = 5801.674  correctly classified = 71.2750%\n",
      "alpha =  0.661578947368421 b =  -9789.492512394343 epoch =  80  loss = 6772.622  loss reduction = 1167.242  correctly classified = 75.5000%\n",
      "alpha =  0.661578947368421 b =  -9166.650335552238 epoch =  81  loss = 7166.307  loss reduction = -393.685  correctly classified = 74.0750%\n",
      "alpha =  0.661578947368421 b =  -10329.139813446975 epoch =  82  loss = 13271.88  loss reduction = -6105.571  correctly classified = 51.9750%\n",
      "alpha =  0.661578947368421 b =  -9575.56699028908 epoch =  83  loss = 7912.236  loss reduction = 5359.642  correctly classified = 71.3750%\n",
      "alpha =  0.661578947368421 b =  -10049.409679762764 epoch =  84  loss = 6966.011  loss reduction = 946.2254  correctly classified = 74.8000%\n",
      "alpha =  0.661578947368421 b =  -9429.868781868028 epoch =  85  loss = 7131.773  loss reduction = -165.7621  correctly classified = 74.2000%\n",
      "alpha =  0.661578947368421 b =  -10534.916006078554 epoch =  86  loss = 12684.8  loss reduction = -5553.031  correctly classified = 54.1000%\n",
      "alpha =  0.661578947368421 b =  -9791.247019762764 epoch =  87  loss = 7850.075  loss reduction = 4834.728  correctly classified = 71.6000%\n",
      "alpha =  0.661578947368421 b =  -10335.076822920659 epoch =  88  loss = 7504.738  loss reduction = 345.3377  correctly classified = 72.8500%\n",
      "alpha =  0.661578947368421 b =  -9710.914134499606 epoch =  89  loss = 7166.307  loss reduction = 338.431  correctly classified = 74.0750%\n",
      "alpha =  0.661578947368421 b =  -10751.256291341711 epoch =  90  loss = 12049.38  loss reduction = -4883.076  correctly classified = 56.4000%\n",
      "alpha =  0.661578947368421 b =  -10020.132165025921 epoch =  91  loss = 7746.474  loss reduction = 4302.908  correctly classified = 71.9750%\n",
      "alpha =  0.661578947368421 b =  -10651.115732394343 epoch =  92  loss = 8264.481  loss reduction = -518.0066  correctly classified = 70.1000%\n",
      "alpha =  0.661578947368421 b =  -10003.183835552238 epoch =  93  loss = 7332.069  loss reduction = 932.4119  correctly classified = 73.4750%\n",
      "alpha =  0.661578947368421 b =  -10988.064506078554 epoch =  94  loss = 11510.66  loss reduction = -4178.587  correctly classified = 58.3500%\n",
      "alpha =  0.661578947368421 b =  -10269.485239762764 epoch =  95  loss = 7656.686  loss reduction = 3853.969  correctly classified = 72.3000%\n",
      "alpha =  0.661578947368421 b =  -10970.455920815395 epoch =  96  loss = 8899.902  loss reduction = -1243.216  correctly classified = 67.8000%\n",
      "alpha =  0.661578947368421 b =  -10313.280442920659 epoch =  97  loss = 7359.696  loss reduction = 1540.206  correctly classified = 73.3750%\n",
      "alpha =  0.661578947368421 b =  -11224.212465025921 epoch =  98  loss = 10792.35  loss reduction = -3432.657  correctly classified = 60.9500%\n",
      "alpha =  0.661578947368421 b =  -10512.896012394342 epoch =  99  loss = 7594.526  loss reduction = 3197.827  correctly classified = 72.5250%\n",
      "alpha =  0.661578947368421 b =  -11261.405110289079 epoch =  100  loss = 9300.494  loss reduction = -1705.968  correctly classified = 66.3500%\n",
      "alpha =  0.661578947368421 b =  -10601.588609236447 epoch =  101  loss = 7373.509  loss reduction = 1926.985  correctly classified = 73.3250%\n",
      "alpha =  0.661578947368421 b =  -11466.302726078553 epoch =  102  loss = 10336.51  loss reduction = -2962.998  correctly classified = 62.6000%\n",
      "alpha =  0.661578947368421 b =  -10779.4157376575 epoch =  103  loss = 7546.178  loss reduction = 2790.329  correctly classified = 72.7000%\n",
      "alpha =  0.661578947368421 b =  -11551.69404397329 epoch =  104  loss = 9535.324  loss reduction = -1989.145  correctly classified = 65.5000%\n",
      "alpha =  0.661578947368421 b =  -10888.57626397329 epoch =  105  loss = 7394.23  loss reduction = 2141.094  correctly classified = 73.2500%\n",
      "alpha =  0.661578947368421 b =  -11714.99554502592 epoch =  106  loss = 9977.356  loss reduction = -2583.126  correctly classified = 63.9000%\n",
      "alpha =  0.661578947368421 b =  -11043.954695552236 epoch =  107  loss = 7435.67  loss reduction = 2541.686  correctly classified = 73.1000%\n",
      "alpha =  0.661578947368421 b =  -11825.476582920657 epoch =  108  loss = 9618.205  loss reduction = -2182.535  correctly classified = 65.2000%\n",
      "alpha =  0.661578947368421 b =  -11169.621616604867 epoch =  109  loss = 7345.882  loss reduction = 2272.322  correctly classified = 73.4250%\n",
      "alpha =  0.661578947368421 b =  -11963.028108183815 epoch =  110  loss = 9742.526  loss reduction = -2396.644  correctly classified = 64.7500%\n",
      "alpha =  0.661578947368421 b =  -11308.493653446973 epoch =  111  loss = 7332.069  loss reduction = 2410.457  correctly classified = 73.4750%\n",
      "alpha =  0.661578947368421 b =  -12076.150169236445 epoch =  112  loss = 9486.976  loss reduction = -2154.907  correctly classified = 65.6750%\n",
      "alpha =  0.661578947368421 b =  -11441.423388183814 epoch =  113  loss = 7193.934  loss reduction = 2293.043  correctly classified = 73.9750%\n",
      "alpha =  0.661578947368421 b =  -12203.797857657497 epoch =  114  loss = 9431.722  loss reduction = -2237.789  correctly classified = 65.8750%\n",
      "alpha =  0.661578947368421 b =  -11578.314657657496 epoch =  115  loss = 7152.493  loss reduction = 2279.229  correctly classified = 74.1250%\n",
      "alpha =  0.661578947368421 b =  -12337.387848183813 epoch =  116  loss = 9397.189  loss reduction = -2244.695  correctly classified = 66.0000%\n",
      "alpha =  0.661578947368421 b =  -11714.545671341708 epoch =  117  loss = 7124.866  loss reduction = 2272.322  correctly classified = 74.2250%\n",
      "alpha =  0.661578947368421 b =  -12449.84965344697 epoch =  118  loss = 9189.986  loss reduction = -2065.12  correctly classified = 66.7500%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.661578947368421 b =  -11842.853615552234 epoch =  119  loss = 7028.172  loss reduction = 2161.814  correctly classified = 74.5750%\n",
      "alpha =  0.661578947368421 b =  -12571.555039762761 epoch =  120  loss = 9162.359  loss reduction = -2134.187  correctly classified = 66.8500%\n",
      "alpha =  0.661578947368421 b =  -11970.501303973288 epoch =  121  loss = 6966.011  loss reduction = 2196.348  correctly classified = 74.8000%\n",
      "alpha =  0.661578947368421 b =  -12664.209171341708 epoch =  122  loss = 8865.368  loss reduction = -1899.358  correctly classified = 67.9250%\n",
      "alpha =  0.661578947368421 b =  -12077.681062920656 epoch =  123  loss = 6855.503  loss reduction = 2009.866  correctly classified = 75.2000%\n",
      "alpha =  0.661578947368421 b =  -12781.292767131183 epoch =  124  loss = 8955.156  loss reduction = -2099.653  correctly classified = 67.6000%\n",
      "alpha =  0.661578947368421 b =  -12198.726193446972 epoch =  125  loss = 6841.689  loss reduction = 2113.467  correctly classified = 75.2500%\n",
      "alpha =  0.661578947368421 b =  -12884.510991341709 epoch =  126  loss = 8796.301  loss reduction = -1954.612  correctly classified = 68.1750%\n",
      "alpha =  0.661578947368421 b =  -12308.546975552235 epoch =  127  loss = 6814.062  loss reduction = 1982.239  correctly classified = 75.3500%\n",
      "alpha =  0.661578947368421 b =  -12988.389471341708 epoch =  128  loss = 8734.14  loss reduction = -1920.078  correctly classified = 68.4000%\n",
      "alpha =  0.661578947368421 b =  -12420.348525025918 epoch =  129  loss = 6786.435  loss reduction = 1947.705  correctly classified = 75.4500%\n",
      "alpha =  0.661578947368421 b =  -13059.255161868023 epoch =  130  loss = 8347.362  loss reduction = -1560.927  correctly classified = 69.8000%\n",
      "alpha =  0.661578947368421 b =  -12514.323168183812 epoch =  131  loss = 6682.834  loss reduction = 1664.528  correctly classified = 75.8250%\n",
      "alpha =  0.661578947368421 b =  -13111.633690289074 epoch =  132  loss = 7926.05  loss reduction = -1243.216  correctly classified = 71.3250%\n",
      "alpha =  0.661578947368421 b =  -12587.169626078548 epoch =  133  loss = 6579.233  loss reduction = 1346.817  correctly classified = 76.2000%\n",
      "alpha =  0.661578947368421 b =  -13122.416103973284 epoch =  134  loss = 7414.95  loss reduction = -835.7173  correctly classified = 73.1750%\n",
      "alpha =  0.661578947368421 b =  -12648.131479762758 epoch =  135  loss = 6316.776  loss reduction = 1098.174  correctly classified = 77.1500%\n",
      "alpha =  0.661578947368421 b =  -13079.057542920653 epoch =  136  loss = 6627.58  loss reduction = -310.804  correctly classified = 76.0250%\n",
      "alpha =  0.661578947368421 b =  -12645.04852186802 epoch =  137  loss = 6075.039  loss reduction = 552.5404  correctly classified = 78.0250%\n",
      "alpha =  0.661578947368421 b =  -12955.808031341705 epoch =  138  loss = 5936.904  loss reduction = 138.1351  correctly classified = 78.5250%\n",
      "alpha =  0.661578947368421 b =  -12558.7733344996 epoch =  139  loss = 5840.21  loss reduction = 96.69457  correctly classified = 78.8750%\n",
      "alpha =  0.661578947368421 b =  -12794.263683973284 epoch =  140  loss = 5550.126  loss reduction = 290.0837  correctly classified = 79.9250%\n",
      "alpha =  0.661578947368421 b =  -12422.318707131179 epoch =  141  loss = 5688.261  loss reduction = -138.1351  correctly classified = 79.4250%\n",
      "alpha =  0.661578947368421 b =  -12624.796267131178 epoch =  142  loss = 5411.991  loss reduction = 276.2702  correctly classified = 80.4250%\n",
      "alpha =  0.661578947368421 b =  -12254.832057657493 epoch =  143  loss = 5667.541  loss reduction = -255.5499  correctly classified = 79.5000%\n",
      "alpha =  0.661578947368421 b =  -12456.64936186802 epoch =  144  loss = 5391.271  loss reduction = 276.2702  correctly classified = 80.5000%\n",
      "alpha =  0.661578947368421 b =  -12086.024896604862 epoch =  145  loss = 5619.194  loss reduction = -227.9229  correctly classified = 79.6750%\n",
      "alpha =  0.661578947368421 b =  -12277.27810818381 epoch =  146  loss = 5322.203  loss reduction = 296.9905  correctly classified = 80.7500%\n",
      "alpha =  0.661578947368421 b =  -11910.615177657493 epoch =  147  loss = 5577.753  loss reduction = -255.5499  correctly classified = 79.8250%\n",
      "alpha =  0.661578947368421 b =  -12105.829923973282 epoch =  148  loss = 5308.39  loss reduction = 269.3634  correctly classified = 80.8000%\n",
      "alpha =  0.661578947368421 b =  -11736.525970289073 epoch =  149  loss = 5591.567  loss reduction = -283.1769  correctly classified = 79.7750%\n",
      "alpha =  0.661578947368421 b =  -11935.702251341703 epoch =  150  loss = 5336.017  loss reduction = 255.5499  correctly classified = 80.7000%\n",
      "alpha =  0.661578947368421 b =  -11567.058553446966 epoch =  151  loss = 5584.66  loss reduction = -248.6432  correctly classified = 79.8000%\n",
      "alpha =  0.661578947368421 b =  -11766.234834499597 epoch =  152  loss = 5308.39  loss reduction = 276.2702  correctly classified = 80.8000%\n",
      "alpha =  0.661578947368421 b =  -11396.270625025913 epoch =  153  loss = 5584.66  loss reduction = -276.2702  correctly classified = 79.8000%\n",
      "alpha =  0.661578947368421 b =  -11613.934068183808 epoch =  154  loss = 5336.017  loss reduction = 248.6432  correctly classified = 80.7000%\n",
      "alpha =  0.661578947368421 b =  -11235.386533446965 epoch =  155  loss = 5577.753  loss reduction = -241.7364  correctly classified = 79.8250%\n",
      "alpha =  0.661578947368421 b =  -11463.614069236439 epoch =  156  loss = 5405.084  loss reduction = 172.6689  correctly classified = 80.4500%\n",
      "alpha =  0.661578947368421 b =  -11070.540907131175 epoch =  157  loss = 5660.634  loss reduction = -255.5499  correctly classified = 79.5250%\n",
      "alpha =  0.661578947368421 b =  -11340.36455765749 epoch =  158  loss = 5563.94  loss reduction = 96.69457  correctly classified = 79.8750%\n",
      "alpha =  0.661578947368421 b =  -10943.329860815385 epoch =  159  loss = 5688.261  loss reduction = -124.3216  correctly classified = 79.4250%\n",
      "alpha =  0.661578947368421 b =  -11217.115046078543 epoch =  160  loss = 5591.567  loss reduction = 96.69457  correctly classified = 79.7750%\n",
      "alpha =  0.661578947368421 b =  -10817.439326078544 epoch =  161  loss = 5702.075  loss reduction = -110.5081  correctly classified = 79.3750%\n",
      "alpha =  0.661578947368421 b =  -11101.78860397328 epoch =  162  loss = 5660.634  loss reduction = 41.44053  correctly classified = 79.5250%\n",
      "alpha =  0.661578947368421 b =  -10691.548791341702 epoch =  163  loss = 5771.142  loss reduction = -110.5081  correctly classified = 79.1250%\n",
      "alpha =  0.661578947368421 b =  -11002.96855660486 epoch =  164  loss = 5791.863  loss reduction = -20.72026  correctly classified = 79.0500%\n",
      "alpha =  0.661578947368421 b =  -10580.844139762754 epoch =  165  loss = 5867.837  loss reduction = -75.9743  correctly classified = 78.7750%\n",
      "alpha =  0.661578947368421 b =  -10935.1805313417 epoch =  166  loss = 6019.785  loss reduction = -151.9486  correctly classified = 78.2250%\n",
      "alpha =  0.661578947368421 b =  -10507.774068183806 epoch =  167  loss = 5881.65  loss reduction = 138.1351  correctly classified = 78.7250%\n",
      "alpha =  0.661578947368421 b =  -10902.386062920648 epoch =  168  loss = 6247.708  loss reduction = -366.058  correctly classified = 77.4000%\n",
      "alpha =  0.661578947368421 b =  -10439.325787131174 epoch =  169  loss = 6047.412  loss reduction = 200.2959  correctly classified = 78.1250%\n",
      "alpha =  0.661578947368421 b =  -10923.072313446964 epoch =  170  loss = 6848.596  loss reduction = -801.1836  correctly classified = 75.2250%\n",
      "alpha =  0.661578947368421 b =  -10437.563340815386 epoch =  171  loss = 6185.548  loss reduction = 663.0485  correctly classified = 77.6250%\n",
      "alpha =  0.661578947368421 b =  -10997.23928292065 epoch =  172  loss = 7490.924  loss reduction = -1305.377  correctly classified = 72.9000%\n",
      "alpha =  0.661578947368421 b =  -10474.095730289071 epoch =  173  loss = 6399.657  loss reduction = 1091.267  correctly classified = 76.8500%\n",
      "alpha =  0.661578947368421 b =  -11121.585692394334 epoch =  174  loss = 8285.201  loss reduction = -1885.544  correctly classified = 70.0250%\n",
      "alpha =  0.661578947368421 b =  -10552.88449028907 epoch =  175  loss = 6613.766  loss reduction = 1671.435  correctly classified = 76.0750%\n",
      "alpha =  0.661578947368421 b =  -11267.060287131175 epoch =  176  loss = 8830.835  loss reduction = -2217.068  correctly classified = 68.0500%\n",
      "alpha =  0.661578947368421 b =  -10656.76297028907 epoch =  177  loss = 6703.554  loss reduction = 2127.28  correctly classified = 75.7500%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.661578947368421 b =  -11349.810581868018 epoch =  178  loss = 8637.445  loss reduction = -1933.891  correctly classified = 68.7500%\n",
      "alpha =  0.661578947368421 b =  -10771.205542920648 epoch =  179  loss = 6703.554  loss reduction = 1933.891  correctly classified = 75.7500%\n",
      "alpha =  0.661578947368421 b =  -11437.842922920649 epoch =  180  loss = 8444.056  loss reduction = -1740.502  correctly classified = 69.4500%\n",
      "alpha =  0.661578947368421 b =  -10877.06479028907 epoch =  181  loss = 6572.326  loss reduction = 1871.731  correctly classified = 76.2250%\n",
      "alpha =  0.661578947368421 b =  -11537.759868183808 epoch =  182  loss = 8409.523  loss reduction = -1837.197  correctly classified = 69.5750%\n",
      "alpha =  0.661578947368421 b =  -10981.603526078545 epoch =  183  loss = 6565.419  loss reduction = 1844.104  correctly classified = 76.2500%\n",
      "alpha =  0.661578947368421 b =  -11635.696046078545 epoch =  184  loss = 8368.082  loss reduction = -1802.663  correctly classified = 69.7250%\n",
      "alpha =  0.661578947368421 b =  -11083.501238710123 epoch =  185  loss = 6537.792  loss reduction = 1830.29  correctly classified = 76.3500%\n",
      "alpha =  0.661578947368421 b =  -11724.38864292065 epoch =  186  loss = 8229.947  loss reduction = -1692.155  correctly classified = 70.2250%\n",
      "alpha =  0.661578947368421 b =  -11181.43741660486 epoch =  187  loss = 6482.538  loss reduction = 1747.409  correctly classified = 76.5500%\n",
      "alpha =  0.661578947368421 b =  -11798.555612394333 epoch =  188  loss = 8008.931  loss reduction = -1526.393  correctly classified = 71.0250%\n",
      "alpha =  0.661578947368421 b =  -11278.05308292065 epoch =  189  loss = 6344.403  loss reduction = 1664.528  correctly classified = 77.0500%\n",
      "alpha =  0.661578947368421 b =  -11831.78672292065 epoch =  190  loss = 7442.577  loss reduction = -1098.174  correctly classified = 73.0750%\n",
      "alpha =  0.661578947368421 b =  -11355.521331341703 epoch =  191  loss = 6102.666  loss reduction = 1339.91  correctly classified = 77.9250%\n",
      "alpha =  0.661578947368421 b =  -11828.043509236439 epoch =  192  loss = 6758.808  loss reduction = -656.1417  correctly classified = 75.5500%\n",
      "alpha =  0.661578947368421 b =  -11395.354999762754 epoch =  193  loss = 5854.023  loss reduction = 904.7849  correctly classified = 78.8250%\n",
      "alpha =  0.661578947368421 b =  -11750.351647131176 epoch =  194  loss = 5985.252  loss reduction = -131.2283  correctly classified = 78.3500%\n",
      "alpha =  0.661578947368421 b =  -11357.278485025912 epoch =  195  loss = 5605.38  loss reduction = 379.8715  correctly classified = 79.7250%\n",
      "alpha =  0.661578947368421 b =  -11594.089346078545 epoch =  196  loss = 5273.856  loss reduction = 331.5242  correctly classified = 80.9250%\n",
      "alpha =  0.661578947368421 b =  -11249.875112394335 epoch =  197  loss = 5329.11  loss reduction = -55.25404  correctly classified = 80.7250%\n",
      "alpha =  0.661578947368421 b =  -11405.474511341703 epoch =  198  loss = 4935.425  loss reduction = 393.685  correctly classified = 82.1500%\n",
      "alpha =  0.661578947368421 b =  -11096.914090289072 epoch =  199  loss = 5135.721  loss reduction = -200.2959  correctly classified = 81.4250%\n",
      "alpha =  0.661578947368421 b =  -11183.186631341703 epoch =  200  loss = 4693.688  loss reduction = 442.0323  correctly classified = 83.0250%\n",
      "alpha =  0.661578947368421 b =  -10946.594091341703 epoch =  201  loss = 4797.29  loss reduction = -103.6013  correctly classified = 82.6500%\n",
      "alpha =  0.661578947368421 b =  -10931.187240815387 epoch =  202  loss = 4500.299  loss reduction = 296.9905  correctly classified = 83.7250%\n",
      "alpha =  0.661578947368421 b =  -10712.421607131177 epoch =  203  loss = 4735.129  loss reduction = -234.8297  correctly classified = 82.8750%\n",
      "alpha =  0.661578947368421 b =  -10672.585292394335 epoch =  204  loss = 4479.579  loss reduction = 255.5499  correctly classified = 83.8000%\n",
      "alpha =  0.661578947368421 b =  -10478.24912292065 epoch =  205  loss = 4672.968  loss reduction = -193.3891  correctly classified = 83.1000%\n",
      "alpha =  0.661578947368421 b =  -10423.226925025912 epoch =  206  loss = 4472.672  loss reduction = 200.2959  correctly classified = 83.8250%\n",
      "alpha =  0.661578947368421 b =  -10234.833057657492 epoch =  207  loss = 4638.434  loss reduction = -165.7621  correctly classified = 83.2250%\n",
      "alpha =  0.661578947368421 b =  -10175.849325025913 epoch =  208  loss = 4431.232  loss reduction = 207.2026  correctly classified = 83.9750%\n",
      "alpha =  0.661578947368421 b =  -9996.699038710123 epoch =  209  loss = 4596.994  loss reduction = -165.7621  correctly classified = 83.3750%\n",
      "alpha =  0.661578947368421 b =  -9941.676840815386 epoch =  210  loss = 4417.418  loss reduction = 179.5756  correctly classified = 84.0250%\n",
      "alpha =  0.661578947368421 b =  -9759.8855313417 epoch =  211  loss = 4583.18  loss reduction = -165.7621  correctly classified = 83.4250%\n",
      "alpha =  0.661578947368421 b =  -9704.863333446963 epoch =  212  loss = 4431.232  loss reduction = 151.9486  correctly classified = 83.9750%\n",
      "alpha =  0.661578947368421 b =  -9527.693814499595 epoch =  213  loss = 4548.647  loss reduction = -117.4148  correctly classified = 83.5500%\n",
      "alpha =  0.661578947368421 b =  -9473.992128183805 epoch =  214  loss = 4389.791  loss reduction = 158.8554  correctly classified = 84.1250%\n",
      "alpha =  0.661578947368421 b =  -9292.20081871012 epoch =  215  loss = 4541.74  loss reduction = -151.9486  correctly classified = 83.5750%\n",
      "alpha =  0.661578947368421 b =  -9240.479899762751 epoch =  216  loss = 4369.071  loss reduction = 172.6689  correctly classified = 84.2000%\n",
      "alpha =  0.661578947368421 b =  -9060.009101868014 epoch =  217  loss = 4514.113  loss reduction = -145.0419  correctly classified = 83.6750%\n",
      "alpha =  0.661578947368421 b =  -9006.967671341697 epoch =  218  loss = 4355.258  loss reduction = 158.8554  correctly classified = 84.2500%\n",
      "alpha =  0.661578947368421 b =  -8830.458408183802 epoch =  219  loss = 4486.486  loss reduction = -131.2283  correctly classified = 83.7750%\n",
      "alpha =  0.661578947368421 b =  -8776.756721868012 epoch =  220  loss = 4348.351  loss reduction = 138.1351  correctly classified = 84.2750%\n",
      "alpha =  0.661578947368421 b =  -8604.20899344696 epoch =  221  loss = 4458.859  loss reduction = -110.5081  correctly classified = 83.8750%\n",
      "alpha =  0.661578947368421 b =  -8547.866283973277 epoch =  222  loss = 4348.351  loss reduction = 110.5081  correctly classified = 84.2750%\n",
      "alpha =  0.661578947368421 b =  -8371.357020815381 epoch =  223  loss = 4431.232  loss reduction = -82.88106  correctly classified = 83.9750%\n",
      "alpha =  0.661578947368421 b =  -8318.315590289065 epoch =  224  loss = 4313.817  loss reduction = 117.4148  correctly classified = 84.4000%\n",
      "alpha =  0.661578947368421 b =  -8112.094816604855 epoch =  225  loss = 4507.206  loss reduction = -193.3891  correctly classified = 83.7000%\n",
      "alpha =  0.661578947368421 b =  -8075.559780815381 epoch =  226  loss = 4265.47  loss reduction = 241.7364  correctly classified = 84.5750%\n",
      "alpha =  0.661578947368421 b =  -7857.454402920644 epoch =  227  loss = 4534.833  loss reduction = -269.3634  correctly classified = 83.6000%\n",
      "alpha =  0.661578947368421 b =  -7868.457783973275 epoch =  228  loss = 4293.097  loss reduction = 241.7364  correctly classified = 84.4750%\n",
      "alpha =  0.661578947368421 b =  -7634.50626713117 epoch =  229  loss = 4603.901  loss reduction = -310.804  correctly classified = 83.3500%\n",
      "alpha =  0.661578947368421 b =  -7669.939112394328 epoch =  230  loss = 4327.63  loss reduction = 276.2702  correctly classified = 84.3500%\n",
      "alpha =  0.661578947368421 b =  -7424.102991341696 epoch =  231  loss = 4645.341  loss reduction = -317.7107  correctly classified = 83.2000%\n",
      "alpha =  0.661578947368421 b =  -7483.96530081538 epoch =  232  loss = 4403.605  loss reduction = 241.7364  correctly classified = 84.0750%\n",
      "alpha =  0.661578947368421 b =  -7237.468923973274 epoch =  233  loss = 4624.621  loss reduction = -221.0162  correctly classified = 83.2750%\n",
      "alpha =  0.661578947368421 b =  -7301.953023973274 epoch =  234  loss = 4396.698  loss reduction = 227.9229  correctly classified = 84.1000%\n",
      "alpha =  0.661578947368421 b =  -7054.136135552221 epoch =  235  loss = 4610.807  loss reduction = -214.1094  correctly classified = 83.3250%\n",
      "alpha =  0.661578947368421 b =  -7117.959979762748 epoch =  236  loss = 4375.978  loss reduction = 234.8297  correctly classified = 84.1750%\n",
      "alpha =  0.661578947368421 b =  -6868.162323973274 epoch =  237  loss = 4617.714  loss reduction = -241.7364  correctly classified = 83.3000%\n",
      "alpha =  0.661578947368421 b =  -6943.210516604853 epoch =  238  loss = 4369.071  loss reduction = 248.6432  correctly classified = 84.2000%\n",
      "alpha =  0.661578947368421 b =  -6682.8487681838005 epoch =  239  loss = 4659.155  loss reduction = -290.0837  correctly classified = 83.1500%\n",
      "alpha =  0.661578947368421 b =  -6797.5123081838 epoch =  240  loss = 4438.139  loss reduction = 221.0162  correctly classified = 83.9500%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.661578947368421 b =  -6494.233933446958 epoch =  241  loss = 4900.891  loss reduction = -462.7526  correctly classified = 82.2750%\n",
      "alpha =  0.661578947368421 b =  -6682.84612186801 epoch =  242  loss = 4714.409  loss reduction = 186.4824  correctly classified = 82.9500%\n",
      "alpha =  0.661578947368421 b =  -6289.112703973274 epoch =  243  loss = 5280.763  loss reduction = -566.3539  correctly classified = 80.9000%\n",
      "alpha =  0.661578947368421 b =  -6698.250326078537 epoch =  244  loss = 6040.506  loss reduction = -759.743  correctly classified = 78.1500%\n",
      "alpha =  0.661578947368421 b =  -6186.991377657484 epoch =  245  loss = 5943.811  loss reduction = 96.69457  correctly classified = 78.5000%\n",
      "alpha =  0.661578947368421 b =  -6987.660682920642 epoch =  246  loss = 9390.282  loss reduction = -3446.471  correctly classified = 66.0250%\n",
      "alpha =  0.661578947368421 b =  -6322.562135552221 epoch =  247  loss = 7124.866  loss reduction = 2265.416  correctly classified = 74.2250%\n",
      "alpha =  0.661578947368421 b =  -7147.660905025905 epoch =  248  loss = 9645.832  loss reduction = -2520.965  correctly classified = 65.1000%\n",
      "alpha =  0.661578947368421 b =  -6483.222613446957 epoch =  249  loss = 7117.959  loss reduction = 2527.872  correctly classified = 74.2500%\n",
      "alpha =  0.661578947368421 b =  -7289.173965025905 epoch =  250  loss = 9445.536  loss reduction = -2327.576  correctly classified = 65.8250%\n",
      "alpha =  0.661578947368421 b =  -6633.979254499589 epoch =  251  loss = 7035.078  loss reduction = 2410.457  correctly classified = 74.5500%\n",
      "alpha =  0.661578947368421 b =  -7436.629327131168 epoch =  252  loss = 9411.002  loss reduction = -2375.924  correctly classified = 65.9500%\n",
      "alpha =  0.661578947368421 b =  -6790.01794186801 epoch =  253  loss = 6945.291  loss reduction = 2465.711  correctly classified = 74.8750%\n",
      "alpha =  0.661578947368421 b =  -7580.123154499589 epoch =  254  loss = 9279.774  loss reduction = -2334.483  correctly classified = 66.4250%\n",
      "alpha =  0.661578947368421 b =  -6942.095094499589 epoch =  255  loss = 6883.13  loss reduction = 2396.644  correctly classified = 75.1000%\n",
      "alpha =  0.661578947368421 b =  -7711.07212186801 epoch =  256  loss = 9072.571  loss reduction = -2189.441  correctly classified = 67.1750%\n",
      "alpha =  0.661578947368421 b =  -7080.306875552221 epoch =  257  loss = 6807.155  loss reduction = 2265.416  correctly classified = 75.3750%\n",
      "alpha =  0.661578947368421 b =  -7861.828762920642 epoch =  258  loss = 9203.799  loss reduction = -2396.644  correctly classified = 66.7000%\n",
      "alpha =  0.661578947368421 b =  -7233.044283973273 epoch =  259  loss = 6786.435  loss reduction = 2417.364  correctly classified = 75.4500%\n",
      "alpha =  0.661578947368421 b =  -7994.7584976574835 epoch =  260  loss = 9010.41  loss reduction = -2223.975  correctly classified = 67.4000%\n",
      "alpha =  0.661578947368421 b =  -7377.858622920641 epoch =  261  loss = 6675.927  loss reduction = 2334.483  correctly classified = 75.8500%\n",
      "alpha =  0.661578947368421 b =  -8119.104907131167 epoch =  262  loss = 8823.928  loss reduction = -2148.001  correctly classified = 68.0750%\n",
      "alpha =  0.661578947368421 b =  -7519.3716829206405 epoch =  263  loss = 6523.979  loss reduction = 2299.949  correctly classified = 76.4000%\n",
      "alpha =  0.661578947368421 b =  -8227.605177657482 epoch =  264  loss = 8492.404  loss reduction = -1968.425  correctly classified = 69.2750%\n",
      "alpha =  0.661578947368421 b =  -7649.000138710114 epoch =  265  loss = 6413.47  loss reduction = 2078.933  correctly classified = 76.8000%\n",
      "alpha =  0.661578947368421 b =  -8317.618286078536 epoch =  266  loss = 8174.693  loss reduction = -1761.222  correctly classified = 70.4250%\n",
      "alpha =  0.661578947368421 b =  -7761.461943973272 epoch =  267  loss = 6302.962  loss reduction = 1871.731  correctly classified = 77.2000%\n",
      "alpha =  0.661578947368421 b =  -8428.099323973272 epoch =  268  loss = 8153.973  loss reduction = -1851.01  correctly classified = 70.5000%\n",
      "alpha =  0.661578947368421 b =  -7877.225028183799 epoch =  269  loss = 6247.708  loss reduction = 1906.264  correctly classified = 77.4000%\n",
      "alpha =  0.661578947368421 b =  -8521.413711341693 epoch =  270  loss = 7946.77  loss reduction = -1699.062  correctly classified = 71.2500%\n",
      "alpha =  0.661578947368421 b =  -7991.667600815377 epoch =  271  loss = 6068.133  loss reduction = 1878.637  correctly classified = 78.0500%\n",
      "alpha =  0.661578947368421 b =  -8590.958890289061 epoch =  272  loss = 7573.805  loss reduction = -1505.673  correctly classified = 72.6000%\n",
      "alpha =  0.661578947368421 b =  -8083.001220815377 epoch =  273  loss = 5964.531  loss reduction = 1609.274  correctly classified = 78.4250%\n",
      "alpha =  0.661578947368421 b =  -8634.754093446956 epoch =  274  loss = 7159.4  loss reduction = -1194.869  correctly classified = 74.1000%\n",
      "alpha =  0.661578947368421 b =  -8153.866911341693 epoch =  275  loss = 5764.235  loss reduction = 1395.164  correctly classified = 79.1500%\n",
      "alpha =  0.661578947368421 b =  -8647.517274499587 epoch =  276  loss = 6731.181  loss reduction = -966.9457  correctly classified = 75.6500%\n",
      "alpha =  0.661578947368421 b =  -8193.700579762744 epoch =  277  loss = 5577.753  loss reduction = 1153.428  correctly classified = 79.8250%\n",
      "alpha =  0.661578947368421 b =  -8608.78050397327 epoch =  278  loss = 6102.666  loss reduction = -524.9134  correctly classified = 77.9250%\n",
      "alpha =  0.661578947368421 b =  -8194.579156604848 epoch =  279  loss = 5384.364  loss reduction = 718.3025  correctly classified = 80.5250%\n",
      "alpha =  0.661578947368421 b =  -8514.582247131164 epoch =  280  loss = 5439.618  loss reduction = -55.25404  correctly classified = 80.3250%\n",
      "alpha =  0.661578947368421 b =  -8143.957781868006 epoch =  281  loss = 5232.415  loss reduction = 207.2026  correctly classified = 81.0750%\n",
      "alpha =  0.661578947368421 b =  -8375.48659660485 epoch =  282  loss = 4942.332  loss reduction = 290.0837  correctly classified = 82.1250%\n",
      "alpha =  0.661578947368421 b =  -8040.515943973271 epoch =  283  loss = 5066.653  loss reduction = -124.3216  correctly classified = 81.6750%\n",
      "alpha =  0.661578947368421 b =  -8214.602505025901 epoch =  284  loss = 4631.528  loss reduction = 435.1256  correctly classified = 83.2500%\n",
      "alpha =  0.661578947368421 b =  -7919.247199762744 epoch =  285  loss = 4845.637  loss reduction = -214.1094  correctly classified = 82.4750%\n",
      "alpha =  0.661578947368421 b =  -8049.756878710112 epoch =  286  loss = 4451.952  loss reduction = 393.685  correctly classified = 83.9000%\n",
      "alpha =  0.661578947368421 b =  -7784.11308397327 epoch =  287  loss = 4714.409  loss reduction = -262.4567  correctly classified = 82.9500%\n",
      "alpha =  0.661578947368421 b =  -7843.975393446954 epoch =  288  loss = 4265.47  loss reduction = 448.9391  correctly classified = 84.5750%\n",
      "alpha =  0.661578947368421 b =  -7628.511038710111 epoch =  289  loss = 4382.885  loss reduction = -117.4148  correctly classified = 84.1500%\n",
      "alpha =  0.661578947368421 b =  -7615.74521134169 epoch =  290  loss = 4099.708  loss reduction = 283.1769  correctly classified = 85.1750%\n",
      "alpha =  0.661578947368421 b =  -7410.844949236427 epoch =  291  loss = 4341.444  loss reduction = -241.7364  correctly classified = 84.3000%\n",
      "alpha =  0.661578947368421 b =  -7388.175285025901 epoch =  292  loss = 4065.174  loss reduction = 276.2702  correctly classified = 85.3000%\n",
      "alpha =  0.661578947368421 b =  -7183.935278710112 epoch =  293  loss = 4334.537  loss reduction = -269.3634  correctly classified = 84.3250%\n",
      "alpha =  0.661578947368421 b =  -7161.925870289059 epoch =  294  loss = 4016.827  loss reduction = 317.7107  correctly classified = 85.4750%\n",
      "alpha =  0.661578947368421 b =  -6959.666631341691 epoch =  295  loss = 4300.003  loss reduction = -283.1769  correctly classified = 84.4500%\n",
      "alpha =  0.661578947368421 b =  -6937.657222920639 epoch =  296  loss = 4003.013  loss reduction = 296.9905  correctly classified = 85.5250%\n",
      "alpha =  0.661578947368421 b =  -6742.000541868007 epoch =  297  loss = 4286.19  loss reduction = -283.1769  correctly classified = 84.5000%\n",
      "alpha =  0.661578947368421 b =  -6712.06806397327 epoch =  298  loss = 4003.013  loss reduction = 283.1769  correctly classified = 85.5250%\n",
      "alpha =  0.661578947368421 b =  -6518.39215028906 epoch =  299  loss = 4251.656  loss reduction = -248.6432  correctly classified = 84.6250%\n",
      "alpha =  0.661578947368421 b =  -6495.722486078534 epoch =  300  loss = 3954.666  loss reduction = 296.9905  correctly classified = 85.7000%\n",
      "alpha =  0.661578947368421 b =  -6294.783758710112 epoch =  301  loss = 4258.563  loss reduction = -303.8972  correctly classified = 84.6000%\n",
      "alpha =  0.661578947368421 b =  -6289.941000815375 epoch =  302  loss = 4003.013  loss reduction = 255.5499  correctly classified = 85.5250%\n",
      "alpha =  0.661578947368421 b =  -6089.662529236428 epoch =  303  loss = 4237.843  loss reduction = -234.8297  correctly classified = 84.6750%\n",
      "alpha =  0.661578947368421 b =  -6090.101817657481 epoch =  304  loss = 4016.827  loss reduction = 221.0162  correctly classified = 85.4750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.661578947368421 b =  -5888.502834499586 epoch =  305  loss = 4237.843  loss reduction = -221.0162  correctly classified = 84.6750%\n",
      "alpha =  0.661578947368421 b =  -5896.2049366048495 epoch =  306  loss = 4065.174  loss reduction = 172.6689  correctly classified = 85.3000%\n",
      "alpha =  0.661578947368421 b =  -5695.926465025902 epoch =  307  loss = 4224.029  loss reduction = -158.8554  correctly classified = 84.7250%\n",
      "alpha =  0.661578947368421 b =  -5701.647799762744 epoch =  308  loss = 4030.64  loss reduction = 193.3891  correctly classified = 85.4250%\n",
      "alpha =  0.661578947368421 b =  -5507.971886078534 epoch =  309  loss = 4182.589  loss reduction = -151.9486  correctly classified = 84.8750%\n",
      "alpha =  0.661578947368421 b =  -5504.4496397627445 epoch =  310  loss = 3961.572  loss reduction = 221.0162  correctly classified = 85.6750%\n",
      "alpha =  0.661578947368421 b =  -5304.171168183797 epoch =  311  loss = 4210.216  loss reduction = -248.6432  correctly classified = 84.7750%\n",
      "alpha =  0.661578947368421 b =  -5317.15531660485 epoch =  312  loss = 3954.666  loss reduction = 255.5499  correctly classified = 85.7000%\n",
      "alpha =  0.661578947368421 b =  -5110.934542920639 epoch =  313  loss = 4106.614  loss reduction = -151.9486  correctly classified = 85.1500%\n",
      "alpha =  0.661578947368421 b =  -5127.219970289059 epoch =  314  loss = 3975.386  loss reduction = 131.2283  correctly classified = 85.6250%\n",
      "alpha =  0.661578947368421 b =  -4917.037661868007 epoch =  315  loss = 4134.241  loss reduction = -158.8554  correctly classified = 85.0500%\n",
      "alpha =  0.661578947368421 b =  -4943.887181868006 epoch =  316  loss = 3961.572  loss reduction = 172.6689  correctly classified = 85.6750%\n",
      "alpha =  0.661578947368421 b =  -4733.04461765748 epoch =  317  loss = 4141.148  loss reduction = -179.5756  correctly classified = 85.0250%\n",
      "alpha =  0.661578947368421 b =  -4762.535160815374 epoch =  318  loss = 3961.572  loss reduction = 179.5756  correctly classified = 85.6750%\n",
      "alpha =  0.661578947368421 b =  -4539.807992394321 epoch =  319  loss = 4196.402  loss reduction = -234.8297  correctly classified = 84.8250%\n",
      "alpha =  0.661578947368421 b =  -4600.330557657479 epoch =  320  loss = 3927.039  loss reduction = 269.3634  correctly classified = 85.8000%\n",
      "alpha =  0.661578947368421 b =  -4353.834180815374 epoch =  321  loss = 4362.164  loss reduction = -435.1256  correctly classified = 84.2250%\n",
      "alpha =  0.661578947368421 b =  -4458.593883973268 epoch =  322  loss = 4072.081  loss reduction = 290.0837  correctly classified = 85.2750%\n",
      "alpha =  0.661578947368421 b =  -4168.5206250259 epoch =  323  loss = 4541.74  loss reduction = -469.6593  correctly classified = 83.5750%\n",
      "alpha =  0.661578947368421 b =  -4355.812301868005 epoch =  324  loss = 4410.512  loss reduction = 131.2283  correctly classified = 84.0500%\n",
      "alpha =  0.661578947368421 b =  -4003.6749987101107 epoch =  325  loss = 4776.57  loss reduction = -366.058  correctly classified = 82.7250%\n",
      "alpha =  0.661578947368421 b =  -4317.075531341689 epoch =  326  loss = 5149.534  loss reduction = -372.9648  correctly classified = 81.3750%\n",
      "alpha =  0.661578947368421 b =  -3867.2203713416893 epoch =  327  loss = 5467.245  loss reduction = -317.7107  correctly classified = 80.2250%\n",
      "alpha =  0.661578947368421 b =  -4438.780917657479 epoch =  328  loss = 7117.959  loss reduction = -1650.714  correctly classified = 74.2500%\n",
      "alpha =  0.661578947368421 b =  -3881.3040639732685 epoch =  329  loss = 6178.641  loss reduction = 939.3186  correctly classified = 77.6500%\n",
      "alpha =  0.661578947368421 b =  -4690.556694499584 epoch =  330  loss = 9397.189  loss reduction = -3218.548  correctly classified = 66.0000%\n",
      "alpha =  0.661578947368421 b =  -4046.5863323943213 epoch =  331  loss = 6890.037  loss reduction = 2507.152  correctly classified = 75.0750%\n",
      "alpha =  0.661578947368421 b =  -4844.614614499585 epoch =  332  loss = 9279.774  loss reduction = -2389.737  correctly classified = 66.4250%\n",
      "alpha =  0.661578947368421 b =  -4209.227577657479 epoch =  333  loss = 6814.062  loss reduction = 2465.711  correctly classified = 75.3500%\n",
      "alpha =  0.661578947368421 b =  -5005.27509239432 epoch =  334  loss = 9259.053  loss reduction = -2444.991  correctly classified = 66.5000%\n",
      "alpha =  0.661578947368421 b =  -4374.509846078531 epoch =  335  loss = 6779.528  loss reduction = 2479.525  correctly classified = 75.4750%\n",
      "alpha =  0.661578947368421 b =  -5154.711221868005 epoch =  336  loss = 9107.105  loss reduction = -2327.576  correctly classified = 67.0500%\n",
      "alpha =  0.661578947368421 b =  -4533.849812394321 epoch =  337  loss = 6689.741  loss reduction = 2417.364  correctly classified = 75.8000%\n",
      "alpha =  0.661578947368421 b =  -5305.467862920636 epoch =  338  loss = 9031.13  loss reduction = -2341.39  correctly classified = 67.3250%\n",
      "alpha =  0.661578947368421 b =  -4691.209011341689 epoch =  339  loss = 6634.487  loss reduction = 2396.644  correctly classified = 76.0000%\n",
      "alpha =  0.661578947368421 b =  -5455.564248183794 epoch =  340  loss = 8955.156  loss reduction = -2320.67  correctly classified = 67.6000%\n",
      "alpha =  0.661578947368421 b =  -4849.888721868005 epoch =  341  loss = 6572.326  loss reduction = 2382.83  correctly classified = 76.2250%\n",
      "alpha =  0.661578947368421 b =  -5582.551680815373 epoch =  342  loss = 8651.259  loss reduction = -2078.933  correctly classified = 68.7000%\n",
      "alpha =  0.661578947368421 b =  -4996.6838281837945 epoch =  343  loss = 6378.937  loss reduction = 2272.322  correctly classified = 76.9250%\n",
      "alpha =  0.661578947368421 b =  -5707.558346078531 epoch =  344  loss = 8423.336  loss reduction = -2044.399  correctly classified = 69.5250%\n",
      "alpha =  0.661578947368421 b =  -5138.857143973268 epoch =  345  loss = 6296.056  loss reduction = 2127.28  correctly classified = 77.2250%\n",
      "alpha =  0.661578947368421 b =  -5797.5714544995835 epoch =  346  loss = 7974.397  loss reduction = -1678.341  correctly classified = 71.1500%\n",
      "alpha =  0.661578947368421 b =  -5267.825343973268 epoch =  347  loss = 6012.879  loss reduction = 1961.518  correctly classified = 78.2500%\n",
      "alpha =  0.661578947368421 b =  -5873.058935552215 epoch =  348  loss = 7442.577  loss reduction = -1429.698  correctly classified = 73.0750%\n",
      "alpha =  0.661578947368421 b =  -5371.703823973267 epoch =  349  loss = 5840.21  loss reduction = 1602.367  correctly classified = 78.8750%\n",
      "alpha =  0.661578947368421 b =  -5932.700277657478 epoch =  350  loss = 7104.146  loss reduction = -1263.936  correctly classified = 74.3000%\n",
      "alpha =  0.661578947368421 b =  -5441.2490029206365 epoch =  351  loss = 5736.608  loss reduction = 1367.537  correctly classified = 79.2500%\n",
      "alpha =  0.661578947368421 b =  -5969.232667131163 epoch =  352  loss = 6814.062  loss reduction = -1077.454  correctly classified = 75.3500%\n",
      "alpha =  0.661578947368421 b =  -5494.287787131163 epoch =  353  loss = 5619.194  loss reduction = 1194.869  correctly classified = 79.6750%\n",
      "alpha =  0.661578947368421 b =  -5983.976615552216 epoch =  354  loss = 6482.538  loss reduction = -863.3443  correctly classified = 76.5500%\n",
      "alpha =  0.661578947368421 b =  -5530.820176604847 epoch =  355  loss = 5501.779  loss reduction = 980.7592  correctly classified = 80.1000%\n",
      "alpha =  0.661578947368421 b =  -5972.9705881837945 epoch =  356  loss = 6151.014  loss reduction = -649.2349  correctly classified = 77.7500%\n",
      "alpha =  0.661578947368421 b =  -5551.506427131163 epoch =  357  loss = 5294.576  loss reduction = 856.4376  correctly classified = 80.8500%\n",
      "alpha =  0.661578947368421 b =  -5913.105632394321 epoch =  358  loss = 5501.779  loss reduction = -207.2026  correctly classified = 80.1000%\n",
      "alpha =  0.661578947368421 b =  -5524.654260815374 epoch =  359  loss = 5087.374  loss reduction = 414.4053  correctly classified = 81.6000%\n",
      "alpha =  0.661578947368421 b =  -5816.266352394321 epoch =  360  loss = 5087.374  loss reduction = 9.094947e-13  correctly classified = 81.6000%\n",
      "alpha =  0.6821052631578948 b =  -5437.546503973268 epoch =  0  loss = 4907.798  loss reduction = 179.5756  correctly classified = 82.2500%\n",
      "alpha =  0.6821052631578948 b =  -5701.446209236426 epoch =  1  loss = 4838.73  loss reduction = 69.06755  correctly classified = 82.5000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.6821052631578948 b =  -5327.491548183794 epoch =  2  loss = 4859.451  loss reduction = -20.72026  correctly classified = 82.4250%\n",
      "alpha =  0.6821052631578948 b =  -5593.433476604847 epoch =  3  loss = 4831.824  loss reduction = 27.62702  correctly classified = 82.5250%\n",
      "alpha =  0.6821052631578948 b =  -5217.4365923943205 epoch =  4  loss = 4866.357  loss reduction = -34.53377  correctly classified = 82.4000%\n",
      "alpha =  0.6821052631578948 b =  -5484.059261868005 epoch =  5  loss = 4824.917  loss reduction = 41.44053  correctly classified = 82.5500%\n",
      "alpha =  0.6821052631578948 b =  -5104.65867239432 epoch =  6  loss = 4900.891  loss reduction = -75.9743  correctly classified = 82.2750%\n",
      "alpha =  0.6821052631578948 b =  -5378.08875239432 epoch =  7  loss = 4866.357  loss reduction = 34.53377  correctly classified = 82.4000%\n",
      "alpha =  0.6821052631578948 b =  -4989.8385292364255 epoch =  8  loss = 4976.865  loss reduction = -110.5081  correctly classified = 82.0000%\n",
      "alpha =  0.6821052631578948 b =  -5295.26343871011 epoch =  9  loss = 5080.467  loss reduction = -103.6013  correctly classified = 81.6250%\n",
      "alpha =  0.6821052631578948 b =  -4888.633207131163 epoch =  10  loss = 5080.467  loss reduction = 9.094947e-13  correctly classified = 81.6250%\n",
      "alpha =  0.7026315789473684 b =  -5268.463191341689 epoch =  0  loss = 5432.711  loss reduction = -352.2445  correctly classified = 80.3500%\n",
      "alpha =  0.7026315789473684 b =  -4807.522822920636 epoch =  1  loss = 5370.55  loss reduction = 62.16079  correctly classified = 80.5750%\n",
      "alpha =  0.7026315789473684 b =  -5312.171091341688 epoch =  2  loss = 6316.776  loss reduction = -946.2254  correctly classified = 77.1500%\n",
      "alpha =  0.7026315789473684 b =  -4782.510543973267 epoch =  3  loss = 5784.956  loss reduction = 531.8201  correctly classified = 79.0750%\n",
      "alpha =  0.7026315789473684 b =  -5465.2702966048455 epoch =  4  loss = 7767.194  loss reduction = -1982.239  correctly classified = 71.9000%\n",
      "alpha =  0.7026315789473684 b =  -4866.1883439732665 epoch =  5  loss = 6247.708  loss reduction = 1519.486  correctly classified = 77.4000%\n",
      "alpha =  0.7026315789473684 b =  -5670.961475552213 epoch =  6  loss = 8886.089  loss reduction = -2638.38  correctly classified = 67.8500%\n",
      "alpha =  0.7026315789473684 b =  -5019.287549236424 epoch =  7  loss = 6641.393  loss reduction = 2244.695  correctly classified = 75.9750%\n",
      "alpha =  0.7026315789473684 b =  -5835.981528183792 epoch =  8  loss = 9003.503  loss reduction = -2362.11  correctly classified = 67.4250%\n",
      "alpha =  0.7026315789473684 b =  -5184.307601868002 epoch =  9  loss = 6641.393  loss reduction = 2362.11  correctly classified = 75.9750%\n",
      "alpha =  0.7026315789473684 b =  -5983.470922920634 epoch =  10  loss = 8830.835  loss reduction = -2189.441  correctly classified = 68.0500%\n",
      "alpha =  0.7026315789473684 b =  -5349.327654499581 epoch =  11  loss = 6496.351  loss reduction = 2334.483  correctly classified = 76.5000%\n",
      "alpha =  0.7026315789473684 b =  -6123.94805449958 epoch =  12  loss = 8616.725  loss reduction = -2120.374  correctly classified = 68.8250%\n",
      "alpha =  0.7026315789473684 b =  -5498.920728183791 epoch =  13  loss = 6406.564  loss reduction = 2210.162  correctly classified = 76.8250%\n",
      "alpha =  0.7026315789473684 b =  -6277.748486078528 epoch =  14  loss = 8671.979  loss reduction = -2265.416  correctly classified = 68.6250%\n",
      "alpha =  0.7026315789473684 b =  -5656.2272913416855 epoch =  15  loss = 6372.03  loss reduction = 2299.949  correctly classified = 76.9500%\n",
      "alpha =  0.7026315789473684 b =  -6419.6280702890535 epoch =  16  loss = 8533.844  loss reduction = -2161.814  correctly classified = 69.1250%\n",
      "alpha =  0.7026315789473684 b =  -5814.23508081537 epoch =  17  loss = 6282.242  loss reduction = 2251.602  correctly classified = 77.2750%\n",
      "alpha =  0.7026315789473684 b =  -6503.305870289054 epoch =  18  loss = 7815.542  loss reduction = -1533.3  correctly classified = 71.7250%\n",
      "alpha =  0.7026315789473684 b =  -5949.102401868001 epoch =  19  loss = 5985.252  loss reduction = 1830.29  correctly classified = 78.3500%\n",
      "alpha =  0.7026315789473684 b =  -6589.087349236422 epoch =  20  loss = 7428.763  loss reduction = -1443.512  correctly classified = 73.1250%\n",
      "alpha =  0.7026315789473684 b =  -6058.024349236422 epoch =  21  loss = 5798.769  loss reduction = 1629.994  correctly classified = 79.0250%\n",
      "alpha =  0.7026315789473684 b =  -6622.27685449958 epoch =  22  loss = 6820.969  loss reduction = -1022.2  correctly classified = 75.3250%\n",
      "alpha =  0.7026315789473684 b =  -6122.769038710106 epoch =  23  loss = 5557.033  loss reduction = 1263.936  correctly classified = 79.9000%\n",
      "alpha =  0.7026315789473684 b =  -6621.106270289053 epoch =  24  loss = 6296.056  loss reduction = -739.0228  correctly classified = 77.2250%\n",
      "alpha =  0.7026315789473684 b =  -6153.854865025895 epoch =  25  loss = 5432.711  loss reduction = 863.3443  correctly classified = 80.3500%\n",
      "alpha =  0.7026315789473684 b =  -6582.069465025896 epoch =  26  loss = 5812.583  loss reduction = -379.8715  correctly classified = 78.9750%\n",
      "alpha =  0.7026315789473684 b =  -6146.373243973264 epoch =  27  loss = 5190.975  loss reduction = 621.6079  correctly classified = 81.2250%\n",
      "alpha =  0.7026315789473684 b =  -6503.763986078527 epoch =  28  loss = 5308.39  loss reduction = -117.4148  correctly classified = 80.8000%\n",
      "alpha =  0.7026315789473684 b =  -6097.519270289053 epoch =  29  loss = 5011.399  loss reduction = 296.9905  correctly classified = 81.8750%\n",
      "alpha =  0.7026315789473684 b =  -6370.061628183789 epoch =  30  loss = 4859.451  loss reduction = 151.9486  correctly classified = 82.4250%\n",
      "alpha =  0.7026315789473684 b =  -6009.396622920632 epoch =  31  loss = 4755.849  loss reduction = 103.6013  correctly classified = 82.8000%\n",
      "alpha =  0.7026315789473684 b =  -6192.182012394316 epoch =  32  loss = 4320.724  loss reduction = 435.1256  correctly classified = 84.3750%\n",
      "alpha =  0.7026315789473684 b =  -5900.938412394316 epoch =  33  loss = 4417.418  loss reduction = -96.69457  correctly classified = 84.0250%\n",
      "alpha =  0.7026315789473684 b =  -5991.86315449958 epoch =  34  loss = 3982.293  loss reduction = 435.1256  correctly classified = 85.6000%\n",
      "alpha =  0.7026315789473684 b =  -5758.1201123943165 epoch =  35  loss = 4224.029  loss reduction = -241.7364  correctly classified = 84.7250%\n",
      "alpha =  0.7026315789473684 b =  -5772.611186078527 epoch =  36  loss = 3878.691  loss reduction = 345.3377  correctly classified = 85.9750%\n",
      "alpha =  0.7026315789473684 b =  -5573.228233446947 epoch =  37  loss = 3968.479  loss reduction = -89.78781  correctly classified = 85.6500%\n",
      "alpha =  0.7026315789473684 b =  -5557.56657555221 epoch =  38  loss = 3802.717  loss reduction = 165.7621  correctly classified = 86.2500%\n",
      "alpha =  0.7026315789473684 b =  -5362.3909808153685 epoch =  39  loss = 3982.293  loss reduction = -179.5756  correctly classified = 85.6000%\n",
      "alpha =  0.7026315789473684 b =  -5343.2231913416845 epoch =  40  loss = 3795.81  loss reduction = 186.4824  correctly classified = 86.2750%\n",
      "alpha =  0.7026315789473684 b =  -5151.55372818379 epoch =  41  loss = 3975.386  loss reduction = -179.5756  correctly classified = 85.6250%\n",
      "alpha =  0.7026315789473684 b =  -5121.867543973263 epoch =  42  loss = 3802.717  loss reduction = 172.6689  correctly classified = 86.2500%\n",
      "alpha =  0.7026315789473684 b =  -4925.990722920632 epoch =  43  loss = 3947.759  loss reduction = -145.0419  correctly classified = 85.7250%\n",
      "alpha =  0.7026315789473684 b =  -4913.835196604842 epoch =  44  loss = 3781.997  loss reduction = 165.7621  correctly classified = 86.3250%\n",
      "alpha =  0.7026315789473684 b =  -4716.555922920632 epoch =  45  loss = 3947.759  loss reduction = -165.7621  correctly classified = 85.7250%\n",
      "alpha =  0.7026315789473684 b =  -4706.50407555221 epoch =  46  loss = 3775.09  loss reduction = 172.6689  correctly classified = 86.3500%\n",
      "alpha =  0.7026315789473684 b =  -4509.224801868 epoch =  47  loss = 3947.759  loss reduction = -172.6689  correctly classified = 85.7250%\n",
      "alpha =  0.7026315789473684 b =  -4499.874180815368 epoch =  48  loss = 3781.997  loss reduction = 165.7621  correctly classified = 86.3250%\n",
      "alpha =  0.7026315789473684 b =  -4300.491228183789 epoch =  49  loss = 3954.666  loss reduction = -172.6689  correctly classified = 85.7000%\n",
      "alpha =  0.7026315789473684 b =  -4298.854096604841 epoch =  50  loss = 3775.09  loss reduction = 179.5756  correctly classified = 86.3500%\n",
      "alpha =  0.7026315789473684 b =  -4106.483407131157 epoch =  51  loss = 3927.039  loss reduction = -151.9486  correctly classified = 85.8000%\n",
      "alpha =  0.7026315789473684 b =  -4103.443822920631 epoch =  52  loss = 3761.277  loss reduction = 165.7621  correctly classified = 86.4000%\n",
      "alpha =  0.7026315789473684 b =  -3910.371907131157 epoch =  53  loss = 3920.132  loss reduction = -158.8554  correctly classified = 85.8250%\n",
      "alpha =  0.7026315789473684 b =  -3908.03354923642 epoch =  54  loss = 3754.37  loss reduction = 165.7621  correctly classified = 86.4250%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.7026315789473684 b =  -3714.260407131157 epoch =  55  loss = 3913.225  loss reduction = -158.8554  correctly classified = 85.8500%\n",
      "alpha =  0.7026315789473684 b =  -3712.6232755522096 epoch =  56  loss = 3733.65  loss reduction = 179.5756  correctly classified = 86.5000%\n",
      "alpha =  0.7026315789473684 b =  -3518.8501334469465 epoch =  57  loss = 3871.785  loss reduction = -138.1351  correctly classified = 86.0000%\n",
      "alpha =  0.7026315789473684 b =  -3516.5117755522097 epoch =  58  loss = 3726.743  loss reduction = 145.0419  correctly classified = 86.5250%\n",
      "alpha =  0.7026315789473684 b =  -3322.7386334469466 epoch =  59  loss = 3871.785  loss reduction = -145.0419  correctly classified = 86.0000%\n",
      "alpha =  0.7026315789473684 b =  -3321.101501867999 epoch =  60  loss = 3719.836  loss reduction = 151.9486  correctly classified = 86.5500%\n",
      "alpha =  0.7026315789473684 b =  -3127.328359762736 epoch =  61  loss = 3857.971  loss reduction = -138.1351  correctly classified = 86.0500%\n",
      "alpha =  0.7026315789473684 b =  -3125.6912281837886 epoch =  62  loss = 3719.836  loss reduction = 138.1351  correctly classified = 86.5500%\n",
      "alpha =  0.7026315789473684 b =  -2933.3205387101043 epoch =  63  loss = 3844.158  loss reduction = -124.3216  correctly classified = 86.1000%\n",
      "alpha =  0.7026315789473684 b =  -2932.3846334469463 epoch =  64  loss = 3699.116  loss reduction = 145.0419  correctly classified = 86.6250%\n",
      "alpha =  0.7026315789473684 b =  -2740.013943973262 epoch =  65  loss = 3830.344  loss reduction = -131.2283  correctly classified = 86.1500%\n",
      "alpha =  0.7026315789473684 b =  -2740.480491341683 epoch =  66  loss = 3671.489  loss reduction = 158.8554  correctly classified = 86.7250%\n",
      "alpha =  0.7026315789473684 b =  -2548.811028183788 epoch =  67  loss = 3823.437  loss reduction = -151.9486  correctly classified = 86.1750%\n",
      "alpha =  0.7026315789473684 b =  -2553.484933446946 epoch =  68  loss = 3671.489  loss reduction = 151.9486  correctly classified = 86.7250%\n",
      "alpha =  0.7026315789473684 b =  -2359.0105650258934 epoch =  69  loss = 3809.624  loss reduction = -138.1351  correctly classified = 86.2250%\n",
      "alpha =  0.7026315789473684 b =  -2381.2151281837882 epoch =  70  loss = 3678.396  loss reduction = 131.2283  correctly classified = 86.7000%\n",
      "alpha =  0.7026315789473684 b =  -2174.8199123943145 epoch =  71  loss = 3830.344  loss reduction = -151.9486  correctly classified = 86.1500%\n",
      "alpha =  0.7026315789473684 b =  -2211.7502281837883 epoch =  72  loss = 3699.116  loss reduction = 131.2283  correctly classified = 86.6250%\n",
      "alpha =  0.7026315789473684 b =  -1992.732938710104 epoch =  73  loss = 3885.598  loss reduction = -186.4824  correctly classified = 85.9500%\n",
      "alpha =  0.7026315789473684 b =  -2080.1515492364197 epoch =  74  loss = 3754.37  loss reduction = 131.2283  correctly classified = 86.4250%\n",
      "alpha =  0.7026315789473684 b =  -1821.8655860785248 epoch =  75  loss = 4120.428  loss reduction = -366.058  correctly classified = 85.1000%\n",
      "alpha =  0.7026315789473684 b =  -1968.1872071311564 epoch =  76  loss = 3837.251  loss reduction = 283.1769  correctly classified = 86.1250%\n",
      "alpha =  0.7026315789473684 b =  -1671.3337966048405 epoch =  77  loss = 4237.843  loss reduction = -400.5918  correctly classified = 84.6750%\n",
      "alpha =  0.7026315789473684 b =  -1870.2473913416825 epoch =  78  loss = 4078.987  loss reduction = 158.8554  correctly classified = 85.2500%\n",
      "alpha =  0.7026315789473684 b =  -1520.1007808153668 epoch =  79  loss = 4583.18  loss reduction = -504.1931  correctly classified = 83.4250%\n",
      "alpha =  0.7026315789473684 b =  -1838.2228492364193 epoch =  80  loss = 4838.73  loss reduction = -255.5499  correctly classified = 82.5000%\n",
      "alpha =  0.7026315789473684 b =  -1368.8677650258928 epoch =  81  loss = 5329.11  loss reduction = -490.3796  correctly classified = 80.7250%\n",
      "alpha =  0.7026315789473684 b =  -1980.803659762735 epoch =  82  loss = 7041.985  loss reduction = -1712.875  correctly classified = 74.5250%\n",
      "alpha =  0.7026315789473684 b =  -1391.5388755522085 epoch =  83  loss = 6137.2  loss reduction = 904.7849  correctly classified = 77.8000%\n",
      "alpha =  0.7026315789473684 b =  -2279.757938710103 epoch =  84  loss = 9569.857  loss reduction = -3432.657  correctly classified = 65.3750%\n",
      "alpha =  0.7026315789473684 b =  -1586.0104334469452 epoch =  85  loss = 6972.918  loss reduction = 2596.94  correctly classified = 74.7750%\n",
      "alpha =  0.7026315789473684 b =  -2439.168180815366 epoch =  86  loss = 9238.333  loss reduction = -2265.416  correctly classified = 66.5750%\n",
      "alpha =  0.7026315789473684 b =  -1765.756238710103 epoch =  87  loss = 6786.435  loss reduction = 2451.898  correctly classified = 75.4500%\n",
      "alpha =  0.7026315789473684 b =  -2614.0054018679975 epoch =  88  loss = 9203.799  loss reduction = -2417.364  correctly classified = 66.7000%\n",
      "alpha =  0.7026315789473684 b =  -1946.2032702890501 epoch =  89  loss = 6744.995  loss reduction = 2458.805  correctly classified = 75.6000%\n",
      "alpha =  0.7026315789473684 b =  -2789.5438492364183 epoch =  90  loss = 9155.452  loss reduction = -2410.457  correctly classified = 66.8750%\n",
      "alpha =  0.7026315789473684 b =  -2132.260112394313 epoch =  91  loss = 6655.207  loss reduction = 2500.245  correctly classified = 75.9250%\n",
      "alpha =  0.7026315789473684 b =  -2958.771259762734 epoch =  92  loss = 9003.503  loss reduction = -2348.297  correctly classified = 67.4250%\n",
      "alpha =  0.7026315789473684 b =  -2316.9145018679974 epoch =  93  loss = 6503.258  loss reduction = 2500.245  correctly classified = 76.4750%\n",
      "alpha =  0.7026315789473684 b =  -3111.1692387101025 epoch =  94  loss = 8699.606  loss reduction = -2196.348  correctly classified = 68.5250%\n",
      "alpha =  0.7026315789473684 b =  -2484.0382334469446 epoch =  95  loss = 6385.843  loss reduction = 2313.763  correctly classified = 76.9000%\n",
      "alpha =  0.7026315789473684 b =  -3257.2561808153655 epoch =  96  loss = 8561.471  loss reduction = -2175.628  correctly classified = 69.0250%\n",
      "alpha =  0.7026315789473684 b =  -2646.954607131155 epoch =  97  loss = 6261.522  loss reduction = 2299.949  correctly classified = 77.3500%\n",
      "alpha =  0.7026315789473684 b =  -3413.861517657471 epoch =  98  loss = 8499.31  loss reduction = -2237.789  correctly classified = 69.2500%\n",
      "alpha =  0.7026315789473684 b =  -2815.480791341681 epoch =  99  loss = 6185.548  loss reduction = 2313.763  correctly classified = 77.6250%\n",
      "alpha =  0.7026315789473684 b =  -3549.430065025892 epoch =  100  loss = 8174.693  loss reduction = -1989.145  correctly classified = 70.4250%\n",
      "alpha =  0.7026315789473684 b =  -2972.7873544995764 epoch =  101  loss = 6012.879  loss reduction = 2161.814  correctly classified = 78.2500%\n",
      "alpha =  0.7026315789473684 b =  -3638.0164492364183 epoch =  102  loss = 7539.271  loss reduction = -1526.393  correctly classified = 72.7250%\n",
      "alpha =  0.7026315789473684 b =  -3098.5387334469447 epoch =  103  loss = 5784.956  loss reduction = 1754.316  correctly classified = 79.0750%\n",
      "alpha =  0.7026315789473684 b =  -3700.657459762734 epoch =  104  loss = 6959.104  loss reduction = -1174.148  correctly classified = 74.8250%\n",
      "alpha =  0.7026315789473684 b =  -3184.320212394313 epoch =  105  loss = 5667.541  loss reduction = 1291.563  correctly classified = 79.5000%\n",
      "alpha =  0.7026315789473684 b =  -3742.2616808153653 epoch =  106  loss = 6634.487  loss reduction = -966.9457  correctly classified = 76.0000%\n",
      "alpha =  0.7026315789473684 b =  -3253.9734860785234 epoch =  107  loss = 5446.525  loss reduction = 1187.962  correctly classified = 80.3000%\n",
      "alpha =  0.7026315789473684 b =  -3749.5058123943127 epoch =  108  loss = 6130.293  loss reduction = -683.7687  correctly classified = 77.8250%\n",
      "alpha =  0.7026315789473684 b =  -3297.6813860785232 epoch =  109  loss = 5239.322  loss reduction = 890.9714  correctly classified = 81.0500%\n",
      "alpha =  0.7026315789473684 b =  -3719.5849492364177 epoch =  110  loss = 5612.287  loss reduction = -372.9648  correctly classified = 79.7000%\n",
      "alpha =  0.7026315789473684 b =  -3303.5230650258914 epoch =  111  loss = 5011.399  loss reduction = 600.8877  correctly classified = 81.8750%\n",
      "alpha =  0.7026315789473684 b =  -3657.407675552207 epoch =  112  loss = 5094.28  loss reduction = -82.88106  correctly classified = 81.5750%\n",
      "alpha =  0.7026315789473684 b =  -3266.5899387101017 epoch =  113  loss = 4818.01  loss reduction = 276.2702  correctly classified = 82.5750%\n",
      "alpha =  0.7026315789473684 b =  -3539.8335229206277 epoch =  114  loss = 4603.901  loss reduction = 214.1094  correctly classified = 83.3500%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.7026315789473684 b =  -3177.766065025891 epoch =  115  loss = 4631.528  loss reduction = -27.62702  correctly classified = 83.2500%\n",
      "alpha =  0.7026315789473684 b =  -3396.313996604838 epoch =  116  loss = 4217.122  loss reduction = 414.4053  correctly classified = 84.7500%\n",
      "alpha =  0.7026315789473684 b =  -3095.9544544995747 epoch =  117  loss = 4369.071  loss reduction = -151.9486  correctly classified = 84.2000%\n",
      "alpha =  0.7026315789473684 b =  -3243.678528183785 epoch =  118  loss = 3933.945  loss reduction = 435.1256  correctly classified = 85.7750%\n",
      "alpha =  0.7026315789473684 b =  -2986.7950176574695 epoch =  119  loss = 4092.801  loss reduction = -158.8554  correctly classified = 85.2000%\n",
      "alpha =  0.7026315789473684 b =  -3079.1222123943116 epoch =  120  loss = 3775.09  loss reduction = 317.7107  correctly classified = 86.3500%\n",
      "alpha =  0.7026315789473684 b =  -2853.0926597627326 epoch =  121  loss = 3968.479  loss reduction = -193.3891  correctly classified = 85.6500%\n",
      "alpha =  0.7026315789473684 b =  -2892.827880815364 epoch =  122  loss = 3726.743  loss reduction = 241.7364  correctly classified = 86.5250%\n",
      "alpha =  0.7026315789473684 b =  -2694.847380815364 epoch =  123  loss = 3816.531  loss reduction = -89.78781  correctly classified = 86.2000%\n",
      "alpha =  0.7026315789473684 b =  -2678.4844966048377 epoch =  124  loss = 3533.354  loss reduction = 283.1769  correctly classified = 87.2250%\n",
      "alpha =  0.7026315789473684 b =  -2509.254275552206 epoch =  125  loss = 3712.929  loss reduction = -179.5756  correctly classified = 86.5750%\n",
      "alpha =  0.7026315789473684 b =  -2471.8546018679954 epoch =  126  loss = 3505.727  loss reduction = 207.2026  correctly classified = 87.3250%\n",
      "alpha =  0.7026315789473684 b =  -2314.5452281837847 epoch =  127  loss = 3650.769  loss reduction = -145.0419  correctly classified = 86.8000%\n",
      "alpha =  0.7026315789473684 b =  -2240.6817860785213 epoch =  128  loss = 3436.659  loss reduction = 214.1094  correctly classified = 87.5750%\n",
      "alpha =  0.7026315789473684 b =  -2091.085901867995 epoch =  129  loss = 3588.608  loss reduction = -151.9486  correctly classified = 87.0250%\n",
      "alpha =  0.7026315789473684 b =  -2009.5089702890475 epoch =  130  loss = 3443.566  loss reduction = 145.0419  correctly classified = 87.5500%\n",
      "alpha =  0.7026315789473684 b =  -1862.717991341679 epoch =  131  loss = 3560.981  loss reduction = -117.4148  correctly classified = 87.1250%\n",
      "alpha =  0.7026315789473684 b =  -1782.5435123943105 epoch =  132  loss = 3443.566  loss reduction = 117.4148  correctly classified = 87.5500%\n",
      "alpha =  0.7026315789473684 b =  -1637.154986078521 epoch =  133  loss = 3547.167  loss reduction = -103.6013  correctly classified = 87.1750%\n",
      "alpha =  0.7026315789473684 b =  -1555.5780544995737 epoch =  134  loss = 3429.752  loss reduction = 117.4148  correctly classified = 87.6000%\n",
      "alpha =  0.7026315789473684 b =  -1410.1895281837842 epoch =  135  loss = 3533.354  loss reduction = -103.6013  correctly classified = 87.2250%\n",
      "alpha =  0.7026315789473684 b =  -1331.4175018679948 epoch =  136  loss = 3388.312  loss reduction = 145.0419  correctly classified = 87.7500%\n",
      "alpha =  0.7026315789473684 b =  -1185.327749236416 epoch =  137  loss = 3526.447  loss reduction = -138.1351  correctly classified = 87.2500%\n",
      "alpha =  0.7026315789473684 b =  -1107.256949236416 epoch =  138  loss = 3367.592  loss reduction = 158.8554  correctly classified = 87.8250%\n",
      "alpha =  0.7026315789473684 b =  -962.5696492364159 epoch =  139  loss = 3512.633  loss reduction = -145.0419  correctly classified = 87.3000%\n",
      "alpha =  0.7026315789473684 b =  -885.2000755522054 epoch =  140  loss = 3374.498  loss reduction = 138.1351  correctly classified = 87.8000%\n",
      "alpha =  0.7026315789473684 b =  -741.9152281837843 epoch =  141  loss = 3485.006  loss reduction = -110.5081  correctly classified = 87.4000%\n",
      "alpha =  0.7026315789473684 b =  -664.5456544995737 epoch =  142  loss = 3360.685  loss reduction = 124.3216  correctly classified = 87.8500%\n",
      "alpha =  0.7026315789473684 b =  -521.9620334469421 epoch =  143  loss = 3478.1  loss reduction = -117.4148  correctly classified = 87.4250%\n",
      "alpha =  0.7026315789473684 b =  -445.293686078521 epoch =  144  loss = 3353.778  loss reduction = 124.3216  correctly classified = 87.8750%\n",
      "alpha =  0.7026315789473684 b =  -304.8137439732578 epoch =  145  loss = 3457.379  loss reduction = -103.6013  correctly classified = 87.5000%\n",
      "alpha =  0.7026315789473684 b =  -227.4441702890472 epoch =  146  loss = 3346.871  loss reduction = 110.5081  correctly classified = 87.9000%\n",
      "alpha =  0.7026315789473684 b =  -85.56177555220506 epoch =  147  loss = 3457.379  loss reduction = -110.5081  correctly classified = 87.5000%\n",
      "alpha =  0.7026315789473684 b =  -20.814275552205018 epoch =  148  loss = 3346.871  loss reduction = 110.5081  correctly classified = 87.9000%\n",
      "alpha =  0.7026315789473684 b =  121.76934550042658 epoch =  149  loss = 3450.473  loss reduction = -103.6013  correctly classified = 87.5250%\n",
      "alpha =  0.7026315789473684 b =  184.4131665530582 epoch =  150  loss = 3353.778  loss reduction = 96.69457  correctly classified = 87.8750%\n",
      "alpha =  0.7026315789473684 b =  325.5943349741109 epoch =  151  loss = 3436.659  loss reduction = -82.88106  correctly classified = 87.5750%\n",
      "alpha =  0.7026315789473684 b =  389.64060865832147 epoch =  152  loss = 3339.965  loss reduction = 96.69457  correctly classified = 87.9250%\n",
      "alpha =  0.7026315789473684 b =  531.5230033951636 epoch =  153  loss = 3429.752  loss reduction = -89.78781  correctly classified = 87.6000%\n",
      "alpha =  0.7026315789473684 b =  589.258240237269 epoch =  154  loss = 3346.871  loss reduction = 82.88106  correctly classified = 87.9000%\n",
      "alpha =  0.7026315789473684 b =  733.2443139214795 epoch =  155  loss = 3436.659  loss reduction = -89.78781  correctly classified = 87.5750%\n",
      "alpha =  0.7026315789473684 b =  788.1746455004269 epoch =  156  loss = 3346.871  loss reduction = 89.78781  correctly classified = 87.9000%\n",
      "alpha =  0.7026315789473684 b =  934.9656244477953 epoch =  157  loss = 3422.846  loss reduction = -75.9743  correctly classified = 87.6250%\n",
      "alpha =  0.7026315789473684 b =  983.5849191846374 epoch =  158  loss = 3339.965  loss reduction = 82.88106  correctly classified = 87.9250%\n",
      "alpha =  0.7026315789473684 b =  1133.8820297109532 epoch =  159  loss = 3402.125  loss reduction = -62.16079  correctly classified = 87.7000%\n",
      "alpha =  0.7026315789473684 b =  1162.1657612899007 epoch =  160  loss = 3333.058  loss reduction = 69.06755  correctly classified = 87.9500%\n",
      "alpha =  0.7026315789473684 b =  1319.4751349741114 epoch =  161  loss = 3429.752  loss reduction = -96.69457  correctly classified = 87.6000%\n",
      "alpha =  0.7026315789473684 b =  1309.1914191846377 epoch =  162  loss = 3381.405  loss reduction = 48.34728  correctly classified = 87.7750%\n",
      "alpha =  0.7026315789473684 b =  1496.6535244477955 epoch =  163  loss = 3574.794  loss reduction = -193.3891  correctly classified = 87.0750%\n",
      "alpha =  0.7026315789473684 b =  1428.1680244477955 epoch =  164  loss = 3415.939  loss reduction = 158.8554  correctly classified = 87.6500%\n",
      "alpha =  0.7026315789473684 b =  1682.9478560267428 epoch =  165  loss = 3906.318  loss reduction = -490.3796  correctly classified = 85.8750%\n",
      "alpha =  0.7026315789473684 b =  1518.394350763585 epoch =  166  loss = 3685.302  loss reduction = 221.0162  correctly classified = 86.6750%\n",
      "alpha =  0.7026315789473684 b =  1825.766156026743 epoch =  167  loss = 4230.936  loss reduction = -545.6336  correctly classified = 84.7000%\n",
      "alpha =  0.7026315789473684 b =  1580.5716244477956 epoch =  168  loss = 4120.428  loss reduction = 110.5081  correctly classified = 85.1000%\n",
      "alpha =  0.7026315789473684 b =  1960.8709665530587 epoch =  169  loss = 4686.782  loss reduction = -566.3539  correctly classified = 83.0500%\n",
      "alpha =  0.7026315789473684 b =  1521.4367455004272 epoch =  170  loss = 5536.313  loss reduction = -849.5308  correctly classified = 79.9750%\n",
      "alpha =  0.7026315789473684 b =  2020.2433349741113 epoch =  171  loss = 5453.432  loss reduction = 82.88106  correctly classified = 80.2750%\n",
      "alpha =  0.7026315789473684 b =  1277.879345500427 epoch =  172  loss = 8077.998  loss reduction = -2624.567  correctly classified = 70.7750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.7026315789473684 b =  1912.723840237269 epoch =  173  loss = 6420.377  loss reduction = 1657.621  correctly classified = 76.7750%\n",
      "alpha =  0.7026315789473684 b =  1000.6630823425324 epoch =  174  loss = 9680.365  loss reduction = -3259.988  correctly classified = 64.9750%\n",
      "alpha =  0.7026315789473684 b =  1699.3191718162166 epoch =  175  loss = 6993.638  loss reduction = 2686.728  correctly classified = 74.7000%\n",
      "alpha =  0.7026315789473684 b =  888.9362297109536 epoch =  176  loss = 8720.327  loss reduction = -1726.689  correctly classified = 68.4500%\n",
      "alpha =  0.7026315789473684 b =  1533.5978928688482 epoch =  177  loss = 6517.072  loss reduction = 2203.255  correctly classified = 76.4250%\n",
      "alpha =  0.7026315789473684 b =  652.3910928688483 epoch =  178  loss = 9390.282  loss reduction = -2873.21  correctly classified = 66.0250%\n",
      "alpha =  0.7026315789473684 b =  1329.3091665530587 epoch =  179  loss = 6807.155  loss reduction = 2583.126  correctly classified = 75.3750%\n",
      "alpha =  0.7026315789473684 b =  495.785756026743 epoch =  180  loss = 8934.436  loss reduction = -2127.28  correctly classified = 67.6750%\n",
      "alpha =  0.7026315789473684 b =  1135.5388349741115 epoch =  181  loss = 6468.724  loss reduction = 2465.711  correctly classified = 76.6000%\n",
      "alpha =  0.7026315789473684 b =  317.4424033951643 epoch =  182  loss = 8796.301  loss reduction = -2327.576  correctly classified = 68.1750%\n",
      "alpha =  0.7026315789473684 b =  948.7807665530592 epoch =  183  loss = 6385.843  loss reduction = 2410.457  correctly classified = 76.9000%\n",
      "alpha =  0.7026315789473684 b =  158.0321612899014 epoch =  184  loss = 8582.191  loss reduction = -2196.348  correctly classified = 68.9500%\n",
      "alpha =  0.7026315789473684 b =  772.5410928688488 epoch =  185  loss = 6261.522  loss reduction = 2320.67  correctly classified = 77.3500%\n",
      "alpha =  0.7026315789473684 b =  13.347671816217257 epoch =  186  loss = 8326.642  loss reduction = -2065.12  correctly classified = 69.8750%\n",
      "alpha =  0.7026315789473684 b =  604.0149086583226 epoch =  187  loss = 6109.573  loss reduction = 2217.068  correctly classified = 77.9000%\n",
      "alpha =  0.7026315789473684 b =  -134.14172292062472 epoch =  188  loss = 8160.879  loss reduction = -2051.306  correctly classified = 70.4750%\n",
      "alpha =  0.7026315789473684 b =  449.5132507635858 epoch =  189  loss = 6040.506  loss reduction = 2120.374  correctly classified = 78.1500%\n",
      "alpha =  0.7026315789473684 b =  -254.28329134167734 epoch =  190  loss = 7836.262  loss reduction = -1795.756  correctly classified = 71.6500%\n",
      "alpha =  0.7026315789473684 b =  298.51772444779635 epoch =  191  loss = 5819.49  loss reduction = 2016.772  correctly classified = 78.9500%\n",
      "alpha =  0.7026315789473684 b =  -358.296654499572 epoch =  192  loss = 7387.323  loss reduction = -1567.833  correctly classified = 73.2750%\n",
      "alpha =  0.7026315789473684 b =  179.7786086583228 epoch =  193  loss = 5729.702  loss reduction = 1657.621  correctly classified = 79.2750%\n",
      "alpha =  0.7026315789473684 b =  -430.0536071311508 epoch =  194  loss = 6979.824  loss reduction = -1250.123  correctly classified = 74.7500%\n",
      "alpha =  0.7026315789473684 b =  85.5824139214809 epoch =  195  loss = 5563.94  loss reduction = 1415.885  correctly classified = 79.8750%\n",
      "alpha =  0.7026315789473684 b =  -500.4081071311506 epoch =  196  loss = 6744.995  loss reduction = -1181.055  correctly classified = 75.6000%\n",
      "alpha =  0.7026315789473684 b =  2.605840237270513 epoch =  197  loss = 5522.499  loss reduction = 1222.496  correctly classified = 80.0250%\n",
      "alpha =  0.7026315789473684 b =  -558.14053344694 epoch =  198  loss = 6551.606  loss reduction = -1029.106  correctly classified = 76.3000%\n",
      "alpha =  0.7026315789473684 b =  -73.35847028904533 epoch =  199  loss = 5384.364  loss reduction = 1167.242  correctly classified = 80.5250%\n",
      "alpha =  0.7026315789473684 b =  -568.8907966048348 epoch =  200  loss = 6061.226  loss reduction = -676.862  correctly classified = 78.0750%\n",
      "alpha =  0.7026315789473684 b =  -111.45655976272951 epoch =  201  loss = 5197.882  loss reduction = 863.3443  correctly classified = 81.2000%\n",
      "alpha =  0.7026315789473684 b =  -570.5251176574664 epoch =  202  loss = 5771.142  loss reduction = -573.2606  correctly classified = 79.1250%\n",
      "alpha =  0.7026315789473684 b =  -148.15219660483473 epoch =  203  loss = 4949.238  loss reduction = 821.9038  correctly classified = 82.1000%\n",
      "alpha =  0.7026315789473684 b =  -546.2140650258873 epoch =  204  loss = 5266.949  loss reduction = -317.7107  correctly classified = 80.9500%\n",
      "alpha =  0.7026315789473684 b =  -161.0061387100978 epoch =  205  loss = 4693.688  loss reduction = 573.2606  correctly classified = 83.0250%\n",
      "alpha =  0.7026315789473684 b =  -467.9085860785188 epoch =  206  loss = 4659.155  loss reduction = 34.53377  correctly classified = 83.1500%\n",
      "alpha =  0.7026315789473684 b =  -105.8411281837819 epoch =  207  loss = 4576.274  loss reduction = 82.88106  correctly classified = 83.4500%\n",
      "alpha =  0.7026315789473684 b =  -348.9319808153608 epoch =  208  loss = 4196.402  loss reduction = 379.8715  correctly classified = 84.8250%\n",
      "alpha =  0.7026315789473684 b =  -30.340554499571283 epoch =  209  loss = 4300.003  loss reduction = -103.6013  correctly classified = 84.4500%\n",
      "alpha =  0.7026315789473684 b =  -210.32103871009755 epoch =  210  loss = 3878.691  loss reduction = 421.312  correctly classified = 85.9750%\n",
      "alpha =  0.7026315789473684 b =  54.97718760569197 epoch =  211  loss = 4051.36  loss reduction = -172.6689  correctly classified = 85.3500%\n",
      "alpha =  0.7026315789473684 b =  -62.59415449957113 epoch =  212  loss = 3623.142  loss reduction = 428.2188  correctly classified = 86.9000%\n",
      "alpha =  0.7026315789473684 b =  171.1488876056921 epoch =  213  loss = 3947.759  loss reduction = -324.6175  correctly classified = 85.7250%\n",
      "alpha =  0.7026315789473684 b =  92.84621918463951 epoch =  214  loss = 3485.006  loss reduction = 462.7526  correctly classified = 87.4000%\n",
      "alpha =  0.7026315789473684 b =  313.9671876056922 epoch =  215  loss = 3837.251  loss reduction = -352.2445  correctly classified = 86.1250%\n",
      "alpha =  0.7026315789473684 b =  242.6767823425343 epoch =  216  loss = 3443.566  loss reduction = 393.685  correctly classified = 87.5500%\n",
      "alpha =  0.7026315789473684 b =  460.29161918463956 epoch =  217  loss = 3802.717  loss reduction = -359.1512  correctly classified = 86.2500%\n",
      "alpha =  0.7026315789473684 b =  389.70244023727116 epoch =  218  loss = 3436.659  loss reduction = 366.058  correctly classified = 87.5750%\n",
      "alpha =  0.7026315789473684 b =  601.0062402372712 epoch =  219  loss = 3740.556  loss reduction = -303.8972  correctly classified = 86.4750%\n",
      "alpha =  0.7026315789473684 b =  538.8317770793765 epoch =  220  loss = 3409.032  loss reduction = 331.5242  correctly classified = 87.6750%\n",
      "alpha =  0.7026315789473684 b =  752.9404823425344 epoch =  221  loss = 3754.37  loss reduction = -345.3377  correctly classified = 86.4250%\n",
      "alpha =  0.7026315789473684 b =  678.1439455004293 epoch =  222  loss = 3422.846  loss reduction = 331.5242  correctly classified = 87.6250%\n",
      "alpha =  0.7026315789473684 b =  896.4600086583241 epoch =  223  loss = 3781.997  loss reduction = -359.1512  correctly classified = 86.3250%\n",
      "alpha =  0.7026315789473684 b =  812.5475297109557 epoch =  224  loss = 3443.566  loss reduction = 338.431  correctly classified = 87.5500%\n",
      "alpha =  0.7026315789473684 b =  1049.7967033951663 epoch =  225  loss = 3871.785  loss reduction = -428.2188  correctly classified = 86.0000%\n",
      "alpha =  0.7026315789473684 b =  942.7437560267454 epoch =  226  loss = 3464.286  loss reduction = 407.4985  correctly classified = 87.4750%\n",
      "alpha =  0.7026315789473684 b =  1178.590477079377 epoch =  227  loss = 3844.158  loss reduction = -379.8715  correctly classified = 86.1000%\n",
      "alpha =  0.7026315789473684 b =  1066.6289455004296 epoch =  228  loss = 3471.193  loss reduction = 372.9648  correctly classified = 87.4500%\n",
      "alpha =  0.7026315789473684 b =  1310.8903823425348 epoch =  229  loss = 3871.785  loss reduction = -400.5918  correctly classified = 86.0000%\n",
      "alpha =  0.7026315789473684 b =  1187.0080033951665 epoch =  230  loss = 3491.913  loss reduction = 379.8715  correctly classified = 87.3750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.7026315789473684 b =  1431.2694402372717 epoch =  231  loss = 3871.785  loss reduction = -379.8715  correctly classified = 86.0000%\n",
      "alpha =  0.7026315789473684 b =  1304.5821560267455 epoch =  232  loss = 3491.913  loss reduction = 379.8715  correctly classified = 87.3750%\n",
      "alpha =  0.7026315789473684 b =  1550.9472718162192 epoch =  233  loss = 3892.505  loss reduction = -400.5918  correctly classified = 85.9250%\n",
      "alpha =  0.7026315789473684 b =  1422.857534974114 epoch =  234  loss = 3491.913  loss reduction = 400.5918  correctly classified = 87.3750%\n",
      "alpha =  0.7026315789473684 b =  1670.6251033951667 epoch =  235  loss = 3892.505  loss reduction = -400.5918  correctly classified = 85.9250%\n",
      "alpha =  0.7026315789473684 b =  1541.1329139214824 epoch =  236  loss = 3491.913  loss reduction = 400.5918  correctly classified = 87.3750%\n",
      "alpha =  0.7026315789473684 b =  1803.6262349741141 epoch =  237  loss = 3940.852  loss reduction = -448.9391  correctly classified = 85.7500%\n",
      "alpha =  0.7026315789473684 b =  1667.1217823425352 epoch =  238  loss = 3491.913  loss reduction = 448.9391  correctly classified = 87.3750%\n",
      "alpha =  0.7026315789473684 b =  1924.005292868851 epoch =  239  loss = 3899.412  loss reduction = -407.4985  correctly classified = 85.9000%\n",
      "alpha =  0.7026315789473684 b =  1788.2020665530615 epoch =  240  loss = 3485.006  loss reduction = 414.4053  correctly classified = 87.4000%\n",
      "alpha =  0.7026315789473684 b =  2046.4880297109562 epoch =  241  loss = 3899.412  loss reduction = -414.4053  correctly classified = 85.9000%\n",
      "alpha =  0.7026315789473684 b =  1907.879898132009 epoch =  242  loss = 3485.006  loss reduction = 414.4053  correctly classified = 87.4000%\n",
      "alpha =  0.7026315789473684 b =  2168.9707665530614 epoch =  243  loss = 3927.039  loss reduction = -442.0323  correctly classified = 85.8000%\n",
      "alpha =  0.7026315789473684 b =  2030.3626349741141 epoch =  244  loss = 3485.006  loss reduction = 442.0323  correctly classified = 87.4000%\n",
      "alpha =  0.7026315789473684 b =  2290.7522770793776 epoch =  245  loss = 3920.132  loss reduction = -435.1256  correctly classified = 85.8250%\n",
      "alpha =  0.7026315789473684 b =  2152.8453718162195 epoch =  246  loss = 3478.1  loss reduction = 442.0323  correctly classified = 87.4250%\n",
      "alpha =  0.7026315789473684 b =  2411.1313349741145 epoch =  247  loss = 3899.412  loss reduction = -421.312  correctly classified = 85.9000%\n",
      "alpha =  0.7026315789473684 b =  2273.2244297109564 epoch =  248  loss = 3478.1  loss reduction = 421.312  correctly classified = 87.4250%\n",
      "alpha =  0.7026315789473684 b =  2532.2116191846408 epoch =  249  loss = 3906.318  loss reduction = -428.2188  correctly classified = 85.8750%\n",
      "alpha =  0.7026315789473684 b =  2385.1887718162197 epoch =  250  loss = 3540.26  loss reduction = 366.058  correctly classified = 87.2000%\n",
      "alpha =  0.7026315789473684 b =  2648.3833191846406 epoch =  251  loss = 3906.318  loss reduction = -366.058  correctly classified = 85.8750%\n",
      "alpha =  0.7026315789473684 b =  2488.738398132009 epoch =  252  loss = 3554.074  loss reduction = 352.2445  correctly classified = 87.1500%\n",
      "alpha =  0.7026315789473684 b =  2759.6464349741145 epoch =  253  loss = 3940.852  loss reduction = -386.7783  correctly classified = 85.7500%\n",
      "alpha =  0.7026315789473684 b =  2592.989250763588 epoch =  254  loss = 3554.074  loss reduction = 386.7783  correctly classified = 87.1500%\n",
      "alpha =  0.7026315789473684 b =  2875.116908658325 epoch =  255  loss = 4009.92  loss reduction = -455.8458  correctly classified = 85.5000%\n",
      "alpha =  0.7026315789473684 b =  2705.654819184641 epoch =  256  loss = 3554.074  loss reduction = 455.8458  correctly classified = 87.1500%\n",
      "alpha =  0.7026315789473684 b =  2990.587382342536 epoch =  257  loss = 4023.733  loss reduction = -469.6593  correctly classified = 85.4500%\n",
      "alpha =  0.7026315789473684 b =  2822.5277455004307 epoch =  258  loss = 3526.447  loss reduction = 497.2863  correctly classified = 87.2500%\n",
      "alpha =  0.7026315789473684 b =  3099.746819184641 epoch =  259  loss = 3975.386  loss reduction = -448.9391  correctly classified = 85.6250%\n",
      "alpha =  0.7026315789473684 b =  2929.5835033951676 epoch =  260  loss = 3547.167  loss reduction = 428.2188  correctly classified = 87.1750%\n",
      "alpha =  0.7026315789473684 b =  3218.0221981320096 epoch =  261  loss = 4016.827  loss reduction = -469.6593  correctly classified = 85.4750%\n",
      "alpha =  0.7026315789473684 b =  3044.3527507635886 epoch =  262  loss = 3567.887  loss reduction = 448.9391  correctly classified = 87.1000%\n",
      "alpha =  0.7026315789473684 b =  3339.8037086583254 epoch =  263  loss = 4030.64  loss reduction = -462.7526  correctly classified = 85.4250%\n",
      "alpha =  0.7026315789473684 b =  3145.09747181622 epoch =  264  loss = 3650.769  loss reduction = 379.8715  correctly classified = 86.8000%\n",
      "alpha =  0.7026315789473684 b =  3455.274182342536 epoch =  265  loss = 4134.241  loss reduction = -483.4728  correctly classified = 85.0500%\n",
      "alpha =  0.7026315789473684 b =  3230.4152139214834 epoch =  266  loss = 3864.878  loss reduction = 269.3634  correctly classified = 86.0250%\n",
      "alpha =  0.7026315789473684 b =  3560.2262612899044 epoch =  267  loss = 4258.563  loss reduction = -393.685  correctly classified = 84.6000%\n",
      "alpha =  0.7026315789473684 b =  3282.074092868852 epoch =  268  loss = 4251.656  loss reduction = 6.906755  correctly classified = 84.6250%\n",
      "alpha =  0.7026315789473684 b =  3669.38569813201 epoch =  269  loss = 4603.901  loss reduction = -352.2445  correctly classified = 83.3500%\n",
      "alpha =  0.7026315789473684 b =  3249.585813921484 epoch =  270  loss = 5260.042  loss reduction = -656.1417  correctly classified = 80.9750%\n",
      "alpha =  0.7026315789473684 b =  3711.2274086583257 epoch =  271  loss = 5142.628  loss reduction = 117.4148  correctly classified = 81.4000%\n",
      "alpha =  0.7026315789473684 b =  3126.6393402372732 epoch =  272  loss = 6606.86  loss reduction = -1464.232  correctly classified = 76.1000%\n",
      "alpha =  0.7026315789473684 b =  3678.0379033951676 epoch =  273  loss = 5750.422  loss reduction = 856.4376  correctly classified = 79.2000%\n",
      "alpha =  0.7026315789473684 b =  2939.8812718162203 epoch =  274  loss = 8036.558  loss reduction = -2286.136  correctly classified = 70.9250%\n",
      "alpha =  0.7026315789473684 b =  3550.8840718162205 epoch =  275  loss = 6185.548  loss reduction = 1851.01  correctly classified = 77.6250%\n",
      "alpha =  0.7026315789473684 b =  2721.568019184642 epoch =  276  loss = 8823.928  loss reduction = -2638.38  correctly classified = 68.0750%\n",
      "alpha =  0.7026315789473684 b =  3357.8149665530627 epoch =  277  loss = 6434.191  loss reduction = 2389.737  correctly classified = 76.7250%\n",
      "alpha =  0.7026315789473684 b =  2529.2001402372734 epoch =  278  loss = 8830.835  loss reduction = -2396.644  correctly classified = 68.0500%\n",
      "alpha =  0.7026315789473684 b =  3159.136050763589 epoch =  279  loss = 6372.03  loss reduction = 2458.805  correctly classified = 76.9500%\n",
      "alpha =  0.7026315789473684 b =  2350.155561289905 epoch =  280  loss = 8678.886  loss reduction = -2306.856  correctly classified = 68.6000%\n",
      "alpha =  0.7026315789473684 b =  2972.3779823425366 epoch =  281  loss = 6296.056  loss reduction = 2382.83  correctly classified = 77.2250%\n",
      "alpha =  0.7026315789473684 b =  2201.263713921484 epoch =  282  loss = 8333.548  loss reduction = -2037.493  correctly classified = 69.8500%\n",
      "alpha =  0.7026315789473684 b =  2796.8395349741154 epoch =  283  loss = 6102.666  loss reduction = 2230.882  correctly classified = 77.9250%\n",
      "alpha =  0.7026315789473684 b =  2048.1645086583258 epoch =  284  loss = 8153.973  loss reduction = -2051.306  correctly classified = 70.5000%\n",
      "alpha =  0.7026315789473684 b =  2631.8194823425365 epoch =  285  loss = 6026.692  loss reduction = 2127.28  correctly classified = 78.2000%\n",
      "alpha =  0.7026315789473684 b =  1914.6996402372733 epoch =  286  loss = 7856.982  loss reduction = -1830.29  correctly classified = 71.5750%\n",
      "alpha =  0.7026315789473684 b =  2471.708013921484 epoch =  287  loss = 5805.676  loss reduction = 2051.306  correctly classified = 79.0000%\n",
      "alpha =  0.7026315789473684 b =  1828.9181612899051 epoch =  288  loss = 7207.747  loss reduction = -1402.071  correctly classified = 73.9250%\n",
      "alpha =  0.7026315789473684 b =  2359.9811612899052 epoch =  289  loss = 5619.194  loss reduction = 1588.554  correctly classified = 79.6750%\n",
      "alpha =  0.7026315789473684 b =  1734.721966553063 epoch =  290  loss = 7048.892  loss reduction = -1429.698  correctly classified = 74.5000%\n",
      "alpha =  0.7026315789473684 b =  2249.6567612899053 epoch =  291  loss = 5515.592  loss reduction = 1533.3  correctly classified = 80.0500%\n",
      "alpha =  0.7026315789473684 b =  1663.6662402372738 epoch =  292  loss = 6662.114  loss reduction = -1146.521  correctly classified = 75.9000%\n",
      "alpha =  0.7026315789473684 b =  2158.265471816221 epoch =  293  loss = 5370.55  loss reduction = 1291.563  correctly classified = 80.5750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.7026315789473684 b =  1633.281640237274 epoch =  294  loss = 6171.734  loss reduction = -801.1836  correctly classified = 77.6750%\n",
      "alpha =  0.7026315789473684 b =  2100.533045500432 epoch =  295  loss = 5184.068  loss reduction = 987.6659  correctly classified = 81.2500%\n",
      "alpha =  0.7026315789473684 b =  1631.6473191846424 epoch =  296  loss = 5729.702  loss reduction = -545.6336  correctly classified = 79.2750%\n",
      "alpha =  0.7026315789473684 b =  2068.0447665530637 epoch =  297  loss = 4990.679  loss reduction = 739.0228  correctly classified = 81.9500%\n",
      "alpha =  0.7026315789473684 b =  1647.543656026748 epoch =  298  loss = 5349.83  loss reduction = -359.1512  correctly classified = 80.6500%\n",
      "alpha =  0.7026315789473684 b =  2039.0626191846427 epoch =  299  loss = 4631.528  loss reduction = 718.3025  correctly classified = 83.2500%\n",
      "alpha =  0.7026315789473684 b =  1716.7331928688532 epoch =  300  loss = 4686.782  loss reduction = -55.25404  correctly classified = 83.0500%\n",
      "alpha =  0.7026315789473684 b =  2084.410461289906 epoch =  301  loss = 4507.206  loss reduction = 179.5756  correctly classified = 83.7000%\n",
      "alpha =  0.7026315789473684 b =  1806.9595191846429 epoch =  302  loss = 4313.817  loss reduction = 193.3891  correctly classified = 84.4000%\n",
      "alpha =  0.7026315789473684 b =  2136.770566553064 epoch =  303  loss = 4313.817  loss reduction = -9.094947e-13  correctly classified = 84.4000%\n",
      "alpha =  0.7231578947368421 b =  1950.0888023425377 epoch =  0  loss = 3685.302  loss reduction = 628.5147  correctly classified = 86.6750%\n",
      "alpha =  0.7231578947368421 b =  2237.5715455004324 epoch =  1  loss = 3996.106  loss reduction = -310.804  correctly classified = 85.5500%\n",
      "alpha =  0.7231578947368421 b =  2102.853014974117 epoch =  2  loss = 3395.219  loss reduction = 600.8877  correctly classified = 87.7250%\n",
      "alpha =  0.7231578947368421 b =  2342.7027939214854 epoch =  3  loss = 3733.65  loss reduction = -338.431  correctly classified = 86.5000%\n",
      "alpha =  0.7231578947368421 b =  2225.3053412899067 epoch =  4  loss = 3353.778  loss reduction = 379.8715  correctly classified = 87.8750%\n",
      "alpha =  0.7231578947368421 b =  2466.59854339517 epoch =  5  loss = 3733.65  loss reduction = -379.8715  correctly classified = 86.5000%\n",
      "alpha =  0.7231578947368421 b =  2345.5925328688545 epoch =  6  loss = 3333.058  loss reduction = 400.5918  correctly classified = 87.9500%\n",
      "alpha =  0.7231578947368421 b =  2588.3291581320127 epoch =  7  loss = 3733.65  loss reduction = -400.5918  correctly classified = 86.5000%\n",
      "alpha =  0.7231578947368421 b =  2468.7665707635915 epoch =  8  loss = 3319.244  loss reduction = 414.4053  correctly classified = 88.0000%\n",
      "alpha =  0.7231578947368421 b =  2710.059772868855 epoch =  9  loss = 3733.65  loss reduction = -414.4053  correctly classified = 86.5000%\n",
      "alpha =  0.7231578947368421 b =  2587.6103391846445 epoch =  10  loss = 3319.244  loss reduction = 414.4053  correctly classified = 88.0000%\n",
      "alpha =  0.7231578947368421 b =  2832.5120991846447 epoch =  11  loss = 3740.556  loss reduction = -421.312  correctly classified = 86.4750%\n",
      "alpha =  0.7231578947368421 b =  2708.6192423425396 epoch =  12  loss = 3319.244  loss reduction = 421.312  correctly classified = 88.0000%\n",
      "alpha =  0.7231578947368421 b =  2955.6861370793818 epoch =  13  loss = 3747.463  loss reduction = -428.2188  correctly classified = 86.4500%\n",
      "alpha =  0.7231578947368421 b =  2826.019587605698 epoch =  14  loss = 3319.244  loss reduction = 428.2188  correctly classified = 88.0000%\n",
      "alpha =  0.7231578947368421 b =  3070.1996360267503 epoch =  15  loss = 3719.836  loss reduction = -400.5918  correctly classified = 86.5500%\n",
      "alpha =  0.7231578947368421 b =  2940.5330865530664 epoch =  16  loss = 3319.244  loss reduction = 400.5918  correctly classified = 88.0000%\n",
      "alpha =  0.7231578947368421 b =  3184.713134974119 epoch =  17  loss = 3719.836  loss reduction = -400.5918  correctly classified = 86.5500%\n",
      "alpha =  0.7231578947368421 b =  3055.046585500435 epoch =  18  loss = 3319.244  loss reduction = 400.5918  correctly classified = 88.0000%\n",
      "alpha =  0.7231578947368421 b =  3299.2266339214875 epoch =  19  loss = 3719.836  loss reduction = -400.5918  correctly classified = 86.5500%\n",
      "alpha =  0.7231578947368421 b =  3167.394949710961 epoch =  20  loss = 3339.965  loss reduction = 379.8715  correctly classified = 87.9250%\n",
      "alpha =  0.7231578947368421 b =  3422.4006718162245 epoch =  21  loss = 3768.183  loss reduction = -428.2188  correctly classified = 86.3750%\n",
      "alpha =  0.7231578947368421 b =  3281.1867370793825 epoch =  22  loss = 3374.498  loss reduction = 393.685  correctly classified = 87.8000%\n",
      "alpha =  0.7231578947368421 b =  3544.1312865530667 epoch =  23  loss = 3816.531  loss reduction = -442.0323  correctly classified = 86.2000%\n",
      "alpha =  0.7231578947368421 b =  3402.195640237277 epoch =  24  loss = 3381.405  loss reduction = 435.1256  correctly classified = 87.7750%\n",
      "alpha =  0.7231578947368421 b =  3664.418478132014 epoch =  25  loss = 3809.624  loss reduction = -428.2188  correctly classified = 86.2250%\n",
      "alpha =  0.7231578947368421 b =  3521.7390276834767 epoch =  26  loss = 3371.047  loss reduction = 438.5771  correctly classified = 87.8000%\n",
      "alpha =  0.7231578947368421 b =  3785.4052887361086 epoch =  27  loss = 3823.437  loss reduction = -452.3906  correctly classified = 86.1750%\n",
      "alpha =  0.7231578947368421 b =  3640.5827961045297 epoch =  28  loss = 3381.405  loss reduction = 442.0323  correctly classified = 87.7750%\n",
      "alpha =  0.7231578947368421 b =  3899.918787683477 epoch =  29  loss = 3781.997  loss reduction = -400.5918  correctly classified = 86.3250%\n",
      "alpha =  0.7231578947368421 b =  3758.704852946635 epoch =  30  loss = 3346.871  loss reduction = 435.1256  correctly classified = 87.9000%\n",
      "alpha =  0.7231578947368421 b =  4020.927690841372 epoch =  31  loss = 3809.624  loss reduction = -462.7526  correctly classified = 86.2250%\n",
      "alpha =  0.7231578947368421 b =  3871.774928736109 epoch =  32  loss = 3381.405  loss reduction = 428.2188  correctly classified = 87.7750%\n",
      "alpha =  0.7231578947368421 b =  4135.44118978874 epoch =  33  loss = 3809.624  loss reduction = -428.2188  correctly classified = 86.2250%\n",
      "alpha =  0.7231578947368421 b =  3982.6798697887402 epoch =  34  loss = 3388.312  loss reduction = 421.312  correctly classified = 87.7500%\n",
      "alpha =  0.7231578947368421 b =  4251.398111894004 epoch =  35  loss = 3802.717  loss reduction = -414.4053  correctly classified = 86.2500%\n",
      "alpha =  0.7231578947368421 b =  4092.1413876834777 epoch =  36  loss = 3395.219  loss reduction = 407.4985  correctly classified = 87.7250%\n",
      "alpha =  0.7231578947368421 b =  4351.4773792624255 epoch =  37  loss = 3781.997  loss reduction = -386.7783  correctly classified = 86.3250%\n",
      "alpha =  0.7231578947368421 b =  4201.602905578215 epoch =  38  loss = 3346.871  loss reduction = 435.1256  correctly classified = 87.9000%\n",
      "alpha =  0.7231578947368421 b =  4468.877724525583 epoch =  39  loss = 3775.09  loss reduction = -428.2188  correctly classified = 86.3500%\n",
      "alpha =  0.7231578947368421 b =  4309.621000315057 epoch =  40  loss = 3381.405  loss reduction = 393.685  correctly classified = 87.7750%\n",
      "alpha =  0.7231578947368421 b =  4582.669511894004 epoch =  41  loss = 3788.904  loss reduction = -407.4985  correctly classified = 86.3000%\n",
      "alpha =  0.7231578947368421 b =  4403.926575051899 epoch =  42  loss = 3471.193  loss reduction = 317.7107  correctly classified = 87.4500%\n",
      "alpha =  0.7231578947368421 b =  4689.965895051899 epoch =  43  loss = 3844.158  loss reduction = -372.9648  correctly classified = 86.1000%\n",
      "alpha =  0.7231578947368421 b =  4508.336111894004 epoch =  44  loss = 3471.193  loss reduction = 372.9648  correctly classified = 87.4500%\n",
      "alpha =  0.7231578947368421 b =  4792.932008736109 epoch =  45  loss = 3830.344  loss reduction = -359.1512  correctly classified = 86.1500%\n",
      "alpha =  0.7231578947368421 b =  4609.137090841373 epoch =  46  loss = 3478.1  loss reduction = 352.2445  correctly classified = 87.4250%\n",
      "alpha =  0.7231578947368421 b =  4902.393526630846 epoch =  47  loss = 3885.598  loss reduction = -407.4985  correctly classified = 85.9500%\n",
      "alpha =  0.7231578947368421 b =  4707.051223472951 epoch =  48  loss = 3519.54  loss reduction = 366.058  correctly classified = 87.2750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.7231578947368421 b =  5019.793871894004 epoch =  49  loss = 4016.827  loss reduction = -497.2863  correctly classified = 85.4750%\n",
      "alpha =  0.7231578947368421 b =  4787.644278209794 epoch =  50  loss = 3775.09  loss reduction = 241.7364  correctly classified = 86.3500%\n",
      "alpha =  0.7231578947368421 b =  5124.925120315057 epoch =  51  loss = 4210.216  loss reduction = -435.1256  correctly classified = 84.7750%\n",
      "alpha =  0.7231578947368421 b =  4808.335271894004 epoch =  52  loss = 4306.91  loss reduction = -96.69457  correctly classified = 84.4250%\n",
      "alpha =  0.7231578947368421 b =  5251.707716104531 epoch =  53  loss = 4866.357  loss reduction = -559.4471  correctly classified = 82.4000%\n",
      "alpha =  0.7231578947368421 b =  4679.63196873611 epoch =  54  loss = 6323.683  loss reduction = -1457.325  correctly classified = 77.1250%\n",
      "alpha =  0.7231578947368421 b =  5250.025650841373 epoch =  55  loss = 5736.608  loss reduction = 587.0742  correctly classified = 79.2500%\n",
      "alpha =  0.7231578947368421 b =  4436.898236104531 epoch =  56  loss = 8381.896  loss reduction = -2645.287  correctly classified = 69.6750%\n",
      "alpha =  0.7231578947368421 b =  5094.619019262425 epoch =  57  loss = 6461.818  loss reduction = 1920.078  correctly classified = 76.6250%\n",
      "alpha =  0.7231578947368421 b =  4164.574328736109 epoch =  58  loss = 9431.722  loss reduction = -2969.905  correctly classified = 65.8750%\n",
      "alpha =  0.7231578947368421 b =  4870.649787683477 epoch =  59  loss = 6869.316  loss reduction = 2562.406  correctly classified = 75.1500%\n",
      "alpha =  0.7231578947368421 b =  4030.097332946635 epoch =  60  loss = 8630.539  loss reduction = -1761.222  correctly classified = 68.7750%\n",
      "alpha =  0.7231578947368421 b =  4686.374692946635 epoch =  61  loss = 6448.004  loss reduction = 2182.535  correctly classified = 76.6750%\n",
      "alpha =  0.7231578947368421 b =  3804.684678209793 epoch =  62  loss = 9024.224  loss reduction = -2576.22  correctly classified = 67.3500%\n",
      "alpha =  0.7231578947368421 b =  4480.448250841372 epoch =  63  loss = 6634.487  loss reduction = 2389.737  correctly classified = 76.0000%\n",
      "alpha =  0.7231578947368421 b =  3634.122103472951 epoch =  64  loss = 8699.606  loss reduction = -2065.12  correctly classified = 68.5250%\n",
      "alpha =  0.7231578947368421 b =  4280.295501367688 epoch =  65  loss = 6351.31  loss reduction = 2348.297  correctly classified = 77.0250%\n",
      "alpha =  0.7231578947368421 b =  3448.403585578215 epoch =  66  loss = 8630.539  loss reduction = -2279.229  correctly classified = 68.7750%\n",
      "alpha =  0.7231578947368421 b =  4083.029598209794 epoch =  67  loss = 6240.802  loss reduction = 2389.737  correctly classified = 77.4250%\n",
      "alpha =  0.7231578947368421 b =  3303.8226276834785 epoch =  68  loss = 8195.413  loss reduction = -1954.612  correctly classified = 70.3500%\n",
      "alpha =  0.7231578947368421 b =  3910.30188873611 epoch =  69  loss = 6012.879  loss reduction = 2182.535  correctly classified = 78.2500%\n",
      "alpha =  0.7231578947368421 b =  3172.2324782097944 epoch =  70  loss = 7856.982  loss reduction = -1844.104  correctly classified = 71.5750%\n",
      "alpha =  0.7231578947368421 b =  3749.121564525584 epoch =  71  loss = 5798.769  loss reduction = 2058.213  correctly classified = 79.0250%\n",
      "alpha =  0.7231578947368421 b =  3088.2752929466365 epoch =  72  loss = 7159.4  loss reduction = -1360.631  correctly classified = 74.1000%\n",
      "alpha =  0.7231578947368421 b =  3630.522223472952 epoch =  73  loss = 5550.126  loss reduction = 1609.274  correctly classified = 79.9250%\n",
      "alpha =  0.7231578947368421 b =  3005.752679014444 epoch =  74  loss = 6841.702  loss reduction = -1291.575  correctly classified = 75.2500%\n",
      "alpha =  0.7231578947368421 b =  3536.452224277602 epoch =  75  loss = 5494.872  loss reduction = 1346.83  correctly classified = 80.1250%\n",
      "alpha =  0.7231578947368421 b =  2939.8382832249704 epoch =  76  loss = 6586.139  loss reduction = -1091.267  correctly classified = 76.1750%\n",
      "alpha =  0.7231578947368421 b =  3439.5042305933916 epoch =  77  loss = 5253.136  loss reduction = 1333.004  correctly classified = 81.0000%\n",
      "alpha =  0.7231578947368421 b =  2917.226582172339 epoch =  78  loss = 5971.438  loss reduction = -718.3025  correctly classified = 78.4000%\n",
      "alpha =  0.7231578947368421 b =  3393.076047435497 epoch =  79  loss = 5108.094  loss reduction = 863.3443  correctly classified = 81.5250%\n",
      "alpha =  0.7231578947368421 b =  2911.214247435497 epoch =  80  loss = 5639.914  loss reduction = -531.8201  correctly classified = 79.6000%\n",
      "alpha =  0.7231578947368421 b =  3369.020923224971 epoch =  81  loss = 4963.052  loss reduction = 676.862  correctly classified = 82.0500%\n",
      "alpha =  0.7231578947368421 b =  2933.3486642776024 epoch =  82  loss = 5322.203  loss reduction = -359.1512  correctly classified = 80.7500%\n",
      "alpha =  0.7231578947368421 b =  3363.0085884881287 epoch =  83  loss = 4776.57  loss reduction = 545.6336  correctly classified = 82.7250%\n",
      "alpha =  0.7231578947368421 b =  2998.0640642776025 epoch =  84  loss = 4769.663  loss reduction = 6.906755  correctly classified = 82.7500%\n",
      "alpha =  0.7231578947368421 b =  3397.4121021723395 epoch =  85  loss = 4555.553  loss reduction = 214.1094  correctly classified = 83.5250%\n",
      "alpha =  0.7231578947368421 b =  3084.430811646024 epoch =  86  loss = 4479.579  loss reduction = 75.9743  correctly classified = 83.8000%\n",
      "alpha =  0.7231578947368421 b =  3441.9195779618135 epoch =  87  loss = 4306.91  loss reduction = 172.6689  correctly classified = 84.4250%\n",
      "alpha =  0.7231578947368421 b =  3233.586466382866 epoch =  88  loss = 3726.743  loss reduction = 580.1674  correctly classified = 86.5250%\n",
      "alpha =  0.7231578947368421 b =  3519.625786382866 epoch =  89  loss = 3927.039  loss reduction = -200.2959  correctly classified = 85.8000%\n",
      "alpha =  0.7231578947368421 b =  3397.8980642776028 epoch =  90  loss = 3243.27  loss reduction = 683.7687  correctly classified = 88.2750%\n",
      "alpha =  0.7231578947368421 b =  3608.1576684881293 epoch =  91  loss = 3491.913  loss reduction = -248.6432  correctly classified = 87.3750%\n",
      "alpha =  0.7231578947368421 b =  3592.521548488129 epoch =  92  loss = 3056.788  loss reduction = 435.1256  correctly classified = 88.9500%\n",
      "alpha =  0.7231578947368421 b =  3754.426476909182 epoch =  93  loss = 3305.431  loss reduction = -248.6432  correctly classified = 88.0500%\n",
      "alpha =  0.7231578947368421 b =  3800.1358411197084 epoch =  94  loss = 3118.948  loss reduction = 186.4824  correctly classified = 88.7250%\n",
      "alpha =  0.7231578947368421 b =  3926.67690217234 epoch =  95  loss = 3188.016  loss reduction = -69.06755  correctly classified = 88.4750%\n",
      "alpha =  0.7231578947368421 b =  4012.802114803919 epoch =  96  loss = 3118.948  loss reduction = 69.06755  correctly classified = 88.7250%\n",
      "alpha =  0.7231578947368421 b =  4124.908944277603 epoch =  97  loss = 3160.389  loss reduction = -41.44053  correctly classified = 88.5750%\n",
      "alpha =  0.7231578947368421 b =  4226.190100067077 epoch =  98  loss = 3112.042  loss reduction = 48.34728  correctly classified = 88.7500%\n",
      "alpha =  0.7231578947368421 b =  4332.523236909182 epoch =  99  loss = 3132.762  loss reduction = -20.72026  correctly classified = 88.6750%\n",
      "alpha =  0.7231578947368421 b =  4431.639257961813 epoch =  100  loss = 3105.135  loss reduction = 27.62702  correctly classified = 88.7750%\n",
      "alpha =  0.7231578947368421 b =  4539.415817961813 epoch =  101  loss = 3146.575  loss reduction = -41.44053  correctly classified = 88.6250%\n",
      "alpha =  0.7231578947368421 b =  4637.810127435498 epoch =  102  loss = 3098.228  loss reduction = 48.34728  correctly classified = 88.8000%\n",
      "alpha =  0.7231578947368421 b =  4745.586687435498 epoch =  103  loss = 3146.575  loss reduction = -48.34728  correctly classified = 88.6250%\n",
      "alpha =  0.7231578947368421 b =  4846.1461316460245 epoch =  104  loss = 3091.321  loss reduction = 55.25404  correctly classified = 88.8250%\n",
      "alpha =  0.7231578947368421 b =  4941.653594803919 epoch =  105  loss = 3070.601  loss reduction = 20.72026  correctly classified = 88.9000%\n",
      "alpha =  0.7231578947368421 b =  5049.430154803919 epoch =  106  loss = 3118.948  loss reduction = -48.34728  correctly classified = 88.7250%\n",
      "alpha =  0.7231578947368421 b =  5145.659329540761 epoch =  107  loss = 3063.694  loss reduction = 55.25404  correctly classified = 88.9250%\n",
      "alpha =  0.7231578947368421 b =  5243.331927435498 epoch =  108  loss = 3077.508  loss reduction = -13.81351  correctly classified = 88.8750%\n",
      "alpha =  0.7231578947368421 b =  5343.169660067077 epoch =  109  loss = 3084.415  loss reduction = -6.906755  correctly classified = 88.8500%\n",
      "alpha =  0.7231578947368421 b =  5437.955411646024 epoch =  110  loss = 3049.881  loss reduction = 34.53377  correctly classified = 88.9750%\n",
      "alpha =  0.7231578947368421 b =  5536.349721119708 epoch =  111  loss = 3056.788  loss reduction = -6.906755  correctly classified = 88.9500%\n",
      "alpha =  0.7231578947368421 b =  5634.022319014445 epoch =  112  loss = 3049.881  loss reduction = 6.906755  correctly classified = 88.9750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.7231578947368421 b =  5730.251493751287 epoch =  113  loss = 3036.067  loss reduction = 13.81351  correctly classified = 89.0250%\n",
      "alpha =  0.7231578947368421 b =  5828.645803224971 epoch =  114  loss = 3042.974  loss reduction = -6.906755  correctly classified = 89.0000%\n",
      "alpha =  0.7231578947368421 b =  5924.874977961813 epoch =  115  loss = 3022.254  loss reduction = 20.72026  correctly classified = 89.0750%\n",
      "alpha =  0.7231578947368421 b =  6026.877845330234 epoch =  116  loss = 3049.881  loss reduction = -27.62702  correctly classified = 88.9750%\n",
      "alpha =  0.7231578947368421 b =  6104.342519014444 epoch =  117  loss = 2980.813  loss reduction = 69.06755  correctly classified = 89.2250%\n",
      "alpha =  0.7231578947368421 b =  6226.553310593392 epoch =  118  loss = 3063.694  loss reduction = -82.88106  correctly classified = 88.9250%\n",
      "alpha =  0.7231578947368421 b =  6283.088348488129 epoch =  119  loss = 2946.28  loss reduction = 117.4148  correctly classified = 89.3500%\n",
      "alpha =  0.7231578947368421 b =  6411.794544277603 epoch =  120  loss = 3112.042  loss reduction = -165.7621  correctly classified = 88.7500%\n",
      "alpha =  0.7231578947368421 b =  6463.277601119708 epoch =  121  loss = 2939.373  loss reduction = 172.6689  correctly classified = 89.3750%\n",
      "alpha =  0.7231578947368421 b =  6587.653527435498 epoch =  122  loss = 3070.601  loss reduction = -131.2283  correctly classified = 88.9000%\n",
      "alpha =  0.7231578947368421 b =  6641.301719014446 epoch =  123  loss = 2932.466  loss reduction = 138.1351  correctly classified = 89.4000%\n",
      "alpha =  0.7231578947368421 b =  6769.286203224972 epoch =  124  loss = 3077.508  loss reduction = -145.0419  correctly classified = 88.8750%\n",
      "alpha =  0.7231578947368421 b =  6816.438990593393 epoch =  125  loss = 2939.373  loss reduction = 138.1351  correctly classified = 89.3750%\n",
      "alpha =  0.7231578947368421 b =  6940.093205330235 epoch =  126  loss = 3022.254  loss reduction = -82.88106  correctly classified = 89.0750%\n",
      "alpha =  0.7231578947368421 b =  6987.245992698656 epoch =  127  loss = 2939.373  loss reduction = 82.88106  correctly classified = 89.3750%\n",
      "alpha =  0.7231578947368421 b =  7111.621919014446 epoch =  128  loss = 3029.161  loss reduction = -89.78781  correctly classified = 89.0500%\n",
      "alpha =  0.7231578947368421 b =  7160.218129540762 epoch =  129  loss = 2911.746  loss reduction = 117.4148  correctly classified = 89.4750%\n",
      "alpha =  0.7231578947368421 b =  7282.428921119709 epoch =  130  loss = 3008.44  loss reduction = -96.69457  correctly classified = 89.1250%\n",
      "alpha =  0.7231578947368421 b =  7330.303420067077 epoch =  131  loss = 2918.653  loss reduction = 89.78781  correctly classified = 89.4500%\n",
      "alpha =  0.7231578947368421 b =  7452.514211646025 epoch =  132  loss = 3008.44  loss reduction = -89.78781  correctly classified = 89.1250%\n",
      "alpha =  0.7231578947368421 b =  7500.388710593393 epoch =  133  loss = 2918.653  loss reduction = 89.78781  correctly classified = 89.4500%\n",
      "alpha =  0.7231578947368421 b =  7622.59950217234 epoch =  134  loss = 3008.44  loss reduction = -89.78781  correctly classified = 89.1250%\n",
      "alpha =  0.7231578947368421 b =  7671.195712698656 epoch =  135  loss = 2911.746  loss reduction = 96.69457  correctly classified = 89.4750%\n",
      "alpha =  0.7231578947368421 b =  7794.128215856551 epoch =  136  loss = 3001.534  loss reduction = -89.78781  correctly classified = 89.1500%\n",
      "alpha =  0.7231578947368421 b =  7838.394156909182 epoch =  137  loss = 2884.119  loss reduction = 117.4148  correctly classified = 89.5750%\n",
      "alpha =  0.7231578947368421 b =  7967.822064277603 epoch =  138  loss = 3036.067  loss reduction = -151.9486  correctly classified = 89.0250%\n",
      "alpha =  0.7231578947368421 b =  7983.941253751287 epoch =  139  loss = 2821.958  loss reduction = 214.1094  correctly classified = 89.8000%\n",
      "alpha =  0.7231578947368421 b =  8132.133662172339 epoch =  140  loss = 3091.321  loss reduction = -269.3634  correctly classified = 88.8250%\n",
      "alpha =  0.7231578947368421 b =  8138.870601119708 epoch =  141  loss = 2801.238  loss reduction = 290.0837  correctly classified = 89.8750%\n",
      "alpha =  0.7231578947368421 b =  8290.671567435498 epoch =  142  loss = 3098.228  loss reduction = -296.9905  correctly classified = 88.8000%\n",
      "alpha =  0.7231578947368421 b =  8288.02625585655 epoch =  143  loss = 2752.89  loss reduction = 345.3377  correctly classified = 90.0500%\n",
      "alpha =  0.7231578947368421 b =  8460.035146382867 epoch =  144  loss = 3181.109  loss reduction = -428.2188  correctly classified = 88.5000%\n",
      "alpha =  0.7231578947368421 b =  8437.181910593394 epoch =  145  loss = 2821.958  loss reduction = 359.1512  correctly classified = 89.8000%\n",
      "alpha =  0.7231578947368421 b =  8622.181609540763 epoch =  146  loss = 3181.109  loss reduction = -359.1512  correctly classified = 88.5000%\n",
      "alpha =  0.7231578947368421 b =  8569.738199014448 epoch =  147  loss = 2842.678  loss reduction = 338.431  correctly classified = 89.7250%\n",
      "alpha =  0.7231578947368421 b =  8779.276091646027 epoch =  148  loss = 3319.244  loss reduction = -476.5661  correctly classified = 88.0000%\n",
      "alpha =  0.7231578947368421 b =  8671.982601119711 epoch =  149  loss = 3022.254  loss reduction = 296.9905  correctly classified = 89.0750%\n",
      "alpha =  0.7231578947368421 b =  8936.37057375129 epoch =  150  loss = 3554.074  loss reduction = -531.8201  correctly classified = 87.1500%\n",
      "alpha =  0.7231578947368421 b =  8746.801963224974 epoch =  151  loss = 3339.965  loss reduction = 214.1094  correctly classified = 87.9250%\n",
      "alpha =  0.7231578947368421 b =  9047.99722638287 epoch =  152  loss = 3823.437  loss reduction = -483.4728  correctly classified = 86.1750%\n",
      "alpha =  0.7231578947368421 b =  8799.248266382869 epoch =  153  loss = 3699.116  loss reduction = 124.3216  correctly classified = 86.6250%\n",
      "alpha =  0.7231578947368421 b =  9158.180455856553 epoch =  154  loss = 4196.402  loss reduction = -497.2863  correctly classified = 84.8250%\n",
      "alpha =  0.7231578947368421 b =  8754.985217961816 epoch =  155  loss = 4859.451  loss reduction = -663.0485  correctly classified = 82.4250%\n",
      "alpha =  0.7231578947368421 b =  9251.764319014448 epoch =  156  loss = 5197.882  loss reduction = -338.431  correctly classified = 81.2000%\n",
      "alpha =  0.7231578947368421 b =  8502.869234803922 epoch =  157  loss = 7767.194  loss reduction = -2569.313  correctly classified = 71.9000%\n",
      "alpha =  0.7231578947368421 b =  9141.825516909186 epoch =  158  loss = 6282.242  loss reduction = 1484.952  correctly classified = 77.2750%\n",
      "alpha =  0.7231578947368421 b =  8149.713630593396 epoch =  159  loss = 9970.449  loss reduction = -3688.207  correctly classified = 63.9250%\n",
      "alpha =  0.7231578947368421 b =  8881.048994803923 epoch =  160  loss = 7097.239  loss reduction = 2873.21  correctly classified = 74.3250%\n",
      "alpha =  0.7231578947368421 b =  8107.615716909187 epoch =  161  loss = 8002.024  loss reduction = -904.7849  correctly classified = 71.0500%\n",
      "alpha =  0.7231578947368421 b =  8741.520017961819 epoch =  162  loss = 6220.081  loss reduction = 1781.943  correctly classified = 77.5000%\n",
      "alpha =  0.7231578947368421 b =  7839.622079014451 epoch =  163  loss = 9162.359  loss reduction = -2942.278  correctly classified = 66.8500%\n",
      "alpha =  0.7231578947368421 b =  8539.92384533024 epoch =  164  loss = 6814.062  loss reduction = 2348.297  correctly classified = 75.3500%\n",
      "alpha =  0.7231578947368421 b =  7687.824005330241 epoch =  165  loss = 8699.606  loss reduction = -1885.544  correctly classified = 68.5250%\n",
      "alpha =  0.7231578947368421 b =  8353.483615856556 epoch =  166  loss = 6510.165  loss reduction = 2189.441  correctly classified = 76.4500%\n",
      "alpha =  0.7231578947368421 b =  7504.270622172346 epoch =  167  loss = 8685.793  loss reduction = -2175.628  correctly classified = 68.5750%\n",
      "alpha =  0.7231578947368421 b =  8159.104559014451 epoch =  168  loss = 6406.564  loss reduction = 2279.229  correctly classified = 76.8250%\n",
      "alpha =  0.7231578947368421 b =  7338.7600284881355 epoch =  169  loss = 8464.777  loss reduction = -2058.213  correctly classified = 69.3750%\n",
      "alpha =  0.7231578947368421 b =  7971.942617961819 epoch =  170  loss = 6226.988  loss reduction = 2237.789  correctly classified = 77.4750%\n",
      "alpha =  0.7231578947368421 b =  7185.51853164603 epoch =  171  loss = 8140.159  loss reduction = -1913.171  correctly classified = 70.5500%\n",
      "alpha =  0.7231578947368421 b =  7791.997792698662 epoch =  172  loss = 6012.879  loss reduction = 2127.28  correctly classified = 78.2500%\n",
      "alpha =  0.7231578947368421 b =  7018.564514803926 epoch =  173  loss = 8015.838  loss reduction = -2002.959  correctly classified = 71.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.7231578947368421 b =  7607.722697961821 epoch =  174  loss = 5888.557  loss reduction = 2127.28  correctly classified = 78.7000%\n",
      "alpha =  0.7231578947368421 b =  6922.338232698663 epoch =  175  loss = 7269.908  loss reduction = -1381.351  correctly classified = 73.7000%\n",
      "alpha =  0.7231578947368421 b =  7467.472009540768 epoch =  176  loss = 5536.313  loss reduction = 1733.595  correctly classified = 79.9750%\n",
      "alpha =  0.7231578947368421 b =  6816.007988488137 epoch =  177  loss = 7028.172  loss reduction = -1491.859  correctly classified = 74.5750%\n",
      "alpha =  0.7231578947368421 b =  7353.924649540769 epoch =  178  loss = 5481.059  loss reduction = 1547.113  correctly classified = 80.1750%\n",
      "alpha =  0.7231578947368421 b =  6727.720533751295 epoch =  179  loss = 6786.435  loss reduction = -1305.377  correctly classified = 75.4500%\n",
      "alpha =  0.7231578947368421 b =  7241.099001119716 epoch =  180  loss = 5329.11  loss reduction = 1457.325  correctly classified = 80.7250%\n",
      "alpha =  0.7231578947368421 b =  6664.692984277611 epoch =  181  loss = 6351.31  loss reduction = -1022.2  correctly classified = 77.0250%\n",
      "alpha =  0.7231578947368421 b =  7159.3069505934 epoch =  182  loss = 5177.161  loss reduction = 1174.148  correctly classified = 81.2750%\n",
      "alpha =  0.7231578947368421 b =  6640.637860067084 epoch =  183  loss = 5881.65  loss reduction = -704.489  correctly classified = 78.7250%\n",
      "alpha =  0.7231578947368421 b =  7108.548497961821 epoch =  184  loss = 4990.679  loss reduction = 890.9714  correctly classified = 81.9500%\n",
      "alpha =  0.7231578947368421 b =  6621.63471690919 epoch =  185  loss = 5619.194  loss reduction = -628.5147  correctly classified = 79.6750%\n",
      "alpha =  0.7231578947368421 b =  7067.172295856558 epoch =  186  loss = 4831.824  loss reduction = 787.37  correctly classified = 82.5250%\n",
      "alpha =  0.7231578947368421 b =  6636.552017961821 epoch =  187  loss = 5135.721  loss reduction = -303.8972  correctly classified = 81.4250%\n",
      "alpha =  0.7231578947368421 b =  7030.126363224978 epoch =  188  loss = 4458.859  loss reduction = 676.862  correctly classified = 83.8750%\n",
      "alpha =  0.7231578947368421 b =  6714.979937961821 epoch =  189  loss = 4279.283  loss reduction = 179.5756  correctly classified = 84.5250%\n",
      "alpha =  0.7231578947368421 b =  7080.407531646031 epoch =  190  loss = 4313.817  loss reduction = -34.53377  correctly classified = 84.4000%\n",
      "alpha =  0.7231578947368421 b =  6832.3802832249785 epoch =  191  loss = 3871.785  loss reduction = 442.0323  correctly classified = 86.0000%\n",
      "alpha =  0.7231578947368421 b =  7127.801853751294 epoch =  192  loss = 3906.318  loss reduction = -34.53377  correctly classified = 85.8750%\n",
      "alpha =  0.7231578947368421 b =  6988.753053751295 epoch =  193  loss = 3243.27  loss reduction = 663.0485  correctly classified = 88.2750%\n",
      "alpha =  0.7231578947368421 b =  7217.777159014453 epoch =  194  loss = 3464.286  loss reduction = -221.0162  correctly classified = 87.4750%\n",
      "alpha =  0.7231578947368421 b =  7166.777171646032 epoch =  195  loss = 2897.932  loss reduction = 566.3539  correctly classified = 89.5250%\n",
      "alpha =  0.7231578947368421 b =  7355.385428488137 epoch =  196  loss = 3326.151  loss reduction = -428.2188  correctly classified = 87.9750%\n",
      "alpha =  0.7231578947368421 b =  7351.296693751295 epoch =  197  loss = 2891.025  loss reduction = 435.1256  correctly classified = 89.5500%\n",
      "alpha =  0.7231578947368421 b =  7501.654236909189 epoch =  198  loss = 3153.482  loss reduction = -262.4567  correctly classified = 88.6000%\n",
      "alpha =  0.7231578947368421 b =  7546.641889540769 epoch =  199  loss = 2932.466  loss reduction = 221.0162  correctly classified = 89.4000%\n",
      "alpha =  0.7231578947368421 b =  7671.017815856559 epoch =  200  loss = 3056.788  loss reduction = -124.3216  correctly classified = 88.9500%\n",
      "alpha =  0.7231578947368421 b =  7738.378527435506 epoch =  201  loss = 2925.559  loss reduction = 131.2283  correctly classified = 89.4250%\n",
      "alpha =  0.7231578947368421 b =  7849.763645330243 epoch =  202  loss = 3001.534  loss reduction = -75.9743  correctly classified = 89.1500%\n",
      "alpha =  0.7231578947368421 b =  7928.671742172348 epoch =  203  loss = 2911.746  loss reduction = 89.78781  correctly classified = 89.4750%\n",
      "alpha =  0.7231578947368421 b =  8031.396321119716 epoch =  204  loss = 2960.093  loss reduction = -48.34728  correctly classified = 89.3000%\n",
      "alpha =  0.7231578947368421 b =  8117.5215337512955 epoch =  205  loss = 2939.373  loss reduction = 20.72026  correctly classified = 89.3750%\n",
      "alpha =  0.7231578947368421 b =  8220.967824277612 epoch =  206  loss = 2939.373  loss reduction = 0.0  correctly classified = 89.3750%\n",
      "alpha =  0.7436842105263157 b =  8302.1156705934 epoch =  0  loss = 2897.932  loss reduction = 41.44053  correctly classified = 89.5250%\n",
      "alpha =  0.7436842105263157 b =  8408.498209540769 epoch =  1  loss = 2939.373  loss reduction = -41.44053  correctly classified = 89.3750%\n",
      "alpha =  0.7436842105263157 b =  8491.13044954077 epoch =  2  loss = 2884.119  loss reduction = 55.25404  correctly classified = 89.5750%\n",
      "alpha =  0.7436842105263157 b =  8598.255185330243 epoch =  3  loss = 2946.28  loss reduction = -62.16079  correctly classified = 89.3500%\n",
      "alpha =  0.7436842105263157 b =  8681.629622172348 epoch =  4  loss = 2877.212  loss reduction = 69.06755  correctly classified = 89.6000%\n",
      "alpha =  0.7436842105263157 b =  8790.238751646031 epoch =  5  loss = 2946.28  loss reduction = -69.06755  correctly classified = 89.3500%\n",
      "alpha =  0.7436842105263157 b =  8863.222432698663 epoch =  6  loss = 2877.212  loss reduction = 69.06755  correctly classified = 89.6000%\n",
      "alpha =  0.7436842105263157 b =  8973.315955856559 epoch =  7  loss = 2946.28  loss reduction = -69.06755  correctly classified = 89.3500%\n",
      "alpha =  0.7436842105263157 b =  9040.362062172348 epoch =  8  loss = 2863.398  loss reduction = 82.88106  correctly classified = 89.6500%\n",
      "alpha =  0.7436842105263157 b =  9143.03361690919 epoch =  9  loss = 2918.653  loss reduction = -55.25404  correctly classified = 89.4500%\n",
      "alpha =  0.7436842105263157 b =  9224.181463224979 epoch =  10  loss = 2856.492  loss reduction = 62.16079  correctly classified = 89.6750%\n",
      "alpha =  0.7436842105263157 b =  9315.720065330243 epoch =  11  loss = 2884.119  loss reduction = -27.62702  correctly classified = 89.5750%\n",
      "alpha =  0.7436842105263157 b =  9408.00086427761 epoch =  12  loss = 2877.212  loss reduction = 6.906755  correctly classified = 89.6000%\n",
      "alpha =  0.7436842105263157 b =  9497.312875856558 epoch =  13  loss = 2849.585  loss reduction = 27.62702  correctly classified = 89.7000%\n",
      "alpha =  0.7436842105263157 b =  9590.335871646032 epoch =  14  loss = 2870.305  loss reduction = -20.72026  correctly classified = 89.6250%\n",
      "alpha =  0.7436842105263157 b =  9673.710308488136 epoch =  15  loss = 2849.585  loss reduction = 20.72026  correctly classified = 89.7000%\n",
      "alpha =  0.7436842105263157 b =  9766.73330427761 epoch =  16  loss = 2870.305  loss reduction = -20.72026  correctly classified = 89.6250%\n",
      "alpha =  0.7436842105263157 b =  9850.84993796182 epoch =  17  loss = 2828.865  loss reduction = 41.44053  correctly classified = 89.7750%\n",
      "alpha =  0.7436842105263157 b =  9938.677555856557 epoch =  18  loss = 2835.771  loss reduction = -6.906755  correctly classified = 89.7500%\n",
      "alpha =  0.7436842105263157 b =  10025.020780067083 epoch =  19  loss = 2821.958  loss reduction = 13.81351  correctly classified = 89.8000%\n",
      "alpha =  0.7436842105263157 b =  10110.621807435504 epoch =  20  loss = 2815.051  loss reduction = 6.906755  correctly classified = 89.8250%\n",
      "alpha =  0.7436842105263157 b =  10197.707228488136 epoch =  21  loss = 2801.238  loss reduction = 13.81351  correctly classified = 89.8750%\n",
      "alpha =  0.7436842105263157 b =  10280.339468488137 epoch =  22  loss = 2815.051  loss reduction = -13.81351  correctly classified = 89.8250%\n",
      "alpha =  0.7436842105263157 b =  10365.198299014453 epoch =  23  loss = 2808.144  loss reduction = 6.906755  correctly classified = 89.8500%\n",
      "alpha =  0.7436842105263157 b =  10448.572735856558 epoch =  24  loss = 2794.331  loss reduction = 13.81351  correctly classified = 89.9000%\n",
      "alpha =  0.7436842105263157 b =  10530.462779014453 epoch =  25  loss = 2808.144  loss reduction = -13.81351  correctly classified = 89.8500%\n",
      "alpha =  0.7436842105263157 b =  10614.579412698664 epoch =  26  loss = 2801.238  loss reduction = 6.906755  correctly classified = 89.8750%\n",
      "alpha =  0.7436842105263157 b =  10697.953849540769 epoch =  27  loss = 2808.144  loss reduction = -6.906755  correctly classified = 89.8500%\n",
      "alpha =  0.7436842105263157 b =  10782.07048322498 epoch =  28  loss = 2787.424  loss reduction = 20.72026  correctly classified = 89.9250%\n",
      "alpha =  0.7436842105263157 b =  10858.022951646031 epoch =  29  loss = 2780.517  loss reduction = 6.906755  correctly classified = 89.9500%\n",
      "alpha =  0.7436842105263157 b =  10944.366175856558 epoch =  30  loss = 2780.517  loss reduction = 0.0  correctly classified = 89.9500%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.7642105263157895 b =  11019.364268488136 epoch =  0  loss = 2739.077  loss reduction = 41.44053  correctly classified = 90.1000%\n",
      "alpha =  0.7642105263157895 b =  11108.090639014452 epoch =  1  loss = 2766.704  loss reduction = -27.62702  correctly classified = 90.0000%\n",
      "alpha =  0.7642105263157895 b =  11179.275321119716 epoch =  2  loss = 2732.17  loss reduction = 34.53377  correctly classified = 90.1250%\n",
      "alpha =  0.7642105263157895 b =  11272.577784277611 epoch =  3  loss = 2780.517  loss reduction = -48.34728  correctly classified = 89.9500%\n",
      "alpha =  0.7642105263157895 b =  11339.186373751296 epoch =  4  loss = 2718.357  loss reduction = 62.16079  correctly classified = 90.1750%\n",
      "alpha =  0.7642105263157895 b =  11429.438108488139 epoch =  5  loss = 2752.89  loss reduction = -34.53377  correctly classified = 90.0500%\n",
      "alpha =  0.7642105263157895 b =  11507.48692954077 epoch =  6  loss = 2711.45  loss reduction = 41.44053  correctly classified = 90.2000%\n",
      "alpha =  0.7642105263157895 b =  11586.298432698664 epoch =  7  loss = 2704.543  loss reduction = 6.906755  correctly classified = 90.2250%\n",
      "alpha =  0.7642105263157895 b =  11664.347253751295 epoch =  8  loss = 2697.636  loss reduction = 6.906755  correctly classified = 90.2500%\n",
      "alpha =  0.7642105263157895 b =  11742.396074803926 epoch =  9  loss = 2697.636  loss reduction = 0.0  correctly classified = 90.2500%\n",
      "alpha =  0.7847368421052632 b =  11818.625411646031 epoch =  0  loss = 2704.543  loss reduction = -6.906755  correctly classified = 90.2250%\n",
      "alpha =  0.7847368421052632 b =  11902.686422172346 epoch =  1  loss = 2704.543  loss reduction = 0.0  correctly classified = 90.2250%\n",
      "alpha =  0.8052631578947368 b =  11985.731601119714 epoch =  0  loss = 2690.73  loss reduction = 13.81351  correctly classified = 90.2750%\n",
      "alpha =  0.8052631578947368 b =  12067.973127435504 epoch =  1  loss = 2697.636  loss reduction = -6.906755  correctly classified = 90.2500%\n",
      "alpha =  0.8052631578947368 b =  12149.411001119714 epoch =  2  loss = 2690.73  loss reduction = 6.906755  correctly classified = 90.2750%\n",
      "alpha =  0.8052631578947368 b =  12229.241569540765 epoch =  3  loss = 2676.916  loss reduction = 13.81351  correctly classified = 90.3250%\n",
      "alpha =  0.8052631578947368 b =  12310.679443224975 epoch =  4  loss = 2690.73  loss reduction = -13.81351  correctly classified = 90.2750%\n",
      "alpha =  0.8052631578947368 b =  12390.510011646027 epoch =  5  loss = 2676.916  loss reduction = 13.81351  correctly classified = 90.3250%\n",
      "alpha =  0.8052631578947368 b =  12471.947885330237 epoch =  6  loss = 2676.916  loss reduction = 0.0  correctly classified = 90.3250%\n",
      "alpha =  0.8257894736842105 b =  12555.461626382868 epoch =  0  loss = 2676.916  loss reduction = 0.0  correctly classified = 90.3250%\n",
      "alpha =  0.8463157894736841 b =  12642.74048111971 epoch =  0  loss = 2690.73  loss reduction = -13.81351  correctly classified = 90.2750%\n",
      "alpha =  0.8463157894736841 b =  12727.485466382868 epoch =  1  loss = 2670.009  loss reduction = 20.72026  correctly classified = 90.3500%\n",
      "alpha =  0.8463157894736841 b =  12815.608944277605 epoch =  2  loss = 2683.823  loss reduction = -13.81351  correctly classified = 90.3000%\n",
      "alpha =  0.8463157894736841 b =  12891.06307480392 epoch =  3  loss = 2635.476  loss reduction = 48.34728  correctly classified = 90.4750%\n",
      "alpha =  0.8463157894736841 b =  12974.963436909184 epoch =  4  loss = 2649.289  loss reduction = -13.81351  correctly classified = 90.4250%\n",
      "alpha =  0.8463157894736841 b =  13058.019175856552 epoch =  5  loss = 2642.382  loss reduction = 6.906755  correctly classified = 90.4500%\n",
      "alpha =  0.8463157894736841 b =  13140.230291646027 epoch =  6  loss = 2635.476  loss reduction = 6.906755  correctly classified = 90.4750%\n",
      "alpha =  0.8463157894736841 b =  13220.752161119712 epoch =  7  loss = 2621.662  loss reduction = 13.81351  correctly classified = 90.5250%\n",
      "alpha =  0.8463157894736841 b =  13301.274030593397 epoch =  8  loss = 2621.662  loss reduction = 0.0  correctly classified = 90.5250%\n",
      "alpha =  0.8668421052631579 b =  13382.883747435502 epoch =  0  loss = 2614.755  loss reduction = 6.906755  correctly classified = 90.5500%\n",
      "alpha =  0.8668421052631579 b =  13467.088789540765 epoch =  1  loss = 2607.849  loss reduction = 6.906755  correctly classified = 90.5750%\n",
      "alpha =  0.8668421052631579 b =  13548.69850638287 epoch =  2  loss = 2614.755  loss reduction = -6.906755  correctly classified = 90.5500%\n",
      "alpha =  0.8668421052631579 b =  13638.09419901445 epoch =  3  loss = 2635.476  loss reduction = -20.72026  correctly classified = 90.4750%\n",
      "alpha =  0.8668421052631579 b =  13708.45750638287 epoch =  4  loss = 2580.222  loss reduction = 55.25404  correctly classified = 90.6750%\n",
      "alpha =  0.8668421052631579 b =  13796.122982172345 epoch =  5  loss = 2635.476  loss reduction = -55.25404  correctly classified = 90.4750%\n",
      "alpha =  0.8668421052631579 b =  13868.21650638287 epoch =  6  loss = 2580.222  loss reduction = 55.25404  correctly classified = 90.6750%\n",
      "alpha =  0.8668421052631579 b =  13949.826223224976 epoch =  7  loss = 2614.755  loss reduction = -34.53377  correctly classified = 90.5500%\n",
      "alpha =  0.8668421052631579 b =  14029.705723224977 epoch =  8  loss = 2600.942  loss reduction = 13.81351  correctly classified = 90.6000%\n",
      "alpha =  0.8668421052631579 b =  14111.315440067083 epoch =  9  loss = 2614.755  loss reduction = -13.81351  correctly classified = 90.5500%\n",
      "alpha =  0.8668421052631579 b =  14179.9485305934 epoch =  10  loss = 2538.781  loss reduction = 75.9743  correctly classified = 90.8250%\n",
      "alpha =  0.8668421052631579 b =  14258.097813751294 epoch =  11  loss = 2587.128  loss reduction = -48.34728  correctly classified = 90.6500%\n",
      "alpha =  0.8668421052631579 b =  14339.7075305934 epoch =  12  loss = 2614.755  loss reduction = -27.62702  correctly classified = 90.5500%\n",
      "alpha =  0.8668421052631579 b =  14411.801054803926 epoch =  13  loss = 2552.595  loss reduction = 62.16079  correctly classified = 90.7750%\n",
      "alpha =  0.8668421052631579 b =  14494.275880067084 epoch =  14  loss = 2621.662  loss reduction = -69.06755  correctly classified = 90.5250%\n",
      "alpha =  0.8668421052631579 b =  14565.504295856557 epoch =  15  loss = 2559.501  loss reduction = 62.16079  correctly classified = 90.7500%\n",
      "alpha =  0.8668421052631579 b =  14647.979121119715 epoch =  16  loss = 2621.662  loss reduction = -62.16079  correctly classified = 90.5250%\n",
      "alpha =  0.8668421052631579 b =  14717.477320067084 epoch =  17  loss = 2545.688  loss reduction = 75.9743  correctly classified = 90.8000%\n",
      "alpha =  0.8668421052631579 b =  14800.817253751295 epoch =  18  loss = 2628.569  loss reduction = -82.88106  correctly classified = 90.5000%\n",
      "alpha =  0.8668421052631579 b =  14871.180561119716 epoch =  19  loss = 2552.595  loss reduction = 75.9743  correctly classified = 90.7750%\n",
      "alpha =  0.8668421052631579 b =  14953.655386382874 epoch =  20  loss = 2621.662  loss reduction = -69.06755  correctly classified = 90.5250%\n",
      "alpha =  0.8668421052631579 b =  15028.344235856559 epoch =  21  loss = 2573.315  loss reduction = 48.34728  correctly classified = 90.7000%\n",
      "alpha =  0.8668421052631579 b =  15110.819061119717 epoch =  22  loss = 2607.849  loss reduction = -34.53377  correctly classified = 90.5750%\n",
      "alpha =  0.8668421052631579 b =  15180.317260067086 epoch =  23  loss = 2559.501  loss reduction = 48.34728  correctly classified = 90.7500%\n",
      "alpha =  0.8668421052631579 b =  15267.98273585656 epoch =  24  loss = 2621.662  loss reduction = -62.16079  correctly classified = 90.5250%\n",
      "alpha =  0.8668421052631579 b =  15325.369416909192 epoch =  25  loss = 2518.061  loss reduction = 103.6013  correctly classified = 90.9000%\n",
      "alpha =  0.8668421052631579 b =  15445.043904277614 epoch =  26  loss = 2656.196  loss reduction = -138.1351  correctly classified = 90.4000%\n",
      "alpha =  0.8668421052631579 b =  15418.515068488141 epoch =  27  loss = 2524.967  loss reduction = 131.2283  correctly classified = 90.8750%\n",
      "alpha =  0.8668421052631579 b =  15690.448637961825 epoch =  28  loss = 3139.669  loss reduction = -614.7012  correctly classified = 88.6500%\n",
      "alpha =  0.8668421052631579 b =  15404.387275856561 epoch =  29  loss = 3409.032  loss reduction = -269.3634  correctly classified = 87.6750%\n",
      "alpha =  0.8668421052631579 b =  16030.150189540771 epoch =  30  loss = 5356.737  loss reduction = -1947.705  correctly classified = 80.6250%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.8668421052631579 b =  14391.924365330244 epoch =  31  loss = 13182.09  loss reduction = -7825.353  correctly classified = 52.3000%\n",
      "alpha =  0.8668421052631579 b =  15391.41411690919 epoch =  32  loss = 8008.931  loss reduction = 5173.159  correctly classified = 71.0250%\n",
      "alpha =  0.8668421052631579 b =  14899.456950593401 epoch =  33  loss = 4790.383  loss reduction = 3218.548  correctly classified = 82.6750%\n",
      "alpha =  0.8668421052631579 b =  15684.399813751295 epoch =  34  loss = 6434.191  loss reduction = -1643.808  correctly classified = 76.7250%\n",
      "alpha =  0.8668421052631579 b =  13931.979677961823 epoch =  35  loss = 14079.97  loss reduction = -7645.778  correctly classified = 49.0500%\n",
      "alpha =  0.8668421052631579 b =  14932.334537961822 epoch =  36  loss = 8015.838  loss reduction = 6064.131  correctly classified = 71.0000%\n",
      "alpha =  0.8668421052631579 b =  14493.148985330243 epoch =  37  loss = 4451.952  loss reduction = 3563.885  correctly classified = 83.9000%\n",
      "alpha =  0.8668421052631579 b =  15223.590017961822 epoch =  38  loss = 6026.692  loss reduction = -1574.74  correctly classified = 78.2000%\n",
      "alpha =  0.8668421052631579 b =  13588.824627435506 epoch =  39  loss = 13195.9  loss reduction = -7169.211  correctly classified = 52.2500%\n",
      "alpha =  0.8668421052631579 b =  14582.258620067085 epoch =  40  loss = 7960.584  loss reduction = 5235.32  correctly classified = 71.2000%\n",
      "alpha =  0.8668421052631579 b =  14043.585599014454 epoch =  41  loss = 5204.788  loss reduction = 2755.795  correctly classified = 81.1750%\n",
      "alpha =  0.8668421052631579 b =  14825.068028488138 epoch =  42  loss = 6406.564  loss reduction = -1201.775  correctly classified = 76.8250%\n",
      "alpha =  0.8668421052631579 b =  13208.469914803927 epoch =  43  loss = 13064.68  loss reduction = -6658.112  correctly classified = 52.7250%\n",
      "alpha =  0.8668421052631579 b =  14201.038799014454 epoch =  44  loss = 7953.677  loss reduction = 5110.999  correctly classified = 71.2250%\n",
      "alpha =  0.8668421052631579 b =  13614.784814803927 epoch =  45  loss = 5487.965  loss reduction = 2465.711  correctly classified = 80.1500%\n",
      "alpha =  0.8668421052631579 b =  14376.3697505934 epoch =  46  loss = 6247.708  loss reduction = -759.743  correctly classified = 77.4000%\n",
      "alpha =  0.8668421052631579 b =  12862.719539014452 epoch =  47  loss = 12477.6  loss reduction = -6229.893  correctly classified = 54.8500%\n",
      "alpha =  0.8668421052631579 b =  13847.502447435505 epoch =  48  loss = 7891.516  loss reduction = 4586.085  correctly classified = 71.4500%\n",
      "alpha =  0.8668421052631579 b =  13173.872512698663 epoch =  49  loss = 6144.107  loss reduction = 1747.409  correctly classified = 77.7750%\n",
      "alpha =  0.8668421052631579 b =  13951.029400067084 epoch =  50  loss = 6344.403  loss reduction = -200.2959  correctly classified = 77.0500%\n",
      "alpha =  0.8668421052631579 b =  12504.857645330241 epoch =  51  loss = 11952.69  loss reduction = -5608.285  correctly classified = 56.7500%\n",
      "alpha =  0.8668421052631579 b =  13472.33838533024 epoch =  52  loss = 7767.194  loss reduction = 4185.493  correctly classified = 71.9000%\n",
      "alpha =  0.8668421052631579 b =  12736.420644277609 epoch =  53  loss = 6641.393  loss reduction = 1125.801  correctly classified = 75.9750%\n",
      "alpha =  0.8668421052631579 b =  13508.386881119714 epoch =  54  loss = 6302.962  loss reduction = 338.431  correctly classified = 77.2000%\n",
      "alpha =  0.8668421052631579 b =  12164.297920067082 epoch =  55  loss = 11151.5  loss reduction = -4848.542  correctly classified = 59.6500%\n",
      "alpha =  0.8668421052631579 b =  13108.42073269866 epoch =  56  loss = 7608.339  loss reduction = 3543.165  correctly classified = 72.4750%\n",
      "alpha =  0.8668421052631579 b =  12277.341065330238 epoch =  57  loss = 7304.442  loss reduction = 303.8972  correctly classified = 73.5750%\n",
      "alpha =  0.8668421052631579 b =  13069.204795856554 epoch =  58  loss = 6448.004  loss reduction = 856.4376  correctly classified = 76.6750%\n",
      "alpha =  0.8668421052631579 b =  11771.831689540766 epoch =  59  loss = 10806.17  loss reduction = -4358.162  correctly classified = 60.9000%\n",
      "alpha =  0.8668421052631579 b =  12699.517442172346 epoch =  60  loss = 7490.924  loss reduction = 3315.242  correctly classified = 72.9000%\n",
      "alpha =  0.8668421052631579 b =  11852.000714803926 epoch =  61  loss = 7435.67  loss reduction = 55.25404  correctly classified = 73.1000%\n",
      "alpha =  0.8668421052631579 b =  12617.04608427761 epoch =  62  loss = 6247.708  loss reduction = 1187.962  correctly classified = 77.4000%\n",
      "alpha =  0.8668421052631579 b =  11446.843915856558 epoch =  63  loss = 9859.941  loss reduction = -3612.233  correctly classified = 64.3250%\n",
      "alpha =  0.8668421052631579 b =  12331.274247435505 epoch =  64  loss = 7159.4  loss reduction = 2700.541  correctly classified = 74.1000%\n",
      "alpha =  0.8668421052631579 b =  11361.777232698663 epoch =  65  loss = 8326.642  loss reduction = -1167.242  correctly classified = 69.8750%\n",
      "alpha =  0.8668421052631579 b =  12164.887372698664 epoch =  66  loss = 6537.792  loss reduction = 1788.849  correctly classified = 76.3500%\n",
      "alpha =  0.8668421052631579 b =  11052.647468488138 epoch =  67  loss = 9424.816  loss reduction = -2887.023  correctly classified = 65.9000%\n",
      "alpha =  0.8668421052631579 b =  11911.124547435506 epoch =  68  loss = 6966.011  loss reduction = 2458.805  correctly classified = 74.8000%\n",
      "alpha =  0.8668421052631579 b =  10889.721027435506 epoch =  69  loss = 8741.047  loss reduction = -1775.036  correctly classified = 68.3750%\n",
      "alpha =  0.8668421052631579 b =  11697.156709540768 epoch =  70  loss = 6572.326  loss reduction = 2168.721  correctly classified = 76.2250%\n",
      "alpha =  0.8668421052631579 b =  10667.967213751293 epoch =  71  loss = 8803.208  loss reduction = -2230.882  correctly classified = 68.1500%\n",
      "alpha =  0.8668421052631579 b =  11471.077353751294 epoch =  72  loss = 6537.792  loss reduction = 2265.416  correctly classified = 76.3500%\n",
      "alpha =  0.8668421052631579 b =  10486.008387435504 epoch =  73  loss = 8478.59  loss reduction = -1940.798  correctly classified = 69.3250%\n",
      "alpha =  0.8668421052631579 b =  11250.188648488136 epoch =  74  loss = 6240.802  loss reduction = 2237.789  correctly classified = 77.4250%\n",
      "alpha =  0.8668421052631579 b =  10296.263585330242 epoch =  75  loss = 8271.387  loss reduction = -2030.586  correctly classified = 70.0750%\n",
      "alpha =  0.8668421052631579 b =  11045.737003224978 epoch =  76  loss = 6137.2  loss reduction = 2134.187  correctly classified = 77.8000%\n",
      "alpha =  0.8668421052631579 b =  10121.225626382873 epoch =  77  loss = 8036.558  loss reduction = -1899.358  correctly classified = 70.9250%\n",
      "alpha =  0.8668421052631579 b =  10845.610900067084 epoch =  78  loss = 5978.345  loss reduction = 2058.213  correctly classified = 78.3750%\n",
      "alpha =  0.8668421052631579 b =  9984.25243796182 epoch =  79  loss = 7587.619  loss reduction = -1609.274  correctly classified = 72.5500%\n",
      "alpha =  0.8668421052631579 b =  10680.089133751295 epoch =  80  loss = 5819.49  loss reduction = 1768.129  correctly classified = 78.9500%\n",
      "alpha =  0.8668421052631579 b =  9868.906960067085 epoch =  81  loss = 7242.281  loss reduction = -1422.791  correctly classified = 73.8000%\n",
      "alpha =  0.8668421052631579 b =  10546.576379014454 epoch =  82  loss = 5729.702  loss reduction = 1512.579  correctly classified = 79.2750%\n",
      "alpha =  0.8668421052631579 b =  9775.189192698665 epoch =  83  loss = 6993.638  loss reduction = -1263.936  correctly classified = 74.7000%\n",
      "alpha =  0.8668421052631579 b =  10427.770467435506 epoch =  84  loss = 5557.033  loss reduction = 1436.605  correctly classified = 79.9000%\n",
      "alpha =  0.8668421052631579 b =  9679.741208488138 epoch =  85  loss = 6820.969  loss reduction = -1263.936  correctly classified = 75.3250%\n",
      "alpha =  0.8668421052631579 b =  10311.559881119716 epoch =  86  loss = 5405.084  loss reduction = 1415.885  correctly classified = 80.4500%\n",
      "alpha =  0.8668421052631579 b =  9637.929946382874 epoch =  87  loss = 6337.496  loss reduction = -932.4119  correctly classified = 77.0750%\n",
      "alpha =  0.8668421052631579 b =  10234.279173751294 epoch =  88  loss = 5149.534  loss reduction = 1187.962  correctly classified = 81.3750%\n",
      "alpha =  0.8668421052631579 b =  9650.620514803926 epoch =  89  loss = 5674.448  loss reduction = -524.9134  correctly classified = 79.4750%\n",
      "alpha =  0.8668421052631579 b =  10207.174754803926 epoch =  90  loss = 4928.518  loss reduction = 745.9295  correctly classified = 82.1750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.8668421052631579 b =  9687.534119014452 epoch =  91  loss = 5301.483  loss reduction = -372.9648  correctly classified = 80.8250%\n",
      "alpha =  0.8668421052631579 b =  10242.358142172347 epoch =  92  loss = 4928.518  loss reduction = 372.9648  correctly classified = 82.1750%\n",
      "alpha =  0.8668421052631579 b =  9741.74989164603 epoch =  93  loss = 5177.161  loss reduction = -248.6432  correctly classified = 81.2750%\n",
      "alpha =  0.8668421052631579 b =  10288.787939014452 epoch =  94  loss = 4880.171  loss reduction = 296.9905  correctly classified = 82.3500%\n",
      "alpha =  0.8668421052631579 b =  9807.212073751294 epoch =  95  loss = 5066.653  loss reduction = -186.4824  correctly classified = 81.6750%\n",
      "alpha =  0.8668421052631579 b =  10304.938941119715 epoch =  96  loss = 4596.994  loss reduction = 469.6593  correctly classified = 83.3750%\n",
      "alpha =  0.8668421052631579 b =  9911.604134803925 epoch =  97  loss = 4445.045  loss reduction = 151.9486  correctly classified = 83.9250%\n",
      "alpha =  0.8668421052631579 b =  10360.884930593398 epoch =  98  loss = 4389.791  loss reduction = 55.25404  correctly classified = 84.1250%\n",
      "alpha =  0.8668421052631579 b =  10075.688676909187 epoch =  99  loss = 3913.225  loss reduction = 476.5661  correctly classified = 85.8500%\n",
      "alpha =  0.8668421052631579 b =  10461.816557961818 epoch =  100  loss = 4065.174  loss reduction = -151.9486  correctly classified = 85.3000%\n",
      "alpha =  0.8668421052631579 b =  10296.00526638287 epoch =  101  loss = 3291.617  loss reduction = 773.5565  correctly classified = 88.1000%\n",
      "alpha =  0.8668421052631579 b =  10594.757196909186 epoch =  102  loss = 3602.421  loss reduction = -310.804  correctly classified = 86.9750%\n",
      "alpha =  0.8668421052631579 b =  10483.447735856555 epoch =  103  loss = 3105.135  loss reduction = 497.2863  correctly classified = 88.7750%\n",
      "alpha =  0.8668421052631579 b =  10757.976630593397 epoch =  104  loss = 3464.286  loss reduction = -359.1512  correctly classified = 87.4750%\n",
      "alpha =  0.8668421052631579 b =  10738.368662172345 epoch =  105  loss = 2967.0  loss reduction = 497.2863  correctly classified = 89.2750%\n",
      "alpha =  0.8668421052631579 b =  10942.823774803923 epoch =  106  loss = 3291.617  loss reduction = -324.6175  correctly classified = 88.1000%\n",
      "alpha =  0.8668421052631579 b =  11018.37773269866 epoch =  107  loss = 2967.0  loss reduction = 324.6175  correctly classified = 89.2750%\n",
      "alpha =  0.8668421052631579 b =  11192.554050593397 epoch =  108  loss = 3146.575  loss reduction = -179.5756  correctly classified = 88.6250%\n",
      "alpha =  0.8668421052631579 b =  11306.172779014449 epoch =  109  loss = 3008.44  loss reduction = 138.1351  correctly classified = 89.1250%\n",
      "alpha =  0.8668421052631579 b =  11456.126061119712 epoch =  110  loss = 3077.508  loss reduction = -69.06755  correctly classified = 88.8750%\n",
      "alpha =  0.8668421052631579 b =  11587.046957961817 epoch =  111  loss = 3022.254  loss reduction = 55.25404  correctly classified = 89.0750%\n",
      "alpha =  0.8668421052631579 b =  11722.293396909185 epoch =  112  loss = 3029.161  loss reduction = -6.906755  correctly classified = 89.0500%\n",
      "alpha =  0.8668421052631579 b =  11853.214293751289 epoch =  113  loss = 3022.254  loss reduction = 6.906755  correctly classified = 89.0750%\n",
      "alpha =  0.8668421052631579 b =  11989.32584111971 epoch =  114  loss = 3022.254  loss reduction = 0.0  correctly classified = 89.0750%\n",
      "alpha =  0.8873684210526316 b =  12120.6900874355 epoch =  0  loss = 3001.534  loss reduction = 20.72026  correctly classified = 89.1500%\n",
      "alpha =  0.8873684210526316 b =  12257.367895856552 epoch =  1  loss = 3001.534  loss reduction = 0.0  correctly classified = 89.1500%\n",
      "alpha =  0.9078947368421053 b =  12389.052580067078 epoch =  0  loss = 2994.627  loss reduction = 6.906755  correctly classified = 89.1750%\n",
      "alpha =  0.9078947368421053 b =  12522.549422172342 epoch =  1  loss = 2994.627  loss reduction = 0.0  correctly classified = 89.1750%\n",
      "alpha =  0.9284210526315789 b =  12659.991017961816 epoch =  0  loss = 2987.72  loss reduction = 6.906755  correctly classified = 89.2000%\n",
      "alpha =  0.9284210526315789 b =  12798.359177961816 epoch =  1  loss = 2994.627  loss reduction = -6.906755  correctly classified = 89.1750%\n",
      "alpha =  0.9284210526315789 b =  12935.80077375129 epoch =  2  loss = 2987.72  loss reduction = 6.906755  correctly classified = 89.2000%\n",
      "alpha =  0.9284210526315789 b =  13076.022062172344 epoch =  3  loss = 2980.813  loss reduction = 6.906755  correctly classified = 89.2250%\n",
      "alpha =  0.9284210526315789 b =  13213.463657961818 epoch =  4  loss = 2960.093  loss reduction = 20.72026  correctly classified = 89.3000%\n",
      "alpha =  0.9284210526315789 b =  13352.758382172344 epoch =  5  loss = 2946.28  loss reduction = 13.81351  correctly classified = 89.3500%\n",
      "alpha =  0.9284210526315789 b =  13492.979670593397 epoch =  6  loss = 2939.373  loss reduction = 6.906755  correctly classified = 89.3750%\n",
      "alpha =  0.9284210526315789 b =  13631.347830593397 epoch =  7  loss = 2925.559  loss reduction = 13.81351  correctly classified = 89.4250%\n",
      "alpha =  0.9284210526315789 b =  13768.789426382871 epoch =  8  loss = 2904.839  loss reduction = 20.72026  correctly classified = 89.5000%\n",
      "alpha =  0.9284210526315789 b =  13904.377893751293 epoch =  9  loss = 2891.025  loss reduction = 13.81351  correctly classified = 89.5500%\n",
      "alpha =  0.9284210526315789 b =  14041.819489540767 epoch =  10  loss = 2891.025  loss reduction = 0.0  correctly classified = 89.5500%\n",
      "alpha =  0.9489473684210525 b =  14177.564512698662 epoch =  0  loss = 2870.305  loss reduction = 20.72026  correctly classified = 89.6250%\n",
      "alpha =  0.9489473684210525 b =  14318.044783224977 epoch =  1  loss = 2891.025  loss reduction = -20.72026  correctly classified = 89.5500%\n",
      "alpha =  0.9489473684210525 b =  14451.895707435504 epoch =  2  loss = 2870.305  loss reduction = 20.72026  correctly classified = 89.6250%\n",
      "alpha =  0.9489473684210525 b =  14594.270076909188 epoch =  3  loss = 2904.839  loss reduction = -34.53377  correctly classified = 89.5000%\n",
      "alpha =  0.9489473684210525 b =  14724.332803224977 epoch =  4  loss = 2842.678  loss reduction = 62.16079  correctly classified = 89.7250%\n",
      "alpha =  0.9489473684210525 b =  14859.130776909187 epoch =  5  loss = 2849.585  loss reduction = -6.906755  correctly classified = 89.7000%\n",
      "alpha =  0.9489473684210525 b =  14992.034651646029 epoch =  6  loss = 2835.771  loss reduction = 13.81351  correctly classified = 89.7500%\n",
      "alpha =  0.9489473684210525 b =  15128.726724277607 epoch =  7  loss = 2835.771  loss reduction = 0.0  correctly classified = 89.7500%\n",
      "alpha =  0.9694736842105263 b =  15244.187162172344 epoch =  0  loss = 2801.238  loss reduction = 34.53377  correctly classified = 89.8750%\n",
      "alpha =  0.9694736842105263 b =  15395.446385330239 epoch =  1  loss = 2891.025  loss reduction = -89.78781  correctly classified = 89.5500%\n",
      "alpha =  0.9694736842105263 b =  15500.263941119712 epoch =  2  loss = 2808.144  loss reduction = 82.88106  correctly classified = 89.8500%\n",
      "alpha =  0.9694736842105263 b =  15653.458233751291 epoch =  3  loss = 2891.025  loss reduction = -82.88106  correctly classified = 89.5500%\n",
      "alpha =  0.9694736842105263 b =  15741.82769901445 epoch =  4  loss = 2787.424  loss reduction = 103.6013  correctly classified = 89.9250%\n",
      "alpha =  0.9694736842105263 b =  15890.184317961817 epoch =  5  loss = 2856.492  loss reduction = -69.06755  correctly classified = 89.6750%\n",
      "alpha =  0.9694736842105263 b =  15989.196665330239 epoch =  6  loss = 2766.704  loss reduction = 89.78781  correctly classified = 90.0000%\n",
      "alpha =  0.9694736842105263 b =  16140.455888488133 epoch =  7  loss = 2863.398  loss reduction = -96.69457  correctly classified = 89.6500%\n",
      "alpha =  0.9694736842105263 b =  16226.890284277608 epoch =  8  loss = 2759.797  loss reduction = 103.6013  correctly classified = 90.0250%\n",
      "alpha =  0.9694736842105263 b =  16376.214437961818 epoch =  9  loss = 2835.771  loss reduction = -75.9743  correctly classified = 89.7500%\n",
      "alpha =  0.9694736842105263 b =  16470.38911164603 epoch =  10  loss = 2759.797  loss reduction = 75.9743  correctly classified = 90.0250%\n",
      "alpha =  0.9694736842105263 b =  16624.55093901445 epoch =  11  loss = 2842.678  loss reduction = -82.88106  correctly classified = 89.7250%\n",
      "alpha =  0.9694736842105263 b =  16688.732035856556 epoch =  12  loss = 2739.077  loss reduction = 103.6013  correctly classified = 90.1000%\n",
      "alpha =  0.9694736842105263 b =  16851.601675856557 epoch =  13  loss = 2863.398  loss reduction = -124.3216  correctly classified = 89.6500%\n",
      "alpha =  0.9694736842105263 b =  16897.39961269866 epoch =  14  loss = 2690.73  loss reduction = 172.6689  correctly classified = 90.2750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.9694736842105263 b =  17112.516128488132 epoch =  15  loss = 2973.907  loss reduction = -283.1769  correctly classified = 89.2500%\n",
      "alpha =  0.9694736842105263 b =  17069.300869540763 epoch =  16  loss = 2704.543  loss reduction = 269.3634  correctly classified = 90.2250%\n",
      "alpha =  0.9694736842105263 b =  17401.48908848813 epoch =  17  loss = 3409.032  loss reduction = -704.489  correctly classified = 87.6750%\n",
      "alpha =  0.9694736842105263 b =  17138.643444277604 epoch =  18  loss = 3319.244  loss reduction = 89.78781  correctly classified = 88.0000%\n",
      "alpha =  0.9694736842105263 b =  17666.27368006708 epoch =  19  loss = 4320.724  loss reduction = -1001.479  correctly classified = 84.3750%\n",
      "alpha =  0.9694736842105263 b =  16901.2775074355 epoch =  20  loss = 6199.361  loss reduction = -1878.637  correctly classified = 77.5750%\n",
      "alpha =  0.9694736842105263 b =  17797.538477961818 epoch =  21  loss = 6523.979  loss reduction = -324.6175  correctly classified = 76.4000%\n",
      "alpha =  0.9694736842105263 b =  16065.975103224977 epoch =  22  loss = 12546.67  loss reduction = -6022.69  correctly classified = 54.6000%\n",
      "alpha =  0.9694736842105263 b =  17169.288507435504 epoch =  23  loss = 7905.329  loss reduction = 4641.339  correctly classified = 71.4000%\n",
      "alpha =  0.9694736842105263 b =  16459.441814803926 epoch =  24  loss = 5874.744  loss reduction = 2030.586  correctly classified = 78.7500%\n",
      "alpha =  0.9694736842105263 b =  17302.488374803925 epoch =  25  loss = 6157.921  loss reduction = -283.1769  correctly classified = 77.7250%\n",
      "alpha =  0.9694736842105263 b =  15706.379863224978 epoch =  26  loss = 11800.74  loss reduction = -5642.819  correctly classified = 57.3000%\n",
      "alpha =  0.9694736842105263 b =  16787.439968488135 epoch =  27  loss = 7760.288  loss reduction = 4040.452  correctly classified = 71.9250%\n",
      "alpha =  0.9694736842105263 b =  15941.17087796182 epoch =  28  loss = 6765.715  loss reduction = 994.5727  correctly classified = 75.5250%\n",
      "alpha =  0.9694736842105263 b =  16818.081153751293 epoch =  29  loss = 6399.657  loss reduction = 366.058  correctly classified = 76.8500%\n",
      "alpha =  0.9694736842105263 b =  15269.381844277608 epoch =  30  loss = 11476.12  loss reduction = -5076.465  correctly classified = 58.4750%\n",
      "alpha =  0.9694736842105263 b =  16334.961393751293 epoch =  31  loss = 7663.593  loss reduction = 3812.529  correctly classified = 72.2750%\n",
      "alpha =  0.9694736842105263 b =  15453.861052698661 epoch =  32  loss = 7014.358  loss reduction = 649.2349  correctly classified = 74.6250%\n",
      "alpha =  0.9694736842105263 b =  16311.420633751293 epoch =  33  loss = 6261.522  loss reduction = 752.8363  correctly classified = 77.3500%\n",
      "alpha =  0.9694736842105263 b =  14888.500840067083 epoch =  34  loss = 10605.87  loss reduction = -4344.349  correctly classified = 61.6250%\n",
      "alpha =  0.9694736842105263 b =  15923.11927796182 epoch =  35  loss = 7470.204  loss reduction = 3135.667  correctly classified = 72.9750%\n",
      "alpha =  0.9694736842105263 b =  14940.427789540767 epoch =  36  loss = 7601.432  loss reduction = -131.2283  correctly classified = 72.5000%\n",
      "alpha =  0.9694736842105263 b =  15811.532856909187 epoch =  37  loss = 6358.216  loss reduction = 1243.216  correctly classified = 77.0000%\n",
      "alpha =  0.9694736842105263 b =  14475.691189540767 epoch =  38  loss = 10039.52  loss reduction = -3681.3  correctly classified = 63.6750%\n",
      "alpha =  0.9694736842105263 b =  15475.478376909188 epoch =  39  loss = 7235.374  loss reduction = 2804.142  correctly classified = 73.8250%\n",
      "alpha =  0.9694736842105263 b =  14399.903553751294 epoch =  40  loss = 8264.481  loss reduction = -1029.106  correctly classified = 70.1000%\n",
      "alpha =  0.9694736842105263 b =  15295.196989540767 epoch =  41  loss = 6517.072  loss reduction = 1747.409  correctly classified = 76.4250%\n",
      "alpha =  0.9694736842105263 b =  14034.82303164603 epoch =  42  loss = 9528.417  loss reduction = -3011.345  correctly classified = 65.5250%\n",
      "alpha =  0.9694736842105263 b =  14999.778968488135 epoch =  43  loss = 7000.545  loss reduction = 2527.872  correctly classified = 74.6750%\n",
      "alpha =  0.9694736842105263 b =  13883.567686382872 epoch =  44  loss = 8540.751  loss reduction = -1540.206  correctly classified = 69.1000%\n",
      "alpha =  0.9694736842105263 b =  14774.023448488135 epoch =  45  loss = 6496.351  loss reduction = 2044.399  correctly classified = 76.5000%\n",
      "alpha =  0.9694736842105263 b =  13608.467894803925 epoch =  46  loss = 8892.995  loss reduction = -2396.644  correctly classified = 67.8250%\n",
      "alpha =  0.9694736842105263 b =  14520.209421119715 epoch =  47  loss = 6634.487  loss reduction = 2258.509  correctly classified = 76.0000%\n",
      "alpha =  0.9694736842105263 b =  13368.199353751294 epoch =  48  loss = 8810.114  loss reduction = -2175.628  correctly classified = 68.1250%\n",
      "alpha =  0.9694736842105263 b =  14259.6226505934 epoch =  49  loss = 6503.258  loss reduction = 2306.856  correctly classified = 76.4750%\n",
      "alpha =  0.9694736842105263 b =  13156.956854803926 epoch =  50  loss = 8485.497  loss reduction = -1982.239  correctly classified = 69.3000%\n",
      "alpha =  0.9694736842105263 b =  14007.743692698663 epoch =  51  loss = 6226.988  loss reduction = 2258.509  correctly classified = 77.4750%\n",
      "alpha =  0.9694736842105263 b =  12955.389703224979 epoch =  52  loss = 8167.786  loss reduction = -1940.798  correctly classified = 70.4500%\n",
      "alpha =  0.9694736842105263 b =  13781.020637961821 epoch =  53  loss = 6075.039  loss reduction = 2092.747  correctly classified = 78.0250%\n",
      "alpha =  0.9694736842105263 b =  12776.0758505934 epoch =  54  loss = 7829.355  loss reduction = -1754.316  correctly classified = 71.6750%\n",
      "alpha =  0.9694736842105263 b =  13562.037861119717 epoch =  55  loss = 5874.744  loss reduction = 1954.612  correctly classified = 78.7500%\n",
      "alpha =  0.9694736842105263 b =  12649.008873751296 epoch =  56  loss = 7283.722  loss reduction = -1408.978  correctly classified = 73.6500%\n",
      "alpha =  0.9694736842105263 b =  13404.977307435507 epoch =  57  loss = 5715.888  loss reduction = 1567.833  correctly classified = 79.3250%\n",
      "alpha =  0.9694736842105263 b =  12535.487383224981 epoch =  58  loss = 7014.358  loss reduction = -1298.47  correctly classified = 74.6250%\n",
      "alpha =  0.9694736842105263 b =  13270.170052698666 epoch =  59  loss = 5563.94  loss reduction = 1450.419  correctly classified = 79.8750%\n",
      "alpha =  0.9694736842105263 b =  12428.73863585656 epoch =  60  loss = 6855.503  loss reduction = -1291.563  correctly classified = 75.2000%\n",
      "alpha =  0.9694736842105263 b =  13148.908284277613 epoch =  61  loss = 5501.779  loss reduction = 1353.724  correctly classified = 80.1000%\n",
      "alpha =  0.9694736842105263 b =  12370.366625330245 epoch =  62  loss = 6461.818  loss reduction = -960.0389  correctly classified = 76.6250%\n",
      "alpha =  0.9694736842105263 b =  13038.289397961824 epoch =  63  loss = 5142.628  loss reduction = 1319.19  correctly classified = 81.4000%\n",
      "alpha =  0.9694736842105263 b =  12383.592185330244 epoch =  64  loss = 5688.261  loss reduction = -545.6336  correctly classified = 79.4250%\n",
      "alpha =  0.9694736842105263 b =  13006.040825330245 epoch =  65  loss = 4956.145  loss reduction = 732.116  correctly classified = 82.0750%\n",
      "alpha =  0.9694736842105263 b =  12421.006113751297 epoch =  66  loss = 5260.042  loss reduction = -303.8972  correctly classified = 80.9750%\n",
      "alpha =  0.9694736842105263 b =  13027.974197961823 epoch =  67  loss = 4859.451  loss reduction = 400.5918  correctly classified = 82.4250%\n",
      "alpha =  0.9694736842105263 b =  12503.894174803929 epoch =  68  loss = 4963.052  loss reduction = -103.6013  correctly classified = 82.0500%\n",
      "alpha =  0.9694736842105263 b =  13055.712779014455 epoch =  69  loss = 4590.087  loss reduction = 372.9648  correctly classified = 83.4000%\n",
      "alpha =  0.9694736842105263 b =  12636.126507435507 epoch =  70  loss = 4369.071  loss reduction = 221.0162  correctly classified = 84.2000%\n",
      "alpha =  0.9694736842105263 b =  13123.120284277613 epoch =  71  loss = 4334.537  loss reduction = 34.53377  correctly classified = 84.3250%\n",
      "alpha =  0.9694736842105263 b =  12824.475854803928 epoch =  72  loss = 3823.437  loss reduction = 511.0999  correctly classified = 86.1750%\n",
      "alpha =  0.9694736842105263 b =  13230.196713751297 epoch =  73  loss = 3975.386  loss reduction = -151.9486  correctly classified = 85.6250%\n",
      "alpha =  0.9694736842105263 b =  13066.039612698665 epoch =  74  loss = 3194.923  loss reduction = 780.4633  correctly classified = 88.4500%\n",
      "alpha =  0.9694736842105263 b =  13389.520019014455 epoch =  75  loss = 3567.887  loss reduction = -372.9648  correctly classified = 87.1000%\n",
      "alpha =  0.9694736842105263 b =  13292.122814803928 epoch =  76  loss = 3008.44  loss reduction = 559.4471  correctly classified = 89.1250%\n",
      "alpha =  0.9694736842105263 b =  13585.609644277612 epoch =  77  loss = 3464.286  loss reduction = -455.8458  correctly classified = 87.4750%\n",
      "alpha =  0.9694736842105263 b =  13578.193170593402 epoch =  78  loss = 2960.093  loss reduction = 504.1931  correctly classified = 89.3000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.9694736842105263 b =  13800.082429540771 epoch =  79  loss = 3270.897  loss reduction = -310.804  correctly classified = 88.1750%\n",
      "alpha =  0.9694736842105263 b =  13901.997381119718 epoch =  80  loss = 2980.813  loss reduction = 290.0837  correctly classified = 89.2250%\n",
      "alpha =  0.9694736842105263 b =  14072.607299014455 epoch =  81  loss = 3098.228  loss reduction = -117.4148  correctly classified = 88.8000%\n",
      "alpha =  0.9694736842105263 b =  14196.775549540771 epoch =  82  loss = 2973.907  loss reduction = 124.3216  correctly classified = 89.2500%\n",
      "alpha =  0.9694736842105263 b =  14362.547793751297 epoch =  83  loss = 3077.508  loss reduction = -103.6013  correctly classified = 88.8750%\n",
      "alpha =  0.9694736842105263 b =  14497.358926382876 epoch =  84  loss = 2994.627  loss reduction = 82.88106  correctly classified = 89.1750%\n",
      "alpha =  0.9694736842105263 b =  14648.61814954077 epoch =  85  loss = 3042.974  loss reduction = -48.34728  correctly classified = 89.0000%\n",
      "alpha =  0.9694736842105263 b =  14782.461747435507 epoch =  86  loss = 3001.534  loss reduction = 41.44053  correctly classified = 89.1500%\n",
      "alpha =  0.9694736842105263 b =  14932.75343585656 epoch =  87  loss = 3036.067  loss reduction = -34.53377  correctly classified = 89.0250%\n",
      "alpha =  0.9694736842105263 b =  15066.597033751297 epoch =  88  loss = 2987.72  loss reduction = 48.34728  correctly classified = 89.2000%\n",
      "alpha =  0.9694736842105263 b =  15216.88872217235 epoch =  89  loss = 3022.254  loss reduction = -34.53377  correctly classified = 89.0750%\n",
      "alpha =  0.9694736842105263 b =  15347.829715856562 epoch =  90  loss = 2967.0  loss reduction = 55.25404  correctly classified = 89.2750%\n",
      "alpha =  0.9694736842105263 b =  15498.121404277616 epoch =  91  loss = 3022.254  loss reduction = -55.25404  correctly classified = 89.0750%\n",
      "alpha =  0.9694736842105263 b =  15630.029932698668 epoch =  92  loss = 2987.72  loss reduction = 34.53377  correctly classified = 89.2000%\n",
      "alpha =  0.9694736842105263 b =  15776.451482172351 epoch =  93  loss = 2994.627  loss reduction = -6.906755  correctly classified = 89.1750%\n",
      "alpha =  0.9694736842105263 b =  15909.327545330247 epoch =  94  loss = 2980.813  loss reduction = 13.81351  correctly classified = 89.2250%\n",
      "alpha =  0.9694736842105263 b =  16052.846490593405 epoch =  95  loss = 2987.72  loss reduction = -6.906755  correctly classified = 89.2000%\n",
      "alpha =  0.9694736842105263 b =  16192.495296909196 epoch =  96  loss = 2973.907  loss reduction = 13.81351  correctly classified = 89.2500%\n",
      "alpha =  0.9694736842105263 b =  16334.07917269867 epoch =  97  loss = 2987.72  loss reduction = -13.81351  correctly classified = 89.2000%\n",
      "alpha =  0.9694736842105263 b =  16472.760444277617 epoch =  98  loss = 2953.186  loss reduction = 34.53377  correctly classified = 89.3250%\n",
      "alpha =  0.9694736842105263 b =  16615.311854803935 epoch =  99  loss = 2953.186  loss reduction = 0.0  correctly classified = 89.3250%\n",
      "alpha =  0.99 b =  16756.929374803934 epoch =  0  loss = 2925.559  loss reduction = 27.62702  correctly classified = 89.4250%\n",
      "alpha =  0.99 b =  16902.498974803933 epoch =  1  loss = 2925.559  loss reduction = 0.0  correctly classified = 89.4250%\n",
      "     pred  true_label\n",
      "0     0.0           0\n",
      "1     0.0           0\n",
      "2     0.0           0\n",
      "3     0.0           0\n",
      "4     1.0           1\n",
      "..    ...         ...\n",
      "995   1.0           1\n",
      "996   1.0           0\n",
      "997   0.0           0\n",
      "998   0.0           0\n",
      "999   0.0           1\n",
      "\n",
      "[1000 rows x 2 columns]\n",
      "alpha =  0.6 b =  -1699.4319420548452 epoch =  0  loss = 19605.43  loss reduction = 9.999998e+10  correctly classified = 29.0500%\n",
      "alpha =  0.6 b =  -1004.6319420548452 epoch =  1  loss = 8029.651  loss reduction = 11575.78  correctly classified = 70.9500%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b2/8cn96b9x6qz0b7b79dn_n_1h0000gn/T/ipykernel_13453/3879921196.py:49: RuntimeWarning: overflow encountered in exp\n",
      "  test_pred = 1/(1+np.exp(-test_a))\n",
      "/var/folders/b2/8cn96b9x6qz0b7b79dn_n_1h0000gn/T/ipykernel_13453/3879921196.py:25: RuntimeWarning: overflow encountered in exp\n",
      "  a = (1/(1+np.exp(-a)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.6 b =  -309.8319420548453 epoch =  2  loss = 8029.651  loss reduction = 0.0  correctly classified = 70.9500%\n",
      "alpha =  0.6205263157894737 b =  -2068.403521002214 epoch =  0  loss = 19605.37  loss reduction = -11575.72  correctly classified = 29.0500%\n",
      "alpha =  0.6205263157894737 b =  -1349.8340473180033 epoch =  1  loss = 8029.651  loss reduction = 11575.72  correctly classified = 70.9500%\n",
      "alpha =  0.6205263157894737 b =  -631.2645736337928 epoch =  2  loss = 8029.651  loss reduction = 0.0  correctly classified = 70.9500%\n",
      "alpha =  0.6410526315789473 b =  -2448.0077315285293 epoch =  0  loss = 19605.37  loss reduction = -11575.72  correctly classified = 29.0500%\n",
      "alpha =  0.6410526315789473 b =  -1705.6687841601083 epoch =  1  loss = 8029.651  loss reduction = 11575.72  correctly classified = 70.9500%\n",
      "alpha =  0.6410526315789473 b =  -2998.4398810022135 epoch =  2  loss = 14736.11  loss reduction = -6706.459  correctly classified = 46.6750%\n",
      "alpha =  0.6410526315789473 b =  -2256.1009336337925 epoch =  3  loss = 8029.651  loss reduction = 6706.459  correctly classified = 70.9500%\n",
      "alpha =  0.6410526315789473 b =  -1513.7619862653714 epoch =  4  loss = 8029.651  loss reduction = 0.0  correctly classified = 70.9500%\n",
      "alpha =  0.661578947368421 b =  -3388.6767231074764 epoch =  0  loss = 19605.37  loss reduction = -11575.72  correctly classified = 29.0500%\n",
      "alpha =  0.661578947368421 b =  -2622.568302054845 epoch =  1  loss = 8029.651  loss reduction = 11575.72  correctly classified = 70.9500%\n",
      "alpha =  0.661578947368421 b =  -3425.8878925811605 epoch =  2  loss = 9790.874  loss reduction = -1761.222  correctly classified = 64.5750%\n",
      "alpha =  0.661578947368421 b =  -2659.779471528529 epoch =  3  loss = 8029.651  loss reduction = 1761.222  correctly classified = 70.9500%\n",
      "alpha =  0.661578947368421 b =  -4290.399566265371 epoch =  4  loss = 17491.91  loss reduction = -9462.254  correctly classified = 36.7000%\n",
      "alpha =  0.661578947368421 b =  -3524.291145212739 epoch =  5  loss = 8029.651  loss reduction = 9462.254  correctly classified = 70.9500%\n",
      "alpha =  0.661578947368421 b =  -2758.1827241601077 epoch =  6  loss = 8029.651  loss reduction = 0.0  correctly classified = 70.9500%\n",
      "alpha =  0.6821052631578948 b =  -4679.015701002213 epoch =  0  loss = 19715.88  loss reduction = -11686.23  correctly classified = 28.6500%\n",
      "alpha =  0.6821052631578948 b =  -3889.137806265371 epoch =  1  loss = 8029.651  loss reduction = 11686.23  correctly classified = 70.9500%\n",
      "alpha =  0.6821052631578948 b =  -3848.7558104758973 epoch =  2  loss = 5218.602  loss reduction = 2811.049  correctly classified = 81.1250%\n",
      "alpha =  0.6821052631578948 b =  -3318.920997844318 epoch =  3  loss = 6662.114  loss reduction = -1443.512  correctly classified = 75.9000%\n",
      "alpha =  0.6821052631578948 b =  -5239.753974686424 epoch =  4  loss = 19715.88  loss reduction = -13053.77  correctly classified = 28.6500%\n",
      "alpha =  0.6821052631578948 b =  -4449.876079949582 epoch =  5  loss = 8029.651  loss reduction = 11686.23  correctly classified = 70.9500%\n",
      "alpha =  0.6821052631578948 b =  -4545.642294686424 epoch =  6  loss = 5287.669  loss reduction = 2741.982  correctly classified = 80.8750%\n",
      "alpha =  0.6821052631578948 b =  -3797.2896041601084 epoch =  7  loss = 7732.661  loss reduction = -2444.991  correctly classified = 72.0250%\n",
      "alpha =  0.6821052631578948 b =  -5718.122581002213 epoch =  8  loss = 19715.88  loss reduction = -11983.22  correctly classified = 28.6500%\n",
      "alpha =  0.6821052631578948 b =  -4928.2446862653715 epoch =  9  loss = 8029.651  loss reduction = 11686.23  correctly classified = 70.9500%\n",
      "alpha =  0.6821052631578948 b =  -5695.221578896951 epoch =  10  loss = 9238.333  loss reduction = -1208.682  correctly classified = 66.5750%\n",
      "alpha =  0.6821052631578948 b =  -4905.343684160109 epoch =  11  loss = 8029.651  loss reduction = 1208.682  correctly classified = 70.9500%\n",
      "alpha =  0.6821052631578948 b =  -6447.003894686424 epoch =  12  loss = 16158.9  loss reduction = -8129.25  correctly classified = 41.5250%\n",
      "alpha =  0.6821052631578948 b =  -5657.125999949582 epoch =  13  loss = 8029.651  loss reduction = 8129.25  correctly classified = 70.9500%\n",
      "alpha =  0.6821052631578948 b =  -4996.58890521274 epoch =  14  loss = 7297.535  loss reduction = 732.116  correctly classified = 73.6000%\n",
      "alpha =  0.6821052631578948 b =  -6914.69891784432 epoch =  15  loss = 19715.88  loss reduction = -12418.35  correctly classified = 28.6500%\n",
      "alpha =  0.6821052631578948 b =  -6124.821023107478 epoch =  16  loss = 8029.651  loss reduction = 11686.23  correctly classified = 70.9500%\n",
      "alpha =  0.6821052631578948 b =  -6582.060736791688 epoch =  17  loss = 6910.757  loss reduction = 1118.894  correctly classified = 75.0000%\n",
      "alpha =  0.6821052631578948 b =  -5801.713216791688 epoch =  18  loss = 7946.77  loss reduction = -1036.013  correctly classified = 71.2500%\n",
      "alpha =  0.6821052631578948 b =  -7644.941713633793 epoch =  19  loss = 19039.02  loss reduction = -11092.25  correctly classified = 31.1000%\n",
      "alpha =  0.6821052631578948 b =  -6855.0638188969515 epoch =  20  loss = 8029.651  loss reduction = 11009.37  correctly classified = 70.9500%\n",
      "alpha =  0.6821052631578948 b =  -6553.277258896951 epoch =  21  loss = 5840.21  loss reduction = 2189.441  correctly classified = 78.8750%\n",
      "alpha =  0.6821052631578948 b =  -7525.157208370635 epoch =  22  loss = 10930.49  loss reduction = -5090.278  correctly classified = 60.4500%\n",
      "alpha =  0.6821052631578948 b =  -6735.279313633793 epoch =  23  loss = 8029.651  loss reduction = 2900.837  correctly classified = 70.9500%\n",
      "alpha =  0.6821052631578948 b =  -7664.95331784432 epoch =  24  loss = 10502.27  loss reduction = -2472.618  correctly classified = 62.0000%\n",
      "alpha =  0.6821052631578948 b =  -6875.075423107478 epoch =  25  loss = 8029.651  loss reduction = 2472.618  correctly classified = 70.9500%\n",
      "alpha =  0.6821052631578948 b =  -7923.198370475899 epoch =  26  loss = 11607.35  loss reduction = -3577.699  correctly classified = 58.0000%\n",
      "alpha =  0.6821052631578948 b =  -7133.320475739057 epoch =  27  loss = 8029.651  loss reduction = 3577.699  correctly classified = 70.9500%\n",
      "alpha =  0.6821052631578948 b =  -7884.640324160109 epoch =  28  loss = 9079.478  loss reduction = -1049.827  correctly classified = 67.1500%\n",
      "alpha =  0.6821052631578948 b =  -7098.166134686425 epoch =  29  loss = 7995.117  loss reduction = 1084.361  correctly classified = 71.0750%\n",
      "alpha =  0.6821052631578948 b =  -8527.50407152853 epoch =  30  loss = 15088.35  loss reduction = -7093.237  correctly classified = 45.4000%\n",
      "alpha =  0.6821052631578948 b =  -7737.6261767916885 epoch =  31  loss = 8029.651  loss reduction = 7058.703  correctly classified = 70.9500%\n",
      "alpha =  0.6821052631578948 b =  -7655.718976791689 epoch =  32  loss = 5045.933  loss reduction = 2983.718  correctly classified = 81.7500%\n",
      "alpha =  0.6821052631578948 b =  -7489.399886265373 epoch =  33  loss = 5239.322  loss reduction = -193.3891  correctly classified = 81.0500%\n",
      "alpha =  0.6821052631578948 b =  -7685.9157767916895 epoch =  34  loss = 5425.805  loss reduction = -186.4824  correctly classified = 80.3750%\n",
      "alpha =  0.6821052631578948 b =  -6996.787557844321 epoch =  35  loss = 7435.67  loss reduction = -2009.866  correctly classified = 73.1000%\n",
      "alpha =  0.6821052631578948 b =  -8836.612349423269 epoch =  36  loss = 18990.67  loss reduction = -11555.0  correctly classified = 31.2750%\n",
      "alpha =  0.6821052631578948 b =  -8046.734454686427 epoch =  37  loss = 8029.651  loss reduction = 10961.02  correctly classified = 70.9500%\n",
      "alpha =  0.6821052631578948 b =  -8176.537722054848 epoch =  38  loss = 5218.602  loss reduction = 2811.049  correctly classified = 81.1250%\n",
      "alpha =  0.6821052631578948 b =  -7586.79769679169 epoch =  39  loss = 6910.757  loss reduction = -1692.155  correctly classified = 75.0000%\n",
      "alpha =  0.6821052631578948 b =  -9329.957258896953 epoch =  40  loss = 18065.17  loss reduction = -11154.41  correctly classified = 34.6250%\n",
      "alpha =  0.6821052631578948 b =  -8540.07936416011 epoch =  41  loss = 8029.651  loss reduction = 10035.51  correctly classified = 70.9500%\n",
      "alpha =  0.6821052631578948 b =  -8668.521149423268 epoch =  42  loss = 5190.975  loss reduction = 2838.676  correctly classified = 81.2250%\n",
      "alpha =  0.6821052631578948 b =  -8098.522614686426 epoch =  43  loss = 6820.969  loss reduction = -1629.994  correctly classified = 75.3250%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.6821052631578948 b =  -9751.143616791689 epoch =  44  loss = 17188.01  loss reduction = -10367.04  correctly classified = 37.8000%\n",
      "alpha =  0.6821052631578948 b =  -8961.265722054846 epoch =  45  loss = 8029.651  loss reduction = 9158.357  correctly classified = 70.9500%\n",
      "alpha =  0.6821052631578948 b =  -9061.79712416011 epoch =  46  loss = 5073.56  loss reduction = 2956.091  correctly classified = 81.6500%\n",
      "alpha =  0.6821052631578948 b =  -8542.173427318005 epoch =  47  loss = 6627.58  loss reduction = -1554.02  correctly classified = 76.0250%\n",
      "alpha =  0.6821052631578948 b =  -10062.04992416011 epoch =  48  loss = 15910.26  loss reduction = -9282.678  correctly classified = 42.4250%\n",
      "alpha =  0.6821052631578948 b =  -9272.172029423267 epoch =  49  loss = 8029.651  loss reduction = 7880.607  correctly classified = 70.9500%\n",
      "alpha =  0.6821052631578948 b =  -9398.571591528531 epoch =  50  loss = 5142.628  loss reduction = 2887.023  correctly classified = 81.4000%\n",
      "alpha =  0.6821052631578948 b =  -8871.459743107478 epoch =  51  loss = 6662.114  loss reduction = -1519.486  correctly classified = 75.9000%\n",
      "alpha =  0.6821052631578948 b =  -10360.702892581163 epoch =  52  loss = 15640.89  loss reduction = -8978.781  correctly classified = 43.4000%\n",
      "alpha =  0.6821052631578948 b =  -9572.186479949583 epoch =  53  loss = 8015.838  loss reduction = 7625.057  correctly classified = 71.0000%\n",
      "alpha =  0.6821052631578948 b =  -9770.744593633794 epoch =  54  loss = 5446.525  loss reduction = 2569.313  correctly classified = 80.3000%\n",
      "alpha =  0.6821052631578948 b =  -9168.070488370635 epoch =  55  loss = 6945.291  loss reduction = -1498.766  correctly classified = 74.8750%\n",
      "alpha =  0.6821052631578948 b =  -10719.261073633792 epoch =  56  loss = 16214.16  loss reduction = -9268.865  correctly classified = 41.3250%\n",
      "alpha =  0.6821052631578948 b =  -9932.106143107476 epoch =  57  loss = 8002.024  loss reduction = 8212.131  correctly classified = 71.0500%\n",
      "alpha =  0.6821052631578948 b =  -10174.231684160108 epoch =  58  loss = 5557.033  loss reduction = 2444.991  correctly classified = 79.9000%\n",
      "alpha =  0.6821052631578948 b =  -9547.050901002212 epoch =  59  loss = 7055.799  loss reduction = -1498.766  correctly classified = 74.4750%\n",
      "alpha =  0.6821052631578948 b =  -11043.782202054845 epoch =  60  loss = 15703.06  loss reduction = -8647.257  correctly classified = 43.1750%\n",
      "alpha =  0.6821052631578948 b =  -10257.308012581161 epoch =  61  loss = 7995.117  loss reduction = 7707.938  correctly classified = 71.0750%\n",
      "alpha =  0.6821052631578948 b =  -10549.127650475897 epoch =  62  loss = 5784.956  loss reduction = 2210.162  correctly classified = 79.0750%\n",
      "alpha =  0.6821052631578948 b =  -9917.181679949581 epoch =  63  loss = 7076.519  loss reduction = -1291.563  correctly classified = 74.4000%\n",
      "alpha =  0.6821052631578948 b =  -11343.115911528528 epoch =  64  loss = 15040.01  loss reduction = -7963.488  correctly classified = 45.5750%\n",
      "alpha =  0.6821052631578948 b =  -10562.768391528529 epoch =  65  loss = 7946.77  loss reduction = 7093.237  correctly classified = 71.2500%\n",
      "alpha =  0.6821052631578948 b =  -10902.239903107476 epoch =  66  loss = 6102.666  loss reduction = 1844.104  correctly classified = 77.9250%\n",
      "alpha =  0.6821052631578948 b =  -10274.37837889695 epoch =  67  loss = 7062.705  loss reduction = -960.0389  correctly classified = 74.4500%\n",
      "alpha =  0.6821052631578948 b =  -11654.022218896951 epoch =  68  loss = 14639.42  loss reduction = -7576.71  correctly classified = 47.0250%\n",
      "alpha =  0.6821052631578948 b =  -10876.397663107477 epoch =  69  loss = 7919.143  loss reduction = 6720.272  correctly classified = 71.3500%\n",
      "alpha =  0.6821052631578948 b =  -11268.966976791688 epoch =  70  loss = 6420.377  loss reduction = 1498.766  correctly classified = 76.7750%\n",
      "alpha =  0.6821052631578948 b =  -10639.063229423267 epoch =  71  loss = 7069.612  loss reduction = -649.2349  correctly classified = 74.4250%\n",
      "alpha =  0.6821052631578948 b =  -11958.801856791688 epoch =  72  loss = 14086.87  loss reduction = -7017.263  correctly classified = 49.0250%\n",
      "alpha =  0.6821052631578948 b =  -11187.303970475898 epoch =  73  loss = 7856.982  loss reduction = 6229.893  correctly classified = 71.5750%\n",
      "alpha =  0.6821052631578948 b =  -11633.651827318003 epoch =  74  loss = 6689.741  loss reduction = 1167.242  correctly classified = 75.8000%\n",
      "alpha =  0.6821052631578948 b =  -11011.236231528528 epoch =  75  loss = 7021.265  loss reduction = -331.5242  correctly classified = 74.6000%\n",
      "alpha =  0.6821052631578948 b =  -12289.449654686423 epoch =  76  loss = 13707.0  loss reduction = -6685.739  correctly classified = 50.4000%\n",
      "alpha =  0.6821052631578948 b =  -11522.036214686423 epoch =  77  loss = 7815.542  loss reduction = 5891.462  correctly classified = 71.7250%\n",
      "alpha =  0.6821052631578948 b =  -12022.162614686422 epoch =  78  loss = 6986.731  loss reduction = 828.8106  correctly classified = 74.7250%\n",
      "alpha =  0.6821052631578948 b =  -11395.66257258116 epoch =  79  loss = 7035.078  loss reduction = -48.34728  correctly classified = 74.5500%\n",
      "alpha =  0.6821052631578948 b =  -12612.609301002212 epoch =  80  loss = 13168.28  loss reduction = -6133.198  correctly classified = 52.3500%\n",
      "alpha =  0.6821052631578948 b =  -11856.76845889695 epoch =  81  loss = 7739.567  loss reduction = 5428.709  correctly classified = 72.0000%\n",
      "alpha =  0.6821052631578948 b =  -12494.404551528529 epoch =  82  loss = 8036.558  loss reduction = -296.9905  correctly classified = 70.9250%\n",
      "alpha =  0.6821052631578948 b =  -11836.590421002213 epoch =  83  loss = 7214.654  loss reduction = 821.9038  correctly classified = 73.9000%\n",
      "alpha =  0.6821052631578948 b =  -12969.805999949582 epoch =  84  loss = 12415.44  loss reduction = -5200.786  correctly classified = 55.0750%\n",
      "alpha =  0.6821052631578948 b =  -12224.857014686424 epoch =  85  loss = 7656.686  loss reduction = 4758.754  correctly classified = 72.3000%\n",
      "alpha =  0.6821052631578948 b =  -12955.073890475898 epoch =  86  loss = 8796.301  loss reduction = -1139.615  correctly classified = 68.1750%\n",
      "alpha =  0.6821052631578948 b =  -12285.006421002214 epoch =  87  loss = 7256.095  loss reduction = 1540.206  correctly classified = 73.7500%\n",
      "alpha =  0.6821052631578948 b =  -13324.279734686424 epoch =  88  loss = 11476.12  loss reduction = -4220.027  correctly classified = 58.4750%\n",
      "alpha =  0.6821052631578948 b =  -12596.349275739056 epoch =  89  loss = 7553.085  loss reduction = 3923.037  correctly classified = 72.6750%\n",
      "alpha =  0.6821052631578948 b =  -13396.682479949583 epoch =  90  loss = 9383.375  loss reduction = -1830.29  correctly classified = 66.0500%\n",
      "alpha =  0.6821052631578948 b =  -12721.169082054847 epoch =  91  loss = 7297.535  loss reduction = 2085.84  correctly classified = 73.6000%\n",
      "alpha =  0.6821052631578948 b =  -13694.410513633795 epoch =  92  loss = 10847.61  loss reduction = -3550.072  correctly classified = 60.7500%\n",
      "alpha =  0.6821052631578948 b =  -12980.775616791689 epoch =  93  loss = 7421.857  loss reduction = 3425.75  correctly classified = 73.1500%\n",
      "alpha =  0.6821052631578948 b =  -13813.1036504759 epoch =  94  loss = 9625.111  loss reduction = -2203.255  correctly classified = 65.1750%\n",
      "alpha =  0.6821052631578948 b =  -13138.270993633794 epoch =  95  loss = 7290.628  loss reduction = 2334.483  correctly classified = 73.6250%\n",
      "alpha =  0.6821052631578948 b =  -14069.987221002215 epoch =  96  loss = 10481.55  loss reduction = -3190.921  correctly classified = 62.0750%\n",
      "alpha =  0.6821052631578948 b =  -13376.093814686425 epoch =  97  loss = 7442.577  loss reduction = 3038.972  correctly classified = 73.0750%\n",
      "alpha =  0.6821052631578948 b =  -14221.355928370635 epoch =  98  loss = 9742.526  loss reduction = -2299.949  correctly classified = 64.7500%\n",
      "alpha =  0.6821052631578948 b =  -13550.60771784432 epoch =  99  loss = 7263.001  loss reduction = 2479.525  correctly classified = 73.7250%\n",
      "alpha =  0.6821052631578948 b =  -14448.967633633793 epoch =  100  loss = 10170.75  loss reduction = -2907.744  correctly classified = 63.2000%\n",
      "alpha =  0.6821052631578948 b =  -13770.73127152853 epoch =  101  loss = 7311.349  loss reduction = 2859.396  correctly classified = 73.5500%\n",
      "alpha =  0.6821052631578948 b =  -14611.908938896951 epoch =  102  loss = 9701.086  loss reduction = -2389.737  correctly classified = 64.9000%\n",
      "alpha =  0.6821052631578948 b =  -13952.052585212741 epoch =  103  loss = 7207.747  loss reduction = 2493.338  correctly classified = 73.9250%\n",
      "alpha =  0.6821052631578948 b =  -14842.924349423267 epoch =  104  loss = 10094.77  loss reduction = -2887.023  correctly classified = 63.4750%\n",
      "alpha =  0.6821052631578948 b =  -14175.57984416011 epoch =  105  loss = 7242.281  loss reduction = 2852.49  correctly classified = 73.8000%\n",
      "alpha =  0.6821052631578948 b =  -15013.353806265372 epoch =  106  loss = 9680.365  loss reduction = -2438.084  correctly classified = 64.9750%\n",
      "alpha =  0.6821052631578948 b =  -14367.793014686424 epoch =  107  loss = 7117.959  loss reduction = 2562.406  correctly classified = 74.2500%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.6821052631578948 b =  -15231.435136791686 epoch =  108  loss = 9859.941  loss reduction = -2741.982  correctly classified = 64.3250%\n",
      "alpha =  0.6821052631578948 b =  -14584.512863107475 epoch =  109  loss = 7117.959  loss reduction = 2741.982  correctly classified = 74.2500%\n",
      "alpha =  0.6821052631578948 b =  -15415.485833607572 epoch =  110  loss = 9625.121  loss reduction = -2507.161  correctly classified = 65.1750%\n",
      "alpha =  0.6821052631578948 b =  -14784.220604133889 epoch =  111  loss = 7055.799  loss reduction = 2569.322  correctly classified = 74.4750%\n",
      "alpha =  0.6821052631578948 b =  -15612.46419150231 epoch =  112  loss = 9597.484  loss reduction = -2541.686  correctly classified = 65.2750%\n",
      "alpha =  0.6821052631578948 b =  -14986.644890449677 epoch =  113  loss = 7014.358  loss reduction = 2583.126  correctly classified = 74.6250%\n",
      "alpha =  0.6821052631578948 b =  -15801.9543978181 epoch =  114  loss = 9480.07  loss reduction = -2465.711  correctly classified = 65.7000%\n",
      "alpha =  0.6821052631578948 b =  -15184.984730449678 epoch =  115  loss = 6993.638  loss reduction = 2486.432  correctly classified = 74.7000%\n",
      "alpha =  0.6821052631578948 b =  -16007.782389397047 epoch =  116  loss = 9528.417  loss reduction = -2534.779  correctly classified = 65.5250%\n",
      "alpha =  0.6821052631578948 b =  -15390.812722028626 epoch =  117  loss = 6993.638  loss reduction = 2534.779  correctly classified = 74.7000%\n",
      "alpha =  0.6821052631578948 b =  -16197.272595712837 epoch =  118  loss = 9390.282  loss reduction = -2396.644  correctly classified = 66.0250%\n",
      "alpha =  0.6821052631578948 b =  -15593.917749397047 epoch =  119  loss = 6883.13  loss reduction = 2507.152  correctly classified = 75.1000%\n",
      "alpha =  0.6821052631578948 b =  -16396.9739178181 epoch =  120  loss = 9369.561  loss reduction = -2486.432  correctly classified = 66.1000%\n",
      "alpha =  0.6821052631578948 b =  -15798.384258870732 epoch =  121  loss = 6848.596  loss reduction = 2520.965  correctly classified = 75.2250%\n",
      "alpha =  0.6821052631578948 b =  -16597.355980975994 epoch =  122  loss = 9328.121  loss reduction = -2479.525  correctly classified = 66.2500%\n",
      "alpha =  0.6821052631578948 b =  -16004.212250449678 epoch =  123  loss = 6834.782  loss reduction = 2493.338  correctly classified = 75.2750%\n",
      "alpha =  0.6821052631578948 b =  -16771.189143081257 epoch =  124  loss = 9058.758  loss reduction = -2223.975  correctly classified = 67.2250%\n",
      "alpha =  0.6821052631578948 b =  -16196.425420975995 epoch =  125  loss = 6772.622  loss reduction = 2286.136  correctly classified = 75.5000%\n",
      "alpha =  0.6821052631578948 b =  -16902.816359923363 epoch =  126  loss = 8554.564  loss reduction = -1781.943  correctly classified = 69.0500%\n",
      "alpha =  0.6821052631578948 b =  -16354.601538870731 epoch =  127  loss = 6641.393  loss reduction = 1913.171  correctly classified = 75.9750%\n",
      "alpha =  0.6821052631578948 b =  -17016.744309397047 epoch =  128  loss = 8202.32  loss reduction = -1560.927  correctly classified = 70.3250%\n",
      "alpha =  0.6821052631578948 b =  -16489.632460975994 epoch =  129  loss = 6537.792  loss reduction = 1664.528  correctly classified = 76.3500%\n",
      "alpha =  0.6821052631578948 b =  -17121.82262518652 epoch =  130  loss = 7939.863  loss reduction = -1402.071  correctly classified = 71.2750%\n",
      "alpha =  0.6821052631578948 b =  -16604.92189255494 epoch =  131  loss = 6475.631  loss reduction = 1464.232  correctly classified = 76.5750%\n",
      "alpha =  0.6821052631578948 b =  -17213.96686097599 epoch =  132  loss = 7732.661  loss reduction = -1257.029  correctly classified = 72.0250%\n",
      "alpha =  0.6821052631578948 b =  -16716.126877818097 epoch =  133  loss = 6406.564  loss reduction = 1326.097  correctly classified = 76.8250%\n",
      "alpha =  0.6821052631578948 b =  -17278.20071360757 epoch =  134  loss = 7352.789  loss reduction = -946.2254  correctly classified = 73.4000%\n",
      "alpha =  0.6821052631578948 b =  -16812.35555992336 epoch =  135  loss = 6247.708  loss reduction = 1105.081  correctly classified = 77.4000%\n",
      "alpha =  0.6821052631578948 b =  -17283.2100946602 epoch =  136  loss = 6703.554  loss reduction = -455.8458  correctly classified = 75.7500%\n",
      "alpha =  0.6821052631578948 b =  -16846.63680623915 epoch =  137  loss = 6116.48  loss reduction = 587.0742  correctly classified = 77.8750%\n",
      "alpha =  0.6821052631578948 b =  -17249.417235712834 epoch =  138  loss = 6275.335  loss reduction = -158.8554  correctly classified = 77.3000%\n",
      "alpha =  0.6821052631578948 b =  -16820.332098870727 epoch =  139  loss = 6054.319  loss reduction = 221.0162  correctly classified = 78.1000%\n",
      "alpha =  0.6821052631578948 b =  -17205.41326097599 epoch =  140  loss = 6192.454  loss reduction = -138.1351  correctly classified = 77.6000%\n",
      "alpha =  0.6821052631578948 b =  -16779.05108834441 epoch =  141  loss = 6026.692  loss reduction = 165.7621  correctly classified = 78.2000%\n",
      "alpha =  0.6821052631578948 b =  -17160.047804133887 epoch =  142  loss = 6178.641  loss reduction = -151.9486  correctly classified = 77.6500%\n",
      "alpha =  0.6821052631578948 b =  -16733.685631502307 epoch =  143  loss = 6026.692  loss reduction = 151.9486  correctly classified = 78.2000%\n",
      "alpha =  0.6821052631578948 b =  -17116.724570449675 epoch =  144  loss = 6199.361  loss reduction = -172.6689  correctly classified = 77.5750%\n",
      "alpha =  0.6821052631578948 b =  -16688.3201746602 epoch =  145  loss = 6033.599  loss reduction = 165.7621  correctly classified = 78.1750%\n",
      "alpha =  0.6821052631578948 b =  -17080.889488344408 epoch =  146  loss = 6213.175  loss reduction = -179.5756  correctly classified = 77.5250%\n",
      "alpha =  0.6821052631578948 b =  -16647.719905186514 epoch =  147  loss = 6026.692  loss reduction = 186.4824  correctly classified = 78.2000%\n",
      "alpha =  0.6821052631578948 b =  -17047.09662939704 epoch =  148  loss = 6268.429  loss reduction = -241.7364  correctly classified = 77.3250%\n",
      "alpha =  0.6821052631578948 b =  -16611.88482308125 epoch =  149  loss = 6033.599  loss reduction = 234.8297  correctly classified = 78.1750%\n",
      "alpha =  0.6821052631578948 b =  -17020.79192202862 epoch =  150  loss = 6282.242  loss reduction = -248.6432  correctly classified = 77.2750%\n",
      "alpha =  0.6821052631578948 b =  -16580.134187291776 epoch =  151  loss = 6033.599  loss reduction = 248.6432  correctly classified = 78.1750%\n",
      "alpha =  0.6821052631578948 b =  -17004.01758939704 epoch =  152  loss = 6337.496  loss reduction = -303.8972  correctly classified = 77.0750%\n",
      "alpha =  0.6821052631578948 b =  -16564.04059571283 epoch =  153  loss = 6026.692  loss reduction = 310.804  correctly classified = 78.2000%\n",
      "alpha =  0.6821052631578948 b =  -16989.285479923357 epoch =  154  loss = 6351.31  loss reduction = -324.6175  correctly classified = 77.0250%\n",
      "alpha =  0.6821052631578948 b =  -16549.98922729178 epoch =  155  loss = 6019.785  loss reduction = 331.5242  correctly classified = 78.2250%\n",
      "alpha =  0.6821052631578948 b =  -16974.553370449674 epoch =  156  loss = 6344.403  loss reduction = -324.6175  correctly classified = 77.0500%\n",
      "alpha =  0.6821052631578948 b =  -16535.937858870726 epoch =  157  loss = 6012.879  loss reduction = 331.5242  correctly classified = 78.2500%\n",
      "alpha =  0.6821052631578948 b =  -16960.50200202862 epoch =  158  loss = 6344.403  loss reduction = -331.5242  correctly classified = 77.0500%\n",
      "alpha =  0.6821052631578948 b =  -16521.886490449673 epoch =  159  loss = 6012.879  loss reduction = 331.5242  correctly classified = 78.2500%\n",
      "alpha =  0.6821052631578948 b =  -16950.535079923357 epoch =  160  loss = 6330.589  loss reduction = -317.7107  correctly classified = 77.1000%\n",
      "alpha =  0.6821052631578948 b =  -16507.83512202862 epoch =  161  loss = 6012.879  loss reduction = 317.7107  correctly classified = 78.2500%\n",
      "alpha =  0.6821052631578948 b =  -16941.929639923357 epoch =  162  loss = 6344.403  loss reduction = -331.5242  correctly classified = 77.0500%\n",
      "alpha =  0.6821052631578948 b =  -16500.591164133883 epoch =  163  loss = 6012.879  loss reduction = 331.5242  correctly classified = 78.2500%\n",
      "alpha =  0.6821052631578948 b =  -16936.04716413388 epoch =  164  loss = 6344.403  loss reduction = -331.5242  correctly classified = 77.0500%\n",
      "alpha =  0.6821052631578948 b =  -16491.98572413388 epoch =  165  loss = 6012.879  loss reduction = 331.5242  correctly classified = 78.2500%\n",
      "alpha =  0.6821052631578948 b =  -16928.803206239143 epoch =  166  loss = 6358.216  loss reduction = -345.3377  correctly classified = 77.0000%\n",
      "alpha =  0.6821052631578948 b =  -16484.06102518651 epoch =  167  loss = 6005.972  loss reduction = 352.2445  correctly classified = 78.2750%\n",
      "alpha =  0.6821052631578948 b =  -16929.728140975985 epoch =  168  loss = 6406.564  loss reduction = -400.5918  correctly classified = 76.8250%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.6821052631578948 b =  -16482.943736765457 epoch =  169  loss = 6012.879  loss reduction = 393.685  correctly classified = 78.2500%\n",
      "alpha =  0.6821052631578948 b =  -16938.141227291773 epoch =  170  loss = 6461.818  loss reduction = -448.9391  correctly classified = 76.6250%\n",
      "alpha =  0.6821052631578948 b =  -16487.953117818088 epoch =  171  loss = 5992.158  loss reduction = 469.6593  correctly classified = 78.3250%\n",
      "alpha =  0.6821052631578948 b =  -16942.469867291773 epoch =  172  loss = 6427.284  loss reduction = -435.1256  correctly classified = 76.7500%\n",
      "alpha =  0.6821052631578948 b =  -16489.55879360756 epoch =  173  loss = 5978.345  loss reduction = 448.9391  correctly classified = 78.3750%\n",
      "alpha =  0.6821052631578948 b =  -16954.28665887072 epoch =  174  loss = 6530.885  loss reduction = -552.5404  correctly classified = 76.3750%\n",
      "alpha =  0.6821052631578948 b =  -16501.375585186506 epoch =  175  loss = 5978.345  loss reduction = 552.5404  correctly classified = 78.3750%\n",
      "alpha =  0.6821052631578948 b =  -16960.65752202861 epoch =  176  loss = 6475.631  loss reduction = -497.2863  correctly classified = 76.5750%\n",
      "alpha =  0.6821052631578948 b =  -16507.065707291767 epoch =  177  loss = 5985.252  loss reduction = 490.3796  correctly classified = 78.3500%\n",
      "alpha =  0.6821052631578948 b =  -16975.197277818083 epoch =  178  loss = 6523.979  loss reduction = -538.7269  correctly classified = 76.4000%\n",
      "alpha =  0.6821052631578948 b =  -16520.243980975978 epoch =  179  loss = 5999.065  loss reduction = 524.9134  correctly classified = 78.3000%\n",
      "alpha =  0.6821052631578948 b =  -17011.52074729177 epoch =  180  loss = 6689.741  loss reduction = -690.6755  correctly classified = 75.8000%\n",
      "alpha =  0.6821052631578948 b =  -16539.548924133873 epoch =  181  loss = 6116.48  loss reduction = 573.2606  correctly classified = 77.8750%\n",
      "alpha =  0.6821052631578948 b =  -17070.308671502295 epoch =  182  loss = 6952.197  loss reduction = -835.7173  correctly classified = 74.8500%\n",
      "alpha =  0.6821052631578948 b =  -16582.679804133873 epoch =  183  loss = 6164.827  loss reduction = 787.37  correctly classified = 77.7000%\n",
      "alpha =  0.6821052631578948 b =  -17141.34993466019 epoch =  184  loss = 7152.493  loss reduction = -987.6659  correctly classified = 74.1250%\n",
      "alpha =  0.6821052631578948 b =  -16646.913656765453 epoch =  185  loss = 6192.454  loss reduction = 960.0389  correctly classified = 77.6000%\n",
      "alpha =  0.6821052631578948 b =  -17229.409724133875 epoch =  186  loss = 7338.976  loss reduction = -1146.521  correctly classified = 73.4500%\n",
      "alpha =  0.6821052631578948 b =  -16732.250482028612 epoch =  187  loss = 6220.081  loss reduction = 1118.894  correctly classified = 77.5000%\n",
      "alpha =  0.6821052631578948 b =  -17323.596183081245 epoch =  188  loss = 7401.136  loss reduction = -1181.055  correctly classified = 73.2250%\n",
      "alpha =  0.6821052631578948 b =  -16817.58730729177 epoch =  189  loss = 6240.802  loss reduction = 1160.335  correctly classified = 77.4250%\n",
      "alpha =  0.6821052631578948 b =  -17425.27079360756 epoch =  190  loss = 7566.898  loss reduction = -1326.097  correctly classified = 72.6250%\n",
      "alpha =  0.6821052631578948 b =  -16912.45450729177 epoch =  191  loss = 6268.429  loss reduction = 1298.47  correctly classified = 77.3250%\n",
      "alpha =  0.6821052631578948 b =  -17520.81873466019 epoch =  192  loss = 7573.805  loss reduction = -1305.377  correctly classified = 72.6000%\n",
      "alpha =  0.6821052631578948 b =  -17008.002448344403 epoch =  193  loss = 6268.429  loss reduction = 1305.377  correctly classified = 77.3250%\n",
      "alpha =  0.6821052631578948 b =  -17615.00519360756 epoch =  194  loss = 7559.992  loss reduction = -1291.563  correctly classified = 72.6500%\n",
      "alpha =  0.6821052631578948 b =  -17105.59261255493 epoch =  195  loss = 6261.522  loss reduction = 1298.47  correctly classified = 77.3500%\n",
      "alpha =  0.6821052631578948 b =  -17707.830170449666 epoch =  196  loss = 7511.644  loss reduction = -1250.123  correctly classified = 72.8250%\n",
      "alpha =  0.6821052631578948 b =  -17201.821294660193 epoch =  197  loss = 6240.802  loss reduction = 1270.843  correctly classified = 77.4250%\n",
      "alpha =  0.6821052631578948 b =  -17798.61292413388 epoch =  198  loss = 7456.39  loss reduction = -1215.589  correctly classified = 73.0250%\n",
      "alpha =  0.6821052631578948 b =  -17303.49590518651 epoch =  199  loss = 6171.734  loss reduction = 1284.656  correctly classified = 77.6750%\n",
      "alpha =  0.6821052631578948 b =  -17860.804553607566 epoch =  200  loss = 7111.053  loss reduction = -939.3186  correctly classified = 74.2750%\n",
      "alpha =  0.6821052631578948 b =  -17386.790507291775 epoch =  201  loss = 6026.692  loss reduction = 1084.361  correctly classified = 78.2000%\n",
      "alpha =  0.6821052631578948 b =  -17900.531728344406 epoch =  202  loss = 6820.969  loss reduction = -794.2768  correctly classified = 75.3250%\n",
      "alpha =  0.6821052631578948 b =  -17440.81324413388 epoch =  203  loss = 5923.091  loss reduction = 897.8781  correctly classified = 78.5750%\n",
      "alpha =  0.6821052631578948 b =  -17893.287770449668 epoch =  204  loss = 6365.123  loss reduction = -442.0323  correctly classified = 76.9750%\n",
      "alpha =  0.6821052631578948 b =  -17462.8411515023 epoch =  205  loss = 5778.049  loss reduction = 587.0742  correctly classified = 79.1000%\n",
      "alpha =  0.6821052631578948 b =  -17829.54230518651 epoch =  206  loss = 5798.769  loss reduction = -20.72026  correctly classified = 79.0250%\n",
      "alpha =  0.6821052631578948 b =  -17440.620890449667 epoch =  207  loss = 5550.126  loss reduction = 248.6432  correctly classified = 79.9250%\n",
      "alpha =  0.6821052631578948 b =  -17728.356082028615 epoch =  208  loss = 5315.296  loss reduction = 234.8297  correctly classified = 80.7750%\n",
      "alpha =  0.6821052631578948 b =  -17353.049488344404 epoch =  209  loss = 5453.432  loss reduction = -138.1351  correctly classified = 80.2750%\n",
      "alpha =  0.6821052631578948 b =  -17620.362448344404 epoch =  210  loss = 5232.415  loss reduction = 221.0162  correctly classified = 81.0750%\n",
      "alpha =  0.6821052631578948 b =  -17259.351416765458 epoch =  211  loss = 5336.017  loss reduction = -103.6013  correctly classified = 80.7000%\n",
      "alpha =  0.6821052631578948 b =  -17513.049555712827 epoch =  212  loss = 5163.348  loss reduction = 172.6689  correctly classified = 81.3250%\n",
      "alpha =  0.6821052631578948 b =  -17158.165193607565 epoch =  213  loss = 5315.296  loss reduction = -151.9486  correctly classified = 80.7750%\n",
      "alpha =  0.6821052631578948 b =  -17410.50185044967 epoch =  214  loss = 5135.721  loss reduction = 179.5756  correctly classified = 81.4250%\n",
      "alpha =  0.6821052631578948 b =  -17056.298229397038 epoch =  215  loss = 5308.39  loss reduction = -172.6689  correctly classified = 80.8000%\n",
      "alpha =  0.6821052631578948 b =  -17311.35785044967 epoch =  216  loss = 5135.721  loss reduction = 172.6689  correctly classified = 81.4250%\n",
      "alpha =  0.6821052631578948 b =  -16953.75052413388 epoch =  217  loss = 5315.296  loss reduction = -179.5756  correctly classified = 80.7750%\n",
      "alpha =  0.6821052631578948 b =  -17209.490886239142 epoch =  218  loss = 5128.814  loss reduction = 186.4824  correctly classified = 81.4500%\n",
      "alpha =  0.6821052631578948 b =  -16851.883559923353 epoch =  219  loss = 5315.296  loss reduction = -186.4824  correctly classified = 80.7750%\n",
      "alpha =  0.6821052631578948 b =  -17108.30466308125 epoch =  220  loss = 5108.094  loss reduction = 207.2026  correctly classified = 81.5250%\n",
      "alpha =  0.6821052631578948 b =  -16750.69733676546 epoch =  221  loss = 5315.296  loss reduction = -207.2026  correctly classified = 80.7750%\n",
      "alpha =  0.6821052631578948 b =  -17010.522145186515 epoch =  222  loss = 5101.187  loss reduction = 214.1094  correctly classified = 81.5500%\n",
      "alpha =  0.6821052631578948 b =  -16648.830372554934 epoch =  223  loss = 5315.296  loss reduction = -214.1094  correctly classified = 80.7750%\n",
      "alpha =  0.6821052631578948 b =  -16926.35444834441 epoch =  224  loss = 5197.882  loss reduction = 117.4148  correctly classified = 81.2000%\n",
      "alpha =  0.6821052631578948 b =  -16556.493783081252 epoch =  225  loss = 5370.55  loss reduction = -172.6689  correctly classified = 80.5750%\n",
      "alpha =  0.6821052631578948 b =  -16839.463787291777 epoch =  226  loss = 5197.882  loss reduction = 172.6689  correctly classified = 81.2000%\n",
      "alpha =  0.6821052631578948 b =  -16462.795711502302 epoch =  227  loss = 5411.991  loss reduction = -214.1094  correctly classified = 80.4250%\n",
      "alpha =  0.6821052631578948 b =  -16769.591652554933 epoch =  228  loss = 5273.856  loss reduction = 138.1351  correctly classified = 80.9250%\n",
      "alpha =  0.6821052631578948 b =  -16379.989496765458 epoch =  229  loss = 5474.152  loss reduction = -200.2959  correctly classified = 80.2000%\n",
      "alpha =  0.6821052631578948 b =  -16722.183972554933 epoch =  230  loss = 5494.872  loss reduction = -20.72026  correctly classified = 80.1250%\n",
      "alpha =  0.6821052631578948 b =  -16304.671433607564 epoch =  231  loss = 5425.805  loss reduction = 69.06755  correctly classified = 80.3750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.6821052631578948 b =  -16668.649623081248 epoch =  232  loss = 5591.567  loss reduction = -165.7621  correctly classified = 79.7750%\n",
      "alpha =  0.6821052631578948 b =  -16251.13708413388 epoch =  233  loss = 5425.805  loss reduction = 165.7621  correctly classified = 80.3750%\n",
      "alpha =  0.6821052631578948 b =  -16619.199719923352 epoch =  234  loss = 5619.194  loss reduction = -193.3891  correctly classified = 79.6750%\n",
      "alpha =  0.6821052631578948 b =  -16201.006439923352 epoch =  235  loss = 5432.711  loss reduction = 186.4824  correctly classified = 80.3500%\n",
      "alpha =  0.6821052631578948 b =  -16575.876486239144 epoch =  236  loss = 5674.448  loss reduction = -241.7364  correctly classified = 79.4750%\n",
      "alpha =  0.6821052631578948 b =  -16152.918018870723 epoch =  237  loss = 5453.432  loss reduction = 221.0162  correctly classified = 80.2750%\n",
      "alpha =  0.6821052631578948 b =  -16530.51102939704 epoch =  238  loss = 5688.261  loss reduction = -234.8297  correctly classified = 79.4250%\n",
      "alpha =  0.6821052631578948 b =  -16108.91404413388 epoch =  239  loss = 5439.618  loss reduction = 248.6432  correctly classified = 80.3250%\n",
      "alpha =  0.6821052631578948 b =  -16485.826313607566 epoch =  240  loss = 5667.541  loss reduction = -227.9229  correctly classified = 79.5000%\n",
      "alpha =  0.6821052631578948 b =  -16063.548587291776 epoch =  241  loss = 5446.525  loss reduction = 221.0162  correctly classified = 80.3000%\n",
      "alpha =  0.6821052631578948 b =  -16441.822338870723 epoch =  242  loss = 5667.541  loss reduction = -221.0162  correctly classified = 79.5000%\n",
      "alpha =  0.6821052631578948 b =  -16014.779425186513 epoch =  243  loss = 5467.245  loss reduction = 200.2959  correctly classified = 80.2250%\n",
      "alpha =  0.6821052631578948 b =  -16410.75244413388 epoch =  244  loss = 5764.235  loss reduction = -296.9905  correctly classified = 79.1500%\n",
      "alpha =  0.6821052631578948 b =  -15985.751753607563 epoch =  245  loss = 5446.525  loss reduction = 317.7107  correctly classified = 80.3000%\n",
      "alpha =  0.6821052631578948 b =  -16381.0440315023 epoch =  246  loss = 5757.329  loss reduction = -310.804  correctly classified = 79.1750%\n",
      "alpha =  0.6821052631578948 b =  -15954.00111781809 epoch =  247  loss = 5439.618  loss reduction = 317.7107  correctly classified = 80.3250%\n",
      "alpha =  0.6821052631578948 b =  -16350.65487781809 epoch =  248  loss = 5771.142  loss reduction = -331.5242  correctly classified = 79.1250%\n",
      "alpha =  0.6821052631578948 b =  -15922.931223081247 epoch =  249  loss = 5432.711  loss reduction = 338.431  correctly classified = 80.3500%\n",
      "alpha =  0.6821052631578948 b =  -16321.627206239142 epoch =  250  loss = 5791.863  loss reduction = -359.1512  correctly classified = 79.0500%\n",
      "alpha =  0.6821052631578948 b =  -15891.180587291774 epoch =  251  loss = 5460.338  loss reduction = 331.5242  correctly classified = 80.2500%\n",
      "alpha =  0.6821052631578948 b =  -16289.876570449669 epoch =  252  loss = 5791.863  loss reduction = -331.5242  correctly classified = 79.0500%\n",
      "alpha =  0.6821052631578948 b =  -15859.429951502301 epoch =  253  loss = 5460.338  loss reduction = 331.5242  correctly classified = 80.2500%\n",
      "alpha =  0.6821052631578948 b =  -16258.125934660196 epoch =  254  loss = 5791.863  loss reduction = -331.5242  correctly classified = 79.0500%\n",
      "alpha =  0.6821052631578948 b =  -15827.679315712829 epoch =  255  loss = 5460.338  loss reduction = 331.5242  correctly classified = 80.2500%\n",
      "alpha =  0.6821052631578948 b =  -16226.375298870724 epoch =  256  loss = 5791.863  loss reduction = -331.5242  correctly classified = 79.0500%\n",
      "alpha =  0.6821052631578948 b =  -15795.928679923356 epoch =  257  loss = 5460.338  loss reduction = 331.5242  correctly classified = 80.2500%\n",
      "alpha =  0.6821052631578948 b =  -16200.751332554935 epoch =  258  loss = 5812.583  loss reduction = -352.2445  correctly classified = 78.9750%\n",
      "alpha =  0.6821052631578948 b =  -15769.623972554935 epoch =  259  loss = 5467.245  loss reduction = 345.3377  correctly classified = 80.2250%\n",
      "alpha =  0.6821052631578948 b =  -16173.765884133882 epoch =  260  loss = 5805.676  loss reduction = -338.431  correctly classified = 79.0000%\n",
      "alpha =  0.6821052631578948 b =  -15742.638524133881 epoch =  261  loss = 5453.432  loss reduction = 352.2445  correctly classified = 80.2750%\n",
      "alpha =  0.6821052631578948 b =  -16149.503399923355 epoch =  262  loss = 5819.49  loss reduction = -366.058  correctly classified = 78.9500%\n",
      "alpha =  0.6821052631578948 b =  -15719.737522028618 epoch =  263  loss = 5439.618  loss reduction = 379.8715  correctly classified = 80.3250%\n",
      "alpha =  0.6821052631578948 b =  -16126.602397818091 epoch =  264  loss = 5805.676  loss reduction = -366.058  correctly classified = 79.0000%\n",
      "alpha =  0.6821052631578948 b =  -15696.155778870723 epoch =  265  loss = 5446.525  loss reduction = 359.1512  correctly classified = 80.3000%\n",
      "alpha =  0.6821052631578948 b =  -16105.743618870723 epoch =  266  loss = 5805.676  loss reduction = -359.1512  correctly classified = 79.0000%\n",
      "alpha =  0.6821052631578948 b =  -15673.25477676546 epoch =  267  loss = 5453.432  loss reduction = 352.2445  correctly classified = 80.2750%\n",
      "alpha =  0.6821052631578948 b =  -16093.707792268155 epoch =  268  loss = 5868.697  loss reduction = -415.2655  correctly classified = 78.7500%\n",
      "alpha =  0.6821052631578948 b =  -15646.242647004996 epoch =  269  loss = 5563.94  loss reduction = 304.7575  correctly classified = 79.8750%\n",
      "alpha =  0.6821052631578948 b =  -16116.416440689207 epoch =  270  loss = 6254.615  loss reduction = -690.6755  correctly classified = 77.3750%\n",
      "alpha =  0.6821052631578948 b =  -15612.449788057627 epoch =  271  loss = 5847.117  loss reduction = 407.4985  correctly classified = 78.8500%\n",
      "alpha =  0.6821052631578948 b =  -16257.574032268154 epoch =  272  loss = 7449.484  loss reduction = -1602.367  correctly classified = 73.0500%\n",
      "alpha =  0.6821052631578948 b =  -15699.148095426048 epoch =  273  loss = 6178.641  loss reduction = 1270.843  correctly classified = 77.6500%\n",
      "alpha =  0.6821052631578948 b =  -16474.293880689205 epoch =  274  loss = 8658.166  loss reduction = -2479.525  correctly classified = 68.6750%\n",
      "alpha =  0.6821052631578948 b =  -15862.089400689205 epoch =  275  loss = 6517.072  loss reduction = 2141.094  correctly classified = 76.4250%\n",
      "alpha =  0.6821052631578948 b =  -16665.82631016289 epoch =  276  loss = 8920.622  loss reduction = -2403.551  correctly classified = 67.7250%\n",
      "alpha =  0.6821052631578948 b =  -16051.579607004996 epoch =  277  loss = 6510.165  loss reduction = 2410.457  correctly classified = 76.4500%\n",
      "alpha =  0.6821052631578948 b =  -16834.894284899732 epoch =  278  loss = 8741.047  loss reduction = -2230.882  correctly classified = 68.3750%\n",
      "alpha =  0.6821052631578948 b =  -16230.858697531312 epoch =  279  loss = 6448.004  loss reduction = 2293.043  correctly classified = 76.6750%\n",
      "alpha =  0.6821052631578948 b =  -17013.49263437342 epoch =  280  loss = 8734.14  loss reduction = -2286.136  correctly classified = 68.4000%\n",
      "alpha =  0.6821052631578948 b =  -16413.541493320787 epoch =  281  loss = 6420.377  loss reduction = 2313.763  correctly classified = 76.7750%\n",
      "alpha =  0.6821052631578948 b =  -17187.325796478683 epoch =  282  loss = 8644.352  loss reduction = -2223.975  correctly classified = 68.7250%\n",
      "alpha =  0.6821052631578948 b =  -16595.54354805763 epoch =  283  loss = 6378.937  loss reduction = 2265.416  correctly classified = 76.9250%\n",
      "alpha =  0.6821052631578948 b =  -17342.098209110263 epoch =  284  loss = 8409.523  loss reduction = -2030.586  correctly classified = 69.5750%\n",
      "alpha =  0.6821052631578948 b =  -16769.376710162895 epoch =  285  loss = 6282.242  loss reduction = 2127.28  correctly classified = 77.2750%\n",
      "alpha =  0.6821052631578948 b =  -17489.382470162895 epoch =  286  loss = 8167.786  loss reduction = -1885.544  correctly classified = 70.4500%\n",
      "alpha =  0.6821052631578948 b =  -16937.083202794474 epoch =  287  loss = 6102.666  loss reduction = 2065.12  correctly classified = 77.9250%\n",
      "alpha =  0.6821052631578948 b =  -17561.10447437342 epoch =  288  loss = 7359.696  loss reduction = -1257.029  correctly classified = 73.3750%\n",
      "alpha =  0.6821052631578948 b =  -17060.541527005 epoch =  289  loss = 5840.21  loss reduction = 1519.486  correctly classified = 78.8750%\n",
      "alpha =  0.6821052631578948 b =  -17623.296103847104 epoch =  290  loss = 6959.104  loss reduction = -1118.894  correctly classified = 74.8250%\n",
      "alpha =  0.6821052631578948 b =  -17154.047244899735 epoch =  291  loss = 5702.075  loss reduction = 1257.029  correctly classified = 79.3750%\n",
      "alpha =  0.6821052631578948 b =  -17646.004752268156 epoch =  292  loss = 6448.004  loss reduction = -745.9295  correctly classified = 76.6750%\n",
      "alpha =  0.6821052631578948 b =  -17208.750722794473 epoch =  293  loss = 5487.965  loss reduction = 960.0389  correctly classified = 80.1500%\n",
      "alpha =  0.6821052631578948 b =  -17567.282983847104 epoch =  294  loss = 5439.618  loss reduction = 48.34728  correctly classified = 80.3250%\n",
      "alpha =  0.6821052631578948 b =  -17191.976390162894 epoch =  295  loss = 5080.467  loss reduction = 359.1512  correctly classified = 81.6250%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.6821052631578948 b =  -17421.167851215527 epoch =  296  loss = 4762.756  loss reduction = 317.7107  correctly classified = 82.7750%\n",
      "alpha =  0.6821052631578948 b =  -17110.531657531315 epoch =  297  loss = 4769.663  loss reduction = -6.906755  correctly classified = 82.7500%\n",
      "alpha =  0.6821052631578948 b =  -17275.052718583946 epoch =  298  loss = 4424.325  loss reduction = 345.3377  correctly classified = 84.0000%\n",
      "alpha =  0.6821052631578948 b =  -17028.406183847103 epoch =  299  loss = 4603.901  loss reduction = -179.5756  correctly classified = 83.3500%\n",
      "alpha =  0.6821052631578948 b =  -17099.66572068921 epoch =  300  loss = 4168.775  loss reduction = 435.1256  correctly classified = 84.9250%\n",
      "alpha =  0.6821052631578948 b =  -16913.605139636576 epoch =  301  loss = 4320.724  loss reduction = -151.9486  correctly classified = 84.3750%\n",
      "alpha =  0.6821052631578948 b =  -16897.04908068921 epoch =  302  loss = 4065.174  loss reduction = 255.5499  correctly classified = 85.3000%\n",
      "alpha =  0.6821052631578948 b =  -16733.45295437342 epoch =  303  loss = 4258.563  loss reduction = -193.3891  correctly classified = 84.6000%\n",
      "alpha =  0.6821052631578948 b =  -16704.643556478684 epoch =  304  loss = 4037.547  loss reduction = 221.0162  correctly classified = 85.4000%\n",
      "alpha =  0.6821052631578948 b =  -16555.342992268157 epoch =  305  loss = 4224.029  loss reduction = -186.4824  correctly classified = 84.7250%\n",
      "alpha =  0.6821052631578948 b =  -16510.19580911026 epoch =  306  loss = 3982.293  loss reduction = 241.7364  correctly classified = 85.6000%\n",
      "alpha =  0.6821052631578948 b =  -16377.913771215524 epoch =  307  loss = 4161.868  loss reduction = -179.5756  correctly classified = 84.9500%\n",
      "alpha =  0.6821052631578948 b =  -16321.874731215525 epoch =  308  loss = 3940.852  loss reduction = 221.0162  correctly classified = 85.7500%\n",
      "alpha =  0.6821052631578948 b =  -16184.146764899735 epoch =  309  loss = 4175.682  loss reduction = -234.8297  correctly classified = 84.9000%\n",
      "alpha =  0.6821052631578948 b =  -16132.192171215524 epoch =  310  loss = 3940.852  loss reduction = 234.8297  correctly classified = 85.7500%\n",
      "alpha =  0.6821052631578948 b =  -15998.548651215524 epoch =  311  loss = 4161.868  loss reduction = -221.0162  correctly classified = 84.9500%\n",
      "alpha =  0.6821052631578948 b =  -15942.509611215524 epoch =  312  loss = 3927.039  loss reduction = 234.8297  correctly classified = 85.8000%\n",
      "alpha =  0.6821052631578948 b =  -15803.420162794471 epoch =  313  loss = 4120.428  loss reduction = -193.3891  correctly classified = 85.1000%\n",
      "alpha =  0.6821052631578948 b =  -15760.995943847103 epoch =  314  loss = 3940.852  loss reduction = 179.5756  correctly classified = 85.7500%\n",
      "alpha =  0.6821052631578948 b =  -15616.460567004999 epoch =  315  loss = 4120.428  loss reduction = -179.5756  correctly classified = 85.1000%\n",
      "alpha =  0.6821052631578948 b =  -15581.524499636578 epoch =  316  loss = 3920.132  loss reduction = 200.2959  correctly classified = 85.8250%\n",
      "alpha =  0.6821052631578948 b =  -15441.073569110262 epoch =  317  loss = 4092.801  loss reduction = -172.6689  correctly classified = 85.2000%\n",
      "alpha =  0.6821052631578948 b =  -15402.733796478682 epoch =  318  loss = 3899.412  loss reduction = 193.3891  correctly classified = 85.9000%\n",
      "alpha =  0.6821052631578948 b =  -15251.39100911026 epoch =  319  loss = 3996.106  loss reduction = -96.69457  correctly classified = 85.5500%\n",
      "alpha =  0.6821052631578948 b =  -15217.816423847104 epoch =  320  loss = 3878.691  loss reduction = 117.4148  correctly classified = 85.9750%\n",
      "alpha =  0.6821052631578948 b =  -15061.708449110261 epoch =  321  loss = 4016.827  loss reduction = -138.1351  correctly classified = 85.4750%\n",
      "alpha =  0.6821052631578948 b =  -15046.513872268157 epoch =  322  loss = 3899.412  loss reduction = 117.4148  correctly classified = 85.9000%\n",
      "alpha =  0.6821052631578948 b =  -14888.36367437342 epoch =  323  loss = 3996.106  loss reduction = -96.69457  correctly classified = 85.5500%\n",
      "alpha =  0.6821052631578948 b =  -14874.53057963658 epoch =  324  loss = 3899.412  loss reduction = 96.69457  correctly classified = 85.9000%\n",
      "alpha =  0.6821052631578948 b =  -14713.657417531316 epoch =  325  loss = 4009.92  loss reduction = -110.5081  correctly classified = 85.5000%\n",
      "alpha =  0.6821052631578948 b =  -14701.185804899736 epoch =  326  loss = 3885.598  loss reduction = 124.3216  correctly classified = 85.9500%\n",
      "alpha =  0.6821052631578948 b =  -14536.908937531316 epoch =  327  loss = 4003.013  loss reduction = -117.4148  correctly classified = 85.5250%\n",
      "alpha =  0.6821052631578948 b =  -14540.775110162895 epoch =  328  loss = 3913.225  loss reduction = 89.78781  correctly classified = 85.8500%\n",
      "alpha =  0.6821052631578948 b =  -14361.52193963658 epoch =  329  loss = 4016.827  loss reduction = -103.6013  correctly classified = 85.4750%\n",
      "alpha =  0.6821052631578948 b =  -14385.810343847106 epoch =  330  loss = 3899.412  loss reduction = 117.4148  correctly classified = 85.9000%\n",
      "alpha =  0.6821052631578948 b =  -14202.472727005 epoch =  331  loss = 4003.013  loss reduction = -103.6013  correctly classified = 85.5250%\n",
      "alpha =  0.6821052631578948 b =  -14230.845577531316 epoch =  332  loss = 3871.785  loss reduction = 131.2283  correctly classified = 86.0000%\n",
      "alpha =  0.6821052631578948 b =  -14050.911665952368 epoch =  333  loss = 3996.106  loss reduction = -124.3216  correctly classified = 85.5500%\n",
      "alpha =  0.6821052631578948 b =  -14080.645998583946 epoch =  334  loss = 3844.158  loss reduction = 151.9486  correctly classified = 86.1000%\n",
      "alpha =  0.6821052631578948 b =  -13895.266158583947 epoch =  335  loss = 4023.733  loss reduction = -179.5756  correctly classified = 85.4500%\n",
      "alpha =  0.6821052631578948 b =  -13930.446419636579 epoch =  336  loss = 3857.971  loss reduction = 165.7621  correctly classified = 86.0500%\n",
      "alpha =  0.6821052631578948 b =  -13744.385838583947 epoch =  337  loss = 4003.013  loss reduction = -145.0419  correctly classified = 85.5250%\n",
      "alpha =  0.6821052631578948 b =  -13790.457956478684 epoch =  338  loss = 3844.158  loss reduction = 158.8554  correctly classified = 86.1000%\n",
      "alpha =  0.6821052631578948 b =  -13574.444769110263 epoch =  339  loss = 4099.708  loss reduction = -255.5499  correctly classified = 85.1750%\n",
      "alpha =  0.6821052631578948 b =  -13702.20581332079 epoch =  340  loss = 3996.106  loss reduction = 103.6013  correctly classified = 85.5500%\n",
      "alpha =  0.6821052631578948 b =  -13417.437779636579 epoch =  341  loss = 4410.512  loss reduction = -414.4053  correctly classified = 84.0500%\n",
      "alpha =  0.6821052631578948 b =  -13640.502571215526 epoch =  342  loss = 4327.63  loss reduction = 82.88106  correctly classified = 84.3500%\n",
      "alpha =  0.6821052631578948 b =  -13282.214503847104 epoch =  343  loss = 4838.73  loss reduction = -511.0999  correctly classified = 82.5000%\n",
      "alpha =  0.6821052631578948 b =  -13680.229745952367 epoch =  344  loss = 5411.991  loss reduction = -573.2606  correctly classified = 80.4250%\n",
      "alpha =  0.6821052631578948 b =  -13187.835691215525 epoch =  345  loss = 5674.448  loss reduction = -262.4567  correctly classified = 79.4750%\n",
      "alpha =  0.6821052631578948 b =  -13907.841451215525 epoch =  346  loss = 8015.838  loss reduction = -2341.39  correctly classified = 71.0000%\n",
      "alpha =  0.6821052631578948 b =  -13286.106596478683 epoch =  347  loss = 6530.885  loss reduction = 1484.952  correctly classified = 76.3750%\n",
      "alpha =  0.6821052631578948 b =  -14216.46134174184 epoch =  348  loss = 10025.7  loss reduction = -3494.818  correctly classified = 63.7250%\n",
      "alpha =  0.6821052631578948 b =  -13542.309425952366 epoch =  349  loss = 7021.265  loss reduction = 3004.438  correctly classified = 74.6000%\n",
      "alpha =  0.6821052631578948 b =  -14361.703379636576 epoch =  350  loss = 8955.156  loss reduction = -1933.891  correctly classified = 67.6000%\n",
      "alpha =  0.6821052631578948 b =  -13720.227034373418 epoch =  351  loss = 6717.368  loss reduction = 2237.789  correctly classified = 75.7000%\n",
      "alpha =  0.6821052631578948 b =  -14575.700263847102 epoch =  352  loss = 9279.774  loss reduction = -2562.406  correctly classified = 66.4250%\n",
      "alpha =  0.6821052631578948 b =  -13932.862436478681 epoch =  353  loss = 6731.181  loss reduction = 2548.593  correctly classified = 75.6500%\n",
      "alpha =  0.6821052631578948 b =  -14763.828988057629 epoch =  354  loss = 9072.571  loss reduction = -2341.39  correctly classified = 67.1750%\n",
      "alpha =  0.6821052631578948 b =  -14130.521535426049 epoch =  355  loss = 6634.487  loss reduction = 2438.084  correctly classified = 76.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.6821052631578948 b =  -14951.276971215522 epoch =  356  loss = 8968.97  loss reduction = -2334.483  correctly classified = 67.5500%\n",
      "alpha =  0.6821052631578948 b =  -14322.734705952364 epoch =  357  loss = 6586.139  loss reduction = 2382.83  correctly classified = 76.1750%\n",
      "alpha =  0.6821052631578948 b =  -15136.00199016289 epoch =  358  loss = 8892.995  loss reduction = -2306.856  correctly classified = 67.8250%\n",
      "alpha =  0.6821052631578948 b =  -14514.267135426047 epoch =  359  loss = 6544.699  loss reduction = 2348.297  correctly classified = 76.3250%\n",
      "alpha =  0.6821052631578948 b =  -15320.727009110258 epoch =  360  loss = 8823.928  loss reduction = -2279.229  correctly classified = 68.0750%\n",
      "alpha =  0.6821052631578948 b =  -14708.522529110258 epoch =  361  loss = 6448.004  loss reduction = 2375.924  correctly classified = 76.6750%\n",
      "alpha =  0.6821052631578948 b =  -15485.029796478679 epoch =  362  loss = 8547.658  loss reduction = -2099.653  correctly classified = 69.0750%\n",
      "alpha =  0.6821052631578948 b =  -14895.28977121552 epoch =  363  loss = 6316.776  loss reduction = 2230.882  correctly classified = 77.1500%\n",
      "alpha =  0.6821052631578948 b =  -15658.862958583943 epoch =  364  loss = 8416.429  loss reduction = -2099.653  correctly classified = 69.5500%\n",
      "alpha =  0.6821052631578948 b =  -15080.01479016289 epoch =  365  loss = 6233.895  loss reduction = 2182.535  correctly classified = 77.4500%\n",
      "alpha =  0.6821052631578948 b =  -15823.165745952363 epoch =  366  loss = 8264.481  loss reduction = -2030.586  correctly classified = 70.1000%\n",
      "alpha =  0.6821052631578948 b =  -15262.697585952363 epoch =  367  loss = 6116.48  loss reduction = 2148.001  correctly classified = 77.8750%\n",
      "alpha =  0.6821052631578948 b =  -15943.901105952364 epoch =  368  loss = 7718.847  loss reduction = -1602.367  correctly classified = 72.0750%\n",
      "alpha =  0.6821052631578948 b =  -15410.662588057627 epoch =  369  loss = 5923.091  loss reduction = 1795.756  correctly classified = 78.5750%\n",
      "alpha =  0.6821052631578948 b =  -16036.726082794468 epoch =  370  loss = 7200.84  loss reduction = -1277.75  correctly classified = 73.9500%\n",
      "alpha =  0.6821052631578948 b =  -15531.397948057625 epoch =  371  loss = 5736.608  loss reduction = 1464.232  correctly classified = 79.2500%\n",
      "alpha =  0.6821052631578948 b =  -16097.556230162889 epoch =  372  loss = 6717.368  loss reduction = -980.7592  correctly classified = 75.7000%\n",
      "alpha =  0.6821052631578948 b =  -15617.415514373415 epoch =  373  loss = 5591.567  loss reduction = 1125.801  correctly classified = 79.7750%\n",
      "alpha =  0.6821052631578948 b =  -16122.307101741837 epoch =  374  loss = 6247.708  loss reduction = -656.1417  correctly classified = 77.4000%\n",
      "alpha =  0.6821052631578948 b =  -15667.353804899732 epoch =  375  loss = 5446.525  loss reduction = 801.1836  correctly classified = 80.3000%\n",
      "alpha =  0.6821052631578948 b =  -16134.123893320786 epoch =  376  loss = 6012.879  loss reduction = -566.3539  correctly classified = 78.2500%\n",
      "alpha =  0.6821052631578948 b =  -15703.677274373418 epoch =  377  loss = 5280.763  loss reduction = 732.116  correctly classified = 80.9000%\n",
      "alpha =  0.6821052631578948 b =  -16103.734739636577 epoch =  378  loss = 5529.406  loss reduction = -248.6432  correctly classified = 80.0000%\n",
      "alpha =  0.6821052631578948 b =  -15714.132583847102 epoch =  379  loss = 5045.933  loss reduction = 483.4728  correctly classified = 81.7500%\n",
      "alpha =  0.6821052631578948 b =  -16063.134470162891 epoch =  380  loss = 5204.788  loss reduction = -158.8554  correctly classified = 81.1750%\n",
      "alpha =  0.6821052631578948 b =  -15687.147135426048 epoch =  381  loss = 4949.238  loss reduction = 255.5499  correctly classified = 82.1000%\n",
      "alpha =  0.6821052631578948 b =  -15998.7082638471 epoch =  382  loss = 4907.798  loss reduction = 41.44053  correctly classified = 82.2500%\n",
      "alpha =  0.6821052631578948 b =  -15636.335750162889 epoch =  383  loss = 4824.917  loss reduction = 82.88106  correctly classified = 82.5500%\n",
      "alpha =  0.6821052631578948 b =  -15911.817602794468 epoch =  384  loss = 4638.434  loss reduction = 186.4824  correctly classified = 83.2250%\n",
      "alpha =  0.6821052631578948 b =  -15588.247329110258 epoch =  385  loss = 4638.434  loss reduction = 0.0  correctly classified = 83.2250%\n",
      "alpha =  0.7026315789473684 b =  -15797.689155426047 epoch =  0  loss = 4348.351  loss reduction = 290.0837  correctly classified = 84.2750%\n",
      "alpha =  0.7026315789473684 b =  -15499.443129110257 epoch =  1  loss = 4458.859  loss reduction = -110.5081  correctly classified = 83.8750%\n",
      "alpha =  0.7026315789473684 b =  -15680.134676478678 epoch =  2  loss = 4203.309  loss reduction = 255.5499  correctly classified = 84.8000%\n",
      "alpha =  0.7026315789473684 b =  -15395.211950162888 epoch =  3  loss = 4382.885  loss reduction = -179.5756  correctly classified = 84.1500%\n",
      "alpha =  0.7026315789473684 b =  -15576.604723847098 epoch =  4  loss = 4182.589  loss reduction = 200.2959  correctly classified = 84.8750%\n",
      "alpha =  0.7026315789473684 b =  -15288.87709226815 epoch =  5  loss = 4369.071  loss reduction = -186.4824  correctly classified = 84.2000%\n",
      "alpha =  0.7026315789473684 b =  -15475.879676478677 epoch =  6  loss = 4210.216  loss reduction = 158.8554  correctly classified = 84.7750%\n",
      "alpha =  0.7026315789473684 b =  -15187.45081858394 epoch =  7  loss = 4375.978  loss reduction = -165.7621  correctly classified = 84.1750%\n",
      "alpha =  0.7026315789473684 b =  -15374.453402794466 epoch =  8  loss = 4182.589  loss reduction = 193.3891  correctly classified = 84.8750%\n",
      "alpha =  0.7026315789473684 b =  -15086.02454489973 epoch =  9  loss = 4375.978  loss reduction = -193.3891  correctly classified = 84.1750%\n",
      "alpha =  0.7026315789473684 b =  -15273.728355426047 epoch =  10  loss = 4161.868  loss reduction = 214.1094  correctly classified = 84.9500%\n",
      "alpha =  0.7026315789473684 b =  -14982.49459226815 epoch =  11  loss = 4389.791  loss reduction = -227.9229  correctly classified = 84.1250%\n",
      "alpha =  0.7026315789473684 b =  -15175.106987004992 epoch =  12  loss = 4182.589  loss reduction = 207.2026  correctly classified = 84.8750%\n",
      "alpha =  0.7026315789473684 b =  -14870.549923847098 epoch =  13  loss = 4438.139  loss reduction = -255.5499  correctly classified = 83.9500%\n",
      "alpha =  0.7026315789473684 b =  -15079.991750162888 epoch =  14  loss = 4251.656  loss reduction = 186.4824  correctly classified = 84.6250%\n",
      "alpha =  0.7026315789473684 b =  -14764.916292268152 epoch =  15  loss = 4486.486  loss reduction = -234.8297  correctly classified = 83.7750%\n",
      "alpha =  0.7026315789473684 b =  -14998.199813320784 epoch =  16  loss = 4265.47  loss reduction = 221.0162  correctly classified = 84.5750%\n",
      "alpha =  0.7026315789473684 b =  -14664.89247121552 epoch =  17  loss = 4555.553  loss reduction = -290.0837  correctly classified = 83.5250%\n",
      "alpha =  0.7026315789473684 b =  -14936.042213320783 epoch =  18  loss = 4500.299  loss reduction = 55.25404  correctly classified = 83.7250%\n",
      "alpha =  0.7026315789473684 b =  -14576.08827121552 epoch =  19  loss = 4679.875  loss reduction = -179.5756  correctly classified = 83.0750%\n",
      "alpha =  0.7026315789473684 b =  -14902.634892268152 epoch =  20  loss = 4824.917  loss reduction = -145.0419  correctly classified = 82.5500%\n",
      "alpha =  0.7026315789473684 b =  -14481.674260689204 epoch =  21  loss = 5087.374  loss reduction = -262.4567  correctly classified = 81.6000%\n",
      "alpha =  0.7026315789473684 b =  -14936.54529753131 epoch =  22  loss = 5702.075  loss reduction = -614.7012  correctly classified = 79.3750%\n",
      "alpha =  0.7026315789473684 b =  -14444.059581741836 epoch =  23  loss = 5501.779  loss reduction = 200.2959  correctly classified = 80.1000%\n",
      "alpha =  0.7026315789473684 b =  -15062.316350162888 epoch =  24  loss = 6952.197  loss reduction = -1450.419  correctly classified = 74.8500%\n",
      "alpha =  0.7026315789473684 b =  -14506.019039636572 epoch =  25  loss = 5950.718  loss reduction = 1001.479  correctly classified = 78.4750%\n",
      "alpha =  0.7026315789473684 b =  -15276.441918583942 epoch =  26  loss = 8243.76  loss reduction = -2293.043  correctly classified = 70.1750%\n",
      "alpha =  0.7026315789473684 b =  -14660.54037121552 epoch =  27  loss = 6316.776  loss reduction = 1926.985  correctly classified = 77.1500%\n",
      "alpha =  0.7026315789473684 b =  -15506.695692268151 epoch =  28  loss = 8934.436  loss reduction = -2617.66  correctly classified = 67.6750%\n",
      "alpha =  0.7026315789473684 b =  -14864.14754489973 epoch =  29  loss = 6537.792  loss reduction = 2396.644  correctly classified = 76.3500%\n",
      "alpha =  0.7026315789473684 b =  -15694.174660689203 epoch =  30  loss = 8803.208  loss reduction = -2265.416  correctly classified = 68.1500%\n",
      "alpha =  0.7026315789473684 b =  -15062.846134373414 epoch =  31  loss = 6441.097  loss reduction = 2362.11  correctly classified = 76.7000%\n",
      "alpha =  0.7026315789473684 b =  -15875.34259226815 epoch =  32  loss = 8630.539  loss reduction = -2189.441  correctly classified = 68.7750%\n",
      "alpha =  0.7026315789473684 b =  -15252.428781741835 epoch =  33  loss = 6385.843  loss reduction = 2244.695  correctly classified = 76.9000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.7026315789473684 b =  -16053.00439226815 epoch =  34  loss = 8526.937  loss reduction = -2141.094  correctly classified = 69.1500%\n",
      "alpha =  0.7026315789473684 b =  -15442.712655426045 epoch =  35  loss = 6275.335  loss reduction = 2251.602  correctly classified = 77.3000%\n",
      "alpha =  0.7026315789473684 b =  -16234.873550162887 epoch =  36  loss = 8444.056  loss reduction = -2168.721  correctly classified = 69.4500%\n",
      "alpha =  0.7026315789473684 b =  -15639.30756595236 epoch =  37  loss = 6185.548  loss reduction = 2258.509  correctly classified = 77.6250%\n",
      "alpha =  0.7026315789473684 b =  -16383.08384489973 epoch =  38  loss = 8022.744  loss reduction = -1837.197  correctly classified = 70.9750%\n",
      "alpha =  0.7026315789473684 b =  -15817.67059226815 epoch =  39  loss = 6026.692  loss reduction = 1996.052  correctly classified = 78.2000%\n",
      "alpha =  0.7026315789473684 b =  -16494.830371215518 epoch =  40  loss = 7463.297  loss reduction = -1436.605  correctly classified = 73.0000%\n",
      "alpha =  0.7026315789473684 b =  -15962.374755426044 epoch =  41  loss = 5784.956  loss reduction = 1678.341  correctly classified = 79.0750%\n",
      "alpha =  0.7026315789473684 b =  -16564.50331858394 epoch =  42  loss = 6793.342  loss reduction = -1008.386  correctly classified = 75.4250%\n",
      "alpha =  0.7026315789473684 b =  -16068.511471215517 epoch =  43  loss = 5550.126  loss reduction = 1243.216  correctly classified = 79.9250%\n",
      "alpha =  0.7026315789473684 b =  -16585.791650162886 epoch =  44  loss = 6220.081  loss reduction = -669.9552  correctly classified = 77.5000%\n",
      "alpha =  0.7026315789473684 b =  -16123.45866595236 epoch =  45  loss = 5342.923  loss reduction = 877.1579  correctly classified = 80.6750%\n",
      "alpha =  0.7026315789473684 b =  -16590.250550162884 epoch =  46  loss = 5805.676  loss reduction = -462.7526  correctly classified = 79.0000%\n",
      "alpha =  0.7026315789473684 b =  -16155.265392268147 epoch =  47  loss = 5211.695  loss reduction = 593.9809  correctly classified = 81.1500%\n",
      "alpha =  0.7026315789473684 b =  -16554.739550162885 epoch =  48  loss = 5322.203  loss reduction = -110.5081  correctly classified = 80.7500%\n",
      "alpha =  0.7026315789473684 b =  -16161.126744899728 epoch =  49  loss = 4928.518  loss reduction = 393.685  correctly classified = 82.1750%\n",
      "alpha =  0.7026315789473684 b =  -16497.490534373414 epoch =  50  loss = 4935.425  loss reduction = -6.906755  correctly classified = 82.1500%\n",
      "alpha =  0.7026315789473684 b =  -16129.823102794466 epoch =  51  loss = 4714.409  loss reduction = 221.0162  correctly classified = 82.9500%\n",
      "alpha =  0.7026315789473684 b =  -16403.076523847096 epoch =  52  loss = 4534.833  loss reduction = 179.5756  correctly classified = 83.6000%\n",
      "alpha =  0.7026315789473684 b =  -16078.183897531306 epoch =  53  loss = 4486.486  loss reduction = 48.34728  correctly classified = 83.7750%\n",
      "alpha =  0.7026315789473684 b =  -16279.211008057622 epoch =  54  loss = 4196.402  loss reduction = 290.0837  correctly classified = 84.8250%\n",
      "alpha =  0.7026315789473684 b =  -16003.404223847096 epoch =  55  loss = 4265.47  loss reduction = -69.06755  correctly classified = 84.5750%\n",
      "alpha =  0.7026315789473684 b =  -16129.400118583937 epoch =  56  loss = 3857.971  loss reduction = 407.4985  correctly classified = 86.0500%\n",
      "alpha =  0.7026315789473684 b =  -15885.148518583937 epoch =  57  loss = 4092.801  loss reduction = -234.8297  correctly classified = 85.2000%\n",
      "alpha =  0.7026315789473684 b =  -15987.302718583938 epoch =  58  loss = 3775.09  loss reduction = 317.7107  correctly classified = 86.3500%\n",
      "alpha =  0.7026315789473684 b =  -15771.801397531306 epoch =  59  loss = 3975.386  loss reduction = -200.2959  correctly classified = 85.6250%\n",
      "alpha =  0.7026315789473684 b =  -15840.997960689201 epoch =  60  loss = 3671.489  loss reduction = 303.8972  correctly classified = 86.7250%\n",
      "alpha =  0.7026315789473684 b =  -15640.222392268148 epoch =  61  loss = 3899.412  loss reduction = -227.9229  correctly classified = 85.9000%\n",
      "alpha =  0.7026315789473684 b =  -15664.540471215516 epoch =  62  loss = 3754.37  loss reduction = 145.0419  correctly classified = 86.4250%\n",
      "alpha =  0.7026315789473684 b =  -15505.137255426042 epoch =  63  loss = 3740.556  loss reduction = 13.81351  correctly classified = 86.4750%\n",
      "alpha =  0.7026315789473684 b =  -15455.125344899725 epoch =  64  loss = 3547.167  loss reduction = 193.3891  correctly classified = 87.1750%\n",
      "alpha =  0.7026315789473684 b =  -15312.551560689199 epoch =  65  loss = 3726.743  loss reduction = -179.5756  correctly classified = 86.5250%\n",
      "alpha =  0.7026315789473684 b =  -15242.905313320778 epoch =  66  loss = 3574.794  loss reduction = 151.9486  correctly classified = 87.0750%\n",
      "alpha =  0.7026315789473684 b =  -15103.8376606892 epoch =  67  loss = 3719.836  loss reduction = -145.0419  correctly classified = 86.5500%\n",
      "alpha =  0.7026315789473684 b =  -15029.282829110252 epoch =  68  loss = 3567.887  loss reduction = 151.9486  correctly classified = 87.1000%\n",
      "alpha =  0.7026315789473684 b =  -14889.513950162884 epoch =  69  loss = 3712.929  loss reduction = -145.0419  correctly classified = 86.5750%\n",
      "alpha =  0.7026315789473684 b =  -14820.568929110252 epoch =  70  loss = 3554.074  loss reduction = 158.8554  correctly classified = 87.1500%\n",
      "alpha =  0.7026315789473684 b =  -14681.501276478673 epoch =  71  loss = 3692.209  loss reduction = -138.1351  correctly classified = 86.6500%\n",
      "alpha =  0.7026315789473684 b =  -14611.855029110253 epoch =  72  loss = 3547.167  loss reduction = 145.0419  correctly classified = 87.1750%\n",
      "alpha =  0.7026315789473684 b =  -14473.488602794463 epoch =  73  loss = 3685.302  loss reduction = -138.1351  correctly classified = 86.6750%\n",
      "alpha =  0.7026315789473684 b =  -14405.244808057621 epoch =  74  loss = 3533.354  loss reduction = 151.9486  correctly classified = 87.2250%\n",
      "alpha =  0.7026315789473684 b =  -14264.774702794464 epoch =  75  loss = 3664.582  loss reduction = -131.2283  correctly classified = 86.7500%\n",
      "alpha =  0.7026315789473684 b =  -14195.829681741832 epoch =  76  loss = 3540.26  loss reduction = 124.3216  correctly classified = 87.2000%\n",
      "alpha =  0.7026315789473684 b =  -14052.554671215516 epoch =  77  loss = 3664.582  loss reduction = -124.3216  correctly classified = 86.7500%\n",
      "alpha =  0.7026315789473684 b =  -13995.530497531305 epoch =  78  loss = 3505.727  loss reduction = 158.8554  correctly classified = 87.3250%\n",
      "alpha =  0.7026315789473684 b =  -13834.724829110251 epoch =  79  loss = 3699.116  loss reduction = -193.3891  correctly classified = 86.6250%\n",
      "alpha =  0.7026315789473684 b =  -13813.463197531304 epoch =  80  loss = 3415.939  loss reduction = 283.1769  correctly classified = 87.6500%\n",
      "alpha =  0.7026315789473684 b =  -13666.682055426041 epoch =  81  loss = 3657.675  loss reduction = -241.7364  correctly classified = 86.7750%\n",
      "alpha =  0.7026315789473684 b =  -13618.773823847094 epoch =  82  loss = 3485.006  loss reduction = 172.6689  correctly classified = 87.4000%\n",
      "alpha =  0.7026315789473684 b =  -13460.773060689198 epoch =  83  loss = 3657.675  loss reduction = -172.6689  correctly classified = 86.7750%\n",
      "alpha =  0.7026315789473684 b =  -13431.096713320778 epoch =  84  loss = 3402.125  loss reduction = 255.5499  correctly classified = 87.7000%\n",
      "alpha =  0.7026315789473684 b =  -13274.498402794461 epoch =  85  loss = 3657.675  loss reduction = -255.5499  correctly classified = 86.7750%\n",
      "alpha =  0.7026315789473684 b =  -13246.925734373408 epoch =  86  loss = 3381.405  loss reduction = 276.2702  correctly classified = 87.7750%\n",
      "alpha =  0.7026315789473684 b =  -13088.223744899724 epoch =  87  loss = 3650.769  loss reduction = -269.3634  correctly classified = 86.8000%\n",
      "alpha =  0.7026315789473684 b =  -13064.858434373407 epoch =  88  loss = 3381.405  loss reduction = 269.3634  correctly classified = 87.7750%\n",
      "alpha =  0.7026315789473684 b =  -12909.662576478671 epoch =  89  loss = 3630.048  loss reduction = -248.6432  correctly classified = 86.8750%\n",
      "alpha =  0.7026315789473684 b =  -12891.205850162882 epoch =  90  loss = 3402.125  loss reduction = 227.9229  correctly classified = 87.7000%\n",
      "alpha =  0.7026315789473684 b =  -12732.503860689198 epoch =  91  loss = 3636.955  loss reduction = -234.8297  correctly classified = 86.8500%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.7026315789473684 b =  -12753.31580805762 epoch =  92  loss = 3333.058  loss reduction = 303.8972  correctly classified = 87.9500%\n",
      "alpha =  0.7026315789473684 b =  -12563.058634373408 epoch =  93  loss = 3754.37  loss reduction = -421.312  correctly classified = 86.4250%\n",
      "alpha =  0.7026315789473684 b =  -12631.553971215513 epoch =  94  loss = 3443.566  loss reduction = 310.804  correctly classified = 87.5500%\n",
      "alpha =  0.7026315789473684 b =  -12404.13180279446 epoch =  95  loss = 3899.412  loss reduction = -455.8458  correctly classified = 85.9000%\n",
      "alpha =  0.7026315789473684 b =  -12543.450997531301 epoch =  96  loss = 3547.167  loss reduction = 352.2445  correctly classified = 87.1750%\n",
      "alpha =  0.7026315789473684 b =  -12269.046665952354 epoch =  97  loss = 4099.708  loss reduction = -552.5404  correctly classified = 85.1750%\n",
      "alpha =  0.7026315789473684 b =  -12496.72037647867 epoch =  98  loss = 4016.827  loss reduction = 82.88106  correctly classified = 85.4750%\n",
      "alpha =  0.7026315789473684 b =  -12157.803223847091 epoch =  99  loss = 4458.859  loss reduction = -442.0323  correctly classified = 83.8750%\n",
      "alpha =  0.7026315789473684 b =  -12509.593992268145 epoch =  100  loss = 4783.476  loss reduction = -324.6175  correctly classified = 82.7000%\n",
      "alpha =  0.7026315789473684 b =  -12059.88308174183 epoch =  101  loss = 5108.094  loss reduction = -324.6175  correctly classified = 81.5250%\n",
      "alpha =  0.7026315789473684 b =  -12657.804287004987 epoch =  102  loss = 6641.393  loss reduction = -1533.3  correctly classified = 75.9750%\n",
      "alpha =  0.7026315789473684 b =  -12074.860376478671 epoch =  103  loss = 6047.412  loss reduction = 593.9809  correctly classified = 78.1250%\n",
      "alpha =  0.7026315789473684 b =  -12953.27210805762 epoch =  104  loss = 9210.706  loss reduction = -3163.294  correctly classified = 66.6750%\n",
      "alpha =  0.7026315789473684 b =  -12284.077360689198 epoch =  105  loss = 6800.249  loss reduction = 2410.457  correctly classified = 75.4000%\n",
      "alpha =  0.7026315789473684 b =  -13171.605034373408 epoch =  106  loss = 9314.307  loss reduction = -2514.059  correctly classified = 66.3000%\n",
      "alpha =  0.7026315789473684 b =  -12501.709060689198 epoch =  107  loss = 6807.155  loss reduction = 2507.152  correctly classified = 75.3750%\n",
      "alpha =  0.7026315789473684 b =  -13361.88890805762 epoch =  108  loss = 9044.944  loss reduction = -2237.789  correctly classified = 67.2750%\n",
      "alpha =  0.7026315789473684 b =  -12712.328497531304 epoch =  109  loss = 6606.86  loss reduction = 2438.084  correctly classified = 76.1000%\n",
      "alpha =  0.7026315789473684 b =  -13553.57523437341 epoch =  110  loss = 8872.275  loss reduction = -2265.416  correctly classified = 67.9000%\n",
      "alpha =  0.7026315789473684 b =  -12918.039350162882 epoch =  111  loss = 6468.724  loss reduction = 2403.551  correctly classified = 76.6000%\n",
      "alpha =  0.7026315789473684 b =  -13747.365239636567 epoch =  112  loss = 8754.86  loss reduction = -2286.136  correctly classified = 68.3250%\n",
      "alpha =  0.7026315789473684 b =  -13121.646523847094 epoch =  113  loss = 6385.843  loss reduction = 2369.017  correctly classified = 76.9000%\n",
      "alpha =  0.7026315789473684 b =  -13938.350339636567 epoch =  114  loss = 8630.539  loss reduction = -2244.695  correctly classified = 68.7750%\n",
      "alpha =  0.7026315789473684 b =  -13321.747565952357 epoch =  115  loss = 6309.869  loss reduction = 2320.67  correctly classified = 77.1750%\n",
      "alpha =  0.7026315789473684 b =  -14099.18270805762 epoch =  116  loss = 8271.387  loss reduction = -1961.518  correctly classified = 70.0750%\n",
      "alpha =  0.7026315789473684 b =  -13506.421629110251 epoch =  117  loss = 6130.293  loss reduction = 2141.094  correctly classified = 77.8250%\n",
      "alpha =  0.7026315789473684 b =  -14273.338376478672 epoch =  118  loss = 8167.786  loss reduction = -2037.493  correctly classified = 70.4500%\n",
      "alpha =  0.7026315789473684 b =  -13686.18710805762 epoch =  119  loss = 6075.039  loss reduction = 2092.747  correctly classified = 78.0250%\n",
      "alpha =  0.7026315789473684 b =  -14402.615560689199 epoch =  120  loss = 7711.94  loss reduction = -1636.901  correctly classified = 72.1000%\n",
      "alpha =  0.7026315789473684 b =  -13844.915797531305 epoch =  121  loss = 5881.65  loss reduction = 1830.29  correctly classified = 78.7250%\n",
      "alpha =  0.7026315789473684 b =  -14504.544918583935 epoch =  122  loss = 7193.934  loss reduction = -1312.283  correctly classified = 73.9750%\n",
      "alpha =  0.7026315789473684 b =  -13981.205244899724 epoch =  123  loss = 5653.727  loss reduction = 1540.206  correctly classified = 79.5500%\n",
      "alpha =  0.7026315789473684 b =  -14586.839939636566 epoch =  124  loss = 6744.995  loss reduction = -1091.267  correctly classified = 75.6000%\n",
      "alpha =  0.7026315789473684 b =  -14080.329697531302 epoch =  125  loss = 5543.219  loss reduction = 1201.775  correctly classified = 79.9500%\n",
      "alpha =  0.7026315789473684 b =  -14652.30552911025 epoch =  126  loss = 6468.724  loss reduction = -925.5051  correctly classified = 76.6000%\n",
      "alpha =  0.7026315789473684 b =  -14164.027171215514 epoch =  127  loss = 5405.084  loss reduction = 1063.64  correctly classified = 80.4500%\n",
      "alpha =  0.7026315789473684 b =  -14707.252723847092 epoch =  128  loss = 6254.615  loss reduction = -849.5308  correctly classified = 77.3750%\n",
      "alpha =  0.7026315789473684 b =  -14236.505023847092 epoch =  129  loss = 5273.856  loss reduction = 980.7592  correctly classified = 80.9250%\n",
      "alpha =  0.7026315789473684 b =  -14724.333697531303 epoch =  130  loss = 5819.49  loss reduction = -545.6336  correctly classified = 78.9500%\n",
      "alpha =  0.7026315789473684 b =  -14274.622787004988 epoch =  131  loss = 5135.721  loss reduction = 683.7687  correctly classified = 81.4250%\n",
      "alpha =  0.7026315789473684 b =  -14727.390144899724 epoch =  132  loss = 5570.846  loss reduction = -435.1256  correctly classified = 79.8500%\n",
      "alpha =  0.7026315789473684 b =  -14307.130739636566 epoch =  133  loss = 4928.518  loss reduction = 642.3282  correctly classified = 82.1750%\n",
      "alpha =  0.7026315789473684 b =  -14729.044139636566 epoch =  134  loss = 5349.83  loss reduction = -421.312  correctly classified = 80.6500%\n",
      "alpha =  0.7026315789473684 b =  -14329.120297531303 epoch =  135  loss = 4838.73  loss reduction = 511.0999  correctly classified = 82.5000%\n",
      "alpha =  0.7026315789473684 b =  -14708.258892268144 epoch =  136  loss = 5011.399  loss reduction = -172.6689  correctly classified = 81.8750%\n",
      "alpha =  0.7026315789473684 b =  -14313.944860689197 epoch =  137  loss = 4811.103  loss reduction = 200.2959  correctly classified = 82.6000%\n",
      "alpha =  0.7026315789473684 b =  -14683.266287004986 epoch =  138  loss = 4914.705  loss reduction = -103.6013  correctly classified = 82.2250%\n",
      "alpha =  0.7026315789473684 b =  -14297.366971215513 epoch =  139  loss = 4783.476  loss reduction = 131.2283  correctly classified = 82.7000%\n",
      "alpha =  0.7026315789473684 b =  -14642.84670279446 epoch =  140  loss = 4721.316  loss reduction = 62.16079  correctly classified = 82.9250%\n",
      "alpha =  0.7026315789473684 b =  -14277.98417647867 epoch =  141  loss = 4617.714  loss reduction = 103.6013  correctly classified = 83.3000%\n",
      "alpha =  0.7026315789473684 b =  -14560.353539636566 epoch =  142  loss = 4389.791  loss reduction = 227.9229  correctly classified = 84.1250%\n",
      "alpha =  0.7026315789473684 b =  -14227.747423847093 epoch =  143  loss = 4410.512  loss reduction = -20.72026  correctly classified = 84.0500%\n",
      "alpha =  0.7026315789473684 b =  -14478.561602794462 epoch =  144  loss = 4189.495  loss reduction = 221.0162  correctly classified = 84.8500%\n",
      "alpha =  0.7026315789473684 b =  -14176.108218583935 epoch =  145  loss = 4237.843  loss reduction = -48.34728  correctly classified = 84.6750%\n",
      "alpha =  0.7026315789473684 b =  -14381.342687004988 epoch =  146  loss = 3961.572  loss reduction = 276.2702  correctly classified = 85.6750%\n",
      "alpha =  0.7026315789473684 b =  -14092.913829110252 epoch =  147  loss = 4168.775  loss reduction = -207.2026  correctly classified = 84.9250%\n",
      "alpha =  0.7026315789473684 b =  -14279.916413320778 epoch =  148  loss = 3809.624  loss reduction = 359.1512  correctly classified = 86.2250%\n",
      "alpha =  0.7026315789473684 b =  -14011.823118583936 epoch =  149  loss = 4106.614  loss reduction = -296.9905  correctly classified = 85.1500%\n",
      "alpha =  0.7026315789473684 b =  -14179.191365952356 epoch =  150  loss = 3685.302  loss reduction = 421.312  correctly classified = 86.6750%\n",
      "alpha =  0.7026315789473684 b =  -13923.018918583935 epoch =  151  loss = 4030.64  loss reduction = -345.3377  correctly classified = 85.4250%\n",
      "alpha =  0.7026315789473684 b =  -14056.728302794461 epoch =  152  loss = 3560.981  loss reduction = 469.6593  correctly classified = 87.1250%\n",
      "alpha =  0.7026315789473684 b =  -13825.098776478671 epoch =  153  loss = 3913.225  loss reduction = -352.2445  correctly classified = 85.8500%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.7026315789473684 b =  -13925.850523847092 epoch =  154  loss = 3512.633  loss reduction = 400.5918  correctly classified = 87.3000%\n",
      "alpha =  0.7026315789473684 b =  -13717.361465952356 epoch =  155  loss = 3781.997  loss reduction = -269.3634  correctly classified = 86.3250%\n",
      "alpha =  0.7026315789473684 b =  -13805.491139636566 epoch =  156  loss = 3471.193  loss reduction = 310.804  correctly classified = 87.4500%\n",
      "alpha =  0.7026315789473684 b =  -13597.703308057618 epoch =  157  loss = 3775.09  loss reduction = -303.8972  correctly classified = 86.3500%\n",
      "alpha =  0.7026315789473684 b =  -13687.936660689198 epoch =  158  loss = 3478.1  loss reduction = 296.9905  correctly classified = 87.4250%\n",
      "alpha =  0.7026315789473684 b =  -13477.343923847093 epoch =  159  loss = 3788.904  loss reduction = -310.804  correctly classified = 86.3000%\n",
      "alpha =  0.7026315789473684 b =  -13578.796897531303 epoch =  160  loss = 3505.727  loss reduction = 283.1769  correctly classified = 87.3250%\n",
      "alpha =  0.7026315789473684 b =  -13361.893123847092 epoch =  161  loss = 3795.81  loss reduction = -290.0837  correctly classified = 86.2750%\n",
      "alpha =  0.7026315789473684 b =  -13466.85222911025 epoch =  162  loss = 3485.006  loss reduction = 310.804  correctly classified = 87.4000%\n",
      "alpha =  0.7026315789473684 b =  -13251.350908057619 epoch =  163  loss = 3781.997  loss reduction = -296.9905  correctly classified = 86.3250%\n",
      "alpha =  0.7026315789473684 b =  -13359.816144899723 epoch =  164  loss = 3450.473  loss reduction = 331.5242  correctly classified = 87.5250%\n",
      "alpha =  0.7026315789473684 b =  -13142.211144899724 epoch =  165  loss = 3775.09  loss reduction = -324.6175  correctly classified = 86.3500%\n",
      "alpha =  0.7026315789473684 b =  -13252.078834373408 epoch =  166  loss = 3450.473  loss reduction = 324.6175  correctly classified = 87.5250%\n",
      "alpha =  0.7026315789473684 b =  -13032.370155426039 epoch =  167  loss = 3781.997  loss reduction = -331.5242  correctly classified = 86.3250%\n",
      "alpha =  0.7026315789473684 b =  -13149.951334373407 epoch =  168  loss = 3443.566  loss reduction = 338.431  correctly classified = 87.5500%\n",
      "alpha =  0.7026315789473684 b =  -12920.425487004986 epoch =  169  loss = 3795.81  loss reduction = -352.2445  correctly classified = 86.2750%\n",
      "alpha =  0.7026315789473684 b =  -13047.122608057618 epoch =  170  loss = 3409.032  loss reduction = 386.7783  correctly classified = 87.6750%\n",
      "alpha =  0.7026315789473684 b =  -12817.596760689197 epoch =  171  loss = 3781.997  loss reduction = -372.9648  correctly classified = 86.3250%\n",
      "alpha =  0.7026315789473684 b =  -12947.800013320777 epoch =  172  loss = 3415.939  loss reduction = 366.058  correctly classified = 87.6500%\n",
      "alpha =  0.7026315789473684 b =  -12714.768034373408 epoch =  173  loss = 3802.717  loss reduction = -386.7783  correctly classified = 86.2500%\n",
      "alpha =  0.7026315789473684 b =  -12847.074965952355 epoch =  174  loss = 3409.032  loss reduction = 393.685  correctly classified = 87.6750%\n",
      "alpha =  0.7026315789473684 b =  -12607.73195016288 epoch =  175  loss = 3795.81  loss reduction = -386.7783  correctly classified = 86.2750%\n",
      "alpha =  0.7026315789473684 b =  -12765.28302911025 epoch =  176  loss = 3478.1  loss reduction = 317.7107  correctly classified = 87.4250%\n",
      "alpha =  0.7026315789473684 b =  -12484.567660689196 epoch =  177  loss = 4037.547  loss reduction = -559.4471  correctly classified = 85.4000%\n",
      "alpha =  0.7026315789473684 b =  -12692.607034373406 epoch =  178  loss = 3754.37  loss reduction = 283.1769  correctly classified = 86.4250%\n",
      "alpha =  0.7026315789473684 b =  -12396.464687004986 epoch =  179  loss = 4120.428  loss reduction = -366.058  correctly classified = 85.1000%\n",
      "alpha =  0.7026315789473684 b =  -12624.138397531302 epoch =  180  loss = 3781.997  loss reduction = 338.431  correctly classified = 86.3250%\n",
      "alpha =  0.7026315789473684 b =  -12307.660487004987 epoch =  181  loss = 4237.843  loss reduction = -455.8458  correctly classified = 84.6750%\n",
      "alpha =  0.7026315789473684 b =  -12576.706550162882 epoch =  182  loss = 4078.987  loss reduction = 158.8554  correctly classified = 85.2500%\n",
      "alpha =  0.7026315789473684 b =  -12204.831760689198 epoch =  183  loss = 4493.393  loss reduction = -414.4053  correctly classified = 83.7500%\n",
      "alpha =  0.7026315789473684 b =  -12583.269129110251 epoch =  184  loss = 4880.171  loss reduction = -386.7783  correctly classified = 82.3500%\n",
      "alpha =  0.7026315789473684 b =  -12146.881518583936 epoch =  185  loss = 4935.425  loss reduction = -55.25404  correctly classified = 82.1500%\n",
      "alpha =  0.7026315789473684 b =  -12683.09480805762 epoch =  186  loss = 6061.226  loss reduction = -1125.801  correctly classified = 78.0750%\n",
      "alpha =  0.7026315789473684 b =  -12174.48088700499 epoch =  187  loss = 5467.245  loss reduction = 593.9809  correctly classified = 80.2250%\n",
      "alpha =  0.7026315789473684 b =  -12827.798971215516 epoch =  188  loss = 7076.519  loss reduction = -1609.274  correctly classified = 74.4000%\n",
      "alpha =  0.7026315789473684 b =  -12267.995529110252 epoch =  189  loss = 5847.117  loss reduction = 1229.402  correctly classified = 78.8500%\n",
      "alpha =  0.7026315789473684 b =  -12980.216623847095 epoch =  190  loss = 7629.059  loss reduction = -1781.943  correctly classified = 72.4000%\n",
      "alpha =  0.7026315789473684 b =  -12397.272713320779 epoch =  191  loss = 6033.599  loss reduction = 1595.46  correctly classified = 78.1750%\n",
      "alpha =  0.7026315789473684 b =  -13175.409081741831 epoch =  192  loss = 8250.667  loss reduction = -2217.068  correctly classified = 70.1500%\n",
      "alpha =  0.7026315789473684 b =  -12567.922250162883 epoch =  193  loss = 6233.895  loss reduction = 2016.772  correctly classified = 77.4500%\n",
      "alpha =  0.7026315789473684 b =  -13372.705218583935 epoch =  194  loss = 8513.124  loss reduction = -2279.229  correctly classified = 69.2000%\n",
      "alpha =  0.7026315789473684 b =  -12763.11470805762 epoch =  195  loss = 6254.615  loss reduction = 2258.509  correctly classified = 77.3750%\n",
      "alpha =  0.7026315789473684 b =  -13547.562113320777 epoch =  196  loss = 8312.828  loss reduction = -2058.213  correctly classified = 69.9250%\n",
      "alpha =  0.7026315789473684 b =  -12949.191223847092 epoch =  197  loss = 6171.734  loss reduction = 2141.094  correctly classified = 77.6750%\n",
      "alpha =  0.7026315789473684 b =  -13728.730044899723 epoch =  198  loss = 8264.481  loss reduction = -2092.747  correctly classified = 70.1000%\n",
      "alpha =  0.7026315789473684 b =  -13137.371418583934 epoch =  199  loss = 6102.666  loss reduction = 2161.814  correctly classified = 77.9250%\n",
      "alpha =  0.7026315789473684 b =  -13876.239113320777 epoch =  200  loss = 7905.329  loss reduction = -1802.663  correctly classified = 71.4000%\n",
      "alpha =  0.7026315789473684 b =  -13309.423408057619 epoch =  201  loss = 5874.744  loss reduction = 2030.586  correctly classified = 78.7500%\n",
      "alpha =  0.7026315789473684 b =  -13967.65007647867 epoch =  202  loss = 7152.493  loss reduction = -1277.75  correctly classified = 74.1250%\n",
      "alpha =  0.7026315789473684 b =  -13452.725118583934 epoch =  203  loss = 5501.779  loss reduction = 1650.714  correctly classified = 80.1000%\n",
      "alpha =  0.7026315789473684 b =  -14039.42670279446 epoch =  204  loss = 6530.885  loss reduction = -1029.106  correctly classified = 76.3750%\n",
      "alpha =  0.7026315789473684 b =  -13544.837308057618 epoch =  205  loss = 5411.991  loss reduction = 1118.894  correctly classified = 80.4250%\n",
      "alpha =  0.7026315789473684 b =  -14083.154276478672 epoch =  206  loss = 6095.76  loss reduction = -683.7687  correctly classified = 77.9500%\n",
      "alpha =  0.7026315789473684 b =  -13626.43110279446 epoch =  207  loss = 5121.907  loss reduction = 973.8524  correctly classified = 81.4750%\n",
      "alpha =  0.7026315789473684 b =  -14093.924213320775 epoch =  208  loss = 5577.753  loss reduction = -455.8458  correctly classified = 79.8250%\n",
      "alpha =  0.7026315789473684 b =  -13668.054997531302 epoch =  209  loss = 4900.891  loss reduction = 676.862  correctly classified = 82.2750%\n",
      "alpha =  0.7026315789473684 b =  -14099.785565952356 epoch =  210  loss = 5322.203  loss reduction = -421.312  correctly classified = 80.7500%\n",
      "alpha =  0.7026315789473684 b =  -13672.513897531304 epoch =  211  loss = 4900.891  loss reduction = 421.312  correctly classified = 82.2750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.7026315789473684 b =  -14101.4395606892 epoch =  212  loss = 5294.576  loss reduction = -393.685  correctly classified = 80.8500%\n",
      "alpha =  0.7026315789473684 b =  -13674.167892268148 epoch =  213  loss = 4900.891  loss reduction = 393.685  correctly classified = 82.2750%\n",
      "alpha =  0.7026315789473684 b =  -14104.496008057622 epoch =  214  loss = 5308.39  loss reduction = -407.4985  correctly classified = 80.8000%\n",
      "alpha =  0.7026315789473684 b =  -13677.22433963657 epoch =  215  loss = 4900.891  loss reduction = 407.4985  correctly classified = 82.2750%\n",
      "alpha =  0.7026315789473684 b =  -14107.552455426045 epoch =  216  loss = 5308.39  loss reduction = -407.4985  correctly classified = 80.8000%\n",
      "alpha =  0.7026315789473684 b =  -13680.280787004993 epoch =  217  loss = 4900.891  loss reduction = 407.4985  correctly classified = 82.2750%\n",
      "alpha =  0.7026315789473684 b =  -14110.608902794467 epoch =  218  loss = 5308.39  loss reduction = -407.4985  correctly classified = 80.8000%\n",
      "alpha =  0.7026315789473684 b =  -13684.739687004994 epoch =  219  loss = 4900.891  loss reduction = 407.4985  correctly classified = 82.2750%\n",
      "alpha =  0.7026315789473684 b =  -14112.26289753131 epoch =  220  loss = 5294.576  loss reduction = -393.685  correctly classified = 80.8500%\n",
      "alpha =  0.7026315789473684 b =  -13689.899813320782 epoch =  221  loss = 4866.357  loss reduction = 428.2188  correctly classified = 82.4000%\n",
      "alpha =  0.7026315789473684 b =  -14116.020571215518 epoch =  222  loss = 5280.763  loss reduction = -414.4053  correctly classified = 80.9000%\n",
      "alpha =  0.7026315789473684 b =  -13691.553808057624 epoch =  223  loss = 4887.078  loss reduction = 393.685  correctly classified = 82.3250%\n",
      "alpha =  0.7026315789473684 b =  -14117.67456595236 epoch =  224  loss = 5280.763  loss reduction = -393.685  correctly classified = 80.9000%\n",
      "alpha =  0.7026315789473684 b =  -13697.415160689203 epoch =  225  loss = 4845.637  loss reduction = 435.1256  correctly classified = 82.4750%\n",
      "alpha =  0.7026315789473684 b =  -14121.432239636571 epoch =  226  loss = 5260.042  loss reduction = -414.4053  correctly classified = 80.9750%\n",
      "alpha =  0.7026315789473684 b =  -13700.471608057624 epoch =  227  loss = 4852.544  loss reduction = 407.4985  correctly classified = 82.4500%\n",
      "alpha =  0.7026315789473684 b =  -14122.385008057623 epoch =  228  loss = 5239.322  loss reduction = -386.7783  correctly classified = 81.0500%\n",
      "alpha =  0.7026315789473684 b =  -13718.253808057623 epoch =  229  loss = 4742.036  loss reduction = 497.2863  correctly classified = 82.8500%\n",
      "alpha =  0.7026315789473684 b =  -14082.666650162886 epoch =  230  loss = 4811.103  loss reduction = -69.06755  correctly classified = 82.6000%\n",
      "alpha =  0.7026315789473684 b =  -13723.413934373413 epoch =  231  loss = 4438.139  loss reduction = 372.9648  correctly classified = 83.9500%\n",
      "alpha =  0.7026315789473684 b =  -13998.771034373412 epoch =  232  loss = 4182.589  loss reduction = 255.5499  correctly classified = 84.8750%\n",
      "alpha =  0.7026315789473684 b =  -13689.305387004992 epoch =  233  loss = 4182.589  loss reduction = 0.0  correctly classified = 84.8750%\n",
      "alpha =  0.7231578947368421 b =  -13871.66700595236 epoch =  0  loss = 3560.981  loss reduction = 621.6079  correctly classified = 87.1250%\n",
      "alpha =  0.7231578947368421 b =  -13610.897715426045 epoch =  1  loss = 3920.132  loss reduction = -359.1512  correctly classified = 85.8250%\n",
      "alpha =  0.7231578947368421 b =  -13757.895467004992 epoch =  2  loss = 3388.312  loss reduction = 531.8201  correctly classified = 87.7500%\n",
      "alpha =  0.7231578947368421 b =  -13528.159774373413 epoch =  3  loss = 3747.463  loss reduction = -359.1512  correctly classified = 86.4500%\n",
      "alpha =  0.7231578947368421 b =  -13635.463389110255 epoch =  4  loss = 3353.778  loss reduction = 393.685  correctly classified = 87.8750%\n",
      "alpha =  0.7231578947368421 b =  -13420.161928057623 epoch =  5  loss = 3678.396  loss reduction = -324.6175  correctly classified = 86.7000%\n",
      "alpha =  0.7231578947368421 b =  -13465.398347004992 epoch =  6  loss = 3174.202  loss reduction = 504.1931  correctly classified = 88.5250%\n",
      "alpha =  0.7231578947368421 b =  -13285.460753320782 epoch =  7  loss = 3533.354  loss reduction = -359.1512  correctly classified = 87.2250%\n",
      "alpha =  0.7231578947368421 b =  -13284.507631215518 epoch =  8  loss = 3229.456  loss reduction = 303.8972  correctly classified = 88.3250%\n",
      "alpha =  0.7231578947368421 b =  -13134.881923847097 epoch =  9  loss = 3409.032  loss reduction = -179.5756  correctly classified = 87.6750%\n",
      "alpha =  0.7231578947368421 b =  -13100.730069110255 epoch =  10  loss = 3229.456  loss reduction = 179.5756  correctly classified = 88.3250%\n",
      "alpha =  0.7231578947368421 b =  -12952.547784899729 epoch =  11  loss = 3395.219  loss reduction = -165.7621  correctly classified = 87.7250%\n",
      "alpha =  0.7231578947368421 b =  -12923.447911215519 epoch =  12  loss = 3194.923  loss reduction = 200.2959  correctly classified = 88.4500%\n",
      "alpha =  0.7231578947368421 b =  -12773.822203847098 epoch =  13  loss = 3395.219  loss reduction = -200.2959  correctly classified = 87.7250%\n",
      "alpha =  0.7231578947368421 b =  -12741.11377226815 epoch =  14  loss = 3201.829  loss reduction = 193.3891  correctly classified = 88.4250%\n",
      "alpha =  0.7231578947368421 b =  -12592.209776478678 epoch =  15  loss = 3388.312  loss reduction = -186.4824  correctly classified = 87.7500%\n",
      "alpha =  0.7231578947368421 b =  -12562.38819121552 epoch =  16  loss = 3215.643  loss reduction = 172.6689  correctly classified = 88.3750%\n",
      "alpha =  0.7231578947368421 b =  -12413.484195426046 epoch =  17  loss = 3374.498  loss reduction = -158.8554  correctly classified = 87.8000%\n",
      "alpha =  0.7231578947368421 b =  -12382.940898583942 epoch =  18  loss = 3208.736  loss reduction = 165.7621  correctly classified = 88.4000%\n",
      "alpha =  0.7231578947368421 b =  -12234.036902794469 epoch =  19  loss = 3346.871  loss reduction = -138.1351  correctly classified = 87.9000%\n",
      "alpha =  0.7231578947368421 b =  -12202.050182794468 epoch =  20  loss = 3194.923  loss reduction = 151.9486  correctly classified = 88.4500%\n",
      "alpha =  0.7231578947368421 b =  -12056.754744899732 epoch =  21  loss = 3326.151  loss reduction = -131.2283  correctly classified = 87.9750%\n",
      "alpha =  0.7231578947368421 b =  -12025.48973647868 epoch =  22  loss = 3201.829  loss reduction = 124.3216  correctly classified = 88.4250%\n",
      "alpha =  0.7231578947368421 b =  -11879.472587004995 epoch =  23  loss = 3319.244  loss reduction = -117.4148  correctly classified = 88.0000%\n",
      "alpha =  0.7231578947368421 b =  -11849.651001741837 epoch =  24  loss = 3160.389  loss reduction = 158.8554  correctly classified = 88.5750%\n",
      "alpha =  0.7231578947368421 b =  -11703.633852268153 epoch =  25  loss = 3319.244  loss reduction = -158.8554  correctly classified = 88.0000%\n",
      "alpha =  0.7231578947368421 b =  -11678.14253647868 epoch =  26  loss = 3160.389  loss reduction = 158.8554  correctly classified = 88.5750%\n",
      "alpha =  0.7231578947368421 b =  -11527.79511753131 epoch =  27  loss = 3305.431  loss reduction = -145.0419  correctly classified = 88.0500%\n",
      "alpha =  0.7231578947368421 b =  -11513.851187004995 epoch =  28  loss = 3132.762  loss reduction = 172.6689  correctly classified = 88.6750%\n",
      "alpha =  0.7231578947368421 b =  -11349.069536478679 epoch =  29  loss = 3388.312  loss reduction = -255.5499  correctly classified = 87.7500%\n",
      "alpha =  0.7231578947368421 b =  -11364.715780689205 epoch =  30  loss = 3070.601  loss reduction = 317.7107  correctly classified = 88.9000%\n",
      "alpha =  0.7231578947368421 b =  -11179.726205952362 epoch =  31  loss = 3457.379  loss reduction = -386.7783  correctly classified = 87.5000%\n",
      "alpha =  0.7231578947368421 b =  -11255.996222794467 epoch =  32  loss = 3125.855  loss reduction = 331.5242  correctly classified = 88.7000%\n",
      "alpha =  0.7231578947368421 b =  -11017.59999121552 epoch =  33  loss = 3664.582  loss reduction = -538.7269  correctly classified = 86.7500%\n",
      "alpha =  0.7231578947368421 b =  -11193.466205952362 epoch =  34  loss = 3305.431  loss reduction = 359.1512  correctly classified = 88.0500%\n",
      "alpha =  0.7231578947368421 b =  -10912.48899121552 epoch =  35  loss = 3864.878  loss reduction = -559.4471  correctly classified = 86.0250%\n",
      "alpha =  0.7231578947368421 b =  -11138.15330489973 epoch =  36  loss = 3602.421  loss reduction = 262.4567  correctly classified = 86.9750%\n",
      "alpha =  0.7231578947368421 b =  -10803.769433320782 epoch =  37  loss = 4141.148  loss reduction = -538.7269  correctly classified = 85.0250%\n",
      "alpha =  0.7231578947368421 b =  -11123.256252268151 epoch =  38  loss = 4265.47  loss reduction = -124.3216  correctly classified = 84.5750%\n",
      "alpha =  0.7231578947368421 b =  -10685.66762489973 epoch =  39  loss = 4797.29  loss reduction = -531.8201  correctly classified = 82.6500%\n",
      "alpha =  0.7231578947368421 b =  -11275.796285952361 epoch =  40  loss = 6344.403  loss reduction = -1547.113  correctly classified = 77.0500%\n",
      "alpha =  0.7231578947368421 b =  -10704.691016478677 epoch =  41  loss = 5771.142  loss reduction = 573.2606  correctly classified = 79.1250%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.7231578947368421 b =  -11486.794957531309 epoch =  42  loss = 8029.651  loss reduction = -2258.509  correctly classified = 70.9500%\n",
      "alpha =  0.7231578947368421 b =  -10837.744837531309 epoch =  43  loss = 6448.004  loss reduction = 1581.647  correctly classified = 76.6750%\n",
      "alpha =  0.7231578947368421 b =  -11805.328654373414 epoch =  44  loss = 9749.433  loss reduction = -3301.429  correctly classified = 64.7250%\n",
      "alpha =  0.7231578947368421 b =  -11115.862685952361 epoch =  45  loss = 6793.342  loss reduction = 2956.091  correctly classified = 75.4250%\n",
      "alpha =  0.7231578947368421 b =  -11975.911477531308 epoch =  46  loss = 8761.767  loss reduction = -1968.425  correctly classified = 68.3000%\n",
      "alpha =  0.7231578947368421 b =  -11320.365953320781 epoch =  47  loss = 6496.351  loss reduction = 2265.416  correctly classified = 76.5000%\n",
      "alpha =  0.7231578947368421 b =  -12202.787803847097 epoch =  48  loss = 8948.249  loss reduction = -2451.898  correctly classified = 67.6250%\n",
      "alpha =  0.7231578947368421 b =  -11543.633721741833 epoch =  49  loss = 6530.885  loss reduction = 2417.364  correctly classified = 76.3750%\n",
      "alpha =  0.7231578947368421 b =  -12393.578551215518 epoch =  50  loss = 8678.886  loss reduction = -2148.001  correctly classified = 68.6000%\n",
      "alpha =  0.7231578947368421 b =  -11750.302123847097 epoch =  51  loss = 6392.75  loss reduction = 2286.136  correctly classified = 76.8750%\n",
      "alpha =  0.7231578947368421 b =  -12599.525241741834 epoch =  52  loss = 8671.979  loss reduction = -2279.229  correctly classified = 68.6250%\n",
      "alpha =  0.7231578947368421 b =  -11962.022507004993 epoch =  53  loss = 6337.496  loss reduction = 2334.483  correctly classified = 77.0750%\n",
      "alpha =  0.7231578947368421 b =  -12785.264008057624 epoch =  54  loss = 8437.15  loss reduction = -2099.653  correctly classified = 69.4750%\n",
      "alpha =  0.7231578947368421 b =  -12162.19550489973 epoch =  55  loss = 6213.175  loss reduction = 2223.975  correctly classified = 77.5250%\n",
      "alpha =  0.7231578947368421 b =  -12973.889620689204 epoch =  56  loss = 8354.269  loss reduction = -2141.094  correctly classified = 69.7750%\n",
      "alpha =  0.7231578947368421 b =  -12366.698772268152 epoch =  57  loss = 6088.853  loss reduction = 2265.416  correctly classified = 77.9750%\n",
      "alpha =  0.7231578947368421 b =  -13114.882269110256 epoch =  58  loss = 7746.474  loss reduction = -1657.621  correctly classified = 71.9750%\n",
      "alpha =  0.7231578947368421 b =  -12536.559883847098 epoch =  59  loss = 5826.396  loss reduction = 1920.078  correctly classified = 78.9250%\n",
      "alpha =  0.7231578947368421 b =  -13216.902492268151 epoch =  60  loss = 7166.307  loss reduction = -1339.91  correctly classified = 74.0750%\n",
      "alpha =  0.7231578947368421 b =  -12686.934782794468 epoch =  61  loss = 5446.525  loss reduction = 1719.782  correctly classified = 80.3000%\n",
      "alpha =  0.7231578947368421 b =  -13289.332540689204 epoch =  62  loss = 6461.818  loss reduction = -1015.293  correctly classified = 76.6250%\n",
      "alpha =  0.7231578947368421 b =  -12789.676717531309 epoch =  63  loss = 5294.576  loss reduction = 1167.242  correctly classified = 80.8500%\n",
      "alpha =  0.7231578947368421 b =  -13337.946107004993 epoch =  64  loss = 5999.065  loss reduction = -704.489  correctly classified = 78.3000%\n",
      "alpha =  0.7231578947368421 b =  -12869.323881741835 epoch =  65  loss = 5066.653  loss reduction = 932.4119  correctly classified = 81.6750%\n",
      "alpha =  0.7231578947368421 b =  -13352.639229110257 epoch =  66  loss = 5529.406  loss reduction = -462.7526  correctly classified = 80.0000%\n",
      "alpha =  0.7231578947368421 b =  -12916.49402489973 epoch =  67  loss = 4824.917  loss reduction = 704.489  correctly classified = 82.5500%\n",
      "alpha =  0.7231578947368421 b =  -13355.784965952362 epoch =  68  loss = 5218.602  loss reduction = -393.685  correctly classified = 81.1250%\n",
      "alpha =  0.7231578947368421 b =  -12910.979222794467 epoch =  69  loss = 4880.171  loss reduction = 338.431  correctly classified = 82.3500%\n",
      "alpha =  0.7231578947368421 b =  -13357.487279636573 epoch =  70  loss = 5273.856  loss reduction = -393.685  correctly classified = 80.9250%\n",
      "alpha =  0.7231578947368421 b =  -12913.403248057624 epoch =  71  loss = 4873.264  loss reduction = 400.5918  correctly classified = 82.3750%\n",
      "alpha =  0.7231578947368421 b =  -13357.02445858394 epoch =  72  loss = 5246.229  loss reduction = -372.9648  correctly classified = 81.0250%\n",
      "alpha =  0.7231578947368421 b =  -12918.71411963657 epoch =  73  loss = 4845.637  loss reduction = 400.5918  correctly classified = 82.4750%\n",
      "alpha =  0.7231578947368421 b =  -13358.005060689202 epoch =  74  loss = 5218.602  loss reduction = -372.9648  correctly classified = 81.1250%\n",
      "alpha =  0.7231578947368421 b =  -12917.52958700499 epoch =  75  loss = 4852.544  loss reduction = 366.058  correctly classified = 82.4500%\n",
      "alpha =  0.7231578947368421 b =  -13357.54223963657 epoch =  76  loss = 5225.509  loss reduction = -372.9648  correctly classified = 81.1000%\n",
      "alpha =  0.7231578947368421 b =  -12920.675323847097 epoch =  77  loss = 4831.824  loss reduction = 393.685  correctly classified = 82.5250%\n",
      "alpha =  0.7231578947368421 b =  -13359.244553320781 epoch =  78  loss = 5211.695  loss reduction = -379.8715  correctly classified = 81.1500%\n",
      "alpha =  0.7231578947368421 b =  -12924.542772268149 epoch =  79  loss = 4811.103  loss reduction = 400.5918  correctly classified = 82.6000%\n",
      "alpha =  0.7231578947368421 b =  -13359.503443847096 epoch =  80  loss = 5177.161  loss reduction = -366.058  correctly classified = 81.2750%\n",
      "alpha =  0.7231578947368421 b =  -12928.4102206892 epoch =  81  loss = 4790.383  loss reduction = 386.7783  correctly classified = 82.6750%\n",
      "alpha =  0.7231578947368421 b =  -13364.092603847095 epoch =  82  loss = 5184.068  loss reduction = -393.685  correctly classified = 81.2500%\n",
      "alpha =  0.7231578947368421 b =  -12930.83424595236 epoch =  83  loss = 4811.103  loss reduction = 372.9648  correctly classified = 82.6000%\n",
      "alpha =  0.7231578947368421 b =  -13364.351494373412 epoch =  84  loss = 5163.348  loss reduction = -352.2445  correctly classified = 81.3250%\n",
      "alpha =  0.7231578947368421 b =  -12956.353041741833 epoch =  85  loss = 4624.621  loss reduction = 538.7269  correctly classified = 83.2750%\n",
      "alpha =  0.7231578947368421 b =  -13316.255709110254 epoch =  86  loss = 4596.994  loss reduction = 27.62702  correctly classified = 83.3750%\n",
      "alpha =  0.7231578947368421 b =  -12959.498778583938 epoch =  87  loss = 4300.003  loss reduction = 296.9905  correctly classified = 84.4500%\n",
      "alpha =  0.7231578947368421 b =  -13213.309843847097 epoch =  88  loss = 3899.412  loss reduction = 400.5918  correctly classified = 85.9000%\n",
      "alpha =  0.7231578947368421 b =  -12928.724071215518 epoch =  89  loss = 3927.039  loss reduction = -27.62702  correctly classified = 85.8000%\n",
      "alpha =  0.7231578947368421 b =  -13081.495515426044 epoch =  90  loss = 3333.058  loss reduction = 593.9809  correctly classified = 87.9500%\n",
      "alpha =  0.7231578947368421 b =  -12851.038111215517 epoch =  91  loss = 3643.862  loss reduction = -310.804  correctly classified = 86.8250%\n",
      "alpha =  0.7231578947368421 b =  -12924.421281741834 epoch =  92  loss = 3139.669  loss reduction = 504.1931  correctly classified = 88.6500%\n",
      "alpha =  0.7231578947368421 b =  -12712.728378583939 epoch =  93  loss = 3574.794  loss reduction = -435.1256  correctly classified = 87.0750%\n",
      "alpha =  0.7231578947368421 b =  -12765.181913320781 epoch =  94  loss = 3036.067  loss reduction = 538.7269  correctly classified = 89.0250%\n",
      "alpha =  0.7231578947368421 b =  -12582.35747332078 epoch =  95  loss = 3464.286  loss reduction = -428.2188  correctly classified = 87.4750%\n",
      "alpha =  0.7231578947368421 b =  -12588.62146700499 epoch =  96  loss = 3160.389  loss reduction = 303.8972  correctly classified = 88.5750%\n",
      "alpha =  0.7231578947368421 b =  -12422.39639332078 epoch =  97  loss = 3388.312  loss reduction = -227.9229  correctly classified = 87.7500%\n",
      "alpha =  0.7231578947368421 b =  -12388.966250162885 epoch =  98  loss = 3167.296  loss reduction = 221.0162  correctly classified = 88.5500%\n",
      "alpha =  0.7231578947368421 b =  -12247.279370162885 epoch =  99  loss = 3291.617  loss reduction = -124.3216  correctly classified = 88.1000%\n",
      "alpha =  0.7231578947368421 b =  -12203.02355332078 epoch =  100  loss = 3132.762  loss reduction = 158.8554  correctly classified = 88.6750%\n",
      "alpha =  0.7231578947368421 b =  -12070.718923847095 epoch =  101  loss = 3284.711  loss reduction = -151.9486  correctly classified = 88.1250%\n",
      "alpha =  0.7231578947368421 b =  -12015.637433320779 epoch =  102  loss = 3112.042  loss reduction = 172.6689  correctly classified = 88.7500%\n",
      "alpha =  0.7231578947368421 b =  -11883.332803847094 epoch =  103  loss = 3257.084  loss reduction = -145.0419  correctly classified = 88.2250%\n",
      "alpha =  0.7231578947368421 b =  -11828.251313320778 epoch =  104  loss = 3098.228  loss reduction = 158.8554  correctly classified = 88.8000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.7231578947368421 b =  -11696.66839542604 epoch =  105  loss = 3250.177  loss reduction = -151.9486  correctly classified = 88.2500%\n",
      "alpha =  0.7231578947368421 b =  -11643.752039636567 epoch =  106  loss = 3077.508  loss reduction = 172.6689  correctly classified = 88.8750%\n",
      "alpha =  0.7231578947368421 b =  -11509.282275426041 epoch =  107  loss = 3236.363  loss reduction = -158.8554  correctly classified = 88.3000%\n",
      "alpha =  0.7231578947368421 b =  -11458.53105437341 epoch =  108  loss = 3070.601  loss reduction = 165.7621  correctly classified = 88.9000%\n",
      "alpha =  0.7231578947368421 b =  -11324.783001741831 epoch =  109  loss = 3229.456  loss reduction = -158.8554  correctly classified = 88.3250%\n",
      "alpha =  0.7231578947368421 b =  -11274.0317806892 epoch =  110  loss = 3070.601  loss reduction = 158.8554  correctly classified = 88.9000%\n",
      "alpha =  0.7231578947368421 b =  -11142.448862794463 epoch =  111  loss = 3194.923  loss reduction = -124.3216  correctly classified = 88.4500%\n",
      "alpha =  0.7231578947368421 b =  -11090.254218583937 epoch =  112  loss = 3070.601  loss reduction = 124.3216  correctly classified = 88.9000%\n",
      "alpha =  0.7231578947368421 b =  -10960.114723847095 epoch =  113  loss = 3181.109  loss reduction = -110.5081  correctly classified = 88.5000%\n",
      "alpha =  0.7231578947368421 b =  -10906.476656478673 epoch =  114  loss = 3056.788  loss reduction = 124.3216  correctly classified = 88.9500%\n",
      "alpha =  0.7231578947368421 b =  -10779.945719636567 epoch =  115  loss = 3160.389  loss reduction = -103.6013  correctly classified = 88.5750%\n",
      "alpha =  0.7231578947368421 b =  -10717.647113320778 epoch =  116  loss = 3084.415  loss reduction = 75.9743  correctly classified = 88.8500%\n",
      "alpha =  0.7231578947368421 b =  -10588.951112824696 epoch =  117  loss = 3153.482  loss reduction = -69.06765  correctly classified = 88.6000%\n",
      "alpha =  0.7231578947368421 b =  -10535.313045456274 epoch =  118  loss = 3042.974  loss reduction = 110.5082  correctly classified = 89.0000%\n",
      "alpha =  0.7231578947368421 b =  -10405.173550719432 epoch =  119  loss = 3167.296  loss reduction = -124.3216  correctly classified = 88.5500%\n",
      "alpha =  0.7231578947368421 b =  -10350.813771772064 epoch =  120  loss = 3036.067  loss reduction = 131.2283  correctly classified = 89.0250%\n",
      "alpha =  0.7231578947368421 b =  -10222.839411772064 epoch =  121  loss = 3160.389  loss reduction = -124.3216  correctly classified = 88.5750%\n",
      "alpha =  0.7231578947368421 b =  -10161.984228614168 epoch =  122  loss = 3042.974  loss reduction = 117.4148  correctly classified = 89.0000%\n",
      "alpha =  0.7231578947368421 b =  -10032.566445456274 epoch =  123  loss = 3132.762  loss reduction = -89.78781  correctly classified = 88.6750%\n",
      "alpha =  0.7231578947368421 b =  -9978.928378087852 epoch =  124  loss = 3015.347  loss reduction = 117.4148  correctly classified = 89.1000%\n",
      "alpha =  0.7231578947368421 b =  -9849.510594929958 epoch =  125  loss = 3132.762  loss reduction = -117.4148  correctly classified = 88.6750%\n",
      "alpha =  0.7231578947368421 b =  -9795.872527561536 epoch =  126  loss = 3001.534  loss reduction = 131.2283  correctly classified = 89.1500%\n",
      "alpha =  0.7231578947368421 b =  -9669.34159071943 epoch =  127  loss = 3105.135  loss reduction = -103.6013  correctly classified = 88.7750%\n",
      "alpha =  0.7231578947368421 b =  -9614.981811772062 epoch =  128  loss = 2994.627  loss reduction = 110.5081  correctly classified = 89.1750%\n",
      "alpha =  0.7231578947368421 b =  -9483.398893877325 epoch =  129  loss = 3125.855  loss reduction = -131.2283  correctly classified = 88.7000%\n",
      "alpha =  0.7231578947368421 b =  -9442.751634929957 epoch =  130  loss = 2973.907  loss reduction = 151.9486  correctly classified = 89.2500%\n",
      "alpha =  0.7231578947368421 b =  -9313.333851772062 epoch =  131  loss = 3077.508  loss reduction = -103.6013  correctly classified = 88.8750%\n",
      "alpha =  0.7231578947368421 b =  -9266.191188614168 epoch =  132  loss = 2967.0  loss reduction = 110.5081  correctly classified = 89.2750%\n",
      "alpha =  0.7231578947368421 b =  -9135.329982298379 epoch =  133  loss = 3049.881  loss reduction = -82.88106  correctly classified = 88.9750%\n",
      "alpha =  0.7231578947368421 b =  -9091.074165456273 epoch =  134  loss = 2967.0  loss reduction = 82.88106  correctly classified = 89.2750%\n",
      "alpha =  0.7231578947368421 b =  -8958.769535982588 epoch =  135  loss = 3049.881  loss reduction = -82.88106  correctly classified = 88.9750%\n",
      "alpha =  0.7231578947368421 b =  -8920.287411772062 epoch =  136  loss = 2967.0  loss reduction = 82.88106  correctly classified = 89.2750%\n",
      "alpha =  0.7231578947368421 b =  -8770.661704403641 epoch =  137  loss = 3132.762  loss reduction = -165.7621  correctly classified = 88.6750%\n",
      "alpha =  0.7231578947368421 b =  -8779.090832824693 epoch =  138  loss = 2960.093  loss reduction = 172.6689  correctly classified = 89.3000%\n",
      "alpha =  0.7231578947368421 b =  -8593.379546508904 epoch =  139  loss = 3270.897  loss reduction = -310.804  correctly classified = 88.1750%\n",
      "alpha =  0.7231578947368421 b =  -8684.805506508905 epoch =  140  loss = 2953.186  loss reduction = 317.7107  correctly classified = 89.3250%\n",
      "alpha =  0.7231578947368421 b =  -8430.531620193115 epoch =  141  loss = 3609.328  loss reduction = -656.1417  correctly classified = 86.9500%\n",
      "alpha =  0.7231578947368421 b =  -8631.657740193115 epoch =  142  loss = 3353.778  loss reduction = 255.5499  correctly classified = 87.8750%\n",
      "alpha =  0.7231578947368421 b =  -8326.86404335101 epoch =  143  loss = 3844.158  loss reduction = -490.3796  correctly classified = 86.1000%\n",
      "alpha =  0.7231578947368421 b =  -8621.812668614168 epoch =  144  loss = 3933.945  loss reduction = -89.78781  correctly classified = 85.7750%\n",
      "alpha =  0.7231578947368421 b =  -8215.257639140484 epoch =  145  loss = 4458.859  loss reduction = -524.9134  correctly classified = 83.8750%\n",
      "alpha =  0.7231578947368421 b =  -8722.389468614168 epoch =  146  loss = 5536.313  loss reduction = -1077.454  correctly classified = 79.9750%\n",
      "alpha =  0.7231578947368421 b =  -8207.577702298378 epoch =  147  loss = 5315.296  loss reduction = 221.0162  correctly classified = 80.7750%\n",
      "alpha =  0.7231578947368421 b =  -8918.23219703522 epoch =  148  loss = 7318.255  loss reduction = -2002.959  correctly classified = 73.5250%\n",
      "alpha =  0.7231578947368421 b =  -8303.824232824694 epoch =  149  loss = 6144.107  loss reduction = 1174.148  correctly classified = 77.7750%\n",
      "alpha =  0.7231578947368421 b =  -9243.261298087851 epoch =  150  loss = 9466.256  loss reduction = -3322.149  correctly classified = 65.7500%\n",
      "alpha =  0.7231578947368421 b =  -8559.569022298378 epoch =  151  loss = 6738.088  loss reduction = 2728.168  correctly classified = 75.6250%\n",
      "alpha =  0.7231578947368421 b =  -9433.330333877326 epoch =  152  loss = 8837.741  loss reduction = -2099.653  correctly classified = 68.0250%\n",
      "alpha =  0.7231578947368421 b =  -8779.949944403641 epoch =  153  loss = 6489.445  loss reduction = 2348.297  correctly classified = 76.5250%\n",
      "alpha =  0.7231578947368421 b =  -9663.093506508903 epoch =  154  loss = 8941.343  loss reduction = -2451.898  correctly classified = 67.6500%\n",
      "alpha =  0.7231578947368421 b =  -9008.991405456272 epoch =  155  loss = 6482.538  loss reduction = 2458.805  correctly classified = 76.5500%\n",
      "alpha =  0.7231578947368421 b =  -9868.318485456271 epoch =  156  loss = 8713.42  loss reduction = -2230.882  correctly classified = 68.4750%\n",
      "alpha =  0.7231578947368421 b =  -9225.04205808785 epoch =  157  loss = 6392.75  loss reduction = 2320.67  correctly classified = 76.8750%\n",
      "alpha =  0.7231578947368421 b =  -10067.048060193114 epoch =  158  loss = 8547.658  loss reduction = -2154.907  correctly classified = 69.0750%\n",
      "alpha =  0.7231578947368421 b =  -9437.484152824693 epoch =  159  loss = 6275.335  loss reduction = 2272.322  correctly classified = 77.3000%\n",
      "alpha =  0.7231578947368421 b =  -10243.404575982588 epoch =  160  loss = 8216.133  loss reduction = -1940.798  correctly classified = 70.2750%\n",
      "alpha =  0.7231578947368421 b =  -9628.274900193113 epoch =  161  loss = 6151.014  loss reduction = 2065.12  correctly classified = 77.7500%\n",
      "alpha =  0.7231578947368421 b =  -10427.699919140481 epoch =  162  loss = 8153.973  loss reduction = -2002.959  correctly classified = 70.5000%\n",
      "alpha =  0.7231578947368421 b =  -9829.891321245745 epoch =  163  loss = 6012.879  loss reduction = 2141.094  correctly classified = 78.2500%\n",
      "alpha =  0.7231578947368421 b =  -10566.527432824692 epoch =  164  loss = 7594.526  loss reduction = -1581.647  correctly classified = 72.5250%\n",
      "alpha =  0.7231578947368421 b =  -10005.526125456272 epoch =  165  loss = 5674.448  loss reduction = 1920.078  correctly classified = 79.4750%\n",
      "alpha =  0.7231578947368421 b =  -10667.825944403641 epoch =  166  loss = 6966.011  loss reduction = -1291.563  correctly classified = 74.8000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.7231578947368421 b =  -10146.518773877326 epoch =  167  loss = 5349.83  loss reduction = 1616.181  correctly classified = 80.6500%\n",
      "alpha =  0.7231578947368421 b =  -10752.525089666799 epoch =  168  loss = 6468.724  loss reduction = -1118.894  correctly classified = 76.6000%\n",
      "alpha =  0.7231578947368421 b =  -10254.312689666798 epoch =  169  loss = 5170.255  loss reduction = 1298.47  correctly classified = 81.3000%\n",
      "alpha =  0.7231578947368421 b =  -10822.790003351009 epoch =  170  loss = 6123.387  loss reduction = -953.1322  correctly classified = 77.8500%\n",
      "alpha =  0.7231578947368421 b =  -10341.898681245746 epoch =  171  loss = 5032.119  loss reduction = 1091.267  correctly classified = 81.8000%\n",
      "alpha =  0.7231578947368421 b =  -10866.351588614167 epoch =  172  loss = 5743.515  loss reduction = -711.3957  correctly classified = 79.2250%\n",
      "alpha =  0.7231578947368421 b =  -10426.597826508903 epoch =  173  loss = 4748.943  loss reduction = 994.5727  correctly classified = 82.8250%\n",
      "alpha =  0.7231578947368421 b =  -10883.93155703522 epoch =  174  loss = 5266.949  loss reduction = -518.0066  correctly classified = 80.9500%\n",
      "alpha =  0.7231578947368421 b =  -10447.064641245744 epoch =  175  loss = 4721.316  loss reduction = 545.6336  correctly classified = 82.9250%\n",
      "alpha =  0.7231578947368421 b =  -10900.789813877323 epoch =  176  loss = 5232.415  loss reduction = -511.0999  correctly classified = 81.0750%\n",
      "alpha =  0.7231578947368421 b =  -10463.201186508903 epoch =  177  loss = 4728.222  loss reduction = 504.1931  correctly classified = 82.9000%\n",
      "alpha =  0.7231578947368421 b =  -10914.761224403639 epoch =  178  loss = 5211.695  loss reduction = -483.4728  correctly classified = 81.1500%\n",
      "alpha =  0.7231578947368421 b =  -10482.22457808785 epoch =  179  loss = 4679.875  loss reduction = 531.8201  correctly classified = 83.0750%\n",
      "alpha =  0.7231578947368421 b =  -10921.515519140481 epoch =  180  loss = 5108.094  loss reduction = -428.2188  correctly classified = 81.5250%\n",
      "alpha =  0.7231578947368421 b =  -10489.70058440364 epoch =  181  loss = 4672.968  loss reduction = 435.1256  correctly classified = 83.1000%\n",
      "alpha =  0.7231578947368421 b =  -10921.774409666798 epoch =  182  loss = 5052.84  loss reduction = -379.8715  correctly classified = 81.7250%\n",
      "alpha =  0.7231578947368421 b =  -10495.011455982587 epoch =  183  loss = 4624.621  loss reduction = 428.2188  correctly classified = 83.2750%\n",
      "alpha =  0.7231578947368421 b =  -10927.806992824691 epoch =  184  loss = 5059.746  loss reduction = -435.1256  correctly classified = 81.7000%\n",
      "alpha =  0.7231578947368421 b =  -10501.765750719429 epoch =  185  loss = 4617.714  loss reduction = 442.0323  correctly classified = 83.3000%\n",
      "alpha =  0.7231578947368421 b =  -10918.683632824692 epoch =  186  loss = 4907.798  loss reduction = -290.0837  correctly classified = 82.2500%\n",
      "alpha =  0.7231578947368421 b =  -10535.223373877323 epoch =  187  loss = 4362.164  loss reduction = 545.6336  correctly classified = 84.2250%\n",
      "alpha =  0.7231578947368421 b =  -10856.153615982586 epoch =  188  loss = 4168.775  loss reduction = 193.3891  correctly classified = 84.9250%\n",
      "alpha =  0.7231578947368421 b =  -10513.10920545627 epoch =  189  loss = 4127.335  loss reduction = 41.44053  correctly classified = 85.0750%\n",
      "alpha =  0.7231578947368421 b =  -10753.207750719428 epoch =  190  loss = 3685.302  loss reduction = 442.0323  correctly classified = 86.6750%\n",
      "alpha =  0.7231578947368421 b =  -10476.56080545627 epoch =  191  loss = 3768.183  loss reduction = -82.88106  correctly classified = 86.3750%\n",
      "alpha =  0.7231578947368421 b =  -10633.662519140482 epoch =  192  loss = 3208.736  loss reduction = 559.4471  correctly classified = 88.4000%\n",
      "alpha =  0.7231578947368421 b =  -10412.587365456271 epoch =  193  loss = 3512.633  loss reduction = -303.8972  correctly classified = 87.3000%\n",
      "alpha =  0.7231578947368421 b =  -10483.805401245745 epoch =  194  loss = 2967.0  loss reduction = 545.6336  correctly classified = 89.2750%\n",
      "alpha =  0.7231578947368421 b =  -10279.329613877324 epoch =  195  loss = 3422.846  loss reduction = -455.8458  correctly classified = 87.6250%\n",
      "alpha =  0.7231578947368421 b =  -10345.495668614167 epoch =  196  loss = 2946.28  loss reduction = 476.5661  correctly classified = 89.3500%\n",
      "alpha =  0.7231578947368421 b =  -10143.185015982588 epoch =  197  loss = 3402.125  loss reduction = -455.8458  correctly classified = 87.7000%\n",
      "alpha =  0.7231578947368421 b =  -10214.403051772062 epoch =  198  loss = 2967.0  loss reduction = 435.1256  correctly classified = 89.2750%\n",
      "alpha =  0.7231578947368421 b =  -10009.205552824693 epoch =  199  loss = 3402.125  loss reduction = -435.1256  correctly classified = 87.7000%\n",
      "alpha =  0.7231578947368421 b =  -10077.536742298376 epoch =  200  loss = 2939.373  loss reduction = 462.7526  correctly classified = 89.3750%\n",
      "alpha =  0.7231578947368421 b =  -9873.060954929955 epoch =  201  loss = 3409.032  loss reduction = -469.6593  correctly classified = 87.6750%\n",
      "alpha =  0.7231578947368421 b =  -9945.000702298375 epoch =  202  loss = 2946.28  loss reduction = 462.7526  correctly classified = 89.3500%\n",
      "alpha =  0.7231578947368421 b =  -9740.524914929954 epoch =  203  loss = 3395.219  loss reduction = -448.9391  correctly classified = 87.7250%\n",
      "alpha =  0.7231578947368421 b =  -9816.073220193111 epoch =  204  loss = 2953.186  loss reduction = 442.0323  correctly classified = 89.3250%\n",
      "alpha =  0.7231578947368421 b =  -9609.432298087848 epoch =  205  loss = 3388.312  loss reduction = -435.1256  correctly classified = 87.7500%\n",
      "alpha =  0.7231578947368421 b =  -9688.589161245742 epoch =  206  loss = 2946.28  loss reduction = 442.0323  correctly classified = 89.3500%\n",
      "alpha =  0.7231578947368421 b =  -9479.06139282469 epoch =  207  loss = 3388.312  loss reduction = -442.0323  correctly classified = 87.7500%\n",
      "alpha =  0.7231578947368421 b =  -9564.71366019311 epoch =  208  loss = 2911.746  loss reduction = 476.5661  correctly classified = 89.4750%\n",
      "alpha =  0.7231578947368421 b =  -9349.412199140479 epoch =  209  loss = 3415.939  loss reduction = -504.1931  correctly classified = 87.6500%\n",
      "alpha =  0.7231578947368421 b =  -9443.725005456268 epoch =  210  loss = 2897.932  loss reduction = 518.0066  correctly classified = 89.5250%\n",
      "alpha =  0.7231578947368421 b =  -9216.876159140478 epoch =  211  loss = 3498.82  loss reduction = -600.8877  correctly classified = 87.3500%\n",
      "alpha =  0.7231578947368421 b =  -9316.962658087847 epoch =  212  loss = 2925.559  loss reduction = 573.2606  correctly classified = 89.4250%\n",
      "alpha =  0.7231578947368421 b =  -9087.226965456268 epoch =  213  loss = 3498.82  loss reduction = -573.2606  correctly classified = 87.3500%\n",
      "alpha =  0.7231578947368421 b =  -9193.087157035216 epoch =  214  loss = 2953.186  loss reduction = 545.6336  correctly classified = 89.3250%\n",
      "alpha =  0.7231578947368421 b =  -8961.908041245742 epoch =  215  loss = 3512.633  loss reduction = -559.4471  correctly classified = 87.3000%\n",
      "alpha =  0.7231578947368421 b =  -9076.428771772058 epoch =  216  loss = 2980.813  loss reduction = 531.8201  correctly classified = 89.2250%\n",
      "alpha =  0.7231578947368421 b =  -8846.69307914048 epoch =  217  loss = 3498.82  loss reduction = -518.0066  correctly classified = 87.3500%\n",
      "alpha =  0.7231578947368421 b =  -8961.935521245743 epoch =  218  loss = 2973.907  loss reduction = 524.9134  correctly classified = 89.2500%\n",
      "alpha =  0.7231578947368421 b =  -8732.92154019311 epoch =  219  loss = 3491.913  loss reduction = -518.0066  correctly classified = 87.3750%\n",
      "alpha =  0.7231578947368421 b =  -8848.88569387732 epoch =  220  loss = 2967.0  loss reduction = 524.9134  correctly classified = 89.2750%\n",
      "alpha =  0.7231578947368421 b =  -8618.428289666794 epoch =  221  loss = 3464.286  loss reduction = -497.2863  correctly classified = 87.4750%\n",
      "alpha =  0.7231578947368421 b =  -8733.670731772057 epoch =  222  loss = 2946.28  loss reduction = 518.0066  correctly classified = 89.3500%\n",
      "alpha =  0.7231578947368421 b =  -8502.491615982584 epoch =  223  loss = 3471.193  loss reduction = -524.9134  correctly classified = 87.4500%\n",
      "alpha =  0.7231578947368421 b =  -8619.899192824689 epoch =  224  loss = 2953.186  loss reduction = 518.0066  correctly classified = 89.3250%\n",
      "alpha =  0.7231578947368421 b =  -8385.833230719425 epoch =  225  loss = 3457.379  loss reduction = -504.1931  correctly classified = 87.5000%\n",
      "alpha =  0.7231578947368421 b =  -8504.684230719426 epoch =  226  loss = 2953.186  loss reduction = 504.1931  correctly classified = 89.3250%\n",
      "alpha =  0.7231578947368421 b =  -8274.948538087847 epoch =  227  loss = 3443.566  loss reduction = -490.3796  correctly classified = 87.5500%\n",
      "alpha =  0.7231578947368421 b =  -8393.0778265089 epoch =  228  loss = 2946.28  loss reduction = 497.2863  correctly classified = 89.3500%\n",
      "alpha =  0.7231578947368421 b =  -8157.568441245741 epoch =  229  loss = 3457.379  loss reduction = -511.0999  correctly classified = 87.5000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.7231578947368421 b =  -8314.670154929952 epoch =  230  loss = 3070.601  loss reduction = 386.7783  correctly classified = 88.9000%\n",
      "alpha =  0.7231578947368421 b =  -8063.283114929953 epoch =  231  loss = 3540.26  loss reduction = -469.6593  correctly classified = 87.2000%\n",
      "alpha =  0.7231578947368421 b =  -8231.93221387732 epoch =  232  loss = 3112.042  loss reduction = 428.2188  correctly classified = 88.7500%\n",
      "alpha =  0.7231578947368421 b =  -7990.649135982583 epoch =  233  loss = 3485.006  loss reduction = -372.9648  correctly classified = 87.4000%\n",
      "alpha =  0.7231578947368421 b =  -8151.35940756153 epoch =  234  loss = 3063.694  loss reduction = 421.312  correctly classified = 88.9250%\n",
      "alpha =  0.7231578947368421 b =  -7902.859213877319 epoch =  235  loss = 3526.447  loss reduction = -462.7526  correctly classified = 87.2500%\n",
      "alpha =  0.7231578947368421 b =  -8072.951735982582 epoch =  236  loss = 3112.042  loss reduction = 414.4053  correctly classified = 88.7500%\n",
      "alpha =  0.7231578947368421 b =  -7829.503523351003 epoch =  237  loss = 3478.1  loss reduction = -366.058  correctly classified = 87.4250%\n",
      "alpha =  0.7231578947368421 b =  -7996.709199140477 epoch =  238  loss = 3084.415  loss reduction = 393.685  correctly classified = 88.8500%\n",
      "alpha =  0.7231578947368421 b =  -7746.765582298372 epoch =  239  loss = 3498.82  loss reduction = -414.4053  correctly classified = 87.3500%\n",
      "alpha =  0.7231578947368421 b =  -7920.466662298371 epoch =  240  loss = 3118.948  loss reduction = 379.8715  correctly classified = 88.7250%\n",
      "alpha =  0.7231578947368421 b =  -7682.070430719424 epoch =  241  loss = 3429.752  loss reduction = -310.804  correctly classified = 87.6000%\n",
      "alpha =  0.7231578947368421 b =  -7816.077373877319 epoch =  242  loss = 2932.466  loss reduction = 497.2863  correctly classified = 89.4000%\n",
      "alpha =  0.7231578947368421 b =  -7577.681142298371 epoch =  243  loss = 3429.752  loss reduction = -497.2863  correctly classified = 87.6000%\n",
      "alpha =  0.7231578947368421 b =  -7713.13150861416 epoch =  244  loss = 2918.653  loss reduction = 511.0999  correctly classified = 89.4500%\n",
      "alpha =  0.7231578947368421 b =  -7473.291853877318 epoch =  245  loss = 3415.939  loss reduction = -497.2863  correctly classified = 87.6500%\n",
      "alpha =  0.7231578947368421 b =  -7615.237624403634 epoch =  246  loss = 2925.559  loss reduction = 490.3796  correctly classified = 89.4250%\n",
      "alpha =  0.7231578947368421 b =  -7369.624277035213 epoch =  247  loss = 3457.379  loss reduction = -531.8201  correctly classified = 87.5000%\n",
      "alpha =  0.7231578947368421 b =  -7549.820761245739 epoch =  248  loss = 3112.042  loss reduction = 345.3377  correctly classified = 88.7500%\n",
      "alpha =  0.7231578947368421 b =  -7294.825163351002 epoch =  249  loss = 3519.54  loss reduction = -407.4985  correctly classified = 87.2750%\n",
      "alpha =  0.7231578947368421 b =  -7490.177590719422 epoch =  250  loss = 3201.829  loss reduction = 317.7107  correctly classified = 88.4250%\n",
      "alpha =  0.7231578947368421 b =  -7211.365510719423 epoch =  251  loss = 3636.955  loss reduction = -435.1256  correctly classified = 86.8500%\n",
      "alpha =  0.7231578947368421 b =  -7444.968651772054 epoch =  252  loss = 3402.125  loss reduction = 234.8297  correctly classified = 87.7000%\n",
      "alpha =  0.7231578947368421 b =  -7118.523607561528 epoch =  253  loss = 3857.971  loss reduction = -455.8458  correctly classified = 86.0500%\n",
      "alpha =  0.7231578947368421 b =  -7422.132771772054 epoch =  254  loss = 3947.759  loss reduction = -89.78781  correctly classified = 85.7250%\n",
      "alpha =  0.7231578947368421 b =  -7031.455397035212 epoch =  255  loss = 4293.097  loss reduction = -345.3377  correctly classified = 84.4750%\n",
      "alpha =  0.7231578947368421 b =  -7483.015434929948 epoch =  256  loss = 5018.306  loss reduction = -725.2093  correctly classified = 81.8500%\n",
      "alpha =  0.7231578947368421 b =  -6999.237266508895 epoch =  257  loss = 5045.933  loss reduction = -27.62702  correctly classified = 81.7500%\n",
      "alpha =  0.7231578947368421 b =  -7659.371950719422 epoch =  258  loss = 6848.596  loss reduction = -1802.663  correctly classified = 75.2250%\n",
      "alpha =  0.7231578947368421 b =  -7091.875239140474 epoch =  259  loss = 5708.981  loss reduction = 1139.615  correctly classified = 79.3500%\n",
      "alpha =  0.7231578947368421 b =  -7865.318641245737 epoch =  260  loss = 7891.516  loss reduction = -2182.535  correctly classified = 71.4500%\n",
      "alpha =  0.7231578947368421 b =  -7239.363291772052 epoch =  261  loss = 6240.802  loss reduction = 1650.714  correctly classified = 77.4250%\n",
      "alpha =  0.7231578947368421 b =  -8138.384508614157 epoch =  262  loss = 9051.851  loss reduction = -2811.049  correctly classified = 67.2500%\n",
      "alpha =  0.7231578947368421 b =  -7484.282407561525 epoch =  263  loss = 6468.724  loss reduction = 2583.126  correctly classified = 76.6000%\n",
      "alpha =  0.7231578947368421 b =  -8321.958140193105 epoch =  264  loss = 8478.59  loss reduction = -2009.866  correctly classified = 69.3250%\n",
      "alpha =  0.7231578947368421 b =  -7690.2290980878415 epoch =  265  loss = 6282.242  loss reduction = 2196.348  correctly classified = 77.2750%\n",
      "alpha =  0.7231578947368421 b =  -8533.678523351 epoch =  266  loss = 8533.844  loss reduction = -2251.602  correctly classified = 69.1250%\n",
      "alpha =  0.7231578947368421 b =  -7906.279750719421 epoch =  267  loss = 6254.615  loss reduction = 2279.229  correctly classified = 77.3750%\n",
      "alpha =  0.7231578947368421 b =  -8717.973866508895 epoch =  268  loss = 8257.574  loss reduction = -2002.959  correctly classified = 70.1250%\n",
      "alpha =  0.7231578947368421 b =  -8112.948152824685 epoch =  269  loss = 6040.506  loss reduction = 2217.068  correctly classified = 78.1500%\n",
      "alpha =  0.7231578947368421 b =  -8862.575072824686 epoch =  270  loss = 7677.407  loss reduction = -1636.901  correctly classified = 72.2250%\n",
      "alpha =  0.7231578947368421 b =  -8296.521784403632 epoch =  271  loss = 5708.981  loss reduction = 1968.425  correctly classified = 79.3500%\n",
      "alpha =  0.7231578947368421 b =  -8993.463759140475 epoch =  272  loss = 7187.027  loss reduction = -1478.046  correctly classified = 74.0000%\n",
      "alpha =  0.7231578947368421 b =  -8468.548030719423 epoch =  273  loss = 5329.11  loss reduction = 1857.917  correctly classified = 80.7250%\n",
      "alpha =  0.7231578947368421 b =  -9075.276058087844 epoch =  274  loss = 6434.191  loss reduction = -1105.081  correctly classified = 76.7250%\n",
      "alpha =  0.7231578947368421 b =  -8587.889331772054 epoch =  275  loss = 5052.84  loss reduction = 1381.351  correctly classified = 81.7250%\n",
      "alpha =  0.7231578947368421 b =  -9141.21070229837 epoch =  276  loss = 5964.531  loss reduction = -911.6916  correctly classified = 78.4250%\n",
      "alpha =  0.7231578947368421 b =  -8681.24901598258 epoch =  277  loss = 4831.824  loss reduction = 1132.708  correctly classified = 82.5250%\n",
      "alpha =  0.7231578947368421 b =  -9169.616344403632 epoch =  278  loss = 5370.55  loss reduction = -538.7269  correctly classified = 80.5750%\n",
      "alpha =  0.7231578947368421 b =  -8725.532312824684 epoch =  279  loss = 4735.129  loss reduction = 635.4214  correctly classified = 82.8750%\n",
      "alpha =  0.7231578947368421 b =  -9188.639735982579 epoch =  280  loss = 5197.882  loss reduction = -462.7526  correctly classified = 81.2000%\n",
      "alpha =  0.7231578947368421 b =  -8744.55570440363 epoch =  281  loss = 4735.129  loss reduction = 462.7526  correctly classified = 82.8750%\n",
      "alpha =  0.7231578947368421 b =  -9207.663127561525 epoch =  282  loss = 5197.882  loss reduction = -462.7526  correctly classified = 81.2000%\n",
      "alpha =  0.7231578947368421 b =  -8766.465942298368 epoch =  283  loss = 4707.502  loss reduction = 490.3796  correctly classified = 82.9750%\n",
      "alpha =  0.7231578947368421 b =  -9225.243095982578 epoch =  284  loss = 5156.441  loss reduction = -448.9391  correctly classified = 81.3500%\n",
      "alpha =  0.7231578947368421 b =  -8786.211045456263 epoch =  285  loss = 4686.782  loss reduction = 469.6593  correctly classified = 83.0500%\n",
      "alpha =  0.7231578947368421 b =  -9233.440813877316 epoch =  286  loss = 5059.746  loss reduction = -372.9648  correctly classified = 81.7000%\n",
      "alpha =  0.7231578947368421 b =  -8798.017321245738 epoch =  287  loss = 4652.248  loss reduction = 407.4985  correctly classified = 83.1750%\n",
      "alpha =  0.7231578947368421 b =  -9235.864839140475 epoch =  288  loss = 4983.772  loss reduction = -331.5242  correctly classified = 81.9750%\n",
      "alpha =  0.7231578947368421 b =  -8813.43215492995 epoch =  289  loss = 4569.367  loss reduction = 414.4053  correctly classified = 83.4750%\n",
      "alpha =  0.7231578947368421 b =  -9222.411209666792 epoch =  290  loss = 4776.57  loss reduction = -207.2026  correctly classified = 82.7250%\n",
      "alpha =  0.7231578947368421 b =  -8823.79500756153 epoch =  291  loss = 4369.071  loss reduction = 407.4985  correctly classified = 84.2000%\n",
      "alpha =  0.7231578947368421 b =  -9171.428578087845 epoch =  292  loss = 4313.817  loss reduction = 55.25404  correctly classified = 84.4000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.7231578947368421 b =  -8811.063089666794 epoch =  293  loss = 4072.081  loss reduction = 241.7364  correctly classified = 85.2750%\n",
      "alpha =  0.7231578947368421 b =  -9074.978117035214 epoch =  294  loss = 3706.023  loss reduction = 366.058  correctly classified = 86.6000%\n",
      "alpha =  0.7231578947368421 b =  -8783.175228614162 epoch =  295  loss = 3802.717  loss reduction = -96.69457  correctly classified = 86.2500%\n",
      "alpha =  0.7231578947368421 b =  -8957.598020193109 epoch =  296  loss = 3153.482  loss reduction = 649.2349  correctly classified = 88.6000%\n",
      "alpha =  0.7231578947368421 b =  -8720.645211772056 epoch =  297  loss = 3485.006  loss reduction = -331.5242  correctly classified = 87.4000%\n",
      "alpha =  0.7231578947368421 b =  -8814.958018087846 epoch =  298  loss = 2884.119  loss reduction = 600.8877  correctly classified = 89.5750%\n",
      "alpha =  0.7231578947368421 b =  -8598.934845456266 epoch =  299  loss = 3353.778  loss reduction = -469.6593  correctly classified = 87.8750%\n",
      "alpha =  0.7231578947368421 b =  -8678.813420193108 epoch =  300  loss = 2870.305  loss reduction = 483.4728  correctly classified = 89.6250%\n",
      "alpha =  0.7231578947368421 b =  -8478.667902298372 epoch =  301  loss = 3312.338  loss reduction = -442.0323  correctly classified = 88.0250%\n",
      "alpha =  0.7231578947368421 b =  -8546.277380193109 epoch =  302  loss = 2863.398  loss reduction = 448.9391  correctly classified = 89.6500%\n",
      "alpha =  0.7231578947368421 b =  -8341.801592824688 epoch =  303  loss = 3326.151  loss reduction = -462.7526  correctly classified = 87.9750%\n",
      "alpha =  0.7231578947368421 b =  -8416.628186508899 epoch =  304  loss = 2835.771  loss reduction = 490.3796  correctly classified = 89.7500%\n",
      "alpha =  0.7231578947368421 b =  -8211.43068756153 epoch =  305  loss = 3319.244  loss reduction = -483.4728  correctly classified = 88.0000%\n",
      "alpha =  0.7231578947368421 b =  -8288.422415982583 epoch =  306  loss = 2842.678  loss reduction = 476.5661  correctly classified = 89.7250%\n",
      "alpha =  0.7231578947368421 b =  -8085.390051772056 epoch =  307  loss = 3312.338  loss reduction = -469.6593  correctly classified = 88.0250%\n",
      "alpha =  0.7231578947368421 b =  -8158.773222298371 epoch =  308  loss = 2821.958  loss reduction = 490.3796  correctly classified = 89.8000%\n",
      "alpha =  0.7231578947368421 b =  -7952.854011772056 epoch =  309  loss = 3298.524  loss reduction = -476.5661  correctly classified = 88.0750%\n",
      "alpha =  0.7231578947368421 b =  -8037.062855982582 epoch =  310  loss = 2842.678  loss reduction = 455.8458  correctly classified = 89.7250%\n",
      "alpha =  0.7231578947368421 b =  -7820.317971772056 epoch =  311  loss = 3360.685  loss reduction = -518.0066  correctly classified = 87.8500%\n",
      "alpha =  0.7231578947368421 b =  -7911.7439317720555 epoch =  312  loss = 2815.051  loss reduction = 545.6336  correctly classified = 89.8250%\n",
      "alpha =  0.7231578947368421 b =  -7692.11220124574 epoch =  313  loss = 3346.871  loss reduction = -531.8201  correctly classified = 87.9000%\n",
      "alpha =  0.7231578947368421 b =  -7784.981584403635 epoch =  314  loss = 2815.051  loss reduction = 531.8201  correctly classified = 89.8250%\n",
      "alpha =  0.7231578947368421 b =  -7563.184719140477 epoch =  315  loss = 3367.592  loss reduction = -552.5404  correctly classified = 87.8250%\n",
      "alpha =  0.7231578947368421 b =  -7663.271218087845 epoch =  316  loss = 2828.865  loss reduction = 538.7269  correctly classified = 89.7750%\n",
      "alpha =  0.7231578947368421 b =  -7439.309218087845 epoch =  317  loss = 3374.498  loss reduction = -545.6336  correctly classified = 87.8000%\n",
      "alpha =  0.7231578947368421 b =  -7538.674005456266 epoch =  318  loss = 2821.958  loss reduction = 552.5404  correctly classified = 89.8000%\n",
      "alpha =  0.7231578947368421 b =  -7314.712005456266 epoch =  319  loss = 3374.498  loss reduction = -552.5404  correctly classified = 87.8000%\n",
      "alpha =  0.7231578947368421 b =  -7414.798504403634 epoch =  320  loss = 2801.238  loss reduction = 573.2606  correctly classified = 89.8750%\n",
      "alpha =  0.7231578947368421 b =  -7190.114792824686 epoch =  321  loss = 3367.592  loss reduction = -566.3539  correctly classified = 87.8250%\n",
      "alpha =  0.7231578947368421 b =  -7291.644714929949 epoch =  322  loss = 2815.051  loss reduction = 552.5404  correctly classified = 89.8250%\n",
      "alpha =  0.7231578947368421 b =  -7066.2392917720545 epoch =  323  loss = 3360.685  loss reduction = -545.6336  correctly classified = 87.8500%\n",
      "alpha =  0.7231578947368421 b =  -7167.769213877317 epoch =  324  loss = 2815.051  loss reduction = 545.6336  correctly classified = 89.8250%\n",
      "alpha =  0.7231578947368421 b =  -6943.807213877317 epoch =  325  loss = 3346.871  loss reduction = -531.8201  correctly classified = 87.9000%\n",
      "alpha =  0.7231578947368421 b =  -7045.33713598258 epoch =  326  loss = 2815.051  loss reduction = 531.8201  correctly classified = 89.8250%\n",
      "alpha =  0.7231578947368421 b =  -6821.375135982579 epoch =  327  loss = 3346.871  loss reduction = -531.8201  correctly classified = 87.9000%\n",
      "alpha =  0.7231578947368421 b =  -6922.905058087842 epoch =  328  loss = 2801.238  loss reduction = 545.6336  correctly classified = 89.8750%\n",
      "alpha =  0.7231578947368421 b =  -6698.943058087842 epoch =  329  loss = 3346.871  loss reduction = -545.6336  correctly classified = 87.9000%\n",
      "alpha =  0.7231578947368421 b =  -6799.751268614157 epoch =  330  loss = 2794.331  loss reduction = 552.5404  correctly classified = 89.9000%\n",
      "alpha =  0.7231578947368421 b =  -6573.624133877315 epoch =  331  loss = 3339.965  loss reduction = -545.6336  correctly classified = 87.9250%\n",
      "alpha =  0.7231578947368421 b =  -6673.710632824684 epoch =  332  loss = 2787.424  loss reduction = 552.5404  correctly classified = 89.9250%\n",
      "alpha =  0.7231578947368421 b =  -6444.696651772052 epoch =  333  loss = 3312.338  loss reduction = -524.9134  correctly classified = 88.0250%\n",
      "alpha =  0.7231578947368421 b =  -6551.278554929947 epoch =  334  loss = 2780.517  loss reduction = 531.8201  correctly classified = 89.9500%\n",
      "alpha =  0.7231578947368421 b =  -6322.264573877315 epoch =  335  loss = 3312.338  loss reduction = -531.8201  correctly classified = 88.0250%\n",
      "alpha =  0.7231578947368421 b =  -6430.289900193105 epoch =  336  loss = 2752.89  loss reduction = 559.4471  correctly classified = 90.0500%\n",
      "alpha =  0.7231578947368421 b =  -6200.554207561526 epoch =  337  loss = 3305.431  loss reduction = -552.5404  correctly classified = 88.0500%\n",
      "alpha =  0.7231578947368421 b =  -6310.7446686141575 epoch =  338  loss = 2759.797  loss reduction = 545.6336  correctly classified = 90.0250%\n",
      "alpha =  0.7231578947368421 b =  -6075.956994929947 epoch =  339  loss = 3326.151  loss reduction = -566.3539  correctly classified = 87.9750%\n",
      "alpha =  0.7231578947368421 b =  -6204.190245456262 epoch =  340  loss = 2808.144  loss reduction = 518.0066  correctly classified = 89.8500%\n",
      "alpha =  0.7231578947368421 b =  -5965.0723022983675 epoch =  341  loss = 3326.151  loss reduction = -518.0066  correctly classified = 87.9750%\n",
      "alpha =  0.7231578947368421 b =  -6105.574649666789 epoch =  342  loss = 2828.865  loss reduction = 497.2863  correctly classified = 89.7750%\n",
      "alpha =  0.7231578947368421 b =  -5862.848148614157 epoch =  343  loss = 3333.058  loss reduction = -504.1931  correctly classified = 87.9500%\n",
      "alpha =  0.7231578947368421 b =  -6006.9590538773155 epoch =  344  loss = 2835.771  loss reduction = 497.2863  correctly classified = 89.7500%\n",
      "alpha =  0.7231578947368421 b =  -5762.789129666789 epoch =  345  loss = 3346.871  loss reduction = -511.0999  correctly classified = 87.9000%\n",
      "alpha =  0.7231578947368421 b =  -5904.734900193105 epoch =  346  loss = 2815.051  loss reduction = 531.8201  correctly classified = 89.8250%\n",
      "alpha =  0.7231578947368421 b =  -5663.451822298368 epoch =  347  loss = 3319.244  loss reduction = -504.1931  correctly classified = 88.0000%\n",
      "alpha =  0.7231578947368421 b =  -5806.119304403631 epoch =  348  loss = 2808.144  loss reduction = 511.0999  correctly classified = 89.8500%\n",
      "alpha =  0.7231578947368421 b =  -5564.114514929946 epoch =  349  loss = 3312.338  loss reduction = -504.1931  correctly classified = 88.0250%\n",
      "alpha =  0.7231578947368421 b =  -5706.781997035209 epoch =  350  loss = 2808.144  loss reduction = 504.1931  correctly classified = 89.8500%\n",
      "alpha =  0.7231578947368421 b =  -5464.777207561525 epoch =  351  loss = 3312.338  loss reduction = -504.1931  correctly classified = 88.0250%\n",
      "alpha =  0.7231578947368421 b =  -5608.888112824683 epoch =  352  loss = 2821.958  loss reduction = 490.3796  correctly classified = 89.8000%\n",
      "alpha =  0.7231578947368421 b =  -5363.274765456262 epoch =  353  loss = 3333.058  loss reduction = -511.0999  correctly classified = 87.9500%\n",
      "alpha =  0.7231578947368421 b =  -5510.272517035209 epoch =  354  loss = 2835.771  loss reduction = 497.2863  correctly classified = 89.7500%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.7231578947368421 b =  -5261.772323350998 epoch =  355  loss = 3360.685  loss reduction = -524.9134  correctly classified = 87.8500%\n",
      "alpha =  0.7231578947368421 b =  -5413.10034440363 epoch =  356  loss = 2877.212  loss reduction = 483.4728  correctly classified = 89.6000%\n",
      "alpha =  0.7231578947368421 b =  -5166.765285456261 epoch =  357  loss = 3339.965  loss reduction = -462.7526  correctly classified = 87.9250%\n",
      "alpha =  0.7231578947368421 b =  -5315.9281717720505 epoch =  358  loss = 2856.492  loss reduction = 483.4728  correctly classified = 89.6750%\n",
      "alpha =  0.7231578947368421 b =  -5068.149689666788 epoch =  359  loss = 3339.965  loss reduction = -483.4728  correctly classified = 87.9250%\n",
      "alpha =  0.7231578947368421 b =  -5219.4777107194195 epoch =  360  loss = 2863.398  loss reduction = 476.5661  correctly classified = 89.6500%\n",
      "alpha =  0.7231578947368421 b =  -4970.977517035209 epoch =  361  loss = 3333.058  loss reduction = -469.6593  correctly classified = 87.9500%\n",
      "alpha =  0.7231578947368421 b =  -5122.30553808784 epoch =  362  loss = 2863.398  loss reduction = 469.6593  correctly classified = 89.6500%\n",
      "alpha =  0.7231578947368421 b =  -4873.8053444036295 epoch =  363  loss = 3319.244  loss reduction = -455.8458  correctly classified = 88.0000%\n",
      "alpha =  0.7231578947368421 b =  -5025.8550770352085 epoch =  364  loss = 2856.492  loss reduction = 462.7526  correctly classified = 89.6750%\n",
      "alpha =  0.7231578947368421 b =  -4776.63317177205 epoch =  365  loss = 3326.151  loss reduction = -469.6593  correctly classified = 87.9750%\n",
      "alpha =  0.7231578947368421 b =  -4942.3954244036295 epoch =  366  loss = 2932.466  loss reduction = 393.685  correctly classified = 89.4000%\n",
      "alpha =  0.7231578947368421 b =  -4684.512980193103 epoch =  367  loss = 3353.778  loss reduction = -421.312  correctly classified = 87.8750%\n",
      "alpha =  0.7231578947368421 b =  -4852.440367561525 epoch =  368  loss = 2939.373  loss reduction = 414.4053  correctly classified = 89.3750%\n",
      "alpha =  0.7231578947368421 b =  -4595.279634929946 epoch =  369  loss = 3346.871  loss reduction = -407.4985  correctly classified = 87.9000%\n",
      "alpha =  0.7231578947368421 b =  -4766.093868614156 epoch =  370  loss = 2939.373  loss reduction = 407.4985  correctly classified = 89.3750%\n",
      "alpha =  0.7231578947368421 b =  -4506.768001245735 epoch =  371  loss = 3353.778  loss reduction = -414.4053  correctly classified = 87.8750%\n",
      "alpha =  0.7231578947368421 b =  -4679.02565808784 epoch =  372  loss = 2953.186  loss reduction = 400.5918  correctly classified = 89.3250%\n",
      "alpha =  0.7231578947368421 b =  -4420.421502298366 epoch =  373  loss = 3346.871  loss reduction = -393.685  correctly classified = 87.9000%\n",
      "alpha =  0.7231578947368421 b =  -4594.844293877313 epoch =  374  loss = 2960.093  loss reduction = 386.7783  correctly classified = 89.3000%\n",
      "alpha =  0.7231578947368421 b =  -4331.188157035208 epoch =  375  loss = 3339.965  loss reduction = -379.8715  correctly classified = 87.9250%\n",
      "alpha =  0.7231578947368421 b =  -4533.035988614155 epoch =  376  loss = 3098.228  loss reduction = 241.7364  correctly classified = 88.8000%\n",
      "alpha =  0.7231578947368421 b =  -4233.294272824682 epoch =  377  loss = 3547.167  loss reduction = -448.9391  correctly classified = 87.1750%\n",
      "alpha =  0.7231578947368421 b =  -4514.530378087839 epoch =  378  loss = 3636.955  loss reduction = -89.78781  correctly classified = 86.8500%\n",
      "alpha =  0.7231578947368421 b =  -4158.495159140471 epoch =  379  loss = 3947.759  loss reduction = -310.804  correctly classified = 85.7250%\n",
      "alpha =  0.7231578947368421 b =  -4545.101154929945 epoch =  380  loss = 4451.952  loss reduction = -504.1931  correctly classified = 83.9000%\n",
      "alpha =  0.7231578947368421 b =  -4062.044698087839 epoch =  381  loss = 4969.959  loss reduction = -518.0066  correctly classified = 82.0250%\n",
      "alpha =  0.7231578947368421 b =  -4737.33532545626 epoch =  382  loss = 6924.57  loss reduction = -1954.612  correctly classified = 74.9500%\n",
      "alpha =  0.7231578947368421 b =  -4151.074112824681 epoch =  383  loss = 5860.93  loss reduction = 1063.64  correctly classified = 78.8000%\n",
      "alpha =  0.7231578947368421 b =  -5017.618308614155 epoch =  384  loss = 8713.42  loss reduction = -2852.49  correctly classified = 68.4750%\n",
      "alpha =  0.7231578947368421 b =  -4358.464226508891 epoch =  385  loss = 6530.885  loss reduction = 2182.535  correctly classified = 76.3750%\n",
      "alpha =  0.7231578947368421 b =  -5266.145982298365 epoch =  386  loss = 9107.105  loss reduction = -2576.22  correctly classified = 67.0500%\n",
      "alpha =  0.7231578947368421 b =  -4601.218207561523 epoch =  387  loss = 6572.326  loss reduction = 2534.779  correctly classified = 76.2250%\n",
      "alpha =  0.7231578947368421 b =  -5474.97951914047 epoch =  388  loss = 8782.487  loss reduction = -2210.162  correctly classified = 68.2250%\n",
      "alpha =  0.7231578947368421 b =  -4828.094533877313 epoch =  389  loss = 6413.47  loss reduction = 2369.017  correctly classified = 76.8000%\n",
      "alpha =  0.7231578947368421 b =  -5692.473594929944 epoch =  390  loss = 8692.7  loss reduction = -2279.229  correctly classified = 68.5500%\n",
      "alpha =  0.7231578947368421 b =  -5054.249148614154 epoch =  391  loss = 6358.216  loss reduction = 2334.483  correctly classified = 77.0000%\n",
      "alpha =  0.7231578947368421 b =  -5904.9156896667855 epoch =  392  loss = 8575.285  loss reduction = -2217.068  correctly classified = 68.9750%\n",
      "alpha =  0.7231578947368421 b =  -5273.1866475615225 epoch =  393  loss = 6296.056  loss reduction = 2279.229  correctly classified = 77.2250%\n",
      "alpha =  0.7231578947368421 b =  -6114.4709380878385 epoch =  394  loss = 8485.497  loss reduction = -2189.441  correctly classified = 69.3000%\n",
      "alpha =  0.7231578947368421 b =  -5494.289281245733 epoch =  395  loss = 6185.548  loss reduction = 2299.949  correctly classified = 77.6250%\n",
      "alpha =  0.7231578947368421 b =  -6304.539973877312 epoch =  396  loss = 8188.506  loss reduction = -2002.959  correctly classified = 70.3750%\n",
      "alpha =  0.7231578947368421 b =  -5711.783357035207 epoch =  397  loss = 5923.091  loss reduction = 2265.416  correctly classified = 78.5750%\n",
      "alpha =  0.7231578947368421 b =  -6429.654967561522 epoch =  398  loss = 7345.882  loss reduction = -1422.791  correctly classified = 73.4250%\n",
      "alpha =  0.7231578947368421 b =  -5906.904373877312 epoch =  399  loss = 5294.576  loss reduction = 2051.306  correctly classified = 80.8500%\n",
      "alpha =  0.7231578947368421 b =  -6486.2073612457325 epoch =  400  loss = 6157.921  loss reduction = -863.3443  correctly classified = 77.7250%\n",
      "alpha =  0.7231578947368421 b =  -6008.202885456259 epoch =  401  loss = 4935.425  loss reduction = 1222.496  correctly classified = 82.1500%\n",
      "alpha =  0.7231578947368421 b =  -6536.264350719416 epoch =  402  loss = 5695.168  loss reduction = -759.743  correctly classified = 79.4000%\n",
      "alpha =  0.7231578947368421 b =  -6080.632933877311 epoch =  403  loss = 4748.943  loss reduction = 946.2254  correctly classified = 82.8250%\n",
      "alpha =  0.7231578947368421 b =  -6573.330531772048 epoch =  404  loss = 5398.177  loss reduction = -649.2349  correctly classified = 80.4750%\n",
      "alpha =  0.7231578947368421 b =  -6146.567578087837 epoch =  405  loss = 4527.926  loss reduction = 870.2511  correctly classified = 83.6250%\n",
      "alpha =  0.7231578947368421 b =  -6589.467077035206 epoch =  406  loss = 4949.238  loss reduction = -421.312  correctly classified = 82.1000%\n",
      "alpha =  0.7231578947368421 b =  -6174.251508614153 epoch =  407  loss = 4445.045  loss reduction = 504.1931  correctly classified = 83.9250%\n",
      "alpha =  0.7231578947368421 b =  -6588.282544403626 epoch =  408  loss = 4700.595  loss reduction = -255.5499  correctly classified = 83.0000%\n",
      "alpha =  0.7231578947368421 b =  -6179.5623801931 epoch =  409  loss = 4382.885  loss reduction = 317.7107  correctly classified = 84.1500%\n",
      "alpha =  0.7231578947368421 b =  -6564.724952824678 epoch =  410  loss = 4479.579  loss reduction = -96.69457  correctly classified = 83.8000%\n",
      "alpha =  0.7231578947368421 b =  -6172.604154929942 epoch =  411  loss = 4279.283  loss reduction = 200.2959  correctly classified = 84.5250%\n",
      "alpha =  0.7231578947368421 b =  -6506.525205456257 epoch =  412  loss = 4085.894  loss reduction = 193.3891  correctly classified = 85.2250%\n",
      "alpha =  0.7231578947368421 b =  -6152.655121245731 epoch =  413  loss = 3996.106  loss reduction = 89.78781  correctly classified = 85.5500%\n",
      "alpha =  0.7231578947368421 b =  -6421.622129666784 epoch =  414  loss = 3616.235  loss reduction = 379.8715  correctly classified = 86.9250%\n",
      "alpha =  0.7231578947368421 b =  -6119.715279140468 epoch =  415  loss = 3636.955  loss reduction = -20.72026  correctly classified = 86.8500%\n",
      "alpha =  0.7231578947368421 b =  -6303.520321245731 epoch =  416  loss = 3077.508  loss reduction = 559.4471  correctly classified = 88.8750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.7231578947368421 b =  -6077.393186508889 epoch =  417  loss = 3339.965  loss reduction = -262.4567  correctly classified = 87.9250%\n",
      "alpha =  0.7231578947368421 b =  -6154.384914929941 epoch =  418  loss = 2718.357  loss reduction = 621.6079  correctly classified = 90.1750%\n",
      "alpha =  0.7231578947368421 b =  -5949.90912756152 epoch =  419  loss = 3201.829  loss reduction = -483.4728  correctly classified = 88.4250%\n",
      "alpha =  0.7231578947368421 b =  -6015.353470719415 epoch =  420  loss = 2704.543  loss reduction = 497.2863  correctly classified = 90.2250%\n",
      "alpha =  0.7231578947368421 b =  -5817.37308756152 epoch =  421  loss = 3181.109  loss reduction = -476.5661  correctly classified = 88.5000%\n",
      "alpha =  0.7231578947368421 b =  -5872.713468614152 epoch =  422  loss = 2676.916  loss reduction = 504.1931  correctly classified = 90.3250%\n",
      "alpha =  0.7231578947368421 b =  -5679.063354929941 epoch =  423  loss = 3139.669  loss reduction = -462.7526  correctly classified = 88.6500%\n",
      "alpha =  0.7231578947368421 b =  -5732.23860124573 epoch =  424  loss = 2670.009  loss reduction = 469.6593  correctly classified = 90.3500%\n",
      "alpha =  0.7231578947368421 b =  -5537.145064403625 epoch =  425  loss = 3153.482  loss reduction = -483.4728  correctly classified = 88.6000%\n",
      "alpha =  0.7231578947368421 b =  -5591.763733877309 epoch =  426  loss = 2670.009  loss reduction = 483.4728  correctly classified = 90.3500%\n",
      "alpha =  0.7231578947368421 b =  -5395.948485456257 epoch =  427  loss = 3146.575  loss reduction = -476.5661  correctly classified = 88.6250%\n",
      "alpha =  0.7231578947368421 b =  -5455.6191359825725 epoch =  428  loss = 2649.289  loss reduction = 497.2863  correctly classified = 90.4250%\n",
      "alpha =  0.7231578947368421 b =  -5258.360464403625 epoch =  429  loss = 3160.389  loss reduction = -511.0999  correctly classified = 88.5750%\n",
      "alpha =  0.7231578947368421 b =  -5320.196249666783 epoch =  430  loss = 2642.382  loss reduction = 518.0066  correctly classified = 90.4500%\n",
      "alpha =  0.7231578947368421 b =  -5122.937578087835 epoch =  431  loss = 3160.389  loss reduction = -518.0066  correctly classified = 88.5750%\n",
      "alpha =  0.7231578947368421 b =  -5186.216786508888 epoch =  432  loss = 2656.196  loss reduction = 504.1931  correctly classified = 90.4000%\n",
      "alpha =  0.7231578947368421 b =  -4988.236403350993 epoch =  433  loss = 3167.296  loss reduction = -511.0999  correctly classified = 88.5500%\n",
      "alpha =  0.7231578947368421 b =  -5058.011015982572 epoch =  434  loss = 2676.916  loss reduction = 490.3796  correctly classified = 90.3250%\n",
      "alpha =  0.7231578947368421 b =  -4852.813517035203 epoch =  435  loss = 3194.923  loss reduction = -518.0066  correctly classified = 88.4500%\n",
      "alpha =  0.7231578947368421 b =  -4933.413803350993 epoch =  436  loss = 2656.196  loss reduction = 538.7269  correctly classified = 90.4000%\n",
      "alpha =  0.7231578947368421 b =  -4726.772881245729 epoch =  437  loss = 3208.736  loss reduction = -552.5404  correctly classified = 88.4000%\n",
      "alpha =  0.7231578947368421 b =  -4808.094879140466 epoch =  438  loss = 2649.289  loss reduction = 559.4471  correctly classified = 90.4250%\n",
      "alpha =  0.7231578947368421 b =  -4599.288822298361 epoch =  439  loss = 3188.016  loss reduction = -538.7269  correctly classified = 88.4750%\n",
      "alpha =  0.7231578947368421 b =  -4681.3325317720455 epoch =  440  loss = 2642.382  loss reduction = 545.6336  correctly classified = 90.4500%\n",
      "alpha =  0.7231578947368421 b =  -4471.083051772045 epoch =  441  loss = 3174.202  loss reduction = -531.8201  correctly classified = 88.5250%\n",
      "alpha =  0.7231578947368421 b =  -4553.848472824677 epoch =  442  loss = 2635.476  loss reduction = 538.7269  correctly classified = 90.4750%\n",
      "alpha =  0.7231578947368421 b =  -4342.877281245729 epoch =  443  loss = 3153.482  loss reduction = -518.0066  correctly classified = 88.6000%\n",
      "alpha =  0.7231578947368421 b =  -4428.52954861415 epoch =  444  loss = 2635.476  loss reduction = 518.0066  correctly classified = 90.4750%\n",
      "alpha =  0.7231578947368421 b =  -4208.176106508887 epoch =  445  loss = 3188.016  loss reduction = -552.5404  correctly classified = 88.4750%\n",
      "alpha =  0.7231578947368421 b =  -4305.375759140466 epoch =  446  loss = 2621.662  loss reduction = 566.3539  correctly classified = 90.5250%\n",
      "alpha =  0.7231578947368421 b =  -4079.9703359825708 epoch =  447  loss = 3194.923  loss reduction = -573.2606  correctly classified = 88.4500%\n",
      "alpha =  0.7231578947368421 b =  -4177.891700193097 epoch =  448  loss = 2614.755  loss reduction = 580.1674  correctly classified = 90.5500%\n",
      "alpha =  0.7231578947368421 b =  -3953.207988614149 epoch =  449  loss = 3188.016  loss reduction = -573.2606  correctly classified = 88.4750%\n",
      "alpha =  0.7231578947368421 b =  -4053.2944875615176 epoch =  450  loss = 2607.849  loss reduction = 580.1674  correctly classified = 90.5750%\n",
      "alpha =  0.7231578947368421 b =  -3827.1673528246756 epoch =  451  loss = 3174.202  loss reduction = -566.3539  correctly classified = 88.5250%\n",
      "alpha =  0.7231578947368421 b =  -3928.697274929939 epoch =  452  loss = 2607.849  loss reduction = 566.3539  correctly classified = 90.5750%\n",
      "alpha =  0.7231578947368421 b =  -3702.570140193097 epoch =  453  loss = 3174.202  loss reduction = -566.3539  correctly classified = 88.5250%\n",
      "alpha =  0.7231578947368421 b =  -3805.5434854562545 epoch =  454  loss = 2607.849  loss reduction = 566.3539  correctly classified = 90.5750%\n",
      "alpha =  0.7231578947368421 b =  -3579.4163507194125 epoch =  455  loss = 3160.389  loss reduction = -552.5404  correctly classified = 88.5750%\n",
      "alpha =  0.7231578947368421 b =  -3683.833119140465 epoch =  456  loss = 2594.035  loss reduction = 566.3539  correctly classified = 90.6250%\n",
      "alpha =  0.7231578947368421 b =  -3458.42769598257 epoch =  457  loss = 3153.482  loss reduction = -559.4471  correctly classified = 88.6000%\n",
      "alpha =  0.7231578947368421 b =  -3565.7313107194122 epoch =  458  loss = 2580.222  loss reduction = 573.2606  correctly classified = 90.6750%\n",
      "alpha =  0.7231578947368421 b =  -3340.3258875615174 epoch =  459  loss = 3153.482  loss reduction = -573.2606  correctly classified = 88.6000%\n",
      "alpha =  0.7231578947368421 b =  -3447.6295022983595 epoch =  460  loss = 2580.222  loss reduction = 573.2606  correctly classified = 90.6750%\n",
      "alpha =  0.7231578947368421 b =  -3220.78065598257 epoch =  461  loss = 3139.669  loss reduction = -559.4471  correctly classified = 88.6500%\n",
      "alpha =  0.7231578947368421 b =  -3330.9711170352016 epoch =  462  loss = 2566.408  loss reduction = 573.2606  correctly classified = 90.7250%\n",
      "alpha =  0.7231578947368421 b =  -3107.0091170352016 epoch =  463  loss = 3125.855  loss reduction = -559.4471  correctly classified = 88.7000%\n",
      "alpha =  0.7231578947368421 b =  -3215.7561549299385 epoch =  464  loss = 2566.408  loss reduction = 559.4471  correctly classified = 90.7250%\n",
      "alpha =  0.7231578947368421 b =  -2987.463885456254 epoch =  465  loss = 3125.855  loss reduction = -559.4471  correctly classified = 88.7000%\n",
      "alpha =  0.7231578947368421 b =  -3102.7063275615174 epoch =  466  loss = 2587.128  loss reduction = 538.7269  correctly classified = 90.6500%\n",
      "alpha =  0.7231578947368421 b =  -2870.805500193096 epoch =  467  loss = 3132.762  loss reduction = -545.6336  correctly classified = 88.6750%\n",
      "alpha =  0.7231578947368421 b =  -2987.491365456254 epoch =  468  loss = 2587.128  loss reduction = 545.6336  correctly classified = 90.6500%\n",
      "alpha =  0.7231578947368421 b =  -2752.7036917720434 epoch =  469  loss = 3132.762  loss reduction = -545.6336  correctly classified = 88.6750%\n",
      "alpha =  0.7231578947368421 b =  -2874.4415380878327 epoch =  470  loss = 2607.849  loss reduction = 524.9134  correctly classified = 90.5750%\n",
      "alpha =  0.7231578947368421 b =  -2638.9321528246746 epoch =  471  loss = 3139.669  loss reduction = -531.8201  correctly classified = 88.6500%\n",
      "alpha =  0.7231578947368421 b =  -2764.2785570352007 epoch =  472  loss = 2614.755  loss reduction = 524.9134  correctly classified = 90.5500%\n",
      "alpha =  0.7231578947368421 b =  -2532.3777296667795 epoch =  473  loss = 3105.135  loss reduction = -490.3796  correctly classified = 88.7750%\n",
      "alpha =  0.7231578947368421 b =  -2651.950441245727 epoch =  474  loss = 2600.942  loss reduction = 504.1931  correctly classified = 90.6000%\n",
      "alpha =  0.7231578947368421 b =  -2411.389074929937 epoch =  475  loss = 3160.389  loss reduction = -559.4471  correctly classified = 88.5750%\n",
      "alpha =  0.7231578947368421 b =  -2554.0565570352 epoch =  476  loss = 2725.263  loss reduction = 435.1256  correctly classified = 90.1500%\n",
      "alpha =  0.7231578947368421 b =  -2306.9997865088844 epoch =  477  loss = 3181.109  loss reduction = -455.8458  correctly classified = 88.5000%\n",
      "alpha =  0.7231578947368421 b =  -2455.4409612457266 epoch =  478  loss = 2739.077  loss reduction = 442.0323  correctly classified = 90.1000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.7231578947368421 b =  -2205.4973444036214 epoch =  479  loss = 3194.923  loss reduction = -455.8458  correctly classified = 88.4500%\n",
      "alpha =  0.7231578947368421 b =  -2361.155634929937 epoch =  480  loss = 2780.517  loss reduction = 414.4053  correctly classified = 89.9500%\n",
      "alpha =  0.7231578947368421 b =  -2109.768594929937 epoch =  481  loss = 3181.109  loss reduction = -400.5918  correctly classified = 88.5000%\n",
      "alpha =  0.7231578947368421 b =  -2265.426885456253 epoch =  482  loss = 2780.517  loss reduction = 400.5918  correctly classified = 89.9500%\n",
      "alpha =  0.7231578947368421 b =  -2014.0398454562528 epoch =  483  loss = 3167.296  loss reduction = -386.7783  correctly classified = 88.5500%\n",
      "alpha =  0.7231578947368421 b =  -2170.419847561516 epoch =  484  loss = 2759.797  loss reduction = 407.4985  correctly classified = 90.0250%\n",
      "alpha =  0.7231578947368421 b =  -1919.7545191404631 epoch =  485  loss = 3160.389  loss reduction = -400.5918  correctly classified = 88.5750%\n",
      "alpha =  0.7231578947368421 b =  -2072.5259633509895 epoch =  486  loss = 2752.89  loss reduction = 407.4985  correctly classified = 90.0500%\n",
      "alpha =  0.7231578947368421 b =  -1819.6955001930946 epoch =  487  loss = 3167.296  loss reduction = -414.4053  correctly classified = 88.5500%\n",
      "alpha =  0.7231578947368421 b =  -1982.570906508884 epoch =  488  loss = 2766.704  loss reduction = 400.5918  correctly classified = 90.0000%\n",
      "alpha =  0.7231578947368421 b =  -1726.1318854562523 epoch =  489  loss = 3201.829  loss reduction = -435.1256  correctly classified = 88.4250%\n",
      "alpha =  0.7231578947368421 b =  -1903.4415233509892 epoch =  490  loss = 2849.585  loss reduction = 352.2445  correctly classified = 89.7000%\n",
      "alpha =  0.7231578947368421 b =  -1647.0025022983575 epoch =  491  loss = 3201.829  loss reduction = -352.2445  correctly classified = 88.4250%\n",
      "alpha =  0.7231578947368421 b =  -1824.3121401930944 epoch =  492  loss = 2849.585  loss reduction = 352.2445  correctly classified = 89.7000%\n",
      "alpha =  0.7231578947368421 b =  -1563.5428496667785 epoch =  493  loss = 3215.643  loss reduction = -366.058  correctly classified = 88.3750%\n",
      "alpha =  0.7231578947368421 b =  -1745.1827570351995 epoch =  494  loss = 2835.771  loss reduction = 379.8715  correctly classified = 89.7500%\n",
      "alpha =  0.7231578947368421 b =  -1482.2483317720416 epoch =  495  loss = 3222.55  loss reduction = -386.7783  correctly classified = 88.3500%\n",
      "alpha =  0.7231578947368421 b =  -1664.6099507194099 epoch =  496  loss = 2842.678  loss reduction = 379.8715  correctly classified = 89.7250%\n",
      "alpha =  0.7231578947368421 b =  -1399.5103907194098 epoch =  497  loss = 3229.456  loss reduction = -386.7783  correctly classified = 88.3250%\n",
      "alpha =  0.7231578947368421 b =  -1581.1502980878308 epoch =  498  loss = 2835.771  loss reduction = 393.685  correctly classified = 89.7500%\n",
      "alpha =  0.7231578947368421 b =  -1315.3290265088835 epoch =  499  loss = 3222.55  loss reduction = -386.7783  correctly classified = 88.3500%\n",
      "alpha =  0.7231578947368421 b =  -1496.9689338773046 epoch =  500  loss = 2835.771  loss reduction = 386.7783  correctly classified = 89.7500%\n",
      "alpha =  0.7231578947368421 b =  -1231.1476622983573 epoch =  501  loss = 3222.55  loss reduction = -386.7783  correctly classified = 88.3500%\n",
      "alpha =  0.7231578947368421 b =  -1411.3441465088836 epoch =  502  loss = 2821.958  loss reduction = 400.5918  correctly classified = 89.8000%\n",
      "alpha =  0.7231578947368421 b =  -1145.5228749299363 epoch =  503  loss = 3222.55  loss reduction = -400.5918  correctly classified = 88.3500%\n",
      "alpha =  0.7231578947368421 b =  -1325.7193591404625 epoch =  504  loss = 2821.958  loss reduction = 400.5918  correctly classified = 89.8000%\n",
      "alpha =  0.7231578947368421 b =  -1059.8980875615152 epoch =  505  loss = 3222.55  loss reduction = -400.5918  correctly classified = 88.3500%\n",
      "alpha =  0.7231578947368421 b =  -1240.816283350989 epoch =  506  loss = 2815.051  loss reduction = 407.4985  correctly classified = 89.8250%\n",
      "alpha =  0.7231578947368421 b =  -974.9950117720415 epoch =  507  loss = 3222.55  loss reduction = -407.4985  correctly classified = 88.3500%\n",
      "alpha =  0.7231578947368421 b =  -1155.1914959825679 epoch =  508  loss = 2808.144  loss reduction = 414.4053  correctly classified = 89.8500%\n",
      "alpha =  0.7231578947368421 b =  -890.0919359825677 epoch =  509  loss = 3215.643  loss reduction = -407.4985  correctly classified = 88.3750%\n",
      "alpha =  0.7231578947368421 b =  -1071.0101317720414 epoch =  510  loss = 2815.051  loss reduction = 400.5918  correctly classified = 89.8250%\n",
      "alpha =  0.7231578947368421 b =  -802.3020138773045 epoch =  511  loss = 3250.177  loss reduction = -435.1256  correctly classified = 88.2500%\n",
      "alpha =  0.7231578947368421 b =  -988.993902298357 epoch =  512  loss = 2856.492  loss reduction = 393.685  correctly classified = 89.6750%\n",
      "alpha =  0.7231578947368421 b =  -717.3989380878306 epoch =  513  loss = 3263.99  loss reduction = -407.4985  correctly classified = 88.2000%\n",
      "alpha =  0.7231578947368421 b =  -904.0908265088832 epoch =  514  loss = 2856.492  loss reduction = 407.4985  correctly classified = 89.6750%\n",
      "alpha =  0.7231578947368421 b =  -633.2175738773042 epoch =  515  loss = 3257.084  loss reduction = -400.5918  correctly classified = 88.2250%\n",
      "alpha =  0.7231578947368421 b =  -819.9094622983567 epoch =  516  loss = 2856.492  loss reduction = 400.5918  correctly classified = 89.6750%\n",
      "alpha =  0.7231578947368421 b =  -546.1493633509882 epoch =  517  loss = 3270.897  loss reduction = -414.4053  correctly classified = 88.1750%\n",
      "alpha =  0.7231578947368421 b =  -745.110348614146 epoch =  518  loss = 2960.093  loss reduction = 310.804  correctly classified = 89.3000%\n",
      "alpha =  0.7231578947368421 b =  -444.6469212457249 epoch =  519  loss = 3457.379  loss reduction = -497.2863  correctly classified = 87.5000%\n",
      "alpha =  0.7231578947368421 b =  -746.0909507194091 epoch =  520  loss = 3706.023  loss reduction = -248.6432  correctly classified = 86.6000%\n",
      "alpha =  0.7231578947368421 b =  -346.0313254562512 epoch =  521  loss = 4258.563  loss reduction = -552.5404  correctly classified = 84.6000%\n",
      "alpha =  0.7231578947368421 b =  -874.8145022983565 epoch =  522  loss = 5605.38  loss reduction = -1346.817  correctly classified = 79.7250%\n",
      "alpha =  0.7231578947368421 b =  -368.66327492993537 epoch =  523  loss = 5163.348  loss reduction = 442.0323  correctly classified = 81.3250%\n",
      "alpha =  0.7231578947368421 b =  -1072.1006538773038 epoch =  524  loss = 7180.12  loss reduction = -2016.772  correctly classified = 74.0250%\n",
      "alpha =  0.7231578947368421 b =  -463.4663822983563 epoch =  525  loss = 6075.039  loss reduction = 1105.081  correctly classified = 78.0250%\n",
      "alpha =  0.7231578947368421 b =  -1443.319295982567 epoch =  526  loss = 9770.153  loss reduction = -3695.114  correctly classified = 64.6500%\n",
      "alpha =  0.7231578947368421 b =  -745.9145001930932 epoch =  527  loss = 6827.876  loss reduction = 2942.278  correctly classified = 75.3000%\n",
      "alpha =  0.7231578947368421 b =  -1569.877712824672 epoch =  528  loss = 8305.921  loss reduction = -1478.046  correctly classified = 69.9500%\n",
      "alpha =  0.7231578947368421 b =  -930.9315549299351 epoch =  529  loss = 6351.31  loss reduction = 1954.612  correctly classified = 77.0250%\n",
      "alpha =  0.7231578947368421 b =  -1846.55213808783 epoch =  530  loss = 9169.266  loss reduction = -2817.956  correctly classified = 66.8250%\n",
      "alpha =  0.7231578947368421 b =  -1183.0677865088824 epoch =  531  loss = 6558.512  loss reduction = 2610.753  correctly classified = 76.2750%\n",
      "alpha =  0.7231578947368421 b =  -2046.7251359825664 epoch =  532  loss = 8685.793  loss reduction = -2127.28  correctly classified = 68.5750%\n",
      "alpha =  0.7231578947368421 b =  -1408.500689666777 epoch =  533  loss = 6344.403  loss reduction = 2341.39  correctly classified = 77.0500%\n",
      "alpha =  0.7231578947368421 b =  -2271.4363275615137 epoch =  534  loss = 8678.886  loss reduction = -2334.483  correctly classified = 68.6000%\n",
      "alpha =  0.7231578947368421 b =  -1638.263862298356 epoch =  535  loss = 6296.056  loss reduction = 2382.83  correctly classified = 77.2250%\n",
      "alpha =  0.7231578947368421 b =  -2489.6521149299347 epoch =  536  loss = 8568.378  loss reduction = -2272.322  correctly classified = 69.0000%\n",
      "alpha =  0.7231578947368421 b =  -1865.1401886141452 epoch =  537  loss = 6226.988  loss reduction = 2341.39  correctly classified = 77.4750%\n",
      "alpha =  0.7231578947368421 b =  -2710.7547486141452 epoch =  538  loss = 8513.124  loss reduction = -2286.136  correctly classified = 69.2000%\n",
      "alpha =  0.7231578947368421 b =  -2097.790207561514 epoch =  539  loss = 6116.48  loss reduction = 2396.644  correctly classified = 77.8750%\n",
      "alpha =  0.7231578947368421 b =  -2897.9369380878297 epoch =  540  loss = 8077.998  loss reduction = -1961.518  correctly classified = 70.7750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.7231578947368421 b =  -2315.2842833509876 epoch =  541  loss = 5826.396  loss reduction = 2251.602  correctly classified = 78.9250%\n",
      "alpha =  0.7231578947368421 b =  -3017.999950719409 epoch =  542  loss = 7187.027  loss reduction = -1360.631  correctly classified = 74.0000%\n",
      "alpha =  0.7231578947368421 b =  -2503.909895982567 epoch =  543  loss = 5225.509  loss reduction = 1961.518  correctly classified = 81.1000%\n",
      "alpha =  0.7231578947368421 b =  -3063.0049591404613 epoch =  544  loss = 5936.904  loss reduction = -711.3957  correctly classified = 78.5250%\n",
      "alpha =  0.7231578947368421 b =  -2609.538677035198 epoch =  545  loss = 4672.968  loss reduction = 1263.936  correctly classified = 83.1000%\n",
      "alpha =  0.7231578947368421 b =  -3094.2974475615138 epoch =  546  loss = 5266.949  loss reduction = -593.9809  correctly classified = 80.9500%\n",
      "alpha =  0.7231578947368421 b =  -2679.081879140461 epoch =  547  loss = 4403.605  loss reduction = 863.3443  correctly classified = 84.0750%\n",
      "alpha =  0.7231578947368421 b =  -3083.0089528246713 epoch =  548  loss = 4576.274  loss reduction = -172.6689  correctly classified = 83.4500%\n",
      "alpha =  0.7231578947368421 b =  -2685.836173877303 epoch =  549  loss = 4244.749  loss reduction = 331.5242  correctly classified = 84.6500%\n",
      "alpha =  0.7231578947368421 b =  -3053.6776686141447 epoch =  550  loss = 4286.19  loss reduction = -41.44053  correctly classified = 84.5000%\n",
      "alpha =  0.7231578947368421 b =  -2668.7739865088815 epoch =  551  loss = 4141.148  loss reduction = 145.0419  correctly classified = 85.0250%\n",
      "alpha =  0.7231578947368421 b =  -2991.8693633509865 epoch =  552  loss = 3927.039  loss reduction = 214.1094  correctly classified = 85.8000%\n",
      "alpha =  0.7231578947368421 b =  -2626.451893877302 epoch =  553  loss = 4009.92  loss reduction = -82.88106  correctly classified = 85.5000%\n",
      "alpha =  0.7231578947368421 b =  -2917.791961245723 epoch =  554  loss = 3678.396  loss reduction = 331.5242  correctly classified = 86.7000%\n",
      "alpha =  0.7231578947368421 b =  -2560.31331914046 epoch =  555  loss = 3961.572  loss reduction = -283.1769  correctly classified = 85.6750%\n",
      "alpha =  0.7231578947368421 b =  -2846.6014054562493 epoch =  556  loss = 3643.862  loss reduction = 317.7107  correctly classified = 86.8250%\n",
      "alpha =  0.7231578947368421 b =  -2528.095188614144 epoch =  557  loss = 3643.862  loss reduction = -9.094947e-13  correctly classified = 86.8250%\n",
      "alpha =  0.7436842105263157 b =  -2757.1960338773015 epoch =  0  loss = 3201.829  loss reduction = 442.0323  correctly classified = 88.4250%\n",
      "alpha =  0.7436842105263157 b =  -2457.1105307194066 epoch =  1  loss = 3485.006  loss reduction = -283.1769  correctly classified = 87.4000%\n",
      "alpha =  0.7436842105263157 b =  -2620.898053877301 epoch =  2  loss = 2856.492  loss reduction = 628.5147  correctly classified = 89.6750%\n",
      "alpha =  0.7436842105263157 b =  -2374.992920193091 epoch =  3  loss = 3257.084  loss reduction = -400.5918  correctly classified = 88.2250%\n",
      "alpha =  0.7436842105263157 b =  -2476.4359086141435 epoch =  4  loss = 2621.662  loss reduction = 635.4214  correctly classified = 90.5250%\n",
      "alpha =  0.7436842105263157 b =  -2252.0544833509857 epoch =  5  loss = 3098.228  loss reduction = -476.5661  correctly classified = 88.8000%\n",
      "alpha =  0.7436842105263157 b =  -2330.489369666775 epoch =  6  loss = 2573.315  loss reduction = 524.9134  correctly classified = 90.7000%\n",
      "alpha =  0.7436842105263157 b =  -2119.467487561512 epoch =  7  loss = 3042.974  loss reduction = -469.6593  correctly classified = 89.0000%\n",
      "alpha =  0.7436842105263157 b =  -2185.285027561512 epoch =  8  loss = 2524.967  loss reduction = 518.0066  correctly classified = 90.8750%\n",
      "alpha =  0.7436842105263157 b =  -1982.4273107194067 epoch =  9  loss = 2994.627  loss reduction = -469.6593  correctly classified = 89.1750%\n",
      "alpha =  0.7436842105263157 b =  -2038.5962917720383 epoch =  10  loss = 2531.874  loss reduction = 462.7526  correctly classified = 90.8500%\n",
      "alpha =  0.7436842105263157 b =  -1852.0669054562488 epoch =  11  loss = 2953.186  loss reduction = -421.312  correctly classified = 89.3250%\n",
      "alpha =  0.7436842105263157 b =  -1892.6497528246698 epoch =  12  loss = 2497.34  loss reduction = 455.8458  correctly classified = 90.9750%\n",
      "alpha =  0.7436842105263157 b =  -1715.7689254562488 epoch =  13  loss = 2891.025  loss reduction = -393.685  correctly classified = 89.5500%\n",
      "alpha =  0.7436842105263157 b =  -1742.2500328246697 epoch =  14  loss = 2462.807  loss reduction = 428.2188  correctly classified = 91.1000%\n",
      "alpha =  0.7436842105263157 b =  -1569.8223865088803 epoch =  15  loss = 2849.585  loss reduction = -386.7783  correctly classified = 89.7000%\n",
      "alpha =  0.7436842105263157 b =  -1583.686147561512 epoch =  16  loss = 2400.646  loss reduction = 448.9391  correctly classified = 91.3250%\n",
      "alpha =  0.7436842105263157 b =  -1429.813422298354 epoch =  17  loss = 2732.17  loss reduction = -331.5242  correctly classified = 90.1250%\n",
      "alpha =  0.7436842105263157 b =  -1436.255214929933 epoch =  18  loss = 2373.019  loss reduction = 359.1512  correctly classified = 91.4250%\n",
      "alpha =  0.7436842105263157 b =  -1285.351277035196 epoch =  19  loss = 2704.543  loss reduction = -331.5242  correctly classified = 90.2250%\n",
      "alpha =  0.7436842105263157 b =  -1292.5352665088803 epoch =  20  loss = 2366.112  loss reduction = 338.431  correctly classified = 91.4500%\n",
      "alpha =  0.7436842105263157 b =  -1141.6313286141435 epoch =  21  loss = 2704.543  loss reduction = -338.431  correctly classified = 90.2250%\n",
      "alpha =  0.7436842105263157 b =  -1149.557514929933 epoch =  22  loss = 2373.019  loss reduction = 331.5242  correctly classified = 91.4250%\n",
      "alpha =  0.7436842105263157 b =  -997.1691833509856 epoch =  23  loss = 2690.73  loss reduction = -317.7107  correctly classified = 90.2750%\n",
      "alpha =  0.7436842105263157 b =  -1014.0017317720382 epoch =  24  loss = 2414.459  loss reduction = 276.2702  correctly classified = 91.2750%\n",
      "alpha =  0.7436842105263157 b =  -857.9024159825644 epoch =  25  loss = 2711.45  loss reduction = -296.9905  correctly classified = 90.2000%\n",
      "alpha =  0.7436842105263157 b =  -872.5083738773012 epoch =  26  loss = 2407.553  loss reduction = 303.8972  correctly classified = 91.3000%\n",
      "alpha =  0.7436842105263157 b =  -716.4090580878275 epoch =  27  loss = 2711.45  loss reduction = -303.8972  correctly classified = 90.2000%\n",
      "alpha =  0.7436842105263157 b =  -732.4994096667748 epoch =  28  loss = 2407.553  loss reduction = 303.8972  correctly classified = 91.3000%\n",
      "alpha =  0.7436842105263157 b =  -573.43130650888 epoch =  29  loss = 2739.077  loss reduction = -331.5242  correctly classified = 90.1000%\n",
      "alpha =  0.7436842105263157 b =  -593.9748391404589 epoch =  30  loss = 2421.366  loss reduction = 317.7107  correctly classified = 91.2500%\n",
      "alpha =  0.7436842105263157 b =  -436.3911296667747 epoch =  31  loss = 2725.263  loss reduction = -303.8972  correctly classified = 90.1500%\n",
      "alpha =  0.7436842105263157 b =  -449.512693877301 epoch =  32  loss = 2393.739  loss reduction = 331.5242  correctly classified = 91.3500%\n",
      "alpha =  0.7436842105263157 b =  -292.67118124572204 epoch =  33  loss = 2718.357  loss reduction = -324.6175  correctly classified = 90.1750%\n",
      "alpha =  0.7436842105263157 b =  -308.76153282466936 epoch =  34  loss = 2379.926  loss reduction = 338.431  correctly classified = 91.4000%\n",
      "alpha =  0.7436842105263157 b =  -151.17782335098516 epoch =  35  loss = 2711.45  loss reduction = -331.5242  correctly classified = 90.2000%\n",
      "alpha =  0.7436842105263157 b =  -169.49476545624827 epoch =  36  loss = 2345.392  loss reduction = 366.058  correctly classified = 91.5250%\n",
      "alpha =  0.7436842105263157 b =  -12.659734467787956 epoch =  37  loss = 2702.269  loss reduction = -356.8775  correctly classified = 90.2250%\n",
      "alpha =  0.7436842105263157 b =  -31.71887341515634 epoch =  38  loss = 2338.485  loss reduction = 363.7843  correctly classified = 91.5500%\n",
      "alpha =  0.7436842105263157 b =  130.31801711115946 epoch =  39  loss = 2711.45  loss reduction = -372.9648  correctly classified = 90.2000%\n",
      "alpha =  0.7436842105263157 b =  95.67274447958056 epoch =  40  loss = 2373.019  loss reduction = 338.431  correctly classified = 91.4250%\n",
      "alpha =  0.7436842105263157 b =  276.26455605852794 epoch =  41  loss = 2759.797  loss reduction = -386.7783  correctly classified = 90.0250%\n",
      "alpha =  0.7436842105263157 b =  216.3845907953701 epoch =  42  loss = 2414.459  loss reduction = 345.3377  correctly classified = 91.2750%\n",
      "alpha =  0.7436842105263157 b =  426.664276058528 epoch =  43  loss = 2884.119  loss reduction = -469.6593  correctly classified = 89.5750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.7436842105263157 b =  333.3854529006333 epoch =  44  loss = 2435.18  loss reduction = 448.9391  correctly classified = 91.2000%\n",
      "alpha =  0.7436842105263157 b =  561.4778623743175 epoch =  45  loss = 2939.373  loss reduction = -504.1931  correctly classified = 89.3750%\n",
      "alpha =  0.7436842105263157 b =  455.58169290063336 epoch =  46  loss = 2483.527  loss reduction = 455.8458  correctly classified = 91.0250%\n",
      "alpha =  0.7436842105263157 b =  688.1272834269491 epoch =  47  loss = 2953.186  loss reduction = -469.6593  correctly classified = 89.3250%\n",
      "alpha =  0.7436842105263157 b =  577.0357360585281 epoch =  48  loss = 2518.061  loss reduction = 435.1256  correctly classified = 90.9000%\n",
      "alpha =  0.7436842105263157 b =  808.8391297427386 epoch =  49  loss = 2946.28  loss reduction = -428.2188  correctly classified = 89.3500%\n",
      "alpha =  0.7436842105263157 b =  697.7475823743175 epoch =  50  loss = 2518.061  loss reduction = 428.2188  correctly classified = 90.9000%\n",
      "alpha =  0.7436842105263157 b =  932.5197634269491 epoch =  51  loss = 2973.907  loss reduction = -455.8458  correctly classified = 89.2500%\n",
      "alpha =  0.7436842105263157 b =  817.7172318480018 epoch =  52  loss = 2524.967  loss reduction = 448.9391  correctly classified = 90.8750%\n",
      "alpha =  0.7436842105263157 b =  1060.6535781637913 epoch =  53  loss = 3008.44  loss reduction = -483.4728  correctly classified = 89.1250%\n",
      "alpha =  0.7436842105263157 b =  922.8429444795809 epoch =  54  loss = 2600.942  loss reduction = 407.4985  correctly classified = 90.6000%\n",
      "alpha =  0.7436842105263157 b =  1170.9746686901071 epoch =  55  loss = 3042.974  loss reduction = -442.0323  correctly classified = 89.0000%\n",
      "alpha =  0.7436842105263157 b =  1020.5466886901072 epoch =  56  loss = 2621.662  loss reduction = 421.312  correctly classified = 90.5250%\n",
      "alpha =  0.7436842105263157 b =  1282.7801529006335 epoch =  57  loss = 3105.135  loss reduction = -483.4728  correctly classified = 88.7750%\n",
      "alpha =  0.7436842105263157 b =  1113.0550550058967 epoch =  58  loss = 2704.543  loss reduction = 400.5918  correctly classified = 90.2250%\n",
      "alpha =  0.7436842105263157 b =  1378.9995034269493 epoch =  59  loss = 3125.855  loss reduction = -421.312  correctly classified = 88.7000%\n",
      "alpha =  0.7436842105263157 b =  1208.5322086901074 epoch =  60  loss = 2711.45  loss reduction = 414.4053  correctly classified = 90.2000%\n",
      "alpha =  0.7436842105263157 b =  1474.47665711116 epoch =  61  loss = 3125.855  loss reduction = -414.4053  correctly classified = 88.7000%\n",
      "alpha =  0.7436842105263157 b =  1304.009362374318 epoch =  62  loss = 2711.45  loss reduction = 414.4053  correctly classified = 90.2000%\n",
      "alpha =  0.7436842105263157 b =  1568.46941711116 epoch =  63  loss = 3112.042  loss reduction = -400.5918  correctly classified = 88.7500%\n",
      "alpha =  0.7436842105263157 b =  1398.7443192164233 epoch =  64  loss = 2718.357  loss reduction = 393.685  correctly classified = 90.1750%\n",
      "alpha =  0.7436842105263157 b =  1662.4621771111601 epoch =  65  loss = 3105.135  loss reduction = -386.7783  correctly classified = 88.7750%\n",
      "alpha =  0.7436842105263157 b =  1494.221472900634 epoch =  66  loss = 2704.543  loss reduction = 400.5918  correctly classified = 90.2250%\n",
      "alpha =  0.7436842105263157 b =  1759.4237244795813 epoch =  67  loss = 3118.948  loss reduction = -414.4053  correctly classified = 88.7250%\n",
      "alpha =  0.7436842105263157 b =  1587.4720360585288 epoch =  68  loss = 2711.45  loss reduction = 407.4985  correctly classified = 90.2000%\n",
      "alpha =  0.7436842105263157 b =  1857.127468690108 epoch =  69  loss = 3160.389  loss reduction = -448.9391  correctly classified = 88.5750%\n",
      "alpha =  0.7436842105263157 b =  1665.1364655322132 epoch =  70  loss = 2828.865  loss reduction = 331.5242  correctly classified = 89.7750%\n",
      "alpha =  0.7436842105263157 b =  1963.7375750058973 epoch =  71  loss = 3374.498  loss reduction = -545.6336  correctly classified = 87.8000%\n",
      "alpha =  0.7436842105263157 b =  1701.9800686901078 epoch =  72  loss = 3270.897  loss reduction = 103.6013  correctly classified = 88.1750%\n",
      "alpha =  0.7436842105263157 b =  2071.089878163792 epoch =  73  loss = 3878.691  loss reduction = -607.7944  correctly classified = 85.9750%\n",
      "alpha =  0.7436842105263157 b =  1637.1427044795814 epoch =  74  loss = 4652.248  loss reduction = -773.5565  correctly classified = 83.1750%\n",
      "alpha =  0.7436842105263157 b =  2132.4259771111606 epoch =  75  loss = 4928.518  loss reduction = -276.2702  correctly classified = 82.1750%\n",
      "alpha =  0.7436842105263157 b =  1434.9989244795818 epoch =  76  loss = 6924.57  loss reduction = -1996.052  correctly classified = 74.9500%\n",
      "alpha =  0.7436842105263157 b =  2065.3620223743187 epoch =  77  loss = 6102.666  loss reduction = 821.9038  correctly classified = 77.9250%\n",
      "alpha =  0.7436842105263157 b =  1038.399571848003 epoch =  78  loss = 9922.102  loss reduction = -3819.435  correctly classified = 64.1000%\n",
      "alpha =  0.7436842105263157 b =  1770.443637111161 epoch =  79  loss = 6952.197  loss reduction = 2969.905  correctly classified = 74.8500%\n",
      "alpha =  0.7436842105263157 b =  910.4754760585295 epoch =  80  loss = 8409.523  loss reduction = -1457.325  correctly classified = 69.5750%\n",
      "alpha =  0.7436842105263157 b =  1579.4328097427401 epoch =  81  loss = 6448.004  loss reduction = 1961.518  correctly classified = 76.6750%\n",
      "alpha =  0.7436842105263157 b =  624.4634529006352 epoch =  82  loss = 9293.587  loss reduction = -2845.583  correctly classified = 66.3750%\n",
      "alpha =  0.7436842105263157 b =  1327.5618413216878 epoch =  83  loss = 6710.461  loss reduction = 2583.126  correctly classified = 75.7250%\n",
      "alpha =  0.7436842105263157 b =  443.84338132168807 epoch =  84  loss = 8630.539  loss reduction = -1920.078  correctly classified = 68.7750%\n",
      "alpha =  0.7436842105263157 b =  1101.6677623743196 epoch =  85  loss = 6344.403  loss reduction = 2286.136  correctly classified = 77.0500%\n",
      "alpha =  0.7436842105263157 b =  203.1053655322146 epoch =  86  loss = 8768.674  loss reduction = -2424.271  correctly classified = 68.2750%\n",
      "alpha =  0.7436842105263157 b =  857.9609592164251 epoch =  87  loss = 6316.776  loss reduction = 2451.898  correctly classified = 77.1500%\n",
      "alpha =  0.7436842105263157 b =  -19.81992604673269 epoch =  88  loss = 8589.098  loss reduction = -2272.322  correctly classified = 68.9250%\n",
      "alpha =  0.7436842105263157 b =  627.6136992164253 epoch =  89  loss = 6247.708  loss reduction = 2341.39  correctly classified = 77.4000%\n",
      "alpha =  0.7436842105263157 b =  -247.1983986783116 epoch =  90  loss = 8561.471  loss reduction = -2313.763  correctly classified = 69.0250%\n",
      "alpha =  0.7436842105263157 b =  386.87568342695147 epoch =  91  loss = 6151.014  loss reduction = 2410.457  correctly classified = 77.7500%\n",
      "alpha =  0.7436842105263157 b =  -439.69361973094306 epoch =  92  loss = 8112.532  loss reduction = -1961.518  correctly classified = 70.6500%\n",
      "alpha =  0.7436842105263157 b =  162.46599816379376 epoch =  93  loss = 5854.023  loss reduction = 2258.509  correctly classified = 78.8250%\n",
      "alpha =  0.7436842105263157 b =  -568.359912362522 epoch =  94  loss = 7249.188  loss reduction = -1395.164  correctly classified = 73.7750%\n",
      "alpha =  0.7436842105263157 b =  -30.029222888837694 epoch =  95  loss = 5287.669  loss reduction = 1961.518  correctly classified = 80.8750%\n",
      "alpha =  0.7436842105263157 b =  -634.6816702572587 epoch =  96  loss = 6144.107  loss reduction = -856.4376  correctly classified = 77.7750%\n",
      "alpha =  0.7436842105263157 b =  -151.273547099364 epoch =  97  loss = 4818.01  loss reduction = 1326.097  correctly classified = 82.5750%\n",
      "alpha =  0.7436842105263157 b =  -698.0346407835744 epoch =  98  loss = 5674.448  loss reduction = -856.4376  correctly classified = 79.4750%\n",
      "alpha =  0.7436842105263157 b =  -230.95484815199546 epoch =  99  loss = 4666.061  loss reduction = 1008.386  correctly classified = 83.1250%\n",
      "alpha =  0.7436842105263157 b =  -731.6997376256795 epoch =  100  loss = 5260.042  loss reduction = -593.9809  correctly classified = 80.9750%\n",
      "alpha =  0.7436842105263157 b =  -300.24539341515316 epoch =  101  loss = 4403.605  loss reduction = 856.4376  correctly classified = 84.0750%\n",
      "alpha =  0.7436842105263157 b =  -726.770598678311 epoch =  102  loss = 4666.061  loss reduction = -262.4567  correctly classified = 83.1250%\n",
      "alpha =  0.7436842105263157 b =  -318.32435657304785 epoch =  103  loss = 4230.936  loss reduction = 435.1256  correctly classified = 84.7000%\n",
      "alpha =  0.7436842105263157 b =  -681.020633415153 epoch =  104  loss = 4154.962  loss reduction = 75.9743  correctly classified = 84.9750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.7436842105263157 b =  -288.9027218362056 epoch =  105  loss = 4106.614  loss reduction = 48.34728  correctly classified = 85.1500%\n",
      "alpha =  0.7436842105263157 b =  -613.0047628888371 epoch =  106  loss = 3837.251  loss reduction = 269.3634  correctly classified = 86.1250%\n",
      "alpha =  0.7436842105263157 b =  -235.730788151995 epoch =  107  loss = 3982.293  loss reduction = -145.0419  correctly classified = 85.6000%\n",
      "alpha =  0.7436842105263157 b =  -547.215482888837 epoch =  108  loss = 3733.65  loss reduction = 248.6432  correctly classified = 86.5000%\n",
      "alpha =  0.7436842105263157 b =  -168.45711446778432 epoch =  109  loss = 3996.106  loss reduction = -262.4567  correctly classified = 85.5500%\n",
      "alpha =  0.7436842105263157 b =  -479.19961236252107 epoch =  110  loss = 3726.743  loss reduction = 269.3634  correctly classified = 86.5250%\n",
      "alpha =  0.7436842105263157 b =  -100.44124394146843 epoch =  111  loss = 3996.106  loss reduction = -269.3634  correctly classified = 85.5500%\n",
      "alpha =  0.7436842105263157 b =  -410.44154499409996 epoch =  112  loss = 3719.836  loss reduction = 276.2702  correctly classified = 86.5500%\n",
      "alpha =  0.7436842105263157 b =  -32.425373415152535 epoch =  113  loss = 3989.2  loss reduction = -269.3634  correctly classified = 85.5750%\n",
      "alpha =  0.7436842105263157 b =  -341.68347762567873 epoch =  114  loss = 3712.929  loss reduction = 276.2702  correctly classified = 86.5750%\n",
      "alpha =  0.7436842105263157 b =  6.64482026905813 epoch =  115  loss = 3781.997  loss reduction = -69.06755  correctly classified = 86.3250%\n",
      "alpha =  0.7436842105263157 b =  -243.97973341515234 epoch =  116  loss = 3250.177  loss reduction = 531.8201  correctly classified = 88.2500%\n",
      "alpha =  0.7436842105263157 b =  55.36357290063722 epoch =  117  loss = 3436.659  loss reduction = -186.4824  correctly classified = 87.5750%\n",
      "alpha =  0.7436842105263157 b =  -94.32221025725747 epoch =  118  loss = 2766.704  loss reduction = 669.9552  correctly classified = 90.0000%\n",
      "alpha =  0.7436842105263157 b =  133.7701992164268 epoch =  119  loss = 3077.508  loss reduction = -310.804  correctly classified = 88.8750%\n",
      "alpha =  0.7436842105263157 b =  64.98387184800578 epoch =  120  loss = 2497.34  loss reduction = 580.1674  correctly classified = 90.9750%\n",
      "alpha =  0.7436842105263157 b =  266.35719500590056 epoch =  121  loss = 2980.813  loss reduction = -483.4728  correctly classified = 89.2250%\n",
      "alpha =  0.7436842105263157 b =  225.0321507953743 epoch =  122  loss = 2462.807  loss reduction = 518.0066  correctly classified = 91.1000%\n",
      "alpha =  0.7436842105263157 b =  390.03782869011116 epoch =  123  loss = 2780.517  loss reduction = -317.7107  correctly classified = 89.9500%\n",
      "alpha =  0.7436842105263157 b =  393.24459500590063 epoch =  124  loss = 2324.672  loss reduction = 455.8458  correctly classified = 91.6000%\n",
      "alpha =  0.7436842105263157 b =  536.7265644795849 epoch =  125  loss = 2649.289  loss reduction = -324.6175  correctly classified = 90.4250%\n",
      "alpha =  0.7436842105263157 b =  556.2616613216902 epoch =  126  loss = 2297.045  loss reduction = 352.2445  correctly classified = 91.7000%\n",
      "alpha =  0.7436842105263157 b =  678.962119216427 epoch =  127  loss = 2580.222  loss reduction = -283.1769  correctly classified = 90.6750%\n",
      "alpha =  0.7436842105263157 b =  720.7631213216902 epoch =  128  loss = 2283.231  loss reduction = 296.9905  correctly classified = 91.7500%\n",
      "alpha =  0.7436842105263157 b =  813.0335086901113 epoch =  129  loss = 2435.18  loss reduction = -151.9486  correctly classified = 91.2000%\n",
      "alpha =  0.7436842105263157 b =  878.5848097427429 epoch =  130  loss = 2366.112  loss reduction = 69.06755  correctly classified = 91.4500%\n",
      "alpha =  0.7436842105263157 b =  967.1442129006376 epoch =  131  loss = 2400.646  loss reduction = -34.53377  correctly classified = 91.3250%\n",
      "alpha =  0.7436842105263157 b =  1029.7267265848482 epoch =  132  loss = 2338.485  loss reduction = 62.16079  correctly classified = 91.5500%\n",
      "alpha =  0.7436842105263157 b =  1119.0283265848482 epoch =  133  loss = 2407.553  loss reduction = -69.06755  correctly classified = 91.3000%\n",
      "alpha =  0.7436842105263157 b =  1181.6108402690588 epoch =  134  loss = 2324.672  loss reduction = 82.88106  correctly classified = 91.6000%\n",
      "alpha =  0.7436842105263157 b =  1267.2014560585326 epoch =  135  loss = 2386.832  loss reduction = -62.16079  correctly classified = 91.3750%\n",
      "alpha =  0.7436842105263157 b =  1333.4949539532695 epoch =  136  loss = 2317.765  loss reduction = 69.06755  correctly classified = 91.6250%\n",
      "alpha =  0.7436842105263157 b =  1414.6323886901116 epoch =  137  loss = 2359.205  loss reduction = -41.44053  correctly classified = 91.4750%\n",
      "alpha =  0.7436842105263157 b =  1484.6368707953748 epoch =  138  loss = 2310.858  loss reduction = 48.34728  correctly classified = 91.6500%\n",
      "alpha =  0.7436842105263157 b =  1559.8367307953747 epoch =  139  loss = 2331.578  loss reduction = -20.72026  correctly classified = 91.5750%\n",
      "alpha =  0.7436842105263157 b =  1629.8412129006379 epoch =  140  loss = 2310.858  loss reduction = 20.72026  correctly classified = 91.6500%\n",
      "alpha =  0.7436842105263157 b =  1706.5254665848483 epoch =  141  loss = 2331.578  loss reduction = -20.72026  correctly classified = 91.5750%\n",
      "alpha =  0.7436842105263157 b =  1775.045555005901 epoch =  142  loss = 2297.045  loss reduction = 34.53377  correctly classified = 91.7000%\n",
      "alpha =  0.7436842105263157 b =  1853.214202374322 epoch =  143  loss = 2345.392  loss reduction = -48.34728  correctly classified = 91.5250%\n",
      "alpha =  0.7436842105263157 b =  1921.7342907953746 epoch =  144  loss = 2297.045  loss reduction = 48.34728  correctly classified = 91.7000%\n",
      "alpha =  0.7436842105263157 b =  1997.67634763748 epoch =  145  loss = 2338.485  loss reduction = -41.44053  correctly classified = 91.5500%\n",
      "alpha =  0.7436842105263157 b =  2067.6808297427433 epoch =  146  loss = 2297.045  loss reduction = 41.44053  correctly classified = 91.7000%\n",
      "alpha =  0.7436842105263157 b =  2139.169705532217 epoch =  147  loss = 2310.858  loss reduction = -13.81351  correctly classified = 91.6500%\n",
      "alpha =  0.7436842105263157 b =  2210.6585813216907 epoch =  148  loss = 2310.858  loss reduction = 0.0  correctly classified = 91.6500%\n",
      "alpha =  0.7642105263157895 b =  2283.3579286901117 epoch =  0  loss = 2317.765  loss reduction = -6.906755  correctly classified = 91.6250%\n",
      "alpha =  0.7642105263157895 b =  2356.057276058533 epoch =  1  loss = 2317.765  loss reduction = 0.0  correctly classified = 91.6250%\n",
      "alpha =  0.7847368421052632 b =  2433.0587939532697 epoch =  0  loss = 2324.672  loss reduction = -6.906755  correctly classified = 91.6000%\n",
      "alpha =  0.7847368421052632 b =  2506.927642374322 epoch =  1  loss = 2310.858  loss reduction = 13.81351  correctly classified = 91.6500%\n",
      "alpha =  0.7847368421052632 b =  2580.7964907953747 epoch =  2  loss = 2310.858  loss reduction = 0.0  correctly classified = 91.6500%\n",
      "alpha =  0.8052631578947368 b =  2658.20482763748 epoch =  0  loss = 2310.858  loss reduction = 0.0  correctly classified = 91.6500%\n",
      "alpha =  0.8257894736842105 b =  2732.6414907953745 epoch =  0  loss = 2283.231  loss reduction = 27.62702  correctly classified = 91.7500%\n",
      "alpha =  0.8257894736842105 b =  2814.4953950059007 epoch =  1  loss = 2290.138  loss reduction = -6.906755  correctly classified = 91.7250%\n",
      "alpha =  0.8257894736842105 b =  2887.2837823743216 epoch =  2  loss = 2269.418  loss reduction = 20.72026  correctly classified = 91.8000%\n",
      "alpha =  0.8257894736842105 b =  2966.6652729006373 epoch =  3  loss = 2255.604  loss reduction = 13.81351  correctly classified = 91.8500%\n",
      "alpha =  0.8257894736842105 b =  3040.277798163795 epoch =  4  loss = 2262.511  loss reduction = -6.906755  correctly classified = 91.8250%\n",
      "alpha =  0.8257894736842105 b =  3120.4834265848476 epoch =  5  loss = 2262.511  loss reduction = 0.0  correctly classified = 91.8250%\n",
      "alpha =  0.8463157894736841 b =  3194.2364623743215 epoch =  0  loss = 2234.884  loss reduction = 27.62702  correctly classified = 91.9250%\n",
      "alpha =  0.8463157894736841 b =  3280.658845532216 epoch =  1  loss = 2283.231  loss reduction = -48.34728  correctly classified = 91.7500%\n",
      "alpha =  0.8463157894736841 b =  3338.36404132169 epoch =  2  loss = 2214.164  loss reduction = 69.06755  correctly classified = 92.0000%\n",
      "alpha =  0.8463157894736841 b =  3461.949843426953 epoch =  3  loss = 2379.926  loss reduction = -165.7621  correctly classified = 91.4000%\n",
      "alpha =  0.8463157894736841 b =  3489.248605532216 epoch =  4  loss = 2200.35  loss reduction = 179.5756  correctly classified = 92.0500%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.8463157894736841 b =  3641.5515950059003 epoch =  5  loss = 2435.18  loss reduction = -234.8297  correctly classified = 91.2000%\n",
      "alpha =  0.8463157894736841 b =  3614.7944750059005 epoch =  6  loss = 2227.977  loss reduction = 207.2026  correctly classified = 91.9500%\n",
      "alpha =  0.8463157894736841 b =  3828.7549550059007 epoch =  7  loss = 2649.289  loss reduction = -421.312  correctly classified = 90.4250%\n",
      "alpha =  0.8463157894736841 b =  3719.2247655322167 epoch =  8  loss = 2379.926  loss reduction = 269.3634  correctly classified = 91.4000%\n",
      "alpha =  0.8463157894736841 b =  4018.4921844795854 epoch =  9  loss = 3098.228  loss reduction = -718.3025  correctly classified = 88.8000%\n",
      "alpha =  0.8463157894736841 b =  3779.7346518480067 epoch =  10  loss = 2897.932  loss reduction = 200.2959  correctly classified = 89.5250%\n",
      "alpha =  0.8463157894736841 b =  4197.249312900638 epoch =  11  loss = 3857.971  loss reduction = -960.0389  correctly classified = 86.0500%\n",
      "alpha =  0.8463157894736841 b =  3637.534980269059 epoch =  12  loss = 5121.907  loss reduction = -1263.936  correctly classified = 81.4750%\n",
      "alpha =  0.8463157894736841 b =  4315.193573953269 epoch =  13  loss = 5791.863  loss reduction = -669.9552  correctly classified = 79.0500%\n",
      "alpha =  0.8463157894736841 b =  2990.250660269059 epoch =  14  loss = 11186.04  loss reduction = -5394.175  correctly classified = 59.5250%\n",
      "alpha =  0.8463157894736841 b =  3921.2962013216907 epoch =  15  loss = 7698.127  loss reduction = 3487.911  correctly classified = 72.1500%\n",
      "alpha =  0.8463157894736841 b =  3062.585270795375 epoch =  16  loss = 7428.763  loss reduction = 269.3634  correctly classified = 73.1250%\n",
      "alpha =  0.8463157894736841 b =  3862.714222374322 epoch =  17  loss = 6696.647  loss reduction = 732.116  correctly classified = 75.7750%\n",
      "alpha =  0.8463157894736841 b =  2501.452512900638 epoch =  18  loss = 11469.21  loss reduction = -4772.568  correctly classified = 58.5000%\n",
      "alpha =  0.8463157894736841 b =  3429.1195613216905 epoch =  19  loss = 7670.5  loss reduction = 3798.715  correctly classified = 72.2500%\n",
      "alpha =  0.8463157894736841 b =  2620.2413971111646 epoch =  20  loss = 7035.078  loss reduction = 635.4214  correctly classified = 74.5500%\n",
      "alpha =  0.8463157894736841 b =  3378.98381395327 epoch =  21  loss = 6413.47  loss reduction = 621.6079  correctly classified = 76.8000%\n",
      "alpha =  0.8463157894736841 b =  2070.933363426954 epoch =  22  loss = 11047.9  loss reduction = -4634.432  correctly classified = 60.0250%\n",
      "alpha =  0.8463157894736841 b =  2974.9509634269543 epoch =  23  loss = 7490.924  loss reduction = 3556.979  correctly classified = 72.9000%\n",
      "alpha =  0.8463157894736841 b =  2094.2798307953753 epoch =  24  loss = 7622.153  loss reduction = -131.2283  correctly classified = 72.4250%\n",
      "alpha =  0.8463157894736841 b =  2853.8668707953757 epoch =  25  loss = 6406.564  loss reduction = 1215.589  correctly classified = 76.8250%\n",
      "alpha =  0.8463157894736841 b =  1622.5460266301534 epoch =  26  loss = 10419.56  loss reduction = -4012.993  correctly classified = 62.3000%\n",
      "alpha =  0.8463157894736841 b =  2492.778700314364 epoch =  27  loss = 7228.467  loss reduction = 3191.089  correctly classified = 73.8500%\n",
      "alpha =  0.8463157894736841 b =  1533.5576139985744 epoch =  28  loss = 8264.481  loss reduction = -1036.013  correctly classified = 70.1000%\n",
      "alpha =  0.8463157894736841 b =  2306.65862452489 epoch =  29  loss = 6517.072  loss reduction = 1747.409  correctly classified = 76.4250%\n",
      "alpha =  0.8463157894736841 b =  1158.2419508406795 epoch =  30  loss = 9770.153  loss reduction = -3253.082  correctly classified = 64.6500%\n",
      "alpha =  0.8463157894736841 b =  1987.9327129459425 epoch =  31  loss = 6910.757  loss reduction = 2859.396  correctly classified = 75.0000%\n",
      "alpha =  0.8463157894736841 b =  984.7912224196269 epoch =  32  loss = 8609.818  loss reduction = -1699.062  correctly classified = 68.8500%\n",
      "alpha =  0.8463157894736841 b =  1752.8244939985743 epoch =  33  loss = 6475.631  loss reduction = 2134.187  correctly classified = 76.5750%\n",
      "alpha =  0.8463157894736841 b =  686.3362666301534 epoch =  34  loss = 9127.825  loss reduction = -2652.194  correctly classified = 66.9750%\n",
      "alpha =  0.8463157894736841 b =  1475.4851171564692 epoch =  35  loss = 6620.673  loss reduction = 2507.152  correctly classified = 76.0500%\n",
      "alpha =  0.8463157894736841 b =  432.6463382091008 epoch =  36  loss = 8934.436  loss reduction = -2313.763  correctly classified = 67.6750%\n",
      "alpha =  0.8463157894736841 b =  1203.2134792617323 epoch =  37  loss = 6482.538  loss reduction = 2451.898  correctly classified = 76.5500%\n",
      "alpha =  0.8463157894736841 b =  198.38274241962722 epoch =  38  loss = 8637.445  loss reduction = -2154.907  correctly classified = 68.7500%\n",
      "alpha =  0.8463157894736841 b =  943.6111887354167 epoch =  39  loss = 6302.962  loss reduction = 2334.483  correctly classified = 77.2000%\n",
      "alpha =  0.8463157894736841 b =  -63.7534175803728 epoch =  40  loss = 8658.166  loss reduction = -2355.203  correctly classified = 68.6750%\n",
      "alpha =  0.8463157894736841 b =  677.251912945943 epoch =  41  loss = 6268.429  loss reduction = 2389.737  correctly classified = 77.3250%\n",
      "alpha =  0.8463157894736841 b =  -308.1524912645832 epoch =  42  loss = 8492.404  loss reduction = -2223.975  correctly classified = 69.2750%\n",
      "alpha =  0.8463157894736841 b =  407.5141445248905 epoch =  43  loss = 6061.226  loss reduction = 2431.178  correctly classified = 78.0750%\n",
      "alpha =  0.8463157894736841 b =  -444.4398007382673 epoch =  44  loss = 7442.577  loss reduction = -1381.351  correctly classified = 73.0750%\n",
      "alpha =  0.8463157894736841 b =  196.05537399857485 epoch =  45  loss = 5501.779  loss reduction = 1940.798  correctly classified = 80.1000%\n",
      "alpha =  0.8463157894736841 b =  -558.7669081066882 epoch =  46  loss = 6689.741  loss reduction = -1187.962  correctly classified = 75.8000%\n",
      "alpha =  0.8463157894736841 b =  39.49710873541699 epoch =  47  loss = 5197.882  loss reduction = 1491.859  correctly classified = 81.2000%\n",
      "alpha =  0.8463157894736841 b =  -637.6198428435303 epoch =  48  loss = 6123.387  loss reduction = -925.5051  correctly classified = 77.8500%\n",
      "alpha =  0.8463157894736841 b =  -83.2762302119512 epoch =  49  loss = 4852.544  loss reduction = 1270.843  correctly classified = 82.4500%\n",
      "alpha =  0.8463157894736841 b =  -675.0862428435302 epoch =  50  loss = 5467.245  loss reduction = -614.7012  correctly classified = 80.2250%\n",
      "alpha =  0.8463157894736841 b =  -155.3721796856354 epoch =  51  loss = 4596.994  loss reduction = 870.2511  correctly classified = 83.3750%\n",
      "alpha =  0.8463157894736841 b =  -674.5446007382668 epoch =  52  loss = 4914.705  loss reduction = -317.7107  correctly classified = 82.2250%\n",
      "alpha =  0.8463157894736841 b =  -176.79073968563523 epoch =  53  loss = 4472.672  loss reduction = 442.0323  correctly classified = 83.8250%\n",
      "alpha =  0.8463157894736841 b =  -632.6164238961615 epoch =  54  loss = 4465.766  loss reduction = 6.906755  correctly classified = 83.8500%\n",
      "alpha =  0.8463157894736841 b =  -155.97814179089835 epoch =  55  loss = 4300.003  loss reduction = 165.7621  correctly classified = 84.4500%\n",
      "alpha =  0.8463157894736841 b =  -561.971059685635 epoch =  56  loss = 4113.521  loss reduction = 186.4824  correctly classified = 85.1250%\n",
      "alpha =  0.8463157894736841 b =  -112.36071863300344 epoch =  57  loss = 4120.428  loss reduction = -6.906755  correctly classified = 85.1000%\n",
      "alpha =  0.8463157894736841 b =  -472.7439860014244 epoch =  58  loss = 3837.251  loss reduction = 283.1769  correctly classified = 86.1250%\n",
      "alpha =  0.8463157894736841 b =  -45.09384705405597 epoch =  59  loss = 3996.106  loss reduction = -158.8554  correctly classified = 85.5500%\n",
      "alpha =  0.8463157894736841 b =  -348.88736284352956 epoch =  60  loss = 3567.887  loss reduction = 428.2188  correctly classified = 87.1000%\n",
      "alpha =  0.8463157894736841 b =  4.435938209102005 epoch =  61  loss = 3609.328  loss reduction = -41.44053  correctly classified = 86.9500%\n",
      "alpha =  0.8463157894736841 b =  -164.21787231721373 epoch =  62  loss = 2821.958  loss reduction = 787.37  correctly classified = 89.8000%\n",
      "alpha =  0.8463157894736841 b =  113.08934452489154 epoch =  63  loss = 3305.431  loss reduction = -483.4728  correctly classified = 88.0500%\n",
      "alpha =  0.8463157894736841 b =  15.383879261733696 epoch =  64  loss = 2711.45  loss reduction = 593.9809  correctly classified = 90.2000%\n",
      "alpha =  0.8463157894736841 b =  250.45993820910218 epoch =  65  loss = 3098.228  loss reduction = -386.7783  correctly classified = 88.8000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.8463157894736841 b =  227.08131084068117 epoch =  66  loss = 2490.434  loss reduction = 607.7944  correctly classified = 91.0000%\n",
      "alpha =  0.8463157894736841 b =  435.9740518933128 epoch =  67  loss = 2980.813  loss reduction = -490.3796  correctly classified = 89.2250%\n",
      "alpha =  0.8463157894736841 b =  437.9341192617339 epoch =  68  loss = 2462.807  loss reduction = 518.0066  correctly classified = 91.1000%\n",
      "alpha =  0.8463157894736841 b =  607.1295718933129 epoch =  69  loss = 2808.144  loss reduction = -345.3377  correctly classified = 89.8500%\n",
      "alpha =  0.8463157894736841 b =  634.4283339985761 epoch =  70  loss = 2435.18  loss reduction = 372.9648  correctly classified = 91.2000%\n",
      "alpha =  0.8463157894736841 b =  786.7313234722603 epoch =  71  loss = 2739.077  loss reduction = -303.8972  correctly classified = 90.1000%\n",
      "alpha =  0.8463157894736841 b =  830.0779255775235 epoch =  72  loss = 2428.273  loss reduction = 310.804  correctly classified = 91.2250%\n",
      "alpha =  0.8463157894736841 b =  958.7314666301551 epoch =  73  loss = 2670.009  loss reduction = -241.7364  correctly classified = 90.3500%\n",
      "alpha =  0.8463157894736841 b =  1042.6199803143656 epoch =  74  loss = 2497.34  loss reduction = 172.6689  correctly classified = 90.9750%\n",
      "alpha =  0.8463157894736841 b =  1134.9547255775235 epoch =  75  loss = 2524.967  loss reduction = -27.62702  correctly classified = 90.8750%\n",
      "alpha =  0.8463157894736841 b =  1243.3373108406813 epoch =  76  loss = 2573.315  loss reduction = -48.34728  correctly classified = 90.7000%\n",
      "alpha =  0.8463157894736841 b =  1336.516679261734 epoch =  77  loss = 2504.247  loss reduction = 69.06755  correctly classified = 90.9500%\n",
      "alpha =  0.8463157894736841 b =  1441.520771893313 epoch =  78  loss = 2531.874  loss reduction = -27.62702  correctly classified = 90.8500%\n",
      "alpha =  0.8463157894736841 b =  1533.0108939985762 epoch =  79  loss = 2490.434  loss reduction = 41.44053  correctly classified = 91.0000%\n",
      "alpha =  0.8463157894736841 b =  1636.3257403143657 epoch =  80  loss = 2518.061  loss reduction = -27.62702  correctly classified = 90.9000%\n",
      "alpha =  0.8463157894736841 b =  1726.1266161038393 epoch =  81  loss = 2476.62  loss reduction = 41.44053  correctly classified = 91.0500%\n",
      "alpha =  0.8463157894736841 b =  1826.9075929459445 epoch =  82  loss = 2511.154  loss reduction = -34.53377  correctly classified = 90.9250%\n",
      "alpha =  0.8463157894736841 b =  1916.7084687354181 epoch =  83  loss = 2476.62  loss reduction = 34.53377  correctly classified = 91.0500%\n",
      "alpha =  0.8463157894736841 b =  2017.4894455775234 epoch =  84  loss = 2511.154  loss reduction = -34.53377  correctly classified = 90.9250%\n",
      "alpha =  0.8463157894736841 b =  2108.9795676827866 epoch =  85  loss = 2462.807  loss reduction = 48.34728  correctly classified = 91.1000%\n",
      "alpha =  0.8463157894736841 b =  2208.0712982091027 epoch =  86  loss = 2497.34  loss reduction = -34.53377  correctly classified = 90.9750%\n",
      "alpha =  0.8463157894736841 b =  2299.561420314366 epoch =  87  loss = 2462.807  loss reduction = 34.53377  correctly classified = 91.1000%\n",
      "alpha =  0.8463157894736841 b =  2394.430035051208 epoch =  88  loss = 2476.62  loss reduction = -13.81351  correctly classified = 91.0500%\n",
      "alpha =  0.8463157894736841 b =  2489.29864978805 epoch =  89  loss = 2476.62  loss reduction = 0.0  correctly classified = 91.0500%\n",
      "alpha =  0.8668421052631579 b =  2586.468182419629 epoch =  0  loss = 2476.62  loss reduction = 0.0  correctly classified = 91.0500%\n",
      "alpha =  0.8873684210526316 b =  2685.0530392617343 epoch =  0  loss = 2469.713  loss reduction = 6.906755  correctly classified = 91.0750%\n",
      "alpha =  0.8873684210526316 b =  2784.52348978805 epoch =  1  loss = 2462.807  loss reduction = 6.906755  correctly classified = 91.1000%\n",
      "alpha =  0.8873684210526316 b =  2879.5659718933134 epoch =  2  loss = 2442.086  loss reduction = 20.72026  correctly classified = 91.1750%\n",
      "alpha =  0.8873684210526316 b =  2979.9220161038397 epoch =  3  loss = 2455.9  loss reduction = -13.81351  correctly classified = 91.1250%\n",
      "alpha =  0.8873684210526316 b =  3076.735685577524 epoch =  4  loss = 2442.086  loss reduction = 13.81351  correctly classified = 91.1750%\n",
      "alpha =  0.8873684210526316 b =  3172.6637613669973 epoch =  5  loss = 2435.18  loss reduction = 6.906755  correctly classified = 91.2000%\n",
      "alpha =  0.8873684210526316 b =  3266.82064978805 epoch =  6  loss = 2435.18  loss reduction = 4.547474e-13  correctly classified = 91.2000%\n",
      "alpha =  0.9078947368421053 b =  3362.249465577524 epoch =  0  loss = 2428.273  loss reduction = 6.906755  correctly classified = 91.2250%\n",
      "alpha =  0.9078947368421053 b =  3463.1147550512082 epoch =  1  loss = 2428.273  loss reduction = 0.0  correctly classified = 91.2250%\n",
      "alpha =  0.9284210526315789 b =  3552.362013998577 epoch =  0  loss = 2366.112  loss reduction = 62.16079  correctly classified = 91.4500%\n",
      "alpha =  0.9284210526315789 b =  3653.6546076827876 epoch =  1  loss = 2414.459  loss reduction = -48.34728  correctly classified = 91.2750%\n",
      "alpha =  0.9284210526315789 b =  3742.9018666301563 epoch =  2  loss = 2366.112  loss reduction = 48.34728  correctly classified = 91.4500%\n",
      "alpha =  0.9284210526315789 b =  3847.900717156472 epoch =  3  loss = 2400.646  loss reduction = -34.53377  correctly classified = 91.3250%\n",
      "alpha =  0.9284210526315789 b =  3926.029205577525 epoch =  4  loss = 2324.672  loss reduction = 75.9743  correctly classified = 91.6000%\n",
      "alpha =  0.9284210526315789 b =  4043.073390840683 epoch =  5  loss = 2407.553  loss reduction = -82.88106  correctly classified = 91.3000%\n",
      "alpha =  0.9284210526315789 b =  4105.450287682788 epoch =  6  loss = 2262.511  loss reduction = 145.0419  correctly classified = 91.8250%\n",
      "alpha =  0.9284210526315789 b =  4234.539807682789 epoch =  7  loss = 2455.9  loss reduction = -193.3891  correctly classified = 91.1250%\n",
      "alpha =  0.9284210526315789 b =  4279.311984524894 epoch =  8  loss = 2227.977  loss reduction = 227.9229  correctly classified = 91.9500%\n",
      "alpha =  0.9284210526315789 b =  4426.006224524894 epoch =  9  loss = 2448.993  loss reduction = -221.0162  correctly classified = 91.1500%\n",
      "alpha =  0.9284210526315789 b =  4450.39398873542 epoch =  10  loss = 2227.977  loss reduction = 221.0162  correctly classified = 91.9500%\n",
      "alpha =  0.9284210526315789 b =  4633.224232945946 epoch =  11  loss = 2607.849  loss reduction = -379.8715  correctly classified = 90.5750%\n",
      "alpha =  0.9284210526315789 b =  4601.091580314367 epoch =  12  loss = 2290.138  loss reduction = 317.7107  correctly classified = 91.7250%\n",
      "alpha =  0.9284210526315789 b =  4839.5156771564725 epoch =  13  loss = 2787.424  loss reduction = -497.2863  correctly classified = 89.9250%\n",
      "alpha =  0.9284210526315789 b =  4741.596965577525 epoch =  14  loss = 2435.18  loss reduction = 352.2445  correctly classified = 91.2000%\n",
      "alpha =  0.9284210526315789 b =  5064.338405577525 epoch =  15  loss = 3125.855  loss reduction = -690.6755  correctly classified = 88.7000%\n",
      "alpha =  0.9284210526315789 b =  4824.655369788052 epoch =  16  loss = 2828.865  loss reduction = 296.9905  correctly classified = 89.7750%\n",
      "alpha =  0.9284210526315789 b =  5244.686051893315 epoch =  17  loss = 3588.608  loss reduction = -759.743  correctly classified = 87.0250%\n",
      "alpha =  0.9284210526315789 b =  4755.757243472262 epoch =  18  loss = 4300.003  loss reduction = -711.3957  correctly classified = 84.4500%\n",
      "alpha =  0.9284210526315789 b =  5451.904060314368 epoch =  19  loss = 5439.618  loss reduction = -1139.615  correctly classified = 80.3250%\n",
      "alpha =  0.9284210526315789 b =  4191.147264524894 epoch =  20  loss = 9749.433  loss reduction = -4309.815  correctly classified = 64.7250%\n",
      "alpha =  0.9284210526315789 b =  5164.336780314368 epoch =  21  loss = 7366.603  loss reduction = 2382.83  correctly classified = 73.3500%\n",
      "alpha =  0.9284210526315789 b =  3961.0269655775264 epoch =  22  loss = 9335.028  loss reduction = -1968.425  correctly classified = 66.2250%\n",
      "alpha =  0.9284210526315789 b =  4919.391453998579 epoch =  23  loss = 7256.095  loss reduction = 2078.933  correctly classified = 73.7500%\n",
      "alpha =  0.9284210526315789 b =  3678.092506630158 epoch =  24  loss = 9618.205  loss reduction = -2362.11  correctly classified = 65.2000%\n",
      "alpha =  0.9284210526315789 b =  4635.530430840684 epoch =  25  loss = 7249.188  loss reduction = 2369.017  correctly classified = 73.7750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.9284210526315789 b =  3438.706565577526 epoch =  26  loss = 9300.494  loss reduction = -2051.306  correctly classified = 66.3500%\n",
      "alpha =  0.9284210526315789 b =  4371.127256103841 epoch =  27  loss = 7076.519  loss reduction = 2223.975  correctly classified = 74.4000%\n",
      "alpha =  0.9284210526315789 b =  3142.800207682789 epoch =  28  loss = 9535.324  loss reduction = -2458.805  correctly classified = 65.5000%\n",
      "alpha =  0.9284210526315789 b =  4078.92715505121 epoch =  29  loss = 7104.146  loss reduction = 2431.178  correctly classified = 74.3000%\n",
      "alpha =  0.9284210526315789 b =  2923.798679261736 epoch =  30  loss = 9017.317  loss reduction = -1913.171  correctly classified = 67.3750%\n",
      "alpha =  0.9284210526315789 b =  3815.450544524894 epoch =  31  loss = 6800.249  loss reduction = 2217.068  correctly classified = 75.4000%\n",
      "alpha =  0.9284210526315789 b =  2577.8578539985783 epoch =  32  loss = 9618.205  loss reduction = -2817.956  correctly classified = 65.2000%\n",
      "alpha =  0.9284210526315789 b =  3498.233209788052 epoch =  33  loss = 7000.545  loss reduction = 2617.66  correctly classified = 74.6750%\n",
      "alpha =  0.9284210526315789 b =  2367.195403472263 epoch =  34  loss = 8837.741  loss reduction = -1837.197  correctly classified = 68.0250%\n",
      "alpha =  0.9284210526315789 b =  3240.3159845248947 epoch =  35  loss = 6675.927  loss reduction = 2161.814  correctly classified = 75.8500%\n",
      "alpha =  0.9284210526315789 b =  2015.6951929459474 epoch =  36  loss = 9521.51  loss reduction = -2845.583  correctly classified = 65.5500%\n",
      "alpha =  0.9284210526315789 b =  2911.0533150512106 epoch =  37  loss = 6827.876  loss reduction = 2693.634  correctly classified = 75.3000%\n",
      "alpha =  0.9284210526315789 b =  1783.7217655775264 epoch =  38  loss = 8823.928  loss reduction = -1996.052  correctly classified = 68.0750%\n",
      "alpha =  0.9284210526315789 b =  2631.8251129459477 epoch =  39  loss = 6503.258  loss reduction = 2320.67  correctly classified = 76.4750%\n",
      "alpha =  0.9284210526315789 b =  1498.0076139985792 epoch =  40  loss = 8872.275  loss reduction = -2369.017  correctly classified = 67.9000%\n",
      "alpha =  0.9284210526315789 b =  2339.6250118933162 epoch =  41  loss = 6454.911  loss reduction = 2417.364  correctly classified = 76.6500%\n",
      "alpha =  0.9284210526315789 b =  1223.4122329459478 epoch =  42  loss = 8741.047  loss reduction = -2286.136  correctly classified = 68.3750%\n",
      "alpha =  0.9284210526315789 b =  2049.2780392617374 epoch =  43  loss = 6351.31  loss reduction = 2389.737  correctly classified = 77.0250%\n",
      "alpha =  0.9284210526315789 b =  958.0824939985794 epoch =  44  loss = 8568.378  loss reduction = -2217.068  correctly classified = 69.0000%\n",
      "alpha =  0.9284210526315789 b =  1768.1967087354215 epoch =  45  loss = 6233.895  loss reduction = 2334.483  correctly classified = 77.4500%\n",
      "alpha =  0.9284210526315789 b =  704.798089788053 epoch =  46  loss = 8374.989  loss reduction = -2141.094  correctly classified = 69.7000%\n",
      "alpha =  0.9284210526315789 b =  1483.4091213670004 epoch =  47  loss = 6012.879  loss reduction = 2362.11  correctly classified = 78.2500%\n",
      "alpha =  0.9284210526315789 b =  560.848262419632 epoch =  48  loss = 7352.789  loss reduction = -1339.91  correctly classified = 73.4000%\n",
      "alpha =  0.9284210526315789 b =  1262.5544645248951 epoch =  49  loss = 5494.872  loss reduction = 1857.917  correctly classified = 80.1250%\n",
      "alpha =  0.9284210526315789 b =  444.6953613670005 epoch =  50  loss = 6641.393  loss reduction = -1146.521  correctly classified = 75.9750%\n",
      "alpha =  0.9284210526315789 b =  1091.734275051211 epoch =  51  loss = 5128.814  loss reduction = 1512.579  correctly classified = 81.4500%\n",
      "alpha =  0.9284210526315789 b =  379.5034918933163 epoch =  52  loss = 5923.091  loss reduction = -794.2768  correctly classified = 78.5750%\n",
      "alpha =  0.9284210526315789 b =  985.7735803143689 epoch =  53  loss = 4852.544  loss reduction = 1070.547  correctly classified = 82.4500%\n",
      "alpha =  0.9284210526315789 b =  343.96167715647437 epoch =  54  loss = 5425.805  loss reduction = -573.2606  correctly classified = 80.3750%\n",
      "alpha =  0.9284210526315789 b =  917.802018209106 epoch =  55  loss = 4638.434  loss reduction = 787.37  correctly classified = 83.2250%\n",
      "alpha =  0.9284210526315789 b =  335.2902245248955 epoch =  56  loss = 5025.213  loss reduction = -386.7783  correctly classified = 81.8250%\n",
      "alpha =  0.9284210526315789 b =  889.6727171564745 epoch =  57  loss = 4534.833  loss reduction = 490.3796  correctly classified = 83.6000%\n",
      "alpha =  0.9284210526315789 b =  333.10472136700093 epoch =  58  loss = 4873.264  loss reduction = -338.431  correctly classified = 82.3750%\n",
      "alpha =  0.9284210526315789 b =  883.7809571564746 epoch =  59  loss = 4507.206  loss reduction = 366.058  correctly classified = 83.7000%\n",
      "alpha =  0.9284210526315789 b =  342.037988735422 epoch =  60  loss = 4776.57  loss reduction = -269.3634  correctly classified = 82.7250%\n",
      "alpha =  0.9284210526315789 b =  893.6407887354221 epoch =  61  loss = 4514.113  loss reduction = 262.4567  correctly classified = 83.6750%\n",
      "alpha =  0.9284210526315789 b =  367.64941189331694 epoch =  62  loss = 4659.155  loss reduction = -145.0419  correctly classified = 83.1500%\n",
      "alpha =  0.9284210526315789 b =  912.7662624196329 epoch =  63  loss = 4465.766  loss reduction = 193.3891  correctly classified = 83.8500%\n",
      "alpha =  0.9284210526315789 b =  410.86555505121197 epoch =  64  loss = 4493.393  loss reduction = -27.62702  correctly classified = 83.7500%\n",
      "alpha =  0.9284210526315789 b =  949.4964561038437 epoch =  65  loss = 4417.418  loss reduction = 75.9743  correctly classified = 84.0250%\n",
      "alpha =  0.9284210526315789 b =  467.9801613670017 epoch =  66  loss = 4341.444  loss reduction = 75.9743  correctly classified = 84.3000%\n",
      "alpha =  0.9284210526315789 b =  998.2719845248967 epoch =  67  loss = 4369.071  loss reduction = -27.62702  correctly classified = 84.2000%\n",
      "alpha =  0.9284210526315789 b =  533.4338455775282 epoch =  68  loss = 4230.936  loss reduction = 138.1351  correctly classified = 84.7000%\n",
      "alpha =  0.9284210526315789 b =  1046.120948735423 epoch =  69  loss = 4265.47  loss reduction = -34.53377  correctly classified = 84.5750%\n",
      "alpha =  0.9284210526315789 b =  633.1704055775285 epoch =  70  loss = 3968.479  loss reduction = 296.9905  correctly classified = 85.6500%\n",
      "alpha =  0.9284210526315789 b =  1108.7949403143707 epoch =  71  loss = 4058.267  loss reduction = -89.78781  correctly classified = 85.3250%\n",
      "alpha =  0.9284210526315789 b =  763.4835845248972 epoch =  72  loss = 3657.675  loss reduction = 400.5918  correctly classified = 86.7750%\n",
      "alpha =  0.9284210526315789 b =  1169.6158034722657 epoch =  73  loss = 3692.209  loss reduction = -34.53377  correctly classified = 86.6500%\n",
      "alpha =  0.9284210526315789 b =  942.9046666301606 epoch =  74  loss = 3022.254  loss reduction = 669.9552  correctly classified = 89.0750%\n",
      "alpha =  0.9284210526315789 b =  1248.0413866301606 epoch =  75  loss = 3353.778  loss reduction = -331.5242  correctly classified = 87.8750%\n",
      "alpha =  0.9284210526315789 b =  1151.9758034722659 epoch =  76  loss = 2725.263  loss reduction = 628.5147  correctly classified = 90.1500%\n",
      "alpha =  0.9284210526315789 b =  1402.4452350512133 epoch =  77  loss = 3112.042  loss reduction = -386.7783  correctly classified = 88.7500%\n",
      "alpha =  0.9284210526315789 b =  1398.1095087354238 epoch =  78  loss = 2511.154  loss reduction = 600.8877  correctly classified = 90.9250%\n",
      "alpha =  0.9284210526315789 b =  1603.1772939985817 epoch =  79  loss = 2897.932  loss reduction = -386.7783  correctly classified = 89.5250%\n",
      "alpha =  0.9284210526315789 b =  1627.565058209108 epoch =  80  loss = 2476.62  loss reduction = 421.312  correctly classified = 91.0500%\n",
      "alpha =  0.9284210526315789 b =  1796.4968392617395 epoch =  81  loss = 2808.144  loss reduction = -331.5242  correctly classified = 89.8500%\n",
      "alpha =  0.9284210526315789 b =  1852.3877866301607 epoch =  82  loss = 2476.62  loss reduction = 331.5242  correctly classified = 91.0500%\n",
      "alpha =  0.9284210526315789 b =  1994.449205577529 epoch =  83  loss = 2745.984  loss reduction = -269.3634  correctly classified = 90.0750%\n",
      "alpha =  0.9284210526315789 b =  2083.6964645248977 epoch =  84  loss = 2573.315  loss reduction = 172.6689  correctly classified = 90.7000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.9284210526315789 b =  2202.593778209108 epoch =  85  loss = 2628.569  loss reduction = -55.25404  correctly classified = 90.5000%\n",
      "alpha =  0.9284210526315789 b =  2309.4457571564767 epoch =  86  loss = 2594.035  loss reduction = 34.53377  correctly classified = 90.6250%\n",
      "alpha =  0.9284210526315789 b =  2430.19619926174 epoch =  87  loss = 2614.755  loss reduction = -20.72026  correctly classified = 90.5500%\n",
      "alpha =  0.9284210526315789 b =  2532.4153571564766 epoch =  88  loss = 2559.501  loss reduction = 55.25404  correctly classified = 90.7500%\n",
      "alpha =  0.9284210526315789 b =  2653.1657992617397 epoch =  89  loss = 2600.942  loss reduction = -41.44053  correctly classified = 90.6000%\n",
      "alpha =  0.9284210526315789 b =  2751.6787003143713 epoch =  90  loss = 2545.688  loss reduction = 55.25404  correctly classified = 90.8000%\n",
      "alpha =  0.9284210526315789 b =  2871.5025782091084 epoch =  91  loss = 2594.035  loss reduction = -48.34728  correctly classified = 90.6250%\n",
      "alpha =  0.9284210526315789 b =  2970.01547926174 epoch =  92  loss = 2531.874  loss reduction = 62.16079  correctly classified = 90.8500%\n",
      "alpha =  0.9284210526315789 b =  3084.279971893319 epoch =  93  loss = 2580.222  loss reduction = -48.34728  correctly classified = 90.6750%\n",
      "alpha =  0.9284210526315789 b =  3183.719437156477 epoch =  94  loss = 2524.967  loss reduction = 55.25404  correctly classified = 90.8750%\n",
      "alpha =  0.9284210526315789 b =  3303.543315051214 epoch =  95  loss = 2566.408  loss reduction = -41.44053  correctly classified = 90.7250%\n",
      "alpha =  0.9284210526315789 b =  3400.203087682793 epoch =  96  loss = 2504.247  loss reduction = 62.16079  correctly classified = 90.9500%\n",
      "alpha =  0.9284210526315789 b =  3508.908195051214 epoch =  97  loss = 2524.967  loss reduction = -20.72026  correctly classified = 90.8750%\n",
      "alpha =  0.9284210526315789 b =  3609.2742245248983 epoch =  98  loss = 2504.247  loss reduction = 20.72026  correctly classified = 90.9500%\n",
      "alpha =  0.9284210526315789 b =  3716.1262034722668 epoch =  99  loss = 2511.154  loss reduction = -6.906755  correctly classified = 90.9250%\n",
      "alpha =  0.9284210526315789 b =  3817.4187971564775 epoch =  100  loss = 2497.34  loss reduction = 13.81351  correctly classified = 90.9750%\n",
      "alpha =  0.9284210526315789 b =  3922.4176476827934 epoch =  101  loss = 2497.34  loss reduction = 0.0  correctly classified = 90.9750%\n",
      "alpha =  0.9489473684210525 b =  4027.8438024196357 epoch =  0  loss = 2497.34  loss reduction = 0.0  correctly classified = 90.9750%\n",
      "alpha =  0.9694736842105263 b =  4136.517924524899 epoch =  0  loss = 2490.434  loss reduction = 6.906755  correctly classified = 91.0000%\n",
      "alpha =  0.9694736842105263 b =  4245.192046630163 epoch =  1  loss = 2476.62  loss reduction = 13.81351  correctly classified = 91.0500%\n",
      "alpha =  0.9694736842105263 b =  4352.898633998584 epoch =  2  loss = 2469.713  loss reduction = 6.906755  correctly classified = 91.0750%\n",
      "alpha =  0.9694736842105263 b =  4460.6052213670055 epoch =  3  loss = 2469.713  loss reduction = 0.0  correctly classified = 91.0750%\n",
      "alpha =  0.99 b =  4570.592241367006 epoch =  0  loss = 2469.713  loss reduction = 0.0  correctly classified = 91.0750%\n",
      "     pred  true_label\n",
      "0     0.0           0\n",
      "1     1.0           1\n",
      "2     0.0           0\n",
      "3     0.0           0\n",
      "4     0.0           0\n",
      "..    ...         ...\n",
      "995   0.0           0\n",
      "996   0.0           0\n",
      "997   0.0           0\n",
      "998   0.0           0\n",
      "999   0.0           0\n",
      "\n",
      "[1000 rows x 2 columns]\n",
      "alpha =  0.6 b =  -1705.8819185134862 epoch =  0  loss = 19674.47  loss reduction = 9.999998e+10  correctly classified = 28.8000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b2/8cn96b9x6qz0b7b79dn_n_1h0000gn/T/ipykernel_13453/3879921196.py:49: RuntimeWarning: overflow encountered in exp\n",
      "  test_pred = 1/(1+np.exp(-test_a))\n",
      "/var/folders/b2/8cn96b9x6qz0b7b79dn_n_1h0000gn/T/ipykernel_13453/3879921196.py:25: RuntimeWarning: overflow encountered in exp\n",
      "  a = (1/(1+np.exp(-a)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.6 b =  -1017.0819185134862 epoch =  1  loss = 7960.584  loss reduction = 11713.89  correctly classified = 71.2000%\n",
      "alpha =  0.6 b =  -328.2819185134863 epoch =  2  loss = 7960.584  loss reduction = 0.0  correctly classified = 71.2000%\n",
      "alpha =  0.6205263157894737 b =  -2093.0587606187496 epoch =  0  loss = 19674.44  loss reduction = -11713.86  correctly classified = 28.8000%\n",
      "alpha =  0.6205263157894737 b =  -1380.694550092434 epoch =  1  loss = 7960.584  loss reduction = 11713.86  correctly classified = 71.2000%\n",
      "alpha =  0.6205263157894737 b =  -668.3303395661181 epoch =  2  loss = 7960.584  loss reduction = 0.0  correctly classified = 71.2000%\n",
      "alpha =  0.6410526315789473 b =  -2491.4840237766443 epoch =  0  loss = 19674.44  loss reduction = -11713.86  correctly classified = 28.8000%\n",
      "alpha =  0.6410526315789473 b =  -1755.5556027240127 epoch =  1  loss = 7960.584  loss reduction = 11713.86  correctly classified = 71.2000%\n",
      "alpha =  0.6410526315789473 b =  -1019.6271816713812 epoch =  2  loss = 7960.584  loss reduction = 0.0  correctly classified = 71.2000%\n",
      "alpha =  0.661578947368421 b =  -2901.157707987171 epoch =  0  loss = 19674.44  loss reduction = -11713.86  correctly classified = 28.8000%\n",
      "alpha =  0.661578947368421 b =  -2141.6650764082233 epoch =  1  loss = 7960.584  loss reduction = 11713.86  correctly classified = 71.2000%\n",
      "alpha =  0.661578947368421 b =  -2512.5303564082233 epoch =  2  loss = 6772.622  loss reduction = 1187.962  correctly classified = 75.5000%\n",
      "alpha =  0.661578947368421 b =  -1753.037724829276 epoch =  3  loss = 7960.584  loss reduction = -1187.962  correctly classified = 71.2000%\n",
      "alpha =  0.661578947368421 b =  -3627.305437460855 epoch =  4  loss = 19750.41  loss reduction = -11789.83  correctly classified = 28.5250%\n",
      "alpha =  0.661578947368421 b =  -2867.8128058819075 epoch =  5  loss = 7960.584  loss reduction = 11789.83  correctly classified = 71.2000%\n",
      "alpha =  0.661578947368421 b =  -2118.224011145065 epoch =  6  loss = 7856.982  loss reduction = 103.6013  correctly classified = 71.5750%\n",
      "alpha =  0.661578947368421 b =  -3993.151979566118 epoch =  7  loss = 19743.51  loss reduction = -11886.52  correctly classified = 28.5500%\n",
      "alpha =  0.661578947368421 b =  -3233.659347987171 epoch =  8  loss = 7960.584  loss reduction = 11782.92  correctly classified = 71.2000%\n",
      "alpha =  0.661578947368421 b =  -3367.4927995661183 epoch =  9  loss = 5481.059  loss reduction = 2479.525  correctly classified = 80.1750%\n",
      "alpha =  0.661578947368421 b =  -2625.82707430296 epoch =  10  loss = 7801.728  loss reduction = -2320.67  correctly classified = 71.7750%\n",
      "alpha =  0.661578947368421 b =  -4500.094786934539 epoch =  11  loss = 19750.41  loss reduction = -11948.69  correctly classified = 28.5250%\n",
      "alpha =  0.661578947368421 b =  -3740.602155355592 epoch =  12  loss = 7960.584  loss reduction = 11789.83  correctly classified = 71.2000%\n",
      "alpha =  0.661578947368421 b =  -3673.0575911450655 epoch =  13  loss = 5184.068  loss reduction = 2776.515  correctly classified = 81.2500%\n",
      "alpha =  0.661578947368421 b =  -3268.7825743029603 epoch =  14  loss = 6192.454  loss reduction = -1008.386  correctly classified = 77.6000%\n",
      "alpha =  0.661578947368421 b =  -5121.261845881907 epoch =  15  loss = 19619.19  loss reduction = -13426.73  correctly classified = 29.0000%\n",
      "alpha =  0.661578947368421 b =  -4361.76921430296 epoch =  16  loss = 7960.584  loss reduction = 11658.6  correctly classified = 71.2000%\n",
      "alpha =  0.661578947368421 b =  -3649.154743776644 epoch =  17  loss = 7608.339  loss reduction = 352.2445  correctly classified = 72.4750%\n",
      "alpha =  0.661578947368421 b =  -5521.441689039802 epoch =  18  loss = 19757.32  loss reduction = -12148.98  correctly classified = 28.5000%\n",
      "alpha =  0.661578947368421 b =  -4761.949057460855 epoch =  19  loss = 7960.584  loss reduction = 11796.74  correctly classified = 71.2000%\n",
      "alpha =  0.661578947368421 b =  -4677.237842724013 epoch =  20  loss = 5211.695  loss reduction = 2748.888  correctly classified = 81.1500%\n",
      "alpha =  0.661578947368421 b =  -4424.161401671381 epoch =  21  loss = 5522.499  loss reduction = -310.804  correctly classified = 80.0250%\n",
      "alpha =  0.661578947368421 b =  -5436.795309039802 epoch =  22  loss = 11980.31  loss reduction = -6457.816  correctly classified = 56.6500%\n",
      "alpha =  0.661578947368421 b =  -4677.302677460855 epoch =  23  loss = 7960.584  loss reduction = 4019.731  correctly classified = 71.2000%\n",
      "alpha =  0.661578947368421 b =  -5031.00130693454 epoch =  24  loss = 6523.979  loss reduction = 1436.605  correctly classified = 76.4000%\n",
      "alpha =  0.661578947368421 b =  -4279.431744829277 epoch =  25  loss = 7877.702  loss reduction = -1353.724  correctly classified = 71.5000%\n",
      "alpha =  0.661578947368421 b =  -6113.423854302961 epoch =  26  loss = 19494.86  loss reduction = -11617.16  correctly classified = 29.4500%\n",
      "alpha =  0.661578947368421 b =  -5353.931222724014 epoch =  27  loss = 7960.584  loss reduction = 11534.28  correctly classified = 71.2000%\n",
      "alpha =  0.661578947368421 b =  -4806.38069956612 epoch =  28  loss = 6751.901  loss reduction = 1208.682  correctly classified = 75.5750%\n",
      "alpha =  0.661578947368421 b =  -6650.27664588191 epoch =  29  loss = 19543.21  loss reduction = -12791.31  correctly classified = 29.2750%\n",
      "alpha =  0.661578947368421 b =  -5890.7840143029625 epoch =  30  loss = 7960.584  loss reduction = 11582.63  correctly classified = 71.2000%\n",
      "alpha =  0.661578947368421 b =  -5598.752481671383 epoch =  31  loss = 5667.541  loss reduction = 2293.043  correctly classified = 79.5000%\n",
      "alpha =  0.661578947368421 b =  -6582.995390092436 epoch =  32  loss = 11683.32  loss reduction = -6015.783  correctly classified = 57.7250%\n",
      "alpha =  0.661578947368421 b =  -5823.5027585134885 epoch =  33  loss = 7960.584  loss reduction = 3722.741  correctly classified = 71.2000%\n",
      "alpha =  0.661578947368421 b =  -6346.887125881909 epoch =  34  loss = 7677.407  loss reduction = 283.1769  correctly classified = 72.2250%\n",
      "alpha =  0.661578947368421 b =  -5601.259865881909 epoch =  35  loss = 7829.355  loss reduction = -151.9486  correctly classified = 71.6750%\n",
      "alpha =  0.661578947368421 b =  -7171.809915355593 epoch =  36  loss = 17084.41  loss reduction = -9255.051  correctly classified = 38.1750%\n",
      "alpha =  0.661578947368421 b =  -6412.317283776646 epoch =  37  loss = 7960.584  loss reduction = 9123.823  correctly classified = 71.2000%\n",
      "alpha =  0.661578947368421 b =  -6005.401243776646 epoch =  38  loss = 6095.76  loss reduction = 1864.824  correctly classified = 77.9500%\n",
      "alpha =  0.661578947368421 b =  -7396.361718513488 epoch =  39  loss = 15537.29  loss reduction = -9441.534  correctly classified = 43.7750%\n",
      "alpha =  0.661578947368421 b =  -6636.869086934541 epoch =  40  loss = 7960.584  loss reduction = 7576.71  correctly classified = 71.2000%\n",
      "alpha =  0.661578947368421 b =  -6416.14517956612 epoch =  41  loss = 5336.017  loss reduction = 2624.567  correctly classified = 80.7000%\n",
      "alpha =  0.661578947368421 b =  -6822.004016408225 epoch =  42  loss = 6834.782  loss reduction = -1498.766  correctly classified = 75.2750%\n",
      "alpha =  0.661578947368421 b =  -6105.428011145067 epoch =  43  loss = 7608.339  loss reduction = -773.5565  correctly classified = 72.4750%\n",
      "alpha =  0.661578947368421 b =  -7683.901130092436 epoch =  44  loss = 17139.66  loss reduction = -9531.322  correctly classified = 37.9750%\n",
      "alpha =  0.661578947368421 b =  -6924.408498513489 epoch =  45  loss = 7960.584  loss reduction = 9179.077  correctly classified = 71.2000%\n",
      "alpha =  0.661578947368421 b =  -6701.7038237766465 epoch =  46  loss = 5329.11  loss reduction = 2631.474  correctly classified = 80.7250%\n",
      "alpha =  0.661578947368421 b =  -7077.190894302962 epoch =  47  loss = 6586.139  loss reduction = -1257.029  correctly classified = 76.1750%\n",
      "alpha =  0.661578947368421 b =  -6377.121283776646 epoch =  48  loss = 7477.111  loss reduction = -890.9714  correctly classified = 72.9500%\n",
      "alpha =  0.661578947368421 b =  -7919.940590092436 epoch =  49  loss = 16808.14  loss reduction = -9331.026  correctly classified = 39.1750%\n",
      "alpha =  0.661578947368421 b =  -7160.447958513489 epoch =  50  loss = 7960.584  loss reduction = 8847.553  correctly classified = 71.2000%\n",
      "alpha =  0.661578947368421 b =  -6996.506049039805 epoch =  51  loss = 5115.001  loss reduction = 2845.583  correctly classified = 81.5000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.661578947368421 b =  -7136.2818027240155 epoch =  52  loss = 5294.576  loss reduction = -179.5756  correctly classified = 80.8500%\n",
      "alpha =  0.661578947368421 b =  -6594.6735816713835 epoch =  53  loss = 6689.741  loss reduction = -1395.164  correctly classified = 75.8000%\n",
      "alpha =  0.661578947368421 b =  -8116.364702724015 epoch =  54  loss = 16628.56  loss reduction = -9938.82  correctly classified = 39.8250%\n",
      "alpha =  0.661578947368421 b =  -7356.872071145068 epoch =  55  loss = 7960.584  loss reduction = 8667.977  correctly classified = 71.2000%\n",
      "alpha =  0.661578947368421 b =  -7254.99420588191 epoch =  56  loss = 5032.119  loss reduction = 2928.464  correctly classified = 81.8000%\n",
      "alpha =  0.661578947368421 b =  -7118.122783776646 epoch =  57  loss = 5052.84  loss reduction = -20.72026  correctly classified = 81.7250%\n",
      "alpha =  0.661578947368421 b =  -7141.033262724015 epoch =  58  loss = 4997.586  loss reduction = 55.25404  correctly classified = 81.9250%\n",
      "alpha =  0.661578947368421 b =  -6759.206942724015 epoch =  59  loss = 5874.744  loss reduction = -877.1579  correctly classified = 78.7500%\n",
      "alpha =  0.661578947368421 b =  -7757.315222724015 epoch =  60  loss = 11759.3  loss reduction = -5884.555  correctly classified = 57.4500%\n",
      "alpha =  0.661578947368421 b =  -7004.425149039805 epoch =  61  loss = 7891.516  loss reduction = 3867.783  correctly classified = 71.4500%\n",
      "alpha =  0.661578947368421 b =  -7595.8158627240155 epoch =  62  loss = 8029.651  loss reduction = -138.1351  correctly classified = 70.9500%\n",
      "alpha =  0.661578947368421 b =  -6883.8616479871735 epoch =  63  loss = 7546.178  loss reduction = 483.4728  correctly classified = 72.7000%\n",
      "alpha =  0.661578947368421 b =  -8146.732499566121 epoch =  64  loss = 14238.82  loss reduction = -6692.645  correctly classified = 48.4750%\n",
      "alpha =  0.661578947368421 b =  -7389.880891145069 epoch =  65  loss = 7932.956  loss reduction = 6305.867  correctly classified = 71.3000%\n",
      "alpha =  0.661578947368421 b =  -7568.6117364082265 epoch =  66  loss = 5342.923  loss reduction = 2590.033  correctly classified = 80.6750%\n",
      "alpha =  0.661578947368421 b =  -7025.022747987174 epoch =  67  loss = 6655.207  loss reduction = -1312.283  correctly classified = 75.9250%\n",
      "alpha =  0.661578947368421 b =  -8405.419130092438 epoch =  68  loss = 15343.9  loss reduction = -8688.698  correctly classified = 44.4750%\n",
      "alpha =  0.661578947368421 b =  -7648.567521671385 epoch =  69  loss = 7932.956  loss reduction = 7410.948  correctly classified = 71.3000%\n",
      "alpha =  0.661578947368421 b =  -7744.766393250333 epoch =  70  loss = 5045.933  loss reduction = 2887.023  correctly classified = 81.7500%\n",
      "alpha =  0.661578947368421 b =  -7357.658026934543 epoch =  71  loss = 5860.93  loss reduction = -814.9971  correctly classified = 78.8000%\n",
      "alpha =  0.661578947368421 b =  -8197.304917460859 epoch =  72  loss = 10184.56  loss reduction = -4323.628  correctly classified = 63.1500%\n",
      "alpha =  0.661578947368421 b =  -7468.844307987174 epoch =  73  loss = 7677.407  loss reduction = 2507.152  correctly classified = 72.2250%\n",
      "alpha =  0.661578947368421 b =  -8315.093756408227 epoch =  74  loss = 10253.63  loss reduction = -2576.22  correctly classified = 62.9000%\n",
      "alpha =  0.661578947368421 b =  -7588.613914302964 epoch =  75  loss = 7656.686  loss reduction = 2596.94  correctly classified = 72.3000%\n",
      "alpha =  0.661578947368421 b =  -8419.677479566122 epoch =  76  loss = 10094.77  loss reduction = -2438.084  correctly classified = 63.4750%\n",
      "alpha =  0.661578947368421 b =  -7696.498916408227 epoch =  77  loss = 7622.153  loss reduction = 2472.618  correctly classified = 72.4250%\n",
      "alpha =  0.661578947368421 b =  -8555.953480618753 epoch =  78  loss = 10377.95  loss reduction = -2755.795  correctly classified = 62.4500%\n",
      "alpha =  0.661578947368421 b =  -7832.774917460858 epoch =  79  loss = 7622.153  loss reduction = 2755.795  correctly classified = 72.4250%\n",
      "alpha =  0.661578947368421 b =  -8639.40901851349 epoch =  80  loss = 9894.475  loss reduction = -2272.322  correctly classified = 64.2000%\n",
      "alpha =  0.661578947368421 b =  -7924.153524829279 epoch =  81  loss = 7566.898  loss reduction = 2327.576  correctly classified = 72.6250%\n",
      "alpha =  0.661578947368421 b =  -8783.608089039806 epoch =  82  loss = 10377.95  loss reduction = -2811.049  correctly classified = 62.4500%\n",
      "alpha =  0.661578947368421 b =  -8065.051316408227 epoch =  83  loss = 7601.432  loss reduction = 2776.515  correctly classified = 72.5000%\n",
      "alpha =  0.661578947368421 b =  -8861.781580618754 epoch =  84  loss = 9818.501  loss reduction = -2217.068  correctly classified = 64.4750%\n",
      "alpha =  0.661578947368421 b =  -8161.051714302965 epoch =  85  loss = 7470.204  loss reduction = 2348.297  correctly classified = 72.9750%\n",
      "alpha =  0.661578947368421 b =  -9012.583209039807 epoch =  86  loss = 10295.07  loss reduction = -2824.863  correctly classified = 62.7500%\n",
      "alpha =  0.661578947368421 b =  -8305.25078482928 epoch =  87  loss = 7497.831  loss reduction = 2797.236  correctly classified = 72.8750%\n",
      "alpha =  0.661578947368421 b =  -9092.737467987175 epoch =  88  loss = 9749.433  loss reduction = -2251.602  correctly classified = 64.7250%\n",
      "alpha =  0.661578947368421 b =  -8396.629392197701 epoch =  89  loss = 7421.857  loss reduction = 2327.576  correctly classified = 73.1500%\n",
      "alpha =  0.661578947368421 b =  -9246.840375355596 epoch =  90  loss = 10281.25  loss reduction = -2859.396  correctly classified = 62.8000%\n",
      "alpha =  0.661578947368421 b =  -8546.110509039807 epoch =  91  loss = 7470.204  loss reduction = 2811.049  correctly classified = 72.9750%\n",
      "alpha =  0.661578947368421 b =  -9325.013866934543 epoch =  92  loss = 9701.086  loss reduction = -2230.882  correctly classified = 64.9000%\n",
      "alpha =  0.661578947368421 b =  -8634.848093250333 epoch =  93  loss = 7387.323  loss reduction = 2313.763  correctly classified = 73.2750%\n",
      "alpha =  0.661578947368421 b =  -9483.078309039807 epoch =  94  loss = 10260.53  loss reduction = -2873.21  correctly classified = 62.8750%\n",
      "alpha =  0.661578947368421 b =  -8788.951000618754 epoch =  95  loss = 7414.95  loss reduction = 2845.583  correctly classified = 73.1750%\n",
      "alpha =  0.661578947368421 b =  -9553.32873114507 epoch =  96  loss = 9604.391  loss reduction = -2189.441  correctly classified = 65.2500%\n",
      "alpha =  0.661578947368421 b =  -8890.23344482928 epoch =  97  loss = 7352.789  loss reduction = 2251.602  correctly classified = 73.4000%\n",
      "alpha =  0.661578947368421 b =  -9712.053429039806 epoch =  98  loss = 10039.52  loss reduction = -2686.728  correctly classified = 63.6750%\n",
      "alpha =  0.661578947368421 b =  -9029.81072482928 epoch =  99  loss = 7318.255  loss reduction = 2721.261  correctly classified = 73.5250%\n",
      "alpha =  0.661578947368421 b =  -9804.752547987175 epoch =  100  loss = 9687.272  loss reduction = -2369.017  correctly classified = 64.9500%\n",
      "alpha =  0.661578947368421 b =  -9148.259819566121 epoch =  101  loss = 7283.722  loss reduction = 2403.551  correctly classified = 73.6500%\n",
      "alpha =  0.661578947368421 b =  -9947.631106934543 epoch =  102  loss = 9846.128  loss reduction = -2562.406  correctly classified = 64.3750%\n",
      "alpha =  0.661578947368421 b =  -9290.478122724016 epoch =  103  loss = 7290.628  loss reduction = 2555.499  correctly classified = 73.6250%\n",
      "alpha =  0.661578947368421 b =  -10064.759690092438 epoch =  104  loss = 9680.365  loss reduction = -2389.737  correctly classified = 64.9750%\n",
      "alpha =  0.661578947368421 b =  -9416.205818170745 epoch =  105  loss = 7197.627  loss reduction = 2482.738  correctly classified = 73.9500%\n",
      "alpha =  0.661578947368421 b =  -10190.487385539167 epoch =  106  loss = 9694.179  loss reduction = -2496.552  correctly classified = 64.9250%\n",
      "alpha =  0.661578947368421 b =  -9545.219005539167 epoch =  107  loss = 7180.12  loss reduction = 2514.059  correctly classified = 74.0250%\n",
      "alpha =  0.661578947368421 b =  -10314.2185265918 epoch =  108  loss = 9638.925  loss reduction = -2458.805  correctly classified = 65.1250%\n",
      "alpha =  0.661578947368421 b =  -9670.930913960221 epoch =  109  loss = 7173.213  loss reduction = 2465.711  correctly classified = 74.0500%\n",
      "alpha =  0.661578947368421 b =  -10432.007365539168 epoch =  110  loss = 9556.044  loss reduction = -2382.83  correctly classified = 65.4250%\n",
      "alpha =  0.661578947368421 b =  -9795.9825665918 epoch =  111  loss = 7111.053  loss reduction = 2444.991  correctly classified = 74.2750%\n",
      "alpha =  0.661578947368421 b =  -10551.776971854957 epoch =  112  loss = 9500.79  loss reduction = -2389.737  correctly classified = 65.6250%\n",
      "alpha =  0.661578947368421 b =  -9924.99575396022 epoch =  113  loss = 7028.172  loss reduction = 2472.618  correctly classified = 74.5750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.661578947368421 b =  -10671.546578170746 epoch =  114  loss = 9445.536  loss reduction = -2417.364  correctly classified = 65.8250%\n",
      "alpha =  0.661578947368421 b =  -10051.367918170747 epoch =  115  loss = 6986.731  loss reduction = 2458.805  correctly classified = 74.7250%\n",
      "alpha =  0.661578947368421 b =  -10795.937975012852 epoch =  116  loss = 9424.816  loss reduction = -2438.084  correctly classified = 65.9000%\n",
      "alpha =  0.661578947368421 b =  -10181.041361328642 epoch =  117  loss = 6945.291  loss reduction = 2479.525  correctly classified = 74.8750%\n",
      "alpha =  0.661578947368421 b =  -10920.98962764443 epoch =  118  loss = 9362.655  loss reduction = -2417.364  correctly classified = 66.1250%\n",
      "alpha =  0.661578947368421 b =  -10311.37506027601 epoch =  119  loss = 6903.85  loss reduction = 2458.805  correctly classified = 75.0250%\n",
      "alpha =  0.661578947368421 b =  -11046.04128027601 epoch =  120  loss = 9307.401  loss reduction = -2403.551  correctly classified = 66.3250%\n",
      "alpha =  0.661578947368421 b =  -10444.349782381272 epoch =  121  loss = 6862.409  loss reduction = 2444.991  correctly classified = 75.1750%\n",
      "alpha =  0.661578947368421 b =  -11166.471142381273 epoch =  122  loss = 9176.172  loss reduction = -2313.763  correctly classified = 66.8000%\n",
      "alpha =  0.661578947368421 b =  -10584.587318170747 epoch =  123  loss = 6751.901  loss reduction = 2424.271  correctly classified = 75.5750%\n",
      "alpha =  0.661578947368421 b =  -11276.336911854956 epoch =  124  loss = 8886.089  loss reduction = -2134.187  correctly classified = 67.8500%\n",
      "alpha =  0.661578947368421 b =  -10706.337691854957 epoch =  125  loss = 6696.647  loss reduction = 2189.441  correctly classified = 75.7750%\n",
      "alpha =  0.661578947368421 b =  -11390.164216065483 epoch =  126  loss = 8830.835  loss reduction = -2134.187  correctly classified = 68.0500%\n",
      "alpha =  0.661578947368421 b =  -10823.466275012852 epoch =  127  loss = 6662.114  loss reduction = 2168.721  correctly classified = 75.9000%\n",
      "alpha =  0.661578947368421 b =  -11480.222311854957 epoch =  128  loss = 8602.912  loss reduction = -1940.798  correctly classified = 68.8750%\n",
      "alpha =  0.661578947368421 b =  -10929.370509749693 epoch =  129  loss = 6565.419  loss reduction = 2037.493  correctly classified = 76.2500%\n",
      "alpha =  0.661578947368421 b =  -11574.241942381272 epoch =  130  loss = 8492.404  loss reduction = -1926.985  correctly classified = 69.2750%\n",
      "alpha =  0.661578947368421 b =  -11030.65295396022 epoch =  131  loss = 6544.699  loss reduction = 1947.705  correctly classified = 76.3250%\n",
      "alpha =  0.661578947368421 b =  -11645.812876065484 epoch =  132  loss = 8181.6  loss reduction = -1636.901  correctly classified = 70.4000%\n",
      "alpha =  0.661578947368421 b =  -11118.730282381273 epoch =  133  loss = 6441.097  loss reduction = 1740.502  correctly classified = 76.7000%\n",
      "alpha =  0.661578947368421 b =  -11729.928669749694 epoch =  134  loss = 8153.973  loss reduction = -1712.875  correctly classified = 70.5000%\n",
      "alpha =  0.661578947368421 b =  -11206.147355012852 epoch =  135  loss = 6420.377  loss reduction = 1733.595  correctly classified = 76.7750%\n",
      "alpha =  0.661578947368421 b =  -11805.461138170747 epoch =  136  loss = 8057.278  loss reduction = -1636.901  correctly classified = 70.8500%\n",
      "alpha =  0.661578947368421 b =  -11289.60289290759 epoch =  137  loss = 6365.123  loss reduction = 1692.155  correctly classified = 76.9750%\n",
      "alpha =  0.661578947368421 b =  -11865.807723433905 epoch =  138  loss = 7815.542  loss reduction = -1450.419  correctly classified = 71.7250%\n",
      "alpha =  0.661578947368421 b =  -11371.077663433905 epoch =  139  loss = 6240.802  loss reduction = 1574.74  correctly classified = 77.4250%\n",
      "alpha =  0.661578947368421 b =  -11918.891495012853 epoch =  140  loss = 7559.992  loss reduction = -1319.19  correctly classified = 72.6500%\n",
      "alpha =  0.661578947368421 b =  -11443.969108697063 epoch =  141  loss = 6144.107  loss reduction = 1415.885  correctly classified = 77.7750%\n",
      "alpha =  0.661578947368421 b =  -11952.16759290759 epoch =  142  loss = 7256.095  loss reduction = -1111.988  correctly classified = 73.7500%\n",
      "alpha =  0.661578947368421 b =  -11490.450322381274 epoch =  143  loss = 6088.853  loss reduction = 1167.242  correctly classified = 77.9750%\n",
      "alpha =  0.661578947368421 b =  -11974.219342381273 epoch =  144  loss = 7069.612  loss reduction = -980.7592  correctly classified = 74.4250%\n",
      "alpha =  0.661578947368421 b =  -11525.707187644432 epoch =  145  loss = 6019.785  loss reduction = 1049.827  correctly classified = 78.2250%\n",
      "alpha =  0.661578947368421 b =  -11987.6877665918 epoch =  146  loss = 6883.13  loss reduction = -863.3443  correctly classified = 75.1000%\n",
      "alpha =  0.661578947368421 b =  -11543.797402381273 epoch =  147  loss = 5985.252  loss reduction = 897.8781  correctly classified = 78.3500%\n",
      "alpha =  0.661578947368421 b =  -12005.117725539169 epoch =  148  loss = 6876.223  loss reduction = -890.9714  correctly classified = 75.1250%\n",
      "alpha =  0.661578947368421 b =  -11560.567105539169 epoch =  149  loss = 5978.345  loss reduction = 897.8781  correctly classified = 78.3750%\n",
      "alpha =  0.661578947368421 b =  -12020.566917118116 epoch =  150  loss = 6862.409  loss reduction = -884.0646  correctly classified = 75.1750%\n",
      "alpha =  0.661578947368421 b =  -11576.016297118116 epoch =  151  loss = 5978.345  loss reduction = 884.0646  correctly classified = 78.3750%\n",
      "alpha =  0.661578947368421 b =  -12034.695597118116 epoch =  152  loss = 6862.409  loss reduction = -884.0646  correctly classified = 75.1750%\n",
      "alpha =  0.661578947368421 b =  -11589.484721328643 epoch =  153  loss = 5943.811  loss reduction = 918.5984  correctly classified = 78.5000%\n",
      "alpha =  0.661578947368421 b =  -12049.48453290759 epoch =  154  loss = 6876.223  loss reduction = -932.4119  correctly classified = 75.1250%\n",
      "alpha =  0.661578947368421 b =  -11603.613401328643 epoch =  155  loss = 5950.718  loss reduction = 925.5051  correctly classified = 78.4750%\n",
      "alpha =  0.661578947368421 b =  -12061.63244553917 epoch =  156  loss = 6855.503  loss reduction = -904.7849  correctly classified = 75.2000%\n",
      "alpha =  0.661578947368421 b =  -11617.742081328643 epoch =  157  loss = 5929.998  loss reduction = 925.5051  correctly classified = 78.5500%\n",
      "alpha =  0.661578947368421 b =  -12077.74189290759 epoch =  158  loss = 6862.409  loss reduction = -932.4119  correctly classified = 75.1750%\n",
      "alpha =  0.661578947368421 b =  -11634.511784486538 epoch =  159  loss = 5923.091  loss reduction = 939.3186  correctly classified = 78.5750%\n",
      "alpha =  0.661578947368421 b =  -12095.171851854959 epoch =  160  loss = 6869.316  loss reduction = -946.2254  correctly classified = 75.1500%\n",
      "alpha =  0.661578947368421 b =  -11651.941743433907 epoch =  161  loss = 5936.904  loss reduction = 932.4119  correctly classified = 78.5250%\n",
      "alpha =  0.661578947368421 b =  -12111.941555012854 epoch =  162  loss = 6862.409  loss reduction = -925.5051  correctly classified = 75.1750%\n",
      "alpha =  0.661578947368421 b =  -11669.371702381275 epoch =  163  loss = 5929.998  loss reduction = 932.4119  correctly classified = 78.5500%\n",
      "alpha =  0.661578947368421 b =  -12128.711258170748 epoch =  164  loss = 6855.503  loss reduction = -925.5051  correctly classified = 75.2000%\n",
      "alpha =  0.661578947368421 b =  -11686.141405539169 epoch =  165  loss = 5929.998  loss reduction = 925.5051  correctly classified = 78.5500%\n",
      "alpha =  0.661578947368421 b =  -12146.80147290759 epoch =  166  loss = 6869.316  loss reduction = -939.3186  correctly classified = 75.1500%\n",
      "alpha =  0.661578947368421 b =  -11704.891876065483 epoch =  167  loss = 5923.091  loss reduction = 946.2254  correctly classified = 78.5750%\n",
      "alpha =  0.661578947368421 b =  -12165.551943433904 epoch =  168  loss = 6869.316  loss reduction = -946.2254  correctly classified = 75.1500%\n",
      "alpha =  0.661578947368421 b =  -11723.642346591798 epoch =  169  loss = 5936.904  loss reduction = 932.4119  correctly classified = 78.5250%\n",
      "alpha =  0.661578947368421 b =  -12180.340879223377 epoch =  170  loss = 6827.876  loss reduction = -890.9714  correctly classified = 75.3000%\n",
      "alpha =  0.661578947368421 b =  -11740.412049749693 epoch =  171  loss = 5916.184  loss reduction = 911.6916  correctly classified = 78.6000%\n",
      "alpha =  0.661578947368421 b =  -12191.16828027601 epoch =  172  loss = 6765.715  loss reduction = -849.5308  correctly classified = 75.5250%\n",
      "alpha =  0.661578947368421 b =  -11751.239450802326 epoch =  173  loss = 5902.371  loss reduction = 863.3443  correctly classified = 78.6500%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.661578947368421 b =  -12201.335425539168 epoch =  174  loss = 6758.808  loss reduction = -856.4376  correctly classified = 75.5500%\n",
      "alpha =  0.661578947368421 b =  -11763.387363433905 epoch =  175  loss = 5881.65  loss reduction = 877.1579  correctly classified = 78.7250%\n",
      "alpha =  0.661578947368421 b =  -12212.823082381274 epoch =  176  loss = 6751.901  loss reduction = -870.2511  correctly classified = 75.5750%\n",
      "alpha =  0.661578947368421 b =  -11774.875020276011 epoch =  177  loss = 5881.65  loss reduction = 870.2511  correctly classified = 78.7250%\n",
      "alpha =  0.661578947368421 b =  -12226.951762381274 epoch =  178  loss = 6765.715  loss reduction = -884.0646  correctly classified = 75.5250%\n",
      "alpha =  0.661578947368421 b =  -11789.003700276011 epoch =  179  loss = 5881.65  loss reduction = 884.0646  correctly classified = 78.7250%\n",
      "alpha =  0.661578947368421 b =  -12240.4201865918 epoch =  180  loss = 6758.808  loss reduction = -877.1579  correctly classified = 75.5500%\n",
      "alpha =  0.661578947368421 b =  -11803.792636065484 epoch =  181  loss = 5867.837  loss reduction = 890.9714  correctly classified = 78.7750%\n",
      "alpha =  0.661578947368421 b =  -12253.888610802325 epoch =  182  loss = 6744.995  loss reduction = -877.1579  correctly classified = 75.6000%\n",
      "alpha =  0.661578947368421 b =  -11817.261060276009 epoch =  183  loss = 5854.023  loss reduction = 890.9714  correctly classified = 78.8250%\n",
      "alpha =  0.661578947368421 b =  -12262.07498869706 epoch =  184  loss = 6689.741  loss reduction = -835.7173  correctly classified = 75.8000%\n",
      "alpha =  0.661578947368421 b =  -11826.767949749692 epoch =  185  loss = 5840.21  loss reduction = 849.5308  correctly classified = 78.8750%\n",
      "alpha =  0.661578947368421 b =  -12271.581878170744 epoch =  186  loss = 6689.741  loss reduction = -849.5308  correctly classified = 75.8000%\n",
      "alpha =  0.661578947368421 b =  -11836.935095012848 epoch =  187  loss = 5833.303  loss reduction = 856.4376  correctly classified = 78.9000%\n",
      "alpha =  0.661578947368421 b =  -12279.76825606548 epoch =  188  loss = 6682.834  loss reduction = -849.5308  correctly classified = 75.8250%\n",
      "alpha =  0.661578947368421 b =  -11843.140705539163 epoch =  189  loss = 5840.21  loss reduction = 842.6241  correctly classified = 78.8750%\n",
      "alpha =  0.661578947368421 b =  -12286.634122381269 epoch =  190  loss = 6675.927  loss reduction = -835.7173  correctly classified = 75.8500%\n",
      "alpha =  0.661578947368421 b =  -11850.006571854952 epoch =  191  loss = 5840.21  loss reduction = 835.7173  correctly classified = 78.8750%\n",
      "alpha =  0.661578947368421 b =  -12292.17947711811 epoch =  192  loss = 6662.114  loss reduction = -821.9038  correctly classified = 75.9000%\n",
      "alpha =  0.661578947368421 b =  -11854.231415012848 epoch =  193  loss = 5854.023  loss reduction = 808.0903  correctly classified = 78.8250%\n",
      "alpha =  0.661578947368421 b =  -12298.385087644427 epoch =  194  loss = 6669.02  loss reduction = -814.9971  correctly classified = 75.8750%\n",
      "alpha =  0.661578947368421 b =  -11862.417792907585 epoch =  195  loss = 5833.303  loss reduction = 835.7173  correctly classified = 78.9000%\n",
      "alpha =  0.661578947368421 b =  -12304.590698170743 epoch =  196  loss = 6648.3  loss reduction = -814.9971  correctly classified = 75.9500%\n",
      "alpha =  0.661578947368421 b =  -11869.283659223374 epoch =  197  loss = 5840.21  loss reduction = 808.0903  correctly classified = 78.8750%\n",
      "alpha =  0.661578947368421 b =  -12312.116820276005 epoch =  198  loss = 6641.393  loss reduction = -801.1836  correctly classified = 75.9750%\n",
      "alpha =  0.661578947368421 b =  -11875.489269749689 epoch =  199  loss = 5840.21  loss reduction = 801.1836  correctly classified = 78.8750%\n",
      "alpha =  0.661578947368421 b =  -12320.963453960216 epoch =  200  loss = 6655.207  loss reduction = -814.9971  correctly classified = 75.9250%\n",
      "alpha =  0.661578947368421 b =  -11885.656415012847 epoch =  201  loss = 5826.396  loss reduction = 828.8106  correctly classified = 78.9250%\n",
      "alpha =  0.661578947368421 b =  -12326.508808697057 epoch =  202  loss = 6620.673  loss reduction = -794.2768  correctly classified = 76.0500%\n",
      "alpha =  0.661578947368421 b =  -11891.862025539162 epoch =  203  loss = 5805.676  loss reduction = 814.9971  correctly classified = 79.0000%\n",
      "alpha =  0.661578947368421 b =  -12333.374675012847 epoch =  204  loss = 6627.58  loss reduction = -821.9038  correctly classified = 76.0250%\n",
      "alpha =  0.661578947368421 b =  -11899.388147644426 epoch =  205  loss = 5798.769  loss reduction = 828.8106  correctly classified = 79.0250%\n",
      "alpha =  0.661578947368421 b =  -12340.240541328636 epoch =  206  loss = 6620.673  loss reduction = -821.9038  correctly classified = 76.0500%\n",
      "alpha =  0.661578947368421 b =  -11907.574525539163 epoch =  207  loss = 5798.769  loss reduction = 821.9038  correctly classified = 79.0250%\n",
      "alpha =  0.661578947368421 b =  -12346.446151854952 epoch =  208  loss = 6599.953  loss reduction = -801.1836  correctly classified = 76.1250%\n",
      "alpha =  0.661578947368421 b =  -11912.459624486532 epoch =  209  loss = 5784.956  loss reduction = 814.9971  correctly classified = 79.0750%\n",
      "alpha =  0.661578947368421 b =  -12352.651762381269 epoch =  210  loss = 6586.139  loss reduction = -801.1836  correctly classified = 76.1750%\n",
      "alpha =  0.661578947368421 b =  -11918.004979223373 epoch =  211  loss = 5778.049  loss reduction = 808.0903  correctly classified = 79.1000%\n",
      "alpha =  0.661578947368421 b =  -12360.177884486531 epoch =  212  loss = 6606.86  loss reduction = -828.8106  correctly classified = 76.1000%\n",
      "alpha =  0.661578947368421 b =  -11926.851612907583 epoch =  213  loss = 5764.235  loss reduction = 842.6241  correctly classified = 79.1500%\n",
      "alpha =  0.661578947368421 b =  -12367.04375080232 epoch =  214  loss = 6586.139  loss reduction = -821.9038  correctly classified = 76.1750%\n",
      "alpha =  0.661578947368421 b =  -11934.377735012848 epoch =  215  loss = 5743.515  loss reduction = 842.6241  correctly classified = 79.2250%\n",
      "alpha =  0.661578947368421 b =  -12371.268593960216 epoch =  216  loss = 6551.606  loss reduction = -808.0903  correctly classified = 76.3000%\n",
      "alpha =  0.661578947368421 b =  -11942.564112907585 epoch =  217  loss = 5702.075  loss reduction = 849.5308  correctly classified = 79.3750%\n",
      "alpha =  0.661578947368421 b =  -12374.833181328637 epoch =  218  loss = 6517.072  loss reduction = -814.9971  correctly classified = 76.4250%\n",
      "alpha =  0.661578947368421 b =  -11947.449211854953 epoch =  219  loss = 5688.261  loss reduction = 828.8106  correctly classified = 79.4250%\n",
      "alpha =  0.661578947368421 b =  -12366.513164486532 epoch =  220  loss = 6406.564  loss reduction = -718.3025  correctly classified = 76.8250%\n",
      "alpha =  0.661578947368421 b =  -11949.693287644426 epoch =  221  loss = 5674.448  loss reduction = 732.116  correctly classified = 79.4750%\n",
      "alpha =  0.661578947368421 b =  -12356.872636065478 epoch =  222  loss = 6309.869  loss reduction = -635.4214  correctly classified = 77.1750%\n",
      "alpha =  0.661578947368421 b =  -11965.142479223374 epoch =  223  loss = 5522.499  loss reduction = 787.37  correctly classified = 80.0250%\n",
      "alpha =  0.661578947368421 b =  -12306.296248697057 epoch =  224  loss = 5784.956  loss reduction = -262.4567  correctly classified = 79.0750%\n",
      "alpha =  0.661578947368421 b =  -11929.091719223374 epoch =  225  loss = 5425.805  loss reduction = 359.1512  correctly classified = 80.3750%\n",
      "alpha =  0.661578947368421 b =  -12237.892955012847 epoch =  226  loss = 5515.592  loss reduction = -89.78781  correctly classified = 80.0500%\n",
      "alpha =  0.661578947368421 b =  -11891.720447644426 epoch =  227  loss = 5266.949  loss reduction = 248.6432  correctly classified = 80.9500%\n",
      "alpha =  0.661578947368421 b =  -12142.419173960216 epoch =  228  loss = 5184.068  loss reduction = 82.88106  correctly classified = 81.2500%\n",
      "alpha =  0.661578947368421 b =  -11822.656898170742 epoch =  229  loss = 5059.746  loss reduction = 124.3216  correctly classified = 81.7000%\n",
      "alpha =  0.661578947368421 b =  -12011.291580276005 epoch =  230  loss = 4797.29  loss reduction = 262.4567  correctly classified = 82.6500%\n",
      "alpha =  0.661578947368421 b =  -11722.561326591795 epoch =  231  loss = 4956.145  loss reduction = -158.8554  correctly classified = 82.0750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.661578947368421 b =  -11850.452476065479 epoch =  232  loss = 4603.901  loss reduction = 352.2445  correctly classified = 83.3500%\n",
      "alpha =  0.661578947368421 b =  -11621.145243433899 epoch =  233  loss = 4693.688  loss reduction = -89.78781  correctly classified = 83.0250%\n",
      "alpha =  0.661578947368421 b =  -11661.222372907583 epoch =  234  loss = 4417.418  loss reduction = 276.2702  correctly classified = 84.0250%\n",
      "alpha =  0.661578947368421 b =  -11468.229208697057 epoch =  235  loss = 4507.206  loss reduction = -89.78781  correctly classified = 83.7000%\n",
      "alpha =  0.661578947368421 b =  -11421.152573960215 epoch =  236  loss = 4265.47  loss reduction = 241.7364  correctly classified = 84.5750%\n",
      "alpha =  0.661578947368421 b =  -11248.627339223372 epoch =  237  loss = 4389.791  loss reduction = -124.3216  correctly classified = 84.1250%\n",
      "alpha =  0.661578947368421 b =  -11154.012287644426 epoch =  238  loss = 4182.589  loss reduction = 207.2026  correctly classified = 84.8750%\n",
      "alpha =  0.661578947368421 b =  -11023.083167644425 epoch =  239  loss = 4286.19  loss reduction = -103.6013  correctly classified = 84.5000%\n",
      "alpha =  0.661578947368421 b =  -10906.679675012845 epoch =  240  loss = 4217.122  loss reduction = 69.06755  correctly classified = 84.7500%\n",
      "alpha =  0.661578947368421 b =  -10779.712089749688 epoch =  241  loss = 4272.376  loss reduction = -55.25404  correctly classified = 84.5500%\n",
      "alpha =  0.661578947368421 b =  -10663.968852907583 epoch =  242  loss = 4224.029  loss reduction = 48.34728  correctly classified = 84.7250%\n",
      "alpha =  0.661578947368421 b =  -10535.020500276003 epoch =  243  loss = 4251.656  loss reduction = -27.62702  correctly classified = 84.6250%\n",
      "alpha =  0.661578947368421 b =  -10420.597775012846 epoch =  244  loss = 4210.216  loss reduction = 41.44053  correctly classified = 84.7750%\n",
      "alpha =  0.661578947368421 b =  -10289.668655012845 epoch =  245  loss = 4244.749  loss reduction = -34.53377  correctly classified = 84.6500%\n",
      "alpha =  0.661578947368421 b =  -10178.547208697055 epoch =  246  loss = 4161.868  loss reduction = 82.88106  correctly classified = 84.9500%\n",
      "alpha =  0.661578947368421 b =  -10046.957832907581 epoch =  247  loss = 4210.216  loss reduction = -48.34728  correctly classified = 84.7750%\n",
      "alpha =  0.661578947368421 b =  -9936.496642381266 epoch =  248  loss = 4141.148  loss reduction = 69.06755  correctly classified = 85.0250%\n",
      "alpha =  0.661578947368421 b =  -9808.20854553916 epoch =  249  loss = 4189.495  loss reduction = -48.34728  correctly classified = 84.8500%\n",
      "alpha =  0.661578947368421 b =  -9694.446076065477 epoch =  250  loss = 4106.614  loss reduction = 82.88106  correctly classified = 85.1500%\n",
      "alpha =  0.661578947368421 b =  -9566.818235012845 epoch =  251  loss = 4168.775  loss reduction = -62.16079  correctly classified = 84.9250%\n",
      "alpha =  0.661578947368421 b =  -9453.05576553916 epoch =  252  loss = 4092.801  loss reduction = 75.9743  correctly classified = 85.2000%\n",
      "alpha =  0.661578947368421 b =  -9324.767668697055 epoch =  253  loss = 4134.241  loss reduction = -41.44053  correctly classified = 85.0500%\n",
      "alpha =  0.661578947368421 b =  -9210.344943433898 epoch =  254  loss = 4085.894  loss reduction = 48.34728  correctly classified = 85.2250%\n",
      "alpha =  0.661578947368421 b =  -9083.377358170741 epoch =  255  loss = 4106.614  loss reduction = -20.72026  correctly classified = 85.1500%\n",
      "alpha =  0.661578947368421 b =  -8966.313609749688 epoch =  256  loss = 4085.894  loss reduction = 20.72026  correctly classified = 85.2250%\n",
      "alpha =  0.661578947368421 b =  -8841.987047644425 epoch =  257  loss = 4078.987  loss reduction = 6.906755  correctly classified = 85.2500%\n",
      "alpha =  0.661578947368421 b =  -8722.282276065478 epoch =  258  loss = 4044.454  loss reduction = 34.53377  correctly classified = 85.3750%\n",
      "alpha =  0.661578947368421 b =  -8600.59673711811 epoch =  259  loss = 4051.36  loss reduction = -6.906755  correctly classified = 85.3500%\n",
      "alpha =  0.661578947368421 b =  -8481.552221328637 epoch =  260  loss = 4037.547  loss reduction = 13.81351  correctly classified = 85.4000%\n",
      "alpha =  0.661578947368421 b =  -8363.167961328636 epoch =  261  loss = 4016.827  loss reduction = 20.72026  correctly classified = 85.4750%\n",
      "alpha =  0.661578947368421 b =  -8241.482422381268 epoch =  262  loss = 4023.733  loss reduction = -6.906755  correctly classified = 85.4500%\n",
      "alpha =  0.661578947368421 b =  -8123.758418170742 epoch =  263  loss = 3996.106  loss reduction = 27.62702  correctly classified = 85.5500%\n",
      "alpha =  0.661578947368421 b =  -7998.771600276004 epoch =  264  loss = 3989.2  loss reduction = 6.906755  correctly classified = 85.5750%\n",
      "alpha =  0.661578947368421 b =  -7883.028363433899 epoch =  265  loss = 3975.386  loss reduction = 13.81351  correctly classified = 85.6250%\n",
      "alpha =  0.661578947368421 b =  -7758.701801328636 epoch =  266  loss = 3982.293  loss reduction = -6.906755  correctly classified = 85.6000%\n",
      "alpha =  0.661578947368421 b =  -7650.221378170741 epoch =  267  loss = 3927.039  loss reduction = 55.25404  correctly classified = 85.8000%\n",
      "alpha =  0.661578947368421 b =  -7525.234560276004 epoch =  268  loss = 3989.2  loss reduction = -62.16079  correctly classified = 85.5750%\n",
      "alpha =  0.661578947368421 b =  -7416.75413711811 epoch =  269  loss = 3913.225  loss reduction = 75.9743  correctly classified = 85.8500%\n",
      "alpha =  0.661578947368421 b =  -7293.08783080232 epoch =  270  loss = 3975.386  loss reduction = -62.16079  correctly classified = 85.6250%\n",
      "alpha =  0.661578947368421 b =  -7180.645872907583 epoch =  271  loss = 3899.412  loss reduction = 75.9743  correctly classified = 85.9000%\n",
      "alpha =  0.661578947368421 b =  -7062.921868697056 epoch =  272  loss = 3913.225  loss reduction = -13.81351  correctly classified = 85.8500%\n",
      "alpha =  0.661578947368421 b =  -6944.537608697056 epoch =  273  loss = 3920.132  loss reduction = -6.906755  correctly classified = 85.8250%\n",
      "alpha =  0.661578947368421 b =  -6832.755906591793 epoch =  274  loss = 3878.691  loss reduction = 41.44053  correctly classified = 85.9750%\n",
      "alpha =  0.661578947368421 b =  -6712.390879223372 epoch =  275  loss = 3913.225  loss reduction = -34.53377  correctly classified = 85.8500%\n",
      "alpha =  0.661578947368421 b =  -6603.910456065478 epoch =  276  loss = 3871.785  loss reduction = 41.44053  correctly classified = 86.0000%\n",
      "alpha =  0.661578947368421 b =  -6484.20568448653 epoch =  277  loss = 3892.505  loss reduction = -20.72026  correctly classified = 85.9250%\n",
      "alpha =  0.661578947368421 b =  -6377.706028697056 epoch =  278  loss = 3851.064  loss reduction = 41.44053  correctly classified = 86.0750%\n",
      "alpha =  0.661578947368421 b =  -6258.001257118109 epoch =  279  loss = 3892.505  loss reduction = -41.44053  correctly classified = 85.9250%\n",
      "alpha =  0.661578947368421 b =  -6147.540066591793 epoch =  280  loss = 3864.878  loss reduction = 27.62702  correctly classified = 86.0250%\n",
      "alpha =  0.661578947368421 b =  -6031.796829749688 epoch =  281  loss = 3878.691  loss reduction = -13.81351  correctly classified = 85.9750%\n",
      "alpha =  0.661578947368421 b =  -5928.598452907583 epoch =  282  loss = 3816.531  loss reduction = 62.16079  correctly classified = 86.2000%\n",
      "alpha =  0.661578947368421 b =  -5810.214192907583 epoch =  283  loss = 3878.691  loss reduction = -62.16079  correctly classified = 85.9750%\n",
      "alpha =  0.661578947368421 b =  -5701.073513960215 epoch =  284  loss = 3837.251  loss reduction = 41.44053  correctly classified = 86.1250%\n",
      "alpha =  0.661578947368421 b =  -5585.33027711811 epoch =  285  loss = 3864.878  loss reduction = -27.62702  correctly classified = 86.0250%\n",
      "alpha =  0.661578947368421 b =  -5484.1126676444255 epoch =  286  loss = 3781.997  loss reduction = 82.88106  correctly classified = 86.3250%\n",
      "alpha =  0.661578947368421 b =  -5366.388663433899 epoch =  287  loss = 3857.971  loss reduction = -75.9743  correctly classified = 86.0500%\n",
      "alpha =  0.661578947368421 b =  -5262.53003080232 epoch =  288  loss = 3795.81  loss reduction = 62.16079  correctly classified = 86.2750%\n",
      "alpha =  0.661578947368421 b =  -5145.466282381267 epoch =  289  loss = 3851.064  loss reduction = -55.25404  correctly classified = 86.0750%\n",
      "alpha =  0.661578947368421 b =  -5046.2294402760035 epoch =  290  loss = 3788.904  loss reduction = 62.16079  correctly classified = 86.3000%\n",
      "alpha =  0.661578947368421 b =  -4915.300320276004 epoch =  291  loss = 3733.65  loss reduction = 55.25404  correctly classified = 86.5000%\n",
      "alpha =  0.661578947368421 b =  -4823.986547644425 epoch =  292  loss = 3761.277  loss reduction = -27.62702  correctly classified = 86.4000%\n",
      "alpha =  0.661578947368421 b =  -4690.41640448653 epoch =  293  loss = 3719.836  loss reduction = 41.44053  correctly classified = 86.5500%\n",
      "alpha =  0.661578947368421 b =  -4611.647491854951 epoch =  294  loss = 3726.743  loss reduction = -6.906755  correctly classified = 86.5250%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.661578947368421 b =  -4468.833767644424 epoch =  295  loss = 3733.65  loss reduction = -6.906755  correctly classified = 86.5000%\n",
      "alpha =  0.661578947368421 b =  -4420.436621328635 epoch =  296  loss = 3740.556  loss reduction = -6.906755  correctly classified = 86.4750%\n",
      "alpha =  0.661578947368421 b =  -4256.494711854951 epoch =  297  loss = 3788.904  loss reduction = -48.34728  correctly classified = 86.3000%\n",
      "alpha =  0.661578947368421 b =  -4251.674447644425 epoch =  298  loss = 3699.116  loss reduction = 89.78781  correctly classified = 86.6250%\n",
      "alpha =  0.661578947368421 b =  -4052.0787255391615 epoch =  299  loss = 3982.293  loss reduction = -283.1769  correctly classified = 85.6000%\n",
      "alpha =  0.661578947368421 b =  -4154.219899223372 epoch =  300  loss = 3906.318  loss reduction = 75.9743  correctly classified = 85.8750%\n",
      "alpha =  0.661578947368421 b =  -3852.944785539161 epoch =  301  loss = 4534.833  loss reduction = -628.5147  correctly classified = 83.6000%\n",
      "alpha =  0.661578947368421 b =  -4221.82929817074 epoch =  302  loss = 5481.059  loss reduction = -946.2254  correctly classified = 80.1750%\n",
      "alpha =  0.661578947368421 b =  -3696.0672160654767 epoch =  303  loss = 5929.998  loss reduction = -448.9391  correctly classified = 78.5500%\n",
      "alpha =  0.661578947368421 b =  -4681.630636065476 epoch =  304  loss = 11103.16  loss reduction = -5173.159  correctly classified = 59.8250%\n",
      "alpha =  0.661578947368421 b =  -3972.9777002760025 epoch =  305  loss = 7511.644  loss reduction = 3591.512  correctly classified = 72.8250%\n",
      "alpha =  0.661578947368421 b =  -4553.144065539161 epoch =  306  loss = 7166.307  loss reduction = 345.3377  correctly classified = 74.0750%\n",
      "alpha =  0.661578947368421 b =  -3946.1705213286345 epoch =  307  loss = 6572.326  loss reduction = 593.9809  correctly classified = 76.2250%\n",
      "alpha =  0.661578947368421 b =  -4940.977522381266 epoch =  308  loss = 11158.41  loss reduction = -4586.085  correctly classified = 59.6250%\n",
      "alpha =  0.661578947368421 b =  -4241.568167644424 epoch =  309  loss = 7414.95  loss reduction = 3743.461  correctly classified = 73.1750%\n",
      "alpha =  0.661578947368421 b =  -4812.49095185495 epoch =  310  loss = 7097.239  loss reduction = 317.7107  correctly classified = 74.3250%\n",
      "alpha =  0.661578947368421 b =  -4232.5878950128445 epoch =  311  loss = 6358.216  loss reduction = 739.0228  correctly classified = 77.0000%\n",
      "alpha =  0.661578947368421 b =  -5185.13852553916 epoch =  312  loss = 10771.63  loss reduction = -4413.416  correctly classified = 61.0250%\n",
      "alpha =  0.661578947368421 b =  -4498.274030802318 epoch =  313  loss = 7297.535  loss reduction = 3474.098  correctly classified = 73.6000%\n",
      "alpha =  0.661578947368421 b =  -5093.62627922337 epoch =  314  loss = 7325.162  loss reduction = -27.62702  correctly classified = 73.5000%\n",
      "alpha =  0.661578947368421 b =  -4515.043733960212 epoch =  315  loss = 6358.216  loss reduction = 966.9457  correctly classified = 77.0000%\n",
      "alpha =  0.661578947368421 b =  -5412.793133960212 epoch =  316  loss = 10239.81  loss reduction = -3881.596  correctly classified = 62.9500%\n",
      "alpha =  0.661578947368421 b =  -4739.133755012844 epoch =  317  loss = 7173.213  loss reduction = 3066.599  correctly classified = 74.0500%\n",
      "alpha =  0.661578947368421 b =  -5364.197513960212 epoch =  318  loss = 7608.339  loss reduction = -435.1256  correctly classified = 72.4750%\n",
      "alpha =  0.661578947368421 b =  -4780.993178170738 epoch =  319  loss = 6365.123  loss reduction = 1243.216  correctly classified = 76.9750%\n",
      "alpha =  0.661578947368421 b =  -5620.640068697054 epoch =  320  loss = 9659.645  loss reduction = -3294.522  correctly classified = 65.0500%\n",
      "alpha =  0.661578947368421 b =  -4964.807596065475 epoch =  321  loss = 7014.358  loss reduction = 2645.287  correctly classified = 74.6250%\n",
      "alpha =  0.661578947368421 b =  -5681.646909749686 epoch =  322  loss = 8485.497  loss reduction = -1471.139  correctly classified = 69.3000%\n",
      "alpha =  0.661578947368421 b =  -5070.711830802317 epoch =  323  loss = 6599.953  loss reduction = 1885.544  correctly classified = 76.1250%\n",
      "alpha =  0.661578947368421 b =  -5845.653653960212 epoch =  324  loss = 9024.224  loss reduction = -2424.271  correctly classified = 67.3500%\n",
      "alpha =  0.661578947368421 b =  -5217.551924486528 epoch =  325  loss = 6765.715  loss reduction = 2258.509  correctly classified = 75.5250%\n",
      "alpha =  0.661578947368421 b =  -5960.801469749686 epoch =  326  loss = 8761.767  loss reduction = -1996.052  correctly classified = 68.3000%\n",
      "alpha =  0.661578947368421 b =  -5348.545879223369 epoch =  327  loss = 6627.58  loss reduction = 2134.187  correctly classified = 76.0250%\n",
      "alpha =  0.661578947368421 b =  -6073.308262381264 epoch =  328  loss = 8568.378  loss reduction = -1940.798  correctly classified = 69.0000%\n",
      "alpha =  0.661578947368421 b =  -5478.879578170738 epoch =  329  loss = 6454.911  loss reduction = 2113.467  correctly classified = 76.6500%\n",
      "alpha =  0.661578947368421 b =  -6198.359915012843 epoch =  330  loss = 8513.124  loss reduction = -2058.213  correctly classified = 69.2000%\n",
      "alpha =  0.661578947368421 b =  -5611.194044486527 epoch =  331  loss = 6406.564  loss reduction = 2106.56  correctly classified = 76.8250%\n",
      "alpha =  0.661578947368421 b =  -6312.847475012843 epoch =  332  loss = 8326.642  loss reduction = -1920.078  correctly classified = 69.8750%\n",
      "alpha =  0.661578947368421 b =  -5745.489278170737 epoch =  333  loss = 6254.615  loss reduction = 2072.026  correctly classified = 77.3750%\n",
      "alpha =  0.661578947368421 b =  -6427.335035012842 epoch =  334  loss = 8147.066  loss reduction = -1892.451  correctly classified = 70.5250%\n",
      "alpha =  0.661578947368421 b =  -5871.201186591789 epoch =  335  loss = 6151.014  loss reduction = 1996.052  correctly classified = 77.7500%\n",
      "alpha =  0.661578947368421 b =  -6525.316200276 epoch =  336  loss = 7898.423  loss reduction = -1747.409  correctly classified = 71.4250%\n",
      "alpha =  0.661578947368421 b =  -5979.086188697052 epoch =  337  loss = 6047.412  loss reduction = 1851.01  correctly classified = 78.1250%\n",
      "alpha =  0.661578947368421 b =  -6612.073017118105 epoch =  338  loss = 7746.474  loss reduction = -1699.062  correctly classified = 71.9750%\n",
      "alpha =  0.661578947368421 b =  -6077.727609749683 epoch =  339  loss = 5964.531  loss reduction = 1781.943  correctly classified = 78.4250%\n",
      "alpha =  0.661578947368421 b =  -6688.9259971181045 epoch =  340  loss = 7546.178  loss reduction = -1581.647  correctly classified = 72.7000%\n",
      "alpha =  0.661578947368421 b =  -6173.067751854946 epoch =  341  loss = 5867.837  loss reduction = 1678.341  correctly classified = 78.7750%\n",
      "alpha =  0.661578947368421 b =  -6748.612326591789 epoch =  342  loss = 7228.467  loss reduction = -1360.631  correctly classified = 73.8500%\n",
      "alpha =  0.661578947368421 b =  -6264.446359223368 epoch =  343  loss = 5702.075  loss reduction = 1526.393  correctly classified = 79.3750%\n",
      "alpha =  0.661578947368421 b =  -6776.606378170736 epoch =  344  loss = 6662.114  loss reduction = -960.0389  correctly classified = 75.9000%\n",
      "alpha =  0.661578947368421 b =  -6317.530130802315 epoch =  345  loss = 5522.499  loss reduction = 1139.615  correctly classified = 80.0250%\n",
      "alpha =  0.661578947368421 b =  -6809.882476065473 epoch =  346  loss = 6537.792  loss reduction = -1015.293  correctly classified = 76.3500%\n",
      "alpha =  0.661578947368421 b =  -6352.786996065473 epoch =  347  loss = 5501.779  loss reduction = 1036.013  correctly classified = 80.1000%\n",
      "alpha =  0.661578947368421 b =  -6845.139341328631 epoch =  348  loss = 6537.792  loss reduction = -1036.013  correctly classified = 76.3500%\n",
      "alpha =  0.661578947368421 b =  -6389.364372907578 epoch =  349  loss = 5487.965  loss reduction = 1049.827  correctly classified = 80.1500%\n",
      "alpha =  0.661578947368421 b =  -6879.075695012842 epoch =  350  loss = 6510.165  loss reduction = -1022.2  correctly classified = 76.4500%\n",
      "alpha =  0.661578947368421 b =  -6424.621238170736 epoch =  351  loss = 5474.152  loss reduction = 1036.013  correctly classified = 80.2000%\n",
      "alpha =  0.661578947368421 b =  -6905.088979223368 epoch =  352  loss = 6454.911  loss reduction = -980.7592  correctly classified = 76.6500%\n",
      "alpha =  0.661578947368421 b =  -6458.5575918549475 epoch =  353  loss = 5405.084  loss reduction = 1049.827  correctly classified = 80.4500%\n",
      "alpha =  0.661578947368421 b =  -6933.083030802316 epoch =  354  loss = 6392.75  loss reduction = -987.6659  correctly classified = 76.8750%\n",
      "alpha =  0.661578947368421 b =  -6490.513178170737 epoch =  355  loss = 5377.457  loss reduction = 1015.293  correctly classified = 80.5500%\n",
      "alpha =  0.661578947368421 b =  -6953.154012907579 epoch =  356  loss = 6282.242  loss reduction = -904.7849  correctly classified = 77.2750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.661578947368421 b =  -6518.5072297496845 epoch =  357  loss = 5336.017  loss reduction = 946.2254  correctly classified = 80.7000%\n",
      "alpha =  0.661578947368421 b =  -6977.846785539158 epoch =  358  loss = 6247.708  loss reduction = -911.6916  correctly classified = 77.4000%\n",
      "alpha =  0.661578947368421 b =  -6543.860258170737 epoch =  359  loss = 5329.11  loss reduction = 918.5984  correctly classified = 80.7250%\n",
      "alpha =  0.661578947368421 b =  -7001.21904659179 epoch =  360  loss = 6240.802  loss reduction = -911.6916  correctly classified = 77.4250%\n",
      "alpha =  0.661578947368421 b =  -6568.553030802316 epoch =  361  loss = 5329.11  loss reduction = 911.6916  correctly classified = 80.7250%\n",
      "alpha =  0.661578947368421 b =  -7027.89258659179 epoch =  362  loss = 6261.522  loss reduction = -932.4119  correctly classified = 77.3500%\n",
      "alpha =  0.661578947368421 b =  -6595.226570802316 epoch =  363  loss = 5329.11  loss reduction = 932.4119  correctly classified = 80.7250%\n",
      "alpha =  0.661578947368421 b =  -7050.604591854948 epoch =  364  loss = 6220.081  loss reduction = -890.9714  correctly classified = 77.5000%\n",
      "alpha =  0.661578947368421 b =  -6623.220622381264 epoch =  365  loss = 5287.669  loss reduction = 932.4119  correctly classified = 80.8750%\n",
      "alpha =  0.661578947368421 b =  -7077.278131854948 epoch =  366  loss = 6206.268  loss reduction = -918.5984  correctly classified = 77.5500%\n",
      "alpha =  0.661578947368421 b =  -6649.894162381263 epoch =  367  loss = 5287.669  loss reduction = 918.5984  correctly classified = 80.8750%\n",
      "alpha =  0.661578947368421 b =  -7104.6119276444215 epoch =  368  loss = 6213.175  loss reduction = -925.5051  correctly classified = 77.5250%\n",
      "alpha =  0.661578947368421 b =  -6677.227958170737 epoch =  369  loss = 5301.483  loss reduction = 911.6916  correctly classified = 80.8250%\n",
      "alpha =  0.661578947368421 b =  -7131.285467644421 epoch =  370  loss = 6206.268  loss reduction = -904.7849  correctly classified = 77.5500%\n",
      "alpha =  0.661578947368421 b =  -6703.901498170737 epoch =  371  loss = 5315.296  loss reduction = 890.9714  correctly classified = 80.7750%\n",
      "alpha =  0.661578947368421 b =  -7155.317984486526 epoch =  372  loss = 6178.641  loss reduction = -863.3443  correctly classified = 77.6500%\n",
      "alpha =  0.661578947368421 b =  -6729.25452659179 epoch =  373  loss = 5301.483  loss reduction = 877.1579  correctly classified = 80.8250%\n",
      "alpha =  0.661578947368421 b =  -7180.671012907579 epoch =  374  loss = 6178.641  loss reduction = -877.1579  correctly classified = 77.6500%\n",
      "alpha =  0.661578947368421 b =  -6755.267810802316 epoch =  375  loss = 5294.576  loss reduction = 884.0646  correctly classified = 80.8500%\n",
      "alpha =  0.661578947368421 b =  -7203.383018170736 epoch =  376  loss = 6144.107  loss reduction = -849.5308  correctly classified = 77.7750%\n",
      "alpha =  0.661578947368421 b =  -6785.242629749683 epoch =  377  loss = 5260.042  loss reduction = 884.0646  correctly classified = 80.9750%\n",
      "alpha =  0.661578947368421 b =  -7194.402745539157 epoch =  378  loss = 5833.303  loss reduction = -573.2606  correctly classified = 78.9000%\n",
      "alpha =  0.661578947368421 b =  -6800.031565539157 epoch =  379  loss = 5108.094  loss reduction = 725.2093  correctly classified = 81.5250%\n",
      "alpha =  0.661578947368421 b =  -7157.031473960209 epoch =  380  loss = 5481.059  loss reduction = -372.9648  correctly classified = 80.1750%\n",
      "alpha =  0.661578947368421 b =  -6787.089758170735 epoch =  381  loss = 4949.238  loss reduction = 531.8201  correctly classified = 82.1000%\n",
      "alpha =  0.661578947368421 b =  -7097.211505539156 epoch =  382  loss = 5211.695  loss reduction = -262.4567  correctly classified = 81.1500%\n",
      "alpha =  0.661578947368421 b =  -6754.340277118104 epoch =  383  loss = 4790.383  loss reduction = 421.312  correctly classified = 82.6750%\n",
      "alpha =  0.661578947368421 b =  -7014.282584486525 epoch =  384  loss = 4838.73  loss reduction = -48.34728  correctly classified = 82.5000%\n",
      "alpha =  0.661578947368421 b =  -6695.180564486524 epoch =  385  loss = 4652.248  loss reduction = 186.4824  correctly classified = 83.1750%\n",
      "alpha =  0.661578947368421 b =  -6899.001129749682 epoch =  386  loss = 4445.045  loss reduction = 207.2026  correctly classified = 83.9250%\n",
      "alpha =  0.661578947368421 b =  -6633.3798286970505 epoch =  387  loss = 4355.258  loss reduction = 89.78781  correctly classified = 84.2500%\n",
      "alpha =  0.661578947368421 b =  -6743.444071854945 epoch =  388  loss = 3989.2  loss reduction = 366.058  correctly classified = 85.5750%\n",
      "alpha =  0.661578947368421 b =  -6522.720164486524 epoch =  389  loss = 4078.987  loss reduction = -89.78781  correctly classified = 85.2500%\n",
      "alpha =  0.661578947368421 b =  -6542.329364486523 epoch =  390  loss = 3747.463  loss reduction = 331.5242  correctly classified = 86.4500%\n",
      "alpha =  0.661578947368421 b =  -6374.425920275997 epoch =  391  loss = 3871.785  loss reduction = -124.3216  correctly classified = 86.0000%\n",
      "alpha =  0.661578947368421 b =  -6313.483913960207 epoch =  392  loss = 3650.769  loss reduction = 221.0162  correctly classified = 86.8000%\n",
      "alpha =  0.661578947368421 b =  -6178.593259223365 epoch =  393  loss = 3871.785  loss reduction = -221.0162  correctly classified = 86.0000%\n",
      "alpha =  0.661578947368421 b =  -6096.523067644417 epoch =  394  loss = 3692.209  loss reduction = 179.5756  correctly classified = 86.6500%\n",
      "alpha =  0.661578947368421 b =  -5968.895226591785 epoch =  395  loss = 3823.437  loss reduction = -131.2283  correctly classified = 86.1750%\n",
      "alpha =  0.661578947368421 b =  -5872.9596634338905 epoch =  396  loss = 3768.183  loss reduction = 55.25404  correctly classified = 86.3750%\n",
      "alpha =  0.661578947368421 b =  -5755.895915012838 epoch =  397  loss = 3754.37  loss reduction = 13.81351  correctly classified = 86.4250%\n",
      "alpha =  0.661578947368421 b =  -5649.396259223364 epoch =  398  loss = 3768.183  loss reduction = -13.81351  correctly classified = 86.3750%\n",
      "alpha =  0.661578947368421 b =  -5519.787650802311 epoch =  399  loss = 3650.769  loss reduction = 117.4148  correctly classified = 86.8000%\n",
      "alpha =  0.661578947368421 b =  -5421.2110644865215 epoch =  400  loss = 3754.37  loss reduction = -103.6013  correctly classified = 86.4250%\n",
      "alpha =  0.661578947368421 b =  -5296.884502381258 epoch =  401  loss = 3636.955  loss reduction = 117.4148  correctly classified = 86.8500%\n",
      "alpha =  0.661578947368421 b =  -5181.141265539153 epoch =  402  loss = 3616.235  loss reduction = 20.72026  correctly classified = 86.9250%\n",
      "alpha =  0.661578947368421 b =  -5059.455726591785 epoch =  403  loss = 3623.142  loss reduction = -6.906755  correctly classified = 86.9000%\n",
      "alpha =  0.661578947368421 b =  -4938.43044343389 epoch =  404  loss = 3616.235  loss reduction = 6.906755  correctly classified = 86.9250%\n",
      "alpha =  0.661578947368421 b =  -4818.725671854942 epoch =  405  loss = 3602.421  loss reduction = 13.81351  correctly classified = 86.9750%\n",
      "alpha =  0.661578947368421 b =  -4697.700388697048 epoch =  406  loss = 3588.608  loss reduction = 13.81351  correctly classified = 87.0250%\n",
      "alpha =  0.661578947368421 b =  -4576.014849749679 epoch =  407  loss = 3581.701  loss reduction = 6.906755  correctly classified = 87.0500%\n",
      "alpha =  0.661578947368421 b =  -4458.2908455391525 epoch =  408  loss = 3581.701  loss reduction = 0.0  correctly classified = 87.0500%\n",
      "alpha =  0.6821052631578948 b =  -4332.829860275994 epoch =  0  loss = 3581.701  loss reduction = 0.0  correctly classified = 87.0500%\n",
      "alpha =  0.7026315789473684 b =  -4213.4105971181 epoch =  0  loss = 3540.26  loss reduction = 41.44053  correctly classified = 87.2000%\n",
      "alpha =  0.7026315789473684 b =  -4079.9668076444154 epoch =  1  loss = 3581.701  loss reduction = -41.44053  correctly classified = 87.0500%\n",
      "alpha =  0.7026315789473684 b =  -3994.9076339602047 epoch =  2  loss = 3478.1  loss reduction = 103.6013  correctly classified = 87.4250%\n",
      "alpha =  0.7026315789473684 b =  -3841.1282813286257 epoch =  3  loss = 3657.675  loss reduction = -179.5756  correctly classified = 86.7750%\n",
      "alpha =  0.7026315789473684 b =  -3771.4960865917838 epoch =  4  loss = 3436.659  loss reduction = 221.0162  correctly classified = 87.5750%\n",
      "alpha =  0.7026315789473684 b =  -3619.1191865917835 epoch =  5  loss = 3657.675  loss reduction = -221.0162  correctly classified = 86.7750%\n",
      "alpha =  0.7026315789473684 b =  -3550.188218170731 epoch =  6  loss = 3429.752  loss reduction = 227.9229  correctly classified = 87.6000%\n",
      "alpha =  0.7026315789473684 b =  -3399.21377080231 epoch =  7  loss = 3657.675  loss reduction = -227.9229  correctly classified = 86.7750%\n",
      "alpha =  0.7026315789473684 b =  -3326.77667080231 epoch =  8  loss = 3409.032  loss reduction = 248.6432  correctly classified = 87.6750%\n",
      "alpha =  0.7026315789473684 b =  -3177.204676065468 epoch =  9  loss = 3643.862  loss reduction = -234.8297  correctly classified = 86.8250%\n",
      "alpha =  0.7026315789473684 b =  -3104.0663497496785 epoch =  10  loss = 3388.312  loss reduction = 255.5499  correctly classified = 87.7500%\n",
      "alpha =  0.7026315789473684 b =  -2960.8053918549417 epoch =  11  loss = 3595.514  loss reduction = -207.2026  correctly classified = 87.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.7026315789473684 b =  -2877.8498971180998 epoch =  12  loss = 3415.939  loss reduction = 179.5756  correctly classified = 87.6500%\n",
      "alpha =  0.7026315789473684 b =  -2733.8877129075736 epoch =  13  loss = 3588.608  loss reduction = -172.6689  correctly classified = 87.0250%\n",
      "alpha =  0.7026315789473684 b =  -2657.9444813286264 epoch =  14  loss = 3374.498  loss reduction = 214.1094  correctly classified = 87.8000%\n",
      "alpha =  0.7026315789473684 b =  -2513.2810708023108 epoch =  15  loss = 3581.701  loss reduction = -207.2026  correctly classified = 87.0500%\n",
      "alpha =  0.7026315789473684 b =  -2435.234160275995 epoch =  16  loss = 3381.405  loss reduction = 200.2959  correctly classified = 87.7750%\n",
      "alpha =  0.7026315789473684 b =  -2294.0768813286263 epoch =  17  loss = 3547.167  loss reduction = -165.7621  correctly classified = 87.1750%\n",
      "alpha =  0.7026315789473684 b =  -2212.523839223363 epoch =  18  loss = 3388.312  loss reduction = 158.8554  correctly classified = 87.7500%\n",
      "alpha =  0.7026315789473684 b =  -2074.872691854942 epoch =  19  loss = 3512.633  loss reduction = -124.3216  correctly classified = 87.3000%\n",
      "alpha =  0.7026315789473684 b =  -1991.9171971180997 epoch =  20  loss = 3374.498  loss reduction = 138.1351  correctly classified = 87.8000%\n",
      "alpha =  0.7026315789473684 b =  -1864.0832181707312 epoch =  21  loss = 3457.379  loss reduction = -82.88106  correctly classified = 87.5000%\n",
      "alpha =  0.7026315789473684 b =  -1780.4264971180996 epoch =  22  loss = 3367.592  loss reduction = 89.78781  correctly classified = 87.8250%\n",
      "alpha =  0.7026315789473684 b =  -1645.5802550128365 epoch =  23  loss = 3471.193  loss reduction = -103.6013  correctly classified = 87.4500%\n",
      "alpha =  0.7026315789473684 b =  -1562.6247602759943 epoch =  24  loss = 3360.685  loss reduction = 110.5081  correctly classified = 87.8500%\n",
      "alpha =  0.7026315789473684 b =  -1431.985876065468 epoch =  25  loss = 3443.566  loss reduction = -82.88106  correctly classified = 87.5500%\n",
      "alpha =  0.7026315789473684 b =  -1350.4328339602048 epoch =  26  loss = 3346.871  loss reduction = 96.69457  correctly classified = 87.9000%\n",
      "alpha =  0.7026315789473684 b =  -1216.9890444865205 epoch =  27  loss = 3415.939  loss reduction = -69.06755  correctly classified = 87.6500%\n",
      "alpha =  0.7026315789473684 b =  -1140.3445865917836 epoch =  28  loss = 3312.338  loss reduction = 103.6013  correctly classified = 88.0250%\n",
      "alpha =  0.7026315789473684 b =  -1011.1081550128362 epoch =  29  loss = 3388.312  loss reduction = -75.9743  correctly classified = 87.7500%\n",
      "alpha =  0.7026315789473684 b =  -934.4636971180993 epoch =  30  loss = 3312.338  loss reduction = 75.9743  correctly classified = 88.0250%\n",
      "alpha =  0.7026315789473684 b =  -800.3186813286256 epoch =  31  loss = 3381.405  loss reduction = -69.06755  correctly classified = 87.7750%\n",
      "alpha =  0.7026315789473684 b =  -739.8024286970467 epoch =  32  loss = 3222.55  loss reduction = 158.8554  correctly classified = 88.3500%\n",
      "alpha =  0.7026315789473684 b =  -599.3463760654678 epoch =  33  loss = 3415.939  loss reduction = -193.3891  correctly classified = 87.6500%\n",
      "alpha =  0.7026315789473684 b =  -550.0497444865204 epoch =  34  loss = 3167.296  loss reduction = 248.6432  correctly classified = 88.5500%\n",
      "alpha =  0.7026315789473684 b =  -413.0998234338888 epoch =  35  loss = 3395.219  loss reduction = -227.9229  correctly classified = 87.7250%\n",
      "alpha =  0.7026315789473684 b =  -363.10196553915193 epoch =  36  loss = 3174.202  loss reduction = 221.0162  correctly classified = 88.5250%\n",
      "alpha =  0.7026315789473684 b =  -223.3471392233624 epoch =  37  loss = 3395.219  loss reduction = -221.0162  correctly classified = 87.7250%\n",
      "alpha =  0.7026315789473684 b =  -177.55663922336237 epoch =  38  loss = 3160.389  loss reduction = 234.8297  correctly classified = 88.5750%\n",
      "alpha =  0.7026315789473684 b =  -37.10058659178341 epoch =  39  loss = 3402.125  loss reduction = -241.7364  correctly classified = 87.7000%\n",
      "alpha =  0.7026315789473684 b =  5.18378182926925 epoch =  40  loss = 3167.296  loss reduction = 234.8297  correctly classified = 88.5500%\n",
      "alpha =  0.7026315789473684 b =  148.44473972400613 epoch =  41  loss = 3402.125  loss reduction = -234.8297  correctly classified = 87.7000%\n",
      "alpha =  0.7026315789473684 b =  168.99109235558512 epoch =  42  loss = 3201.829  loss reduction = 200.2959  correctly classified = 88.4250%\n",
      "alpha =  0.7026315789473684 b =  331.8863870924273 epoch =  43  loss = 3457.379  loss reduction = -255.5499  correctly classified = 87.5000%\n",
      "alpha =  0.7026315789473684 b =  291.4260502503221 epoch =  44  loss = 3250.177  loss reduction = 207.2026  correctly classified = 88.2500%\n",
      "alpha =  0.7026315789473684 b =  522.3402976187432 epoch =  45  loss = 3754.37  loss reduction = -504.1931  correctly classified = 86.4250%\n",
      "alpha =  0.7026315789473684 b =  322.7015870924274 epoch =  46  loss = 3961.572  loss reduction = -207.2026  correctly classified = 85.6750%\n",
      "alpha =  0.7026315789473684 b =  698.0684555134801 epoch =  47  loss = 4652.248  loss reduction = -690.6755  correctly classified = 83.1750%\n",
      "alpha =  0.7026315789473684 b =  49.6449028819012 epoch =  48  loss = 7221.561  loss reduction = -2569.313  correctly classified = 73.8750%\n",
      "alpha =  0.7026315789473684 b =  713.2157870924276 epoch =  49  loss = 6731.181  loss reduction = 490.3796  correctly classified = 75.6500%\n",
      "alpha =  0.7026315789473684 b =  -393.10854974967776 epoch =  50  loss = 11455.4  loss reduction = -4724.22  correctly classified = 58.5500%\n",
      "alpha =  0.7026315789473684 b =  367.2315660397959 epoch =  51  loss = 7559.992  loss reduction = 3895.41  correctly classified = 72.6500%\n",
      "alpha =  0.7026315789473684 b =  -239.11840764441456 epoch =  52  loss = 6876.223  loss reduction = 683.7687  correctly classified = 75.1250%\n",
      "alpha =  0.7026315789473684 b =  383.0801239345328 epoch =  53  loss = 6351.31  loss reduction = 524.9134  correctly classified = 77.0250%\n",
      "alpha =  0.7026315789473684 b =  -668.5485602759934 epoch =  54  loss = 10930.49  loss reduction = -4579.178  correctly classified = 60.4500%\n",
      "alpha =  0.7026315789473684 b =  77.06580288190128 epoch =  55  loss = 7456.39  loss reduction = 3474.098  correctly classified = 73.0250%\n",
      "alpha =  0.7026315789473684 b =  -546.8148286970461 epoch =  56  loss = 7035.078  loss reduction = 421.312  correctly classified = 74.5500%\n",
      "alpha =  0.7026315789473684 b =  64.8653081450592 epoch =  57  loss = 6247.708  loss reduction = 787.37  correctly classified = 77.4000%\n",
      "alpha =  0.7026315789473684 b =  -937.6775339602038 epoch =  58  loss = 10502.27  loss reduction = -4254.561  correctly classified = 62.0000%\n",
      "alpha =  0.7026315789473684 b =  -210.2950550128354 epoch =  59  loss = 7290.628  loss reduction = 3211.641  correctly classified = 73.6250%\n",
      "alpha =  0.7026315789473684 b =  -865.0296444865195 epoch =  60  loss = 7311.349  loss reduction = -20.72026  correctly classified = 73.5500%\n",
      "alpha =  0.7026315789473684 b =  -252.64828132862476 epoch =  61  loss = 6254.615  loss reduction = 1056.733  correctly classified = 77.3750%\n",
      "alpha =  0.7026315789473684 b =  -1186.4709444865193 epoch =  62  loss = 9866.848  loss reduction = -3612.233  correctly classified = 64.3000%\n",
      "alpha =  0.7026315789473684 b =  -476.6191234338877 epoch =  63  loss = 7131.773  loss reduction = 2735.075  correctly classified = 74.2000%\n",
      "alpha =  0.7026315789473684 b =  -1211.2935129075718 epoch =  64  loss = 8057.278  loss reduction = -925.5051  correctly classified = 70.8500%\n",
      "alpha =  0.7026315789473684 b =  -569.4606444865192 epoch =  65  loss = 6530.885  loss reduction = 1526.393  correctly classified = 76.3750%\n",
      "alpha =  0.7026315789473684 b =  -1448.587655012835 epoch =  66  loss = 9383.375  loss reduction = -2852.49  correctly classified = 66.0500%\n",
      "alpha =  0.7026315789473684 b =  -760.4738497496772 epoch =  67  loss = 6931.477  loss reduction = 2451.898  correctly classified = 74.9250%\n",
      "alpha =  0.7026315789473684 b =  -1537.2218181707299 epoch =  68  loss = 8416.429  loss reduction = -1484.952  correctly classified = 69.5500%\n",
      "alpha =  0.7026315789473684 b =  -894.6877234338878 epoch =  69  loss = 6537.792  loss reduction = 1878.637  correctly classified = 76.3500%\n",
      "alpha =  0.7026315789473684 b =  -1708.6006865917825 epoch =  70  loss = 8754.86  loss reduction = -2217.068  correctly classified = 68.3250%\n",
      "alpha =  0.7026315789473684 b =  -1056.2494234338878 epoch =  71  loss = 6634.487  loss reduction = 2120.374  correctly classified = 76.0000%\n",
      "alpha =  0.7026315789473684 b =  -1843.5157865917827 epoch =  72  loss = 8520.031  loss reduction = -1885.544  correctly classified = 69.1750%\n",
      "alpha =  0.7026315789473684 b =  -1210.7988602759933 epoch =  73  loss = 6454.911  loss reduction = 2065.12  correctly classified = 76.6500%\n",
      "alpha =  0.7026315789473684 b =  -1993.8578655391511 epoch =  74  loss = 8492.404  loss reduction = -2037.493  correctly classified = 69.2750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.7026315789473684 b =  -1371.6593339602036 epoch =  75  loss = 6351.31  loss reduction = 2141.094  correctly classified = 77.0250%\n",
      "alpha =  0.7026315789473684 b =  -2130.8766444865196 epoch =  76  loss = 8271.387  loss reduction = -1920.078  correctly classified = 70.0750%\n",
      "alpha =  0.7026315789473684 b =  -1520.5989602759932 epoch =  77  loss = 6247.708  loss reduction = 2023.679  correctly classified = 77.4000%\n",
      "alpha =  0.7026315789473684 b =  -2253.8708971180986 epoch =  78  loss = 8071.092  loss reduction = -1823.383  correctly classified = 70.8000%\n",
      "alpha =  0.7026315789473684 b =  -1664.6300023812564 epoch =  79  loss = 6109.573  loss reduction = 1961.518  correctly classified = 77.9000%\n",
      "alpha =  0.7026315789473684 b =  -2352.322228697046 epoch =  80  loss = 7663.593  loss reduction = -1554.02  correctly classified = 72.2750%\n",
      "alpha =  0.7026315789473684 b =  -1786.9230286970458 epoch =  81  loss = 5888.557  loss reduction = 1775.036  correctly classified = 78.7000%\n",
      "alpha =  0.7026315789473684 b =  -2417.1146971180983 epoch =  82  loss = 7152.493  loss reduction = -1263.936  correctly classified = 74.1250%\n",
      "alpha =  0.7026315789473684 b =  -1890.2829444865192 epoch =  83  loss = 5619.194  loss reduction = 1533.3  correctly classified = 79.6750%\n",
      "alpha =  0.7026315789473684 b =  -2484.010844486519 epoch =  84  loss = 6820.969  loss reduction = -1201.775  correctly classified = 75.3250%\n",
      "alpha =  0.7026315789473684 b =  -1981.0207865917823 epoch =  85  loss = 5467.245  loss reduction = 1353.724  correctly classified = 80.2250%\n",
      "alpha =  0.7026315789473684 b =  -2529.1689760654663 epoch =  86  loss = 6496.351  loss reduction = -1029.106  correctly classified = 76.5000%\n",
      "alpha =  0.7026315789473684 b =  -2047.2157076444137 epoch =  87  loss = 5370.55  loss reduction = 1125.801  correctly classified = 80.5750%\n",
      "alpha =  0.7026315789473684 b =  -2575.7295602759928 epoch =  88  loss = 6316.776  loss reduction = -946.2254  correctly classified = 77.1500%\n",
      "alpha =  0.7026315789473684 b =  -2097.983649749677 epoch =  89  loss = 5342.923  loss reduction = 973.8524  correctly classified = 80.6750%\n",
      "alpha =  0.7026315789473684 b =  -2622.2901444865192 epoch =  90  loss = 6275.335  loss reduction = -932.4119  correctly classified = 77.3000%\n",
      "alpha =  0.7026315789473684 b =  -2145.9466865917825 epoch =  91  loss = 5329.11  loss reduction = 946.2254  correctly classified = 80.7250%\n",
      "alpha =  0.7026315789473684 b =  -2670.2531813286246 epoch =  92  loss = 6275.335  loss reduction = -946.2254  correctly classified = 77.3000%\n",
      "alpha =  0.7026315789473684 b =  -2195.3121760654667 epoch =  93  loss = 5329.11  loss reduction = 946.2254  correctly classified = 80.7250%\n",
      "alpha =  0.7026315789473684 b =  -2720.319897118098 epoch =  94  loss = 6282.242  loss reduction = -953.1322  correctly classified = 77.2750%\n",
      "alpha =  0.7026315789473684 b =  -2246.0801181707297 epoch =  95  loss = 5322.203  loss reduction = 960.0389  correctly classified = 80.7500%\n",
      "alpha =  0.7026315789473684 b =  -2771.7890655391507 epoch =  96  loss = 6289.149  loss reduction = -966.9457  correctly classified = 77.2500%\n",
      "alpha =  0.7026315789473684 b =  -2300.35419185494 epoch =  97  loss = 5280.763  loss reduction = 1008.386  correctly classified = 80.9000%\n",
      "alpha =  0.7026315789473684 b =  -2805.727576065466 epoch =  98  loss = 6171.734  loss reduction = -890.9714  correctly classified = 77.6750%\n",
      "alpha =  0.7026315789473684 b =  -2345.512323433887 epoch =  99  loss = 5211.695  loss reduction = 960.0389  correctly classified = 81.1500%\n",
      "alpha =  0.7026315789473684 b =  -2841.7697655391503 epoch =  100  loss = 6081.946  loss reduction = -870.2511  correctly classified = 78.0000%\n",
      "alpha =  0.7026315789473684 b =  -2388.566776065466 epoch =  101  loss = 5184.068  loss reduction = 897.8781  correctly classified = 81.2500%\n",
      "alpha =  0.7026315789473684 b =  -2876.409502381255 epoch =  102  loss = 6068.133  loss reduction = -884.0646  correctly classified = 78.0500%\n",
      "alpha =  0.7026315789473684 b =  -2421.804060275992 epoch =  103  loss = 5184.068  loss reduction = 884.0646  correctly classified = 81.2500%\n",
      "alpha =  0.7026315789473684 b =  -2909.646786591781 epoch =  104  loss = 6068.133  loss reduction = -884.0646  correctly classified = 78.0500%\n",
      "alpha =  0.7026315789473684 b =  -2455.7425708023075 epoch =  105  loss = 5177.161  loss reduction = 890.9714  correctly classified = 81.2750%\n",
      "alpha =  0.7026315789473684 b =  -2942.1828444865178 epoch =  106  loss = 6040.506  loss reduction = -863.3443  correctly classified = 78.1500%\n",
      "alpha =  0.7026315789473684 b =  -2488.9798550128335 epoch =  107  loss = 5170.255  loss reduction = 870.2511  correctly classified = 81.3000%\n",
      "alpha =  0.7026315789473684 b =  -2974.017676065465 epoch =  108  loss = 6040.506  loss reduction = -870.2511  correctly classified = 78.1500%\n",
      "alpha =  0.7026315789473684 b =  -2520.8146865917806 epoch =  109  loss = 5170.255  loss reduction = 870.2511  correctly classified = 81.3000%\n",
      "alpha =  0.7026315789473684 b =  -3005.852507644412 epoch =  110  loss = 6040.506  loss reduction = -870.2511  correctly classified = 78.1500%\n",
      "alpha =  0.7026315789473684 b =  -2554.753197118096 epoch =  111  loss = 5177.161  loss reduction = 863.3443  correctly classified = 81.2750%\n",
      "alpha =  0.7026315789473684 b =  -3023.66281290757 epoch =  112  loss = 5936.904  loss reduction = -759.743  correctly classified = 78.5250%\n",
      "alpha =  0.7026315789473684 b =  -2583.7831234338855 epoch =  113  loss = 5121.907  loss reduction = 814.9971  correctly classified = 81.4750%\n",
      "alpha =  0.7026315789473684 b =  -3043.576797118096 epoch =  114  loss = 5860.93  loss reduction = -739.0228  correctly classified = 78.8000%\n",
      "alpha =  0.7026315789473684 b =  -2614.9167286970433 epoch =  115  loss = 5066.653  loss reduction = 794.2768  correctly classified = 81.6750%\n",
      "alpha =  0.7026315789473684 b =  -3057.8809708023064 epoch =  116  loss = 5708.981  loss reduction = -642.3282  correctly classified = 79.3500%\n",
      "alpha =  0.7026315789473684 b =  -2638.336844486517 epoch =  117  loss = 4976.865  loss reduction = 732.116  correctly classified = 82.0000%\n",
      "alpha =  0.7026315789473684 b =  -3047.642223433885 epoch =  118  loss = 5460.338  loss reduction = -483.4728  correctly classified = 80.2500%\n",
      "alpha =  0.7026315789473684 b =  -2649.13488659178 epoch =  119  loss = 4893.984  loss reduction = 566.3539  correctly classified = 82.3000%\n",
      "alpha =  0.7026315789473684 b =  -3019.872818170727 epoch =  120  loss = 5204.788  loss reduction = -310.804  correctly classified = 81.1750%\n",
      "alpha =  0.7026315789473684 b =  -2645.9084023812534 epoch =  121  loss = 4693.688  loss reduction = 511.0999  correctly classified = 83.0250%\n",
      "alpha =  0.7026315789473684 b =  -2962.651907644411 epoch =  122  loss = 4811.103  loss reduction = -117.4148  correctly classified = 82.6000%\n",
      "alpha =  0.7026315789473684 b =  -2619.541449749674 epoch =  123  loss = 4486.486  loss reduction = 324.6175  correctly classified = 83.7750%\n",
      "alpha =  0.7026315789473684 b =  -2856.345155012832 epoch =  124  loss = 4300.003  loss reduction = 186.4824  correctly classified = 84.4500%\n",
      "alpha =  0.7026315789473684 b =  -2560.21686027599 epoch =  125  loss = 4189.495  loss reduction = 110.5081  correctly classified = 84.8500%\n",
      "alpha =  0.7026315789473684 b =  -2694.6415234338847 epoch =  126  loss = 3761.277  loss reduction = 428.2188  correctly classified = 86.4000%\n",
      "alpha =  0.7026315789473684 b =  -2461.623597118095 epoch =  127  loss = 3927.039  loss reduction = -165.7621  correctly classified = 85.8000%\n",
      "alpha =  0.7026315789473684 b =  -2505.5900655391474 epoch =  128  loss = 3505.727  loss reduction = 421.312  correctly classified = 87.3250%\n",
      "alpha =  0.7026315789473684 b =  -2330.0726971180948 epoch =  129  loss = 3567.887  loss reduction = -62.16079  correctly classified = 87.1000%\n",
      "alpha =  0.7026315789473684 b =  -2277.2699339602 epoch =  130  loss = 3326.151  loss reduction = 241.7364  correctly classified = 87.9750%\n",
      "alpha =  0.7026315789473684 b =  -2139.618786591779 epoch =  131  loss = 3498.82  loss reduction = -172.6689  correctly classified = 87.3500%\n",
      "alpha =  0.7026315789473684 b =  -2054.5596129075684 epoch =  132  loss = 3326.151  loss reduction = 172.6689  correctly classified = 87.9750%\n",
      "alpha =  0.7026315789473684 b =  -1913.4023339602 epoch =  133  loss = 3478.1  loss reduction = -151.9486  correctly classified = 87.4250%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.7026315789473684 b =  -1831.1480655391472 epoch =  134  loss = 3312.338  loss reduction = 165.7621  correctly classified = 88.0250%\n",
      "alpha =  0.7026315789473684 b =  -1688.5883339601999 epoch =  135  loss = 3478.1  loss reduction = -165.7621  correctly classified = 87.4250%\n",
      "alpha =  0.7026315789473684 b =  -1606.334065539147 epoch =  136  loss = 3312.338  loss reduction = 165.7621  correctly classified = 88.0250%\n",
      "alpha =  0.7026315789473684 b =  -1463.7743339601998 epoch =  137  loss = 3478.1  loss reduction = -165.7621  correctly classified = 87.4250%\n",
      "alpha =  0.7026315789473684 b =  -1380.1176129075682 epoch =  138  loss = 3298.524  loss reduction = 179.5756  correctly classified = 88.0750%\n",
      "alpha =  0.7026315789473684 b =  -1243.8689181707261 epoch =  139  loss = 3429.752  loss reduction = -131.2283  correctly classified = 87.6000%\n",
      "alpha =  0.7026315789473684 b =  -1155.3036129075683 epoch =  140  loss = 3291.617  loss reduction = 138.1351  correctly classified = 88.1000%\n",
      "alpha =  0.7026315789473684 b =  -1024.664728697042 epoch =  141  loss = 3374.498  loss reduction = -82.88106  correctly classified = 87.8000%\n",
      "alpha =  0.7026315789473684 b =  -935.3981971180946 epoch =  142  loss = 3270.897  loss reduction = 103.6013  correctly classified = 88.1750%\n",
      "alpha =  0.7026315789473684 b =  -805.4605392233577 epoch =  143  loss = 3381.405  loss reduction = -110.5081  correctly classified = 87.7750%\n",
      "alpha =  0.7026315789473684 b =  -715.4927813286208 epoch =  144  loss = 3263.99  loss reduction = 117.4148  correctly classified = 88.2000%\n",
      "alpha =  0.7026315789473684 b =  -586.2563497496734 epoch =  145  loss = 3374.498  loss reduction = -110.5081  correctly classified = 87.8000%\n",
      "alpha =  0.7026315789473684 b =  -497.69104448651547 epoch =  146  loss = 3263.99  loss reduction = 110.5081  correctly classified = 88.2000%\n",
      "alpha =  0.7026315789473684 b =  -364.2472550128312 epoch =  147  loss = 3360.685  loss reduction = -96.69457  correctly classified = 87.8500%\n",
      "alpha =  0.7026315789473684 b =  -277.08440238125223 epoch =  148  loss = 3250.177  loss reduction = 110.5081  correctly classified = 88.2500%\n",
      "alpha =  0.7026315789473684 b =  -150.65287606546272 epoch =  149  loss = 3360.685  loss reduction = -110.5081  correctly classified = 87.8500%\n",
      "alpha =  0.7026315789473684 b =  -55.77653396019953 epoch =  150  loss = 3243.27  loss reduction = 117.4148  correctly classified = 88.2750%\n",
      "alpha =  0.7026315789473684 b =  64.34395551348469 epoch =  151  loss = 3312.338  loss reduction = -69.06755  correctly classified = 88.0250%\n",
      "alpha =  0.7026315789473684 b =  162.02520288190578 epoch =  152  loss = 3243.27  loss reduction = 69.06755  correctly classified = 88.2750%\n",
      "alpha =  0.7026315789473684 b =  274.4322028819058 epoch =  153  loss = 3250.177  loss reduction = -6.906755  correctly classified = 88.2500%\n",
      "alpha =  0.7026315789473684 b =  379.82693972401114 epoch =  154  loss = 3277.804  loss reduction = -27.62702  correctly classified = 88.1500%\n",
      "alpha =  0.7026315789473684 b =  491.5327134082217 epoch =  155  loss = 3243.27  loss reduction = 34.53377  correctly classified = 88.2750%\n",
      "alpha =  0.7026315789473684 b =  599.7323555134849 epoch =  156  loss = 3236.363  loss reduction = 6.906755  correctly classified = 88.3000%\n",
      "alpha =  0.7026315789473684 b =  706.5295449871692 epoch =  157  loss = 3236.363  loss reduction = 0.0  correctly classified = 88.3000%\n",
      "alpha =  0.7231578947368421 b =  815.7249407766429 epoch =  0  loss = 3243.27  loss reduction = -6.906755  correctly classified = 88.2750%\n",
      "alpha =  0.7231578947368421 b =  927.0854713029588 epoch =  1  loss = 3222.55  loss reduction = 20.72026  correctly classified = 88.3500%\n",
      "alpha =  0.7231578947368421 b =  1037.00257867138 epoch =  2  loss = 3236.363  loss reduction = -13.81351  correctly classified = 88.3000%\n",
      "alpha =  0.7231578947368421 b =  1148.3631091976958 epoch =  3  loss = 3222.55  loss reduction = 13.81351  correctly classified = 88.3500%\n",
      "alpha =  0.7231578947368421 b =  1259.7236397240117 epoch =  4  loss = 3222.55  loss reduction = 0.0  correctly classified = 88.3500%\n",
      "alpha =  0.7436842105263157 b =  1374.24505867138 epoch =  0  loss = 3222.55  loss reduction = 0.0  correctly classified = 88.3500%\n",
      "alpha =  0.7642105263157895 b =  1491.164683934538 epoch =  0  loss = 3229.456  loss reduction = -6.906755  correctly classified = 88.3250%\n",
      "alpha =  0.7642105263157895 b =  1607.321627092433 epoch =  1  loss = 3222.55  loss reduction = 6.906755  correctly classified = 88.3500%\n",
      "alpha =  0.7642105263157895 b =  1724.2412523555909 epoch =  2  loss = 3229.456  loss reduction = -6.906755  correctly classified = 88.3250%\n",
      "alpha =  0.7642105263157895 b =  1841.1608776187488 epoch =  3  loss = 3201.829  loss reduction = 27.62702  correctly classified = 88.4250%\n",
      "alpha =  0.7642105263157895 b =  1956.5551386713805 epoch =  4  loss = 3201.829  loss reduction = 0.0  correctly classified = 88.4250%\n",
      "alpha =  0.7847368421052632 b =  2073.482497618749 epoch =  0  loss = 3188.016  loss reduction = 13.81351  correctly classified = 88.4750%\n",
      "alpha =  0.7847368421052632 b =  2191.193023934539 epoch =  1  loss = 3194.923  loss reduction = -6.906755  correctly classified = 88.4500%\n",
      "alpha =  0.7847368421052632 b =  2308.9035502503284 epoch =  2  loss = 3181.109  loss reduction = 13.81351  correctly classified = 88.5000%\n",
      "alpha =  0.7847368421052632 b =  2417.9992355134864 epoch =  3  loss = 3132.762  loss reduction = 48.34728  correctly classified = 88.6750%\n",
      "alpha =  0.7847368421052632 b =  2541.9751007766445 epoch =  4  loss = 3194.923  loss reduction = -62.16079  correctly classified = 88.4500%\n",
      "alpha =  0.7847368421052632 b =  2634.62427130296 epoch =  5  loss = 3098.228  loss reduction = 96.69457  correctly classified = 88.8000%\n",
      "alpha =  0.7847368421052632 b =  2779.7456555134863 epoch =  6  loss = 3257.084  loss reduction = -158.8554  correctly classified = 88.2250%\n",
      "alpha =  0.7847368421052632 b =  2836.3691270924337 epoch =  7  loss = 3070.601  loss reduction = 186.4824  correctly classified = 88.9000%\n",
      "alpha =  0.7847368421052632 b =  2998.720193408223 epoch =  8  loss = 3298.524  loss reduction = -227.9229  correctly classified = 88.0750%\n",
      "alpha =  0.7847368421052632 b =  3016.185296566118 epoch =  9  loss = 3056.788  loss reduction = 241.7364  correctly classified = 88.9500%\n",
      "alpha =  0.7847368421052632 b =  3186.368036566118 epoch =  10  loss = 3284.711  loss reduction = -227.9229  correctly classified = 88.1250%\n",
      "alpha =  0.7847368421052632 b =  3195.218298671381 epoch =  11  loss = 3063.694  loss reduction = 221.0162  correctly classified = 88.9250%\n",
      "alpha =  0.7847368421052632 b =  3370.1000428819075 epoch =  12  loss = 3312.338  loss reduction = -248.6432  correctly classified = 88.0250%\n",
      "alpha =  0.7847368421052632 b =  3344.4909407766445 epoch =  13  loss = 3022.254  loss reduction = 290.0837  correctly classified = 89.0750%\n",
      "alpha =  0.7847368421052632 b =  3574.1944007766447 epoch =  14  loss = 3505.727  loss reduction = -483.4728  correctly classified = 87.3250%\n",
      "alpha =  0.7847368421052632 b =  3420.92901761875 epoch =  15  loss = 3402.125  loss reduction = 103.6013  correctly classified = 87.7000%\n",
      "alpha =  0.7847368421052632 b =  3774.3729218292765 epoch =  16  loss = 4168.775  loss reduction = -766.6498  correctly classified = 84.9250%\n",
      "alpha =  0.7847368421052632 b =  3258.5010470924344 epoch =  17  loss = 5563.94  loss reduction = -1395.164  correctly classified = 79.8750%\n",
      "alpha =  0.7847368421052632 b =  3927.5614007766453 epoch =  18  loss = 6178.641  loss reduction = -614.7012  correctly classified = 77.6500%\n",
      "alpha =  0.7847368421052632 b =  2626.1726555134874 epoch =  19  loss = 11938.87  loss reduction = -5760.233  correctly classified = 56.8000%\n",
      "alpha =  0.7847368421052632 b =  3499.6396923555926 epoch =  20  loss = 7760.288  loss reduction = 4178.587  correctly classified = 71.9250%\n",
      "alpha =  0.7847368421052632 b =  2917.198591302961 epoch =  21  loss = 6012.879  loss reduction = 1747.409  correctly classified = 78.2500%\n",
      "alpha =  0.7847368421052632 b =  3593.3074513029615 epoch =  22  loss = 6240.802  loss reduction = -227.9229  correctly classified = 77.4250%\n",
      "alpha =  0.7847368421052632 b =  2358.4879323555933 epoch =  23  loss = 11365.61  loss reduction = -5124.812  correctly classified = 58.8750%\n",
      "alpha =  0.7847368421052632 b =  3210.80945025033 epoch =  24  loss = 7587.619  loss reduction = 3777.995  correctly classified = 72.5500%\n",
      "alpha =  0.7847368421052632 b =  2536.737767092435 epoch =  25  loss = 6751.901  loss reduction = 835.7173  correctly classified = 75.5750%\n",
      "alpha =  0.7847368421052632 b =  3224.594137618751 epoch =  26  loss = 6302.962  loss reduction = 448.9391  correctly classified = 77.2000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.7847368421052632 b =  2053.994342881909 epoch =  27  loss = 10854.51  loss reduction = -4551.551  correctly classified = 60.7250%\n",
      "alpha =  0.7847368421052632 b =  2883.602969198872 epoch =  28  loss = 7427.921  loss reduction = 3426.593  correctly classified = 73.1250%\n",
      "alpha =  0.7847368421052632 b =  2183.6867628830823 epoch =  29  loss = 6966.011  loss reduction = 461.9099  correctly classified = 74.8000%\n",
      "alpha =  0.7847368421052632 b =  2859.0124555146613 epoch =  30  loss = 6206.268  loss reduction = 759.743  correctly classified = 77.5500%\n",
      "alpha =  0.7847368421052632 b =  1760.464058672556 epoch =  31  loss = 10274.35  loss reduction = -4068.079  correctly classified = 62.8250%\n",
      "alpha =  0.7847368421052632 b =  2572.060873409398 epoch =  32  loss = 7297.535  loss reduction = 2976.811  correctly classified = 73.6000%\n",
      "alpha =  0.7847368421052632 b =  1825.1546249883454 epoch =  33  loss = 7352.789  loss reduction = -55.25404  correctly classified = 73.4000%\n",
      "alpha =  0.7847368421052632 b =  2512.2278281462404 epoch =  34  loss = 6282.242  loss reduction = 1070.547  correctly classified = 77.2750%\n",
      "alpha =  0.7847368421052632 b =  1457.5368039357143 epoch =  35  loss = 9929.009  loss reduction = -3646.767  correctly classified = 64.0750%\n",
      "alpha =  0.7847368421052632 b =  2250.337601830451 epoch =  36  loss = 7131.773  loss reduction = 2797.236  correctly classified = 74.2000%\n",
      "alpha =  0.7847368421052632 b =  1447.826470251504 epoch =  37  loss = 7787.915  loss reduction = -656.1417  correctly classified = 71.8250%\n",
      "alpha =  0.7847368421052632 b =  2152.9125228830826 epoch =  38  loss = 6441.097  loss reduction = 1346.817  correctly classified = 76.7000%\n",
      "alpha =  0.7847368421052632 b =  1158.525386040977 epoch =  39  loss = 9397.189  loss reduction = -2956.091  correctly classified = 66.0000%\n",
      "alpha =  0.7847368421052632 b =  1924.6984934093982 epoch =  40  loss = 6910.757  loss reduction = 2486.432  correctly classified = 75.0000%\n",
      "alpha =  0.7847368421052632 b =  1068.9319807778193 epoch =  41  loss = 8243.76  loss reduction = -1333.004  correctly classified = 70.1750%\n",
      "alpha =  0.7847368421052632 b =  1780.2833723567667 epoch =  42  loss = 6496.351  loss reduction = 1747.409  correctly classified = 76.5000%\n",
      "alpha =  0.7847368421052632 b =  866.5178955149519 epoch =  43  loss = 8727.292  loss reduction = -2230.94  correctly classified = 68.4250%\n",
      "alpha =  0.7847368421052632 b =  1589.616797620215 epoch =  44  loss = 6586.139  loss reduction = 2141.153  correctly classified = 76.1750%\n",
      "alpha =  0.7847368421052632 b =  716.6206028833728 epoch =  45  loss = 8395.709  loss reduction = -1809.57  correctly classified = 69.6250%\n",
      "alpha =  0.7847368421052632 b =  1418.5739860412677 epoch =  46  loss = 6413.47  loss reduction = 1982.239  correctly classified = 76.8000%\n",
      "alpha =  0.7847368421052632 b =  558.8916365675835 epoch =  47  loss = 8319.735  loss reduction = -1906.264  correctly classified = 69.9000%\n",
      "alpha =  0.7847368421052632 b =  1250.6638439360047 epoch =  48  loss = 6323.683  loss reduction = 1996.052  correctly classified = 77.1250%\n",
      "alpha =  0.7847368421052632 b =  421.5250218307416 epoch =  49  loss = 8064.185  loss reduction = -1740.502  correctly classified = 70.8250%\n",
      "alpha =  0.7847368421052632 b =  1080.4041997254785 epoch =  50  loss = 6075.039  loss reduction = 1989.145  correctly classified = 78.0250%\n",
      "alpha =  0.7847368421052632 b =  326.4494449886364 epoch =  51  loss = 7442.577  loss reduction = -1367.537  correctly classified = 73.0750%\n",
      "alpha =  0.7847368421052632 b =  944.6039197254786 epoch =  52  loss = 5771.142  loss reduction = 1671.435  correctly classified = 79.1250%\n",
      "alpha =  0.7847368421052632 b =  275.2312407781102 epoch =  53  loss = 6820.969  loss reduction = -1049.827  correctly classified = 75.3250%\n",
      "alpha =  0.7847368421052632 b =  836.9976649886366 epoch =  54  loss = 5411.991  loss reduction = 1408.978  correctly classified = 80.4250%\n",
      "alpha =  0.7847368421052632 b =  205.21701972547885 epoch =  55  loss = 6572.326  loss reduction = -1160.335  correctly classified = 76.2250%\n",
      "alpha =  0.7847368421052632 b =  764.6339418307421 epoch =  56  loss = 5391.271  loss reduction = 1181.055  correctly classified = 80.5000%\n",
      "alpha =  0.7847368421052632 b =  137.55230077811052 epoch =  57  loss = 6544.699  loss reduction = -1153.428  correctly classified = 76.3250%\n",
      "alpha =  0.7847368421052632 b =  689.9207165675843 epoch =  58  loss = 5342.923  loss reduction = 1201.775  correctly classified = 80.6750%\n",
      "alpha =  0.7847368421052632 b =  74.58658604126856 epoch =  59  loss = 6454.911  loss reduction = -1111.988  correctly classified = 76.6500%\n",
      "alpha =  0.7847368421052632 b =  620.689662883374 epoch =  60  loss = 5329.11  loss reduction = 1125.801  correctly classified = 80.7250%\n",
      "alpha =  0.7847368421052632 b =  12.404038672847719 epoch =  61  loss = 6406.564  loss reduction = -1077.454  correctly classified = 76.8250%\n",
      "alpha =  0.7847368421052632 b =  552.2417765675847 epoch =  62  loss = 5329.11  loss reduction = 1077.454  correctly classified = 80.7250%\n",
      "alpha =  0.7847368421052632 b =  -40.3805002745205 epoch =  63  loss = 6282.242  loss reduction = -953.1322  correctly classified = 77.2750%\n",
      "alpha =  0.7847368421052632 b =  490.84239656758484 epoch =  64  loss = 5280.763  loss reduction = 1001.479  correctly classified = 80.9000%\n",
      "alpha =  0.7847368421052632 b =  -99.43037816925732 epoch =  65  loss = 6261.522  loss reduction = -980.7592  correctly classified = 77.3500%\n",
      "alpha =  0.7847368421052632 b =  427.09351446232176 epoch =  66  loss = 5253.136  loss reduction = 1008.386  correctly classified = 81.0000%\n",
      "alpha =  0.7847368421052632 b =  -149.86541501136242 epoch =  67  loss = 6157.921  loss reduction = -904.7849  correctly classified = 77.7250%\n",
      "alpha =  0.7847368421052632 b =  368.04363656758505 epoch =  68  loss = 5190.975  loss reduction = 966.9457  correctly classified = 81.2250%\n",
      "alpha =  0.7847368421052632 b =  -188.55294132715187 epoch =  69  loss = 6019.785  loss reduction = -828.8106  correctly classified = 78.2250%\n",
      "alpha =  0.7847368421052632 b =  320.74126919916404 epoch =  70  loss = 5115.001  loss reduction = 904.7849  correctly classified = 81.5000%\n",
      "alpha =  0.7847368421052632 b =  -232.72263922188853 epoch =  71  loss = 5992.158  loss reduction = -877.1579  correctly classified = 78.3250%\n",
      "alpha =  0.7847368421052632 b =  276.5715713044274 epoch =  72  loss = 5115.001  loss reduction = 877.1579  correctly classified = 81.5000%\n",
      "alpha =  0.7847368421052632 b =  -274.54283501136206 epoch =  73  loss = 5985.252  loss reduction = -870.2511  correctly classified = 78.3500%\n",
      "alpha =  0.7847368421052632 b =  230.8355386728485 epoch =  74  loss = 5094.28  loss reduction = 890.9714  correctly classified = 81.5750%\n",
      "alpha =  0.7847368421052632 b =  -299.1333486955726 epoch =  75  loss = 5840.21  loss reduction = -745.9295  correctly classified = 78.8750%\n",
      "alpha =  0.7847368421052632 b =  193.7143470939012 epoch =  76  loss = 5039.026  loss reduction = 801.1836  correctly classified = 81.7750%\n",
      "alpha =  0.7847368421052632 b =  -323.723862379783 epoch =  77  loss = 5743.515  loss reduction = -704.489  correctly classified = 79.2250%\n",
      "alpha =  0.7847368421052632 b =  164.42482919916444 epoch =  78  loss = 5039.026  loss reduction = 704.489  correctly classified = 81.7750%\n",
      "alpha =  0.7847368421052632 b =  -352.23021290609864 epoch =  79  loss = 5736.608  loss reduction = -697.5822  correctly classified = 79.2500%\n",
      "alpha =  0.7847368421052632 b =  131.21947446232247 epoch =  80  loss = 4997.586  loss reduction = 739.0228  correctly classified = 81.9250%\n",
      "alpha =  0.7847368421052632 b =  -383.0860655376775 epoch =  81  loss = 5715.888  loss reduction = -718.3025  correctly classified = 79.3250%\n",
      "alpha =  0.7847368421052632 b =  105.06262604126994 epoch =  82  loss = 5025.213  loss reduction = 690.6755  correctly classified = 81.8250%\n",
      "alpha =  0.7847368421052632 b =  -410.80924869557214 epoch =  83  loss = 5729.702  loss reduction = -704.489  correctly classified = 79.2750%\n",
      "alpha =  0.7847368421052632 b =  73.42360604127003 epoch =  84  loss = 4990.679  loss reduction = 739.0228  correctly classified = 81.9500%\n",
      "alpha =  0.7847368421052632 b =  -439.3155992218879 epoch =  85  loss = 5702.075  loss reduction = -711.3957  correctly classified = 79.3750%\n",
      "alpha =  0.7847368421052632 b =  44.91725551495426 epoch =  86  loss = 4990.679  loss reduction = 711.3957  correctly classified = 81.9500%\n",
      "alpha =  0.7847368421052632 b =  -464.68928027451943 epoch =  87  loss = 5688.261  loss reduction = -697.5822  correctly classified = 79.4250%\n",
      "alpha =  0.7847368421052632 b =  15.627737620217488 epoch =  88  loss = 4956.145  loss reduction = 732.116  correctly classified = 82.0750%\n",
      "alpha =  0.7847368421052632 b =  -470.4837771166246 epoch =  89  loss = 5494.872  loss reduction = -538.7269  correctly classified = 80.1250%\n",
      "alpha =  0.7847368421052632 b =  -10.529110800835042 epoch =  90  loss = 4845.637  loss reduction = 649.2349  correctly classified = 82.4750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.7847368421052632 b =  -450.43375080083507 epoch =  91  loss = 5170.255  loss reduction = -324.6175  correctly classified = 81.3000%\n",
      "alpha =  0.7847368421052632 b =  -41.38496343241394 epoch =  92  loss = 4603.901  loss reduction = 566.3539  correctly classified = 83.3500%\n",
      "alpha =  0.7847368421052632 b =  -366.9471676429402 epoch =  93  loss = 4576.274  loss reduction = 27.62702  correctly classified = 83.4500%\n",
      "alpha =  0.7847368421052632 b =  -8.021091853466487 epoch =  94  loss = 4272.376  loss reduction = 303.8972  correctly classified = 84.5500%\n",
      "alpha =  0.7847368421052632 b =  -252.91705711662436 epoch =  95  loss = 4072.081  loss reduction = 200.2959  correctly classified = 85.2750%\n",
      "alpha =  0.7847368421052632 b =  55.88630709390199 epoch =  96  loss = 4023.733  loss reduction = 48.34728  correctly classified = 85.4500%\n",
      "alpha =  0.7847368421052632 b =  -45.69002974820323 epoch =  97  loss = 3485.006  loss reduction = 538.7269  correctly classified = 87.4000%\n",
      "alpha =  0.7847368421052632 b =  174.6154218307442 epoch =  98  loss = 3643.862  loss reduction = -158.8554  correctly classified = 86.8250%\n",
      "alpha =  0.7847368421052632 b =  204.61120288337582 epoch =  99  loss = 3167.296  loss reduction = 476.5661  correctly classified = 88.5500%\n",
      "alpha =  0.7847368421052632 b =  355.21475867284954 epoch =  100  loss = 3305.431  loss reduction = -138.1351  correctly classified = 88.0500%\n",
      "alpha =  0.7847368421052632 b =  466.65994604127064 epoch =  101  loss = 3291.617  loss reduction = 13.81351  correctly classified = 88.1000%\n",
      "alpha =  0.7847368421052632 b =  609.4318281465338 epoch =  102  loss = 3277.804  loss reduction = 13.81351  correctly classified = 88.1500%\n",
      "alpha =  0.7847368421052632 b =  727.1423544623233 epoch =  103  loss = 3263.99  loss reduction = 13.81351  correctly classified = 88.2000%\n",
      "alpha =  0.7847368421052632 b =  860.5162281465339 epoch =  104  loss = 3277.804  loss reduction = -13.81351  correctly classified = 88.1500%\n",
      "alpha =  0.7847368421052632 b =  977.4435870939024 epoch =  105  loss = 3270.897  loss reduction = 6.906755  correctly classified = 88.1750%\n",
      "alpha =  0.7847368421052632 b =  1110.817460778113 epoch =  106  loss = 3263.99  loss reduction = 6.906755  correctly classified = 88.2000%\n",
      "alpha =  0.7847368421052632 b =  1226.1784849886394 epoch =  107  loss = 3243.27  loss reduction = 20.72026  correctly classified = 88.2750%\n",
      "alpha =  0.7847368421052632 b =  1351.7206849886395 epoch =  108  loss = 3222.55  loss reduction = 20.72026  correctly classified = 88.3500%\n",
      "alpha =  0.7847368421052632 b =  1476.4797176202185 epoch =  109  loss = 3229.456  loss reduction = -6.906755  correctly classified = 88.3250%\n",
      "alpha =  0.7847368421052632 b =  1597.3229134096923 epoch =  110  loss = 3222.55  loss reduction = 6.906755  correctly classified = 88.3500%\n",
      "alpha =  0.7847368421052632 b =  1721.2987786728502 epoch =  111  loss = 3222.55  loss reduction = -4.547474e-13  correctly classified = 88.3500%\n",
      "alpha =  0.8052631578947368 b =  1846.9101681465345 epoch =  0  loss = 3208.736  loss reduction = 13.81351  correctly classified = 88.4000%\n",
      "alpha =  0.8052631578947368 b =  1972.5215576202188 epoch =  1  loss = 3208.736  loss reduction = 0.0  correctly classified = 88.4000%\n",
      "alpha =  0.8257894736842105 b =  2103.807219725482 epoch =  0  loss = 3215.643  loss reduction = -6.906755  correctly classified = 88.3750%\n",
      "alpha =  0.8257894736842105 b =  2229.3239165675873 epoch =  1  loss = 3181.109  loss reduction = 34.53377  correctly classified = 88.5000%\n",
      "alpha =  0.8257894736842105 b =  2361.4337165675875 epoch =  2  loss = 3208.736  loss reduction = -27.62702  correctly classified = 88.4000%\n",
      "alpha =  0.8257894736842105 b =  2486.126275514956 epoch =  3  loss = 3188.016  loss reduction = 20.72026  correctly classified = 88.4750%\n",
      "alpha =  0.8257894736842105 b =  2618.236075514956 epoch =  4  loss = 3208.736  loss reduction = -20.72026  correctly classified = 88.4000%\n",
      "alpha =  0.8257894736842105 b =  2745.4010481465352 epoch =  5  loss = 3181.109  loss reduction = 27.62702  correctly classified = 88.5000%\n",
      "alpha =  0.8257894736842105 b =  2874.214296567588 epoch =  6  loss = 3181.109  loss reduction = -4.547474e-13  correctly classified = 88.5000%\n",
      "alpha =  0.8463157894736841 b =  3008.7632734096933 epoch =  0  loss = 3174.202  loss reduction = 6.906755  correctly classified = 88.5250%\n",
      "alpha =  0.8463157894736841 b =  3137.3998881465354 epoch =  1  loss = 3181.109  loss reduction = -6.906755  correctly classified = 88.5000%\n",
      "alpha =  0.8463157894736841 b =  3271.9488649886407 epoch =  2  loss = 3174.202  loss reduction = 6.906755  correctly classified = 88.5250%\n",
      "alpha =  0.8463157894736841 b =  3399.7408565675883 epoch =  3  loss = 3174.202  loss reduction = 0.0  correctly classified = 88.5250%\n",
      "alpha =  0.8668421052631579 b =  3538.4182565675883 epoch =  0  loss = 3167.296  loss reduction = 6.906755  correctly classified = 88.5500%\n",
      "alpha =  0.8668421052631579 b =  3658.928379725483 epoch =  1  loss = 3118.948  loss reduction = 48.34728  correctly classified = 88.7250%\n",
      "alpha =  0.8668421052631579 b =  3796.74067130443 epoch =  2  loss = 3160.389  loss reduction = -41.44053  correctly classified = 88.5750%\n",
      "alpha =  0.8668421052631579 b =  3920.7112281465356 epoch =  3  loss = 3105.135  loss reduction = 55.25404  correctly classified = 88.7750%\n",
      "alpha =  0.8668421052631579 b =  4058.523519725483 epoch =  4  loss = 3160.389  loss reduction = -55.25404  correctly classified = 88.5750%\n",
      "alpha =  0.8668421052631579 b =  4179.89875130443 epoch =  5  loss = 3084.415  loss reduction = 75.9743  correctly classified = 88.8500%\n",
      "alpha =  0.8668421052631579 b =  4315.980826041273 epoch =  6  loss = 3160.389  loss reduction = -75.9743  correctly classified = 88.5750%\n",
      "alpha =  0.8668421052631579 b =  4439.0862744623255 epoch =  7  loss = 3070.601  loss reduction = 89.78781  correctly classified = 88.9000%\n",
      "alpha =  0.8668421052631579 b =  4563.0568313044305 epoch =  8  loss = 3077.508  loss reduction = -6.906755  correctly classified = 88.8750%\n",
      "alpha =  0.8668421052631579 b =  4689.6227134096935 epoch =  9  loss = 3098.228  loss reduction = -20.72026  correctly classified = 88.8000%\n",
      "alpha =  0.8668421052631579 b =  4815.323487093904 epoch =  10  loss = 3091.321  loss reduction = 6.906755  correctly classified = 88.8250%\n",
      "alpha =  0.8668421052631579 b =  4941.889369199167 epoch =  11  loss = 3098.228  loss reduction = -6.906755  correctly classified = 88.8000%\n",
      "alpha =  0.8668421052631579 b =  5068.45525130443 epoch =  12  loss = 3098.228  loss reduction = 0.0  correctly classified = 88.8000%\n",
      "alpha =  0.8873684210526316 b =  5197.132546041272 epoch =  0  loss = 3091.321  loss reduction = 6.906755  correctly classified = 88.8250%\n",
      "alpha =  0.8873684210526316 b =  5324.924247093903 epoch =  1  loss = 3084.415  loss reduction = 6.906755  correctly classified = 88.8500%\n",
      "alpha =  0.8873684210526316 b =  5453.601541830745 epoch =  2  loss = 3077.508  loss reduction = 6.906755  correctly classified = 88.8750%\n",
      "alpha =  0.8873684210526316 b =  5576.0796807781135 epoch =  3  loss = 3042.974  loss reduction = 34.53377  correctly classified = 89.0000%\n",
      "alpha =  0.8873684210526316 b =  5712.727318672851 epoch =  4  loss = 3084.415  loss reduction = -41.44053  correctly classified = 88.8500%\n",
      "alpha =  0.8873684210526316 b =  5793.582554462325 epoch =  5  loss = 2967.0  loss reduction = 117.4148  correctly classified = 89.2750%\n",
      "alpha =  0.8873684210526316 b =  5952.370034462325 epoch =  6  loss = 3105.135  loss reduction = -138.1351  correctly classified = 88.7750%\n",
      "alpha =  0.8873684210526316 b =  6004.000678672851 epoch =  7  loss = 2960.093  loss reduction = 145.0419  correctly classified = 89.3000%\n",
      "alpha =  0.8873684210526316 b =  6180.500032357061 epoch =  8  loss = 3160.389  loss reduction = -200.2959  correctly classified = 88.5750%\n",
      "alpha =  0.8873684210526316 b =  6200.249303936009 epoch =  9  loss = 2904.839  loss reduction = 255.5499  correctly classified = 89.5000%\n",
      "alpha =  0.8873684210526316 b =  6380.291032357061 epoch =  10  loss = 3174.202  loss reduction = -269.3634  correctly classified = 88.5250%\n",
      "alpha =  0.8873684210526316 b =  6389.413179725482 epoch =  11  loss = 2904.839  loss reduction = 269.3634  correctly classified = 89.5000%\n",
      "alpha =  0.8873684210526316 b =  6576.539657620219 epoch =  12  loss = 3160.389  loss reduction = -255.5499  correctly classified = 88.5750%\n",
      "alpha =  0.8873684210526316 b =  6574.149087093903 epoch =  13  loss = 2897.932  loss reduction = 262.4567  correctly classified = 89.5250%\n",
      "alpha =  0.8873684210526316 b =  6777.2162513044295 epoch =  14  loss = 3188.016  loss reduction = -290.0837  correctly classified = 88.4750%\n",
      "alpha =  0.8873684210526316 b =  6728.774809199166 epoch =  15  loss = 2911.746  loss reduction = 276.2702  correctly classified = 89.4750%\n",
      "alpha =  0.8873684210526316 b =  7009.774217620219 epoch =  16  loss = 3491.913  loss reduction = -580.1674  correctly classified = 87.3750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.8873684210526316 b =  6801.040318672851 epoch =  17  loss = 3277.804  loss reduction = 214.1094  correctly classified = 88.1500%\n",
      "alpha =  0.8873684210526316 b =  7219.306748146535 epoch =  18  loss = 4175.682  loss reduction = -897.8781  correctly classified = 84.9000%\n",
      "alpha =  0.8873684210526316 b =  6569.547194462324 epoch =  19  loss = 5860.93  loss reduction = -1685.248  correctly classified = 78.8000%\n",
      "alpha =  0.8873684210526316 b =  7351.792628146534 epoch =  20  loss = 6351.31  loss reduction = -490.3796  correctly classified = 77.0250%\n",
      "alpha =  0.8873684210526316 b =  5823.524139725481 epoch =  21  loss = 12311.84  loss reduction = -5960.529  correctly classified = 55.4500%\n",
      "alpha =  0.8873684210526316 b =  6820.083244988639 epoch =  22  loss = 7829.355  loss reduction = 4482.484  correctly classified = 71.6750%\n",
      "alpha =  0.8873684210526316 b =  6233.200842883376 epoch =  23  loss = 5494.872  loss reduction = 2334.483  correctly classified = 80.1250%\n",
      "alpha =  0.8873684210526316 b =  6967.624217620218 epoch =  24  loss = 6005.972  loss reduction = -511.0999  correctly classified = 78.2750%\n",
      "alpha =  0.8873684210526316 b =  5588.135468146534 epoch =  25  loss = 11220.57  loss reduction = -5214.6  correctly classified = 59.4000%\n",
      "alpha =  0.8873684210526316 b =  6561.669137620218 epoch =  26  loss = 7663.593  loss reduction = 3556.979  correctly classified = 72.2750%\n",
      "alpha =  0.8873684210526316 b =  5791.468842883376 epoch =  27  loss = 6744.995  loss reduction = 918.5984  correctly classified = 75.6000%\n",
      "alpha =  0.8873684210526316 b =  6580.799026041271 epoch =  28  loss = 6392.75  loss reduction = 352.2445  correctly classified = 76.8750%\n",
      "alpha =  0.8873684210526316 b =  5212.822994462324 epoch =  29  loss = 11144.6  loss reduction = -4751.847  correctly classified = 59.6750%\n",
      "alpha =  0.8873684210526316 b =  6170.415977620218 epoch =  30  loss = 7553.085  loss reduction = 3591.512  correctly classified = 72.6750%\n",
      "alpha =  0.8873684210526316 b =  5402.872463936007 epoch =  31  loss = 6724.274  loss reduction = 828.8106  correctly classified = 75.6750%\n",
      "alpha =  0.8873684210526316 b =  6167.406023936007 epoch =  32  loss = 6213.175  loss reduction = 511.0999  correctly classified = 77.5250%\n",
      "alpha =  0.8873684210526316 b =  4880.019017620218 epoch =  33  loss = 10529.9  loss reduction = -4316.722  correctly classified = 61.9000%\n",
      "alpha =  0.8873684210526316 b =  5808.387409199166 epoch =  34  loss = 7380.416  loss reduction = 3149.48  correctly classified = 73.3000%\n",
      "alpha =  0.8873684210526316 b =  4981.50911867285 epoch =  35  loss = 7159.4  loss reduction = 221.0162  correctly classified = 74.1000%\n",
      "alpha =  0.8873684210526316 b =  5747.813866041271 epoch =  36  loss = 6213.175  loss reduction = 946.2254  correctly classified = 77.5250%\n",
      "alpha =  0.8873684210526316 b =  4523.304011304429 epoch =  37  loss = 10080.96  loss reduction = -3867.783  correctly classified = 63.5250%\n",
      "alpha =  0.8873684210526316 b =  5433.0749355149555 epoch =  38  loss = 7235.374  loss reduction = 2845.583  correctly classified = 73.8250%\n",
      "alpha =  0.8873684210526316 b =  4557.488992357061 epoch =  39  loss = 7539.271  loss reduction = -303.8972  correctly classified = 72.7250%\n",
      "alpha =  0.8873684210526316 b =  5340.620019725482 epoch =  40  loss = 6330.589  loss reduction = 1208.682  correctly classified = 77.1000%\n",
      "alpha =  0.8873684210526316 b =  4192.271221830745 epoch =  41  loss = 9569.857  loss reduction = -3239.268  correctly classified = 65.3750%\n",
      "alpha =  0.8873684210526316 b =  5075.474335514956 epoch =  42  loss = 7028.172  loss reduction = 2541.686  correctly classified = 74.5750%\n",
      "alpha =  0.8873684210526316 b =  4115.756992357061 epoch =  43  loss = 8140.159  loss reduction = -1111.988  correctly classified = 70.5500%\n",
      "alpha =  0.8873684210526316 b =  4923.684642883377 epoch =  44  loss = 6510.165  loss reduction = 1629.994  correctly classified = 76.4500%\n",
      "alpha =  0.8873684210526316 b =  3868.3231818307454 epoch =  45  loss = 8872.275  loss reduction = -2362.11  correctly classified = 67.9000%\n",
      "alpha =  0.8873684210526316 b =  4709.01779867285 epoch =  46  loss = 6724.274  loss reduction = 2148.001  correctly classified = 75.6750%\n",
      "alpha =  0.8873684210526316 b =  3681.9953355149555 epoch =  47  loss = 8651.259  loss reduction = -1926.985  correctly classified = 68.7000%\n",
      "alpha =  0.8873684210526316 b =  4494.350954462324 epoch =  48  loss = 6544.699  loss reduction = 2106.56  correctly classified = 76.3250%\n",
      "alpha =  0.8873684210526316 b =  3521.349706041271 epoch =  49  loss = 8257.574  loss reduction = -1712.875  correctly classified = 70.1250%\n",
      "alpha =  0.8873684210526316 b =  4306.251920778113 epoch =  50  loss = 6344.403  loss reduction = 1913.171  correctly classified = 77.0500%\n",
      "alpha =  0.8873684210526316 b =  3349.19135867285 epoch =  51  loss = 8147.066  loss reduction = -1802.663  correctly classified = 70.5250%\n",
      "alpha =  0.8873684210526316 b =  4119.038480778114 epoch =  52  loss = 6226.988  loss reduction = 1920.078  correctly classified = 77.4750%\n",
      "alpha =  0.8873684210526316 b =  3213.342352357061 epoch =  53  loss = 7760.288  loss reduction = -1533.3  correctly classified = 71.9250%\n",
      "alpha =  0.8873684210526316 b =  3954.850476567587 epoch =  54  loss = 6047.412  loss reduction = 1712.875  correctly classified = 78.1250%\n",
      "alpha =  0.8873684210526316 b =  3123.5442176202187 epoch =  55  loss = 7207.747  loss reduction = -1160.335  correctly classified = 73.9250%\n",
      "alpha =  0.8873684210526316 b =  3799.518409199166 epoch =  56  loss = 5619.194  loss reduction = 1588.554  correctly classified = 79.6750%\n",
      "alpha =  0.8873684210526316 b =  3062.0850807781135 epoch =  57  loss = 6613.766  loss reduction = -994.5727  correctly classified = 76.0750%\n",
      "alpha =  0.8873684210526316 b =  3695.5507755149556 epoch =  58  loss = 5398.177  loss reduction = 1215.589  correctly classified = 80.4750%\n",
      "alpha =  0.8873684210526316 b =  2966.9733839360083 epoch =  59  loss = 6599.953  loss reduction = -1201.775  correctly classified = 76.1250%\n",
      "alpha =  0.8873684210526316 b =  3599.9826878049957 epoch =  60  loss = 5391.933  loss reduction = 1208.02  correctly classified = 80.5000%\n",
      "alpha =  0.8873684210526316 b =  2874.9476709628907 epoch =  61  loss = 6572.326  loss reduction = -1180.393  correctly classified = 76.2250%\n",
      "alpha =  0.8873684210526316 b =  3503.9853972786805 epoch =  62  loss = 5363.644  loss reduction = 1208.682  correctly classified = 80.6000%\n",
      "alpha =  0.8873684210526316 b =  2785.149536226049 epoch =  63  loss = 6537.792  loss reduction = -1174.148  correctly classified = 76.3500%\n",
      "alpha =  0.8873684210526316 b =  3410.6448878049964 epoch =  64  loss = 5336.017  loss reduction = 1201.775  correctly classified = 80.7000%\n",
      "alpha =  0.8873684210526316 b =  2708.635306752365 epoch =  65  loss = 6434.191  loss reduction = -1098.174  correctly classified = 76.7250%\n",
      "alpha =  0.8873684210526316 b =  3324.389127804997 epoch =  66  loss = 5260.042  loss reduction = 1174.148  correctly classified = 80.9750%\n",
      "alpha =  0.8873684210526316 b =  2641.862607804997 epoch =  67  loss = 6309.869  loss reduction = -1049.827  correctly classified = 77.1750%\n",
      "alpha =  0.8873684210526316 b =  3246.9893046471025 epoch =  68  loss = 5246.229  loss reduction = 1063.64  correctly classified = 81.0250%\n",
      "alpha =  0.8873684210526316 b =  2581.2890646471024 epoch =  69  loss = 6178.641  loss reduction = -932.4119  correctly classified = 77.6500%\n",
      "alpha =  0.8873684210526316 b =  3177.5598246471027 epoch =  70  loss = 5204.788  loss reduction = 973.8524  correctly classified = 81.1750%\n",
      "alpha =  0.8873684210526316 b =  2525.1434899102605 epoch =  71  loss = 6130.293  loss reduction = -925.5051  correctly classified = 77.8250%\n",
      "alpha =  0.8873684210526316 b =  3109.9015320155236 epoch =  72  loss = 5128.814  loss reduction = 1001.479  correctly classified = 81.4500%\n",
      "alpha =  0.8873684210526316 b =  2488.48097622605 epoch =  73  loss = 5929.998  loss reduction = -801.1836  correctly classified = 78.5500%\n",
      "alpha =  0.8873684210526316 b =  3056.4127383313134 epoch =  74  loss = 5039.026  loss reduction = 890.9714  correctly classified = 81.7750%\n",
      "alpha =  0.8873684210526316 b =  2455.360837278682 epoch =  75  loss = 5784.956  loss reduction = -745.9295  correctly classified = 79.0750%\n",
      "alpha =  0.8873684210526316 b =  3012.665475173419 epoch =  76  loss = 4997.586  loss reduction = 787.37  correctly classified = 81.9250%\n",
      "alpha =  0.8873684210526316 b =  2418.6983235944717 epoch =  77  loss = 5757.329  loss reduction = -759.743  correctly classified = 79.1750%\n",
      "alpha =  0.8873684210526316 b =  2974.2317741207876 epoch =  78  loss = 4983.772  loss reduction = 773.5565  correctly classified = 81.9750%\n",
      "alpha =  0.8873684210526316 b =  2381.150216226051 epoch =  79  loss = 5750.422  loss reduction = -766.6498  correctly classified = 79.2000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.8873684210526316 b =  2935.798073068156 epoch =  80  loss = 4976.865  loss reduction = 773.5565  correctly classified = 82.0000%\n",
      "alpha =  0.8873684210526316 b =  2343.60210885763 epoch =  81  loss = 5743.515  loss reduction = -766.6498  correctly classified = 79.2250%\n",
      "alpha =  0.8873684210526316 b =  2897.3643720155246 epoch =  82  loss = 4969.959  loss reduction = 773.5565  correctly classified = 82.0250%\n",
      "alpha =  0.8873684210526316 b =  2306.9395951734195 epoch =  83  loss = 5729.702  loss reduction = -759.743  correctly classified = 79.2750%\n",
      "alpha =  0.8873684210526316 b =  2859.8162646471037 epoch =  84  loss = 4976.865  loss reduction = 752.8363  correctly classified = 82.0000%\n",
      "alpha =  0.8873684210526316 b =  2274.7050499102616 epoch =  85  loss = 5702.075  loss reduction = -725.2093  correctly classified = 79.3750%\n",
      "alpha =  0.8873684210526316 b =  2816.9545951734194 epoch =  86  loss = 4921.611  loss reduction = 780.4633  correctly classified = 82.2000%\n",
      "alpha =  0.8873684210526316 b =  2248.6696604365775 epoch =  87  loss = 5598.473  loss reduction = -676.862  correctly classified = 79.7500%\n",
      "alpha =  0.8873684210526316 b =  2791.804799383946 epoch =  88  loss = 4928.518  loss reduction = 669.9552  correctly classified = 82.1750%\n",
      "alpha =  0.8873684210526316 b =  2228.833426752367 epoch =  89  loss = 5557.033  loss reduction = -628.5147  correctly classified = 79.9000%\n",
      "alpha =  0.8873684210526316 b =  2761.341441489209 epoch =  90  loss = 4859.451  loss reduction = 697.5822  correctly classified = 82.4250%\n",
      "alpha =  0.8873684210526316 b =  2237.3361909628934 epoch =  91  loss = 5308.39  loss reduction = -448.9391  correctly classified = 80.8000%\n",
      "alpha =  0.8873684210526316 b =  2750.361144647104 epoch =  92  loss = 4735.129  loss reduction = 573.2606  correctly classified = 82.8750%\n",
      "alpha =  0.8873684210526316 b =  2260.0084541207884 epoch =  93  loss = 5087.374  loss reduction = -352.2445  correctly classified = 81.6000%\n",
      "alpha =  0.8873684210526316 b =  2752.664753068157 epoch =  94  loss = 4659.155  loss reduction = 428.2188  correctly classified = 83.1500%\n",
      "alpha =  0.8873684210526316 b =  2307.4773404365783 epoch =  95  loss = 4804.197  loss reduction = -145.0419  correctly classified = 82.6250%\n",
      "alpha =  0.8873684210526316 b =  2758.510736226052 epoch =  96  loss = 4486.486  loss reduction = 317.7107  correctly classified = 83.7750%\n",
      "alpha =  0.8873684210526316 b =  2415.1665972786836 epoch =  97  loss = 4300.003  loss reduction = 186.4824  correctly classified = 84.4500%\n",
      "alpha =  0.8873684210526316 b =  2804.2084351734206 epoch =  98  loss = 4127.335  loss reduction = 172.6689  correctly classified = 85.0750%\n",
      "alpha =  0.8873684210526316 b =  2614.957597278684 epoch =  99  loss = 3595.514  loss reduction = 531.8201  correctly classified = 87.0000%\n",
      "alpha =  0.8873684210526316 b =  2912.7832856997366 epoch =  100  loss = 3719.836  loss reduction = -124.3216  correctly classified = 86.5500%\n",
      "alpha =  0.8873684210526316 b =  2829.803689910263 epoch =  101  loss = 3333.058  loss reduction = 386.7783  correctly classified = 87.9500%\n",
      "alpha =  0.8873684210526316 b =  3044.383572015526 epoch =  102  loss = 3415.939  loss reduction = -82.88106  correctly classified = 87.6500%\n",
      "alpha =  0.8873684210526316 b =  3100.442184647105 epoch =  103  loss = 3118.948  loss reduction = 296.9905  correctly classified = 88.7250%\n",
      "alpha =  0.8873684210526316 b =  3266.3144141207895 epoch =  104  loss = 3229.456  loss reduction = -110.5081  correctly classified = 88.3250%\n",
      "alpha =  0.8873684210526316 b =  3392.334927805 epoch =  105  loss = 3167.296  loss reduction = 62.16079  correctly classified = 88.5500%\n",
      "alpha =  0.8873684210526316 b =  3550.2368141207894 epoch =  106  loss = 3222.55  loss reduction = -55.25404  correctly classified = 88.3500%\n",
      "alpha =  0.8873684210526316 b =  3685.9988583313157 epoch =  107  loss = 3132.762  loss reduction = 89.78781  correctly classified = 88.6750%\n",
      "alpha =  0.8873684210526316 b =  3827.0744646471053 epoch =  108  loss = 3160.389  loss reduction = -27.62702  correctly classified = 88.5750%\n",
      "alpha =  0.8873684210526316 b =  3969.0356646471055 epoch =  109  loss = 3167.296  loss reduction = -6.906755  correctly classified = 88.5500%\n",
      "alpha =  0.8873684210526316 b =  4110.996864647105 epoch =  110  loss = 3153.482  loss reduction = 13.81351  correctly classified = 88.6000%\n",
      "alpha =  0.8873684210526316 b =  4252.072470962895 epoch =  111  loss = 3146.575  loss reduction = 6.906755  correctly classified = 88.6250%\n",
      "alpha =  0.8873684210526316 b =  4394.033670962895 epoch =  112  loss = 3153.482  loss reduction = -6.906755  correctly classified = 88.6000%\n",
      "alpha =  0.8873684210526316 b =  4535.109277278684 epoch =  113  loss = 3146.575  loss reduction = 6.906755  correctly classified = 88.6250%\n",
      "alpha =  0.8873684210526316 b =  4674.413696226053 epoch =  114  loss = 3146.575  loss reduction = 0.0  correctly classified = 88.6250%\n",
      "alpha =  0.9078947368421053 b =  4819.658696226053 epoch =  0  loss = 3139.669  loss reduction = 6.906755  correctly classified = 88.6500%\n",
      "alpha =  0.9078947368421053 b =  4963.997617278685 epoch =  1  loss = 3132.762  loss reduction = 6.906755  correctly classified = 88.6750%\n",
      "alpha =  0.9078947368421053 b =  5108.336538331317 epoch =  2  loss = 3132.762  loss reduction = 0.0  correctly classified = 88.6750%\n",
      "alpha =  0.9284210526315789 b =  5255.93877412079 epoch =  0  loss = 3132.762  loss reduction = 0.0  correctly classified = 88.6750%\n",
      "alpha =  0.9489473684210525 b =  5404.910225699738 epoch =  0  loss = 3118.948  loss reduction = 13.81351  correctly classified = 88.7250%\n",
      "alpha =  0.9489473684210525 b =  5556.722825699738 epoch =  1  loss = 3112.042  loss reduction = 6.906755  correctly classified = 88.7500%\n",
      "alpha =  0.9489473684210525 b =  5703.800178331317 epoch =  2  loss = 3105.135  loss reduction = 6.906755  correctly classified = 88.7750%\n",
      "alpha =  0.9489473684210525 b =  5856.559827805001 epoch =  3  loss = 3105.135  loss reduction = -4.547474e-13  correctly classified = 88.7750%\n",
      "alpha =  0.9694736842105263 b =  6001.98088043658 epoch =  0  loss = 3070.601  loss reduction = 34.53377  correctly classified = 88.9000%\n",
      "alpha =  0.9694736842105263 b =  6156.109745699739 epoch =  1  loss = 3091.321  loss reduction = -20.72026  correctly classified = 88.8250%\n",
      "alpha =  0.9694736842105263 b =  6299.595728857634 epoch =  2  loss = 3056.788  loss reduction = 34.53377  correctly classified = 88.9500%\n",
      "alpha =  0.9694736842105263 b =  6451.789524647107 epoch =  3  loss = 3077.508  loss reduction = -20.72026  correctly classified = 88.8750%\n",
      "alpha =  0.9694736842105263 b =  6593.340438331317 epoch =  4  loss = 3042.974  loss reduction = 34.53377  correctly classified = 89.0000%\n",
      "alpha =  0.9694736842105263 b =  6749.40437306816 epoch =  5  loss = 3105.135  loss reduction = -62.16079  correctly classified = 88.7750%\n",
      "alpha =  0.9694736842105263 b =  6886.11761306816 epoch =  6  loss = 2994.627  loss reduction = 110.5081  correctly classified = 89.1750%\n",
      "alpha =  0.9694736842105263 b =  7032.506200436581 epoch =  7  loss = 3049.881  loss reduction = -55.25404  correctly classified = 88.9750%\n",
      "alpha =  0.9694736842105263 b =  7175.024648857634 epoch =  8  loss = 3022.254  loss reduction = 27.62702  correctly classified = 89.0750%\n",
      "alpha =  0.9694736842105263 b =  7316.575562541844 epoch =  9  loss = 3015.347  loss reduction = 6.906755  correctly classified = 89.1000%\n",
      "alpha =  0.9694736842105263 b =  7455.223872015528 epoch =  10  loss = 2994.627  loss reduction = 20.72026  correctly classified = 89.1750%\n",
      "alpha =  0.9694736842105263 b =  7595.807250962896 epoch =  11  loss = 3008.44  loss reduction = -13.81351  correctly classified = 89.1250%\n",
      "alpha =  0.9694736842105263 b =  7734.4555604365805 epoch =  12  loss = 2994.627  loss reduction = 13.81351  correctly classified = 89.1750%\n",
      "alpha =  0.9694736842105263 b =  7874.071404647107 epoch =  13  loss = 3001.534  loss reduction = -6.906755  correctly classified = 89.1500%\n",
      "alpha =  0.9694736842105263 b =  8011.752179383949 epoch =  14  loss = 2973.907  loss reduction = 27.62702  correctly classified = 89.2500%\n",
      "alpha =  0.9694736842105263 b =  8146.530349910265 epoch =  15  loss = 2967.0  loss reduction = 6.906755  correctly classified = 89.2750%\n",
      "alpha =  0.9694736842105263 b =  8282.276055173423 epoch =  16  loss = 2960.093  loss reduction = 6.906755  correctly classified = 89.3000%\n",
      "alpha =  0.9694736842105263 b =  8416.086690962897 epoch =  17  loss = 2960.093  loss reduction = 0.0  correctly classified = 89.3000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.99 b =  8555.694510962896 epoch =  0  loss = 2953.186  loss reduction = 6.906755  correctly classified = 89.3250%\n",
      "alpha =  0.99 b =  8691.350250962896 epoch =  1  loss = 2939.373  loss reduction = 13.81351  correctly classified = 89.3750%\n",
      "alpha =  0.99 b =  8827.005990962896 epoch =  2  loss = 2939.373  loss reduction = 0.0  correctly classified = 89.3750%\n",
      "     pred  true_label\n",
      "0     1.0           1\n",
      "1     0.0           0\n",
      "2     0.0           0\n",
      "3     0.0           0\n",
      "4     0.0           1\n",
      "..    ...         ...\n",
      "995   0.0           0\n",
      "996   0.0           0\n",
      "997   0.0           0\n",
      "998   0.0           0\n",
      "999   0.0           0\n",
      "\n",
      "[1000 rows x 2 columns]\n",
      "alpha =  0.6 b =  -1712.8235300923338 epoch =  0  loss = 19758.07  loss reduction = 9.999998e+10  correctly classified = 28.5000%\n",
      "alpha =  0.6 b =  -1031.223530092334 epoch =  1  loss = 7877.702  loss reduction = 11880.37  correctly classified = 71.5000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b2/8cn96b9x6qz0b7b79dn_n_1h0000gn/T/ipykernel_13453/3879921196.py:49: RuntimeWarning: overflow encountered in exp\n",
      "  test_pred = 1/(1+np.exp(-test_a))\n",
      "/var/folders/b2/8cn96b9x6qz0b7b79dn_n_1h0000gn/T/ipykernel_13453/3879921196.py:25: RuntimeWarning: overflow encountered in exp\n",
      "  a = (1/(1+np.exp(-a)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.6 b =  -349.6235300923339 epoch =  2  loss = 7877.702  loss reduction = 0.0  correctly classified = 71.5000%\n",
      "alpha =  0.6205263157894737 b =  -2121.8466879870707 epoch =  0  loss = 19757.32  loss reduction = -11879.62  correctly classified = 28.5000%\n",
      "alpha =  0.6205263157894737 b =  -1416.9287932502286 epoch =  1  loss = 7877.702  loss reduction = 11879.62  correctly classified = 71.5000%\n",
      "alpha =  0.6205263157894737 b =  -712.0108985133866 epoch =  2  loss = 7877.702  loss reduction = 0.0  correctly classified = 71.5000%\n",
      "alpha =  0.6410526315789473 b =  -2542.85721430286 epoch =  0  loss = 19757.32  loss reduction = -11879.62  correctly classified = 28.5000%\n",
      "alpha =  0.6410526315789473 b =  -1814.6214248291758 epoch =  1  loss = 7877.702  loss reduction = 11879.62  correctly classified = 71.5000%\n",
      "alpha =  0.6410526315789473 b =  -1086.3856353554916 epoch =  2  loss = 7877.702  loss reduction = 0.0  correctly classified = 71.5000%\n",
      "alpha =  0.661578947368421 b =  -2975.8551090397023 epoch =  0  loss = 19757.32  loss reduction = -11879.62  correctly classified = 28.5000%\n",
      "alpha =  0.661578947368421 b =  -2224.301424829176 epoch =  1  loss = 7877.702  loss reduction = 11879.62  correctly classified = 71.5000%\n",
      "alpha =  0.661578947368421 b =  -1690.6321511449655 epoch =  2  loss = 6496.351  loss reduction = 1381.351  correctly classified = 76.5000%\n",
      "alpha =  0.661578947368421 b =  -3569.537532197597 epoch =  3  loss = 19867.83  loss reduction = -13371.48  correctly classified = 28.1000%\n",
      "alpha =  0.661578947368421 b =  -2817.983847987071 epoch =  4  loss = 7877.702  loss reduction = 11990.13  correctly classified = 71.5000%\n",
      "alpha =  0.661578947368421 b =  -2388.6349890397023 epoch =  5  loss = 6068.133  loss reduction = 1809.57  correctly classified = 78.0500%\n",
      "alpha =  0.661578947368421 b =  -4266.88011430286 epoch =  6  loss = 19860.92  loss reduction = -13792.79  correctly classified = 28.1250%\n",
      "alpha =  0.661578947368421 b =  -3515.3264300923342 epoch =  7  loss = 7877.702  loss reduction = 11983.22  correctly classified = 71.5000%\n",
      "alpha =  0.661578947368421 b =  -2794.1445121975976 epoch =  8  loss = 7615.246  loss reduction = 262.4567  correctly classified = 72.4500%\n",
      "alpha =  0.661578947368421 b =  -4672.389637460756 epoch =  9  loss = 19860.92  loss reduction = -12245.68  correctly classified = 28.1250%\n",
      "alpha =  0.661578947368421 b =  -3920.8359532502295 epoch =  10  loss = 7877.702  loss reduction = 11983.22  correctly classified = 71.5000%\n",
      "alpha =  0.661578947368421 b =  -3791.903478513387 epoch =  11  loss = 4887.078  loss reduction = 2990.625  correctly classified = 82.3250%\n",
      "alpha =  0.661578947368421 b =  -3833.9772532502293 epoch =  12  loss = 4921.611  loss reduction = -34.53377  correctly classified = 82.2000%\n",
      "alpha =  0.661578947368421 b =  -3170.237589039703 epoch =  13  loss = 7345.882  loss reduction = -2424.271  correctly classified = 73.4250%\n",
      "alpha =  0.661578947368421 b =  -5048.482714302861 epoch =  14  loss = 19860.92  loss reduction = -12515.04  correctly classified = 28.1250%\n",
      "alpha =  0.661578947368421 b =  -4296.929030092334 epoch =  15  loss = 7877.702  loss reduction = 11983.22  correctly classified = 71.5000%\n",
      "alpha =  0.661578947368421 b =  -4160.733741671282 epoch =  16  loss = 4838.73  loss reduction = 3038.972  correctly classified = 82.5000%\n",
      "alpha =  0.661578947368421 b =  -4230.5382595660185 epoch =  17  loss = 4990.679  loss reduction = -151.9486  correctly classified = 81.9500%\n",
      "alpha =  0.661578947368421 b =  -3574.7216648291765 epoch =  18  loss = 7290.628  loss reduction = -2299.949  correctly classified = 73.6250%\n",
      "alpha =  0.661578947368421 b =  -5450.986022723913 epoch =  19  loss = 19854.02  loss reduction = -12563.39  correctly classified = 28.1500%\n",
      "alpha =  0.661578947368421 b =  -4699.432338513387 epoch =  20  loss = 7877.702  loss reduction = 11976.31  correctly classified = 71.5000%\n",
      "alpha =  0.661578947368421 b =  -4492.58968061865 epoch =  21  loss = 4859.451  loss reduction = 3018.252  correctly classified = 82.4250%\n",
      "alpha =  0.661578947368421 b =  -4922.893859566018 epoch =  22  loss = 6634.487  loss reduction = -1775.036  correctly classified = 76.0000%\n",
      "alpha =  0.661578947368421 b =  -4185.20554693444 epoch =  23  loss = 7732.661  loss reduction = -1098.174  correctly classified = 72.0250%\n",
      "alpha =  0.661578947368421 b =  -6007.328930092334 epoch =  24  loss = 19439.61  loss reduction = -11706.95  correctly classified = 29.6500%\n",
      "alpha =  0.661578947368421 b =  -5255.775245881808 epoch =  25  loss = 7877.702  loss reduction = 11561.91  correctly classified = 71.5000%\n",
      "alpha =  0.661578947368421 b =  -4720.125204829176 epoch =  26  loss = 6448.004  loss reduction = 1429.698  correctly classified = 76.6750%\n",
      "alpha =  0.661578947368421 b =  -6525.742193250229 epoch =  27  loss = 19377.45  loss reduction = -12929.44  correctly classified = 29.8750%\n",
      "alpha =  0.661578947368421 b =  -5774.188509039703 epoch =  28  loss = 7877.702  loss reduction = 11499.75  correctly classified = 71.5000%\n",
      "alpha =  0.661578947368421 b =  -5384.454997460755 epoch =  29  loss = 5791.863  loss reduction = 2085.84  correctly classified = 79.0500%\n",
      "alpha =  0.661578947368421 b =  -6677.053237460756 epoch =  30  loss = 14591.07  loss reduction = -8799.206  correctly classified = 47.2000%\n",
      "alpha =  0.661578947368421 b =  -5925.499553250229 epoch =  31  loss = 7877.702  loss reduction = 6713.366  correctly classified = 71.5000%\n",
      "alpha =  0.661578947368421 b =  -5787.323497460755 epoch =  32  loss = 4762.756  loss reduction = 3114.946  correctly classified = 82.7750%\n",
      "alpha =  0.661578947368421 b =  -5786.4806458818075 epoch =  33  loss = 4748.943  loss reduction = 13.81351  correctly classified = 82.8250%\n",
      "alpha =  0.661578947368421 b =  -5333.362578513386 epoch =  34  loss = 6095.76  loss reduction = -1346.817  correctly classified = 77.9500%\n",
      "alpha =  0.661578947368421 b =  -6798.947835355491 epoch =  35  loss = 16221.06  loss reduction = -10125.3  correctly classified = 41.3000%\n",
      "alpha =  0.661578947368421 b =  -6047.394151144965 epoch =  36  loss = 7877.702  loss reduction = 8343.36  correctly classified = 71.5000%\n",
      "alpha =  0.661578947368421 b =  -5810.839982723912 epoch =  37  loss = 4976.865  loss reduction = 2900.837  correctly classified = 82.0000%\n",
      "alpha =  0.661578947368421 b =  -6204.169837460754 epoch =  38  loss = 6358.216  loss reduction = -1381.351  correctly classified = 77.0000%\n",
      "alpha =  0.661578947368421 b =  -5523.9237785133855 epoch =  39  loss = 7449.484  loss reduction = -1091.267  correctly classified = 73.0500%\n",
      "alpha =  0.661578947368421 b =  -7114.957635355491 epoch =  40  loss = 17381.4  loss reduction = -9931.913  correctly classified = 37.1000%\n",
      "alpha =  0.661578947368421 b =  -6363.403951144965 epoch =  41  loss = 7877.702  loss reduction = 9503.695  correctly classified = 71.5000%\n",
      "alpha =  0.661578947368421 b =  -6177.689478513385 epoch =  42  loss = 4735.129  loss reduction = 3142.573  correctly classified = 82.8750%\n",
      "alpha =  0.661578947368421 b =  -6325.404179566017 epoch =  43  loss = 5059.746  loss reduction = -324.6175  correctly classified = 81.7000%\n",
      "alpha =  0.661578947368421 b =  -5754.100325881806 epoch =  44  loss = 6613.766  loss reduction = -1554.02  correctly classified = 76.0750%\n",
      "alpha =  0.661578947368421 b =  -7309.480370092333 epoch =  45  loss = 17022.25  loss reduction = -10408.48  correctly classified = 38.4000%\n",
      "alpha =  0.661578947368421 b =  -6557.926685881806 epoch =  46  loss = 7877.702  loss reduction = 9144.543  correctly classified = 71.5000%\n",
      "alpha =  0.661578947368421 b =  -6455.404442723911 epoch =  47  loss = 4596.994  loss reduction = 3280.709  correctly classified = 83.3750%\n",
      "alpha =  0.661578947368421 b =  -6281.574574302858 epoch =  48  loss = 4707.502  loss reduction = -110.5081  correctly classified = 82.9750%\n",
      "alpha =  0.661578947368421 b =  -6369.205998513385 epoch =  49  loss = 4804.197  loss reduction = -96.69457  correctly classified = 82.6250%\n",
      "alpha =  0.661578947368421 b =  -5878.453351144964 epoch =  50  loss = 6171.734  loss reduction = -1367.537  correctly classified = 77.6750%\n",
      "alpha =  0.661578947368421 b =  -7210.666938513385 epoch =  51  loss = 14894.97  loss reduction = -8723.231  correctly classified = 46.1000%\n",
      "alpha =  0.661578947368421 b =  -6459.113254302858 epoch =  52  loss = 7877.702  loss reduction = 7017.263  correctly classified = 71.5000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.661578947368421 b =  -6503.167796408121 epoch =  53  loss = 4652.248  loss reduction = 3225.454  correctly classified = 83.1750%\n",
      "alpha =  0.661578947368421 b =  -6076.4599606186475 epoch =  54  loss = 5888.557  loss reduction = -1236.309  correctly classified = 78.7000%\n",
      "alpha =  0.661578947368421 b =  -7173.622486934437 epoch =  55  loss = 12670.99  loss reduction = -6782.433  correctly classified = 54.1500%\n",
      "alpha =  0.661578947368421 b =  -6429.991872197595 epoch =  56  loss = 7794.821  loss reduction = 4876.169  correctly classified = 71.8000%\n",
      "alpha =  0.661578947368421 b =  -6943.488280618647 epoch =  57  loss = 7214.654  loss reduction = 580.1674  correctly classified = 73.9000%\n",
      "alpha =  0.661578947368421 b =  -6283.710151144963 epoch =  58  loss = 7235.374  loss reduction = -20.72026  correctly classified = 73.8250%\n",
      "alpha =  0.661578947368421 b =  -7600.737855355489 epoch =  59  loss = 14749.92  loss reduction = -7514.549  correctly classified = 46.6250%\n",
      "alpha =  0.661578947368421 b =  -6851.825194302857 epoch =  60  loss = 7850.075  loss reduction = 6899.848  correctly classified = 71.6000%\n",
      "alpha =  0.661578947368421 b =  -6992.277081671278 epoch =  61  loss = 4873.264  loss reduction = 2976.811  correctly classified = 82.3750%\n",
      "alpha =  0.661578947368421 b =  -6512.74878272391 epoch =  62  loss = 6081.946  loss reduction = -1208.682  correctly classified = 78.0000%\n",
      "alpha =  0.661578947368421 b =  -7621.795913250226 epoch =  63  loss = 12753.87  loss reduction = -6671.925  correctly classified = 53.8500%\n",
      "alpha =  0.661578947368421 b =  -6886.088367987068 epoch =  64  loss = 7711.94  loss reduction = 5041.931  correctly classified = 72.1000%\n",
      "alpha =  0.661578947368421 b =  -7394.962985881804 epoch =  65  loss = 7152.493  loss reduction = 559.4471  correctly classified = 74.1250%\n",
      "alpha =  0.661578947368421 b =  -6774.800203776541 epoch =  66  loss = 6903.85  loss reduction = 248.6432  correctly classified = 75.0250%\n",
      "alpha =  0.661578947368421 b =  -7998.731841671277 epoch =  67  loss = 13845.14  loss reduction = -6941.289  correctly classified = 49.9000%\n",
      "alpha =  0.661578947368421 b =  -7258.402505881803 epoch =  68  loss = 7760.288  loss reduction = 6084.851  correctly classified = 71.9250%\n",
      "alpha =  0.661578947368421 b =  -7564.578596408119 epoch =  69  loss = 5667.541  loss reduction = 2092.747  correctly classified = 79.5000%\n",
      "alpha =  0.661578947368421 b =  -7034.210601671277 epoch =  70  loss = 6365.123  loss reduction = -697.5822  correctly classified = 76.9750%\n",
      "alpha =  0.661578947368421 b =  -8143.917987987066 epoch =  71  loss = 12746.96  loss reduction = -6381.841  correctly classified = 53.8750%\n",
      "alpha =  0.661578947368421 b =  -7416.133512197593 epoch =  72  loss = 7629.059  loss reduction = 5117.905  correctly classified = 72.4000%\n",
      "alpha =  0.661578947368421 b =  -7948.777338513382 epoch =  73  loss = 7359.696  loss reduction = 269.3634  correctly classified = 73.3750%\n",
      "alpha =  0.661578947368421 b =  -7355.024787987067 epoch =  74  loss = 6751.901  loss reduction = 607.7944  correctly classified = 75.5750%\n",
      "alpha =  0.661578947368421 b =  -8453.507825881803 epoch =  75  loss = 12629.55  loss reduction = -5877.648  correctly classified = 54.3000%\n",
      "alpha =  0.661578947368421 b =  -7732.325907987066 epoch =  76  loss = 7587.619  loss reduction = 5041.931  correctly classified = 72.5500%\n",
      "alpha =  0.661578947368421 b =  -8274.213315355486 epoch =  77  loss = 7442.577  loss reduction = 145.0419  correctly classified = 73.0750%\n",
      "alpha =  0.661578947368421 b =  -7696.967159566012 epoch =  78  loss = 6634.487  loss reduction = 808.0903  correctly classified = 76.0000%\n",
      "alpha =  0.661578947368421 b =  -8736.027176408117 epoch =  79  loss = 12077.01  loss reduction = -5442.523  correctly classified = 56.3000%\n",
      "alpha =  0.661578947368421 b =  -8028.050374302854 epoch =  80  loss = 7477.111  loss reduction = 4599.899  correctly classified = 72.9500%\n",
      "alpha =  0.661578947368421 b =  -8633.982593250223 epoch =  81  loss = 8002.024  loss reduction = -524.9134  correctly classified = 71.0500%\n",
      "alpha =  0.661578947368421 b =  -8040.890298513381 epoch =  82  loss = 6731.181  loss reduction = 1270.843  correctly classified = 75.6500%\n",
      "alpha =  0.661578947368421 b =  -8996.097830092329 epoch =  83  loss = 11227.48  loss reduction = -4496.297  correctly classified = 59.3750%\n",
      "alpha =  0.661578947368421 b =  -8307.928701671277 epoch =  84  loss = 7311.349  loss reduction = 3916.13  correctly classified = 73.5500%\n",
      "alpha =  0.661578947368421 b =  -8981.867266934434 epoch =  85  loss = 8630.539  loss reduction = -1319.19  correctly classified = 68.7750%\n",
      "alpha =  0.661578947368421 b =  -8375.569856408118 epoch =  86  loss = 6758.808  loss reduction = 1871.731  correctly classified = 75.5500%\n",
      "alpha =  0.661578947368421 b =  -9274.655645881801 epoch =  87  loss = 10695.66  loss reduction = -3936.85  correctly classified = 61.3000%\n",
      "alpha =  0.661578947368421 b =  -8613.55700482917 epoch =  88  loss = 7249.188  loss reduction = 3446.471  correctly classified = 73.7750%\n",
      "alpha =  0.661578947368421 b =  -9339.65577746075 epoch =  89  loss = 9107.105  loss reduction = -1857.917  correctly classified = 67.0500%\n",
      "alpha =  0.661578947368421 b =  -8726.095553250223 epoch =  90  loss = 6807.155  loss reduction = 2299.949  correctly classified = 75.3750%\n",
      "alpha =  0.661578947368421 b =  -9544.630136408117 epoch =  91  loss = 9908.288  loss reduction = -3101.133  correctly classified = 64.1500%\n",
      "alpha =  0.661578947368421 b =  -8909.941726934434 epoch =  92  loss = 7014.358  loss reduction = 2893.93  correctly classified = 74.6250%\n",
      "alpha =  0.661578947368421 b =  -9688.860962723908 epoch =  93  loss = 9521.51  loss reduction = -2507.152  correctly classified = 65.5500%\n",
      "alpha =  0.661578947368421 b =  -9076.621250092328 epoch =  94  loss = 6807.155  loss reduction = 2714.355  correctly classified = 75.3750%\n",
      "alpha =  0.661578947368421 b =  -9837.05332377654 epoch =  95  loss = 9341.934  loss reduction = -2534.779  correctly classified = 66.2000%\n",
      "alpha =  0.661578947368421 b =  -9231.416169039698 epoch =  96  loss = 6751.901  loss reduction = 2590.033  correctly classified = 75.5750%\n",
      "alpha =  0.661578947368421 b =  -10005.713614302855 epoch =  97  loss = 9473.163  loss reduction = -2721.261  correctly classified = 65.7250%\n",
      "alpha =  0.661578947368421 b =  -9401.396971144959 epoch =  98  loss = 6751.901  loss reduction = 2721.261  correctly classified = 75.5750%\n",
      "alpha =  0.661578947368421 b =  -10155.886742723906 epoch =  99  loss = 9307.401  loss reduction = -2555.499  correctly classified = 66.3250%\n",
      "alpha =  0.661578947368421 b =  -9564.11495956601 epoch =  100  loss = 6662.114  loss reduction = 2645.287  correctly classified = 75.9000%\n",
      "alpha =  0.661578947368421 b =  -10278.329127987063 epoch =  101  loss = 8955.156  loss reduction = -2293.043  correctly classified = 67.6000%\n",
      "alpha =  0.661578947368421 b =  -9705.044506934431 epoch =  102  loss = 6565.419  loss reduction = 2389.737  correctly classified = 76.2500%\n",
      "alpha =  0.661578947368421 b =  -10421.239442723905 epoch =  103  loss = 8975.876  loss reduction = -2410.457  correctly classified = 67.5250%\n",
      "alpha =  0.661578947368421 b =  -9849.935589039695 epoch =  104  loss = 6558.512  loss reduction = 2417.364  correctly classified = 76.2750%\n",
      "alpha =  0.661578947368421 b =  -10557.54719956601 epoch =  105  loss = 8899.902  loss reduction = -2341.39  correctly classified = 67.8000%\n",
      "alpha =  0.661578947368421 b =  -9998.7882058818 epoch =  106  loss = 6468.724  loss reduction = 2431.178  correctly classified = 76.6000%\n",
      "alpha =  0.661578947368421 b =  -10650.938330092325 epoch =  107  loss = 8402.616  loss reduction = -1933.891  correctly classified = 69.6000%\n",
      "alpha =  0.661578947368421 b =  -10128.493404829167 epoch =  108  loss = 6226.988  loss reduction = 2175.628  correctly classified = 77.4750%\n",
      "alpha =  0.661578947368421 b =  -10729.143577460745 epoch =  109  loss = 7974.397  loss reduction = -1747.409  correctly classified = 71.1500%\n",
      "alpha =  0.661578947368421 b =  -10228.487093250218 epoch =  110  loss = 6081.946  loss reduction = 1892.451  correctly classified = 78.0000%\n",
      "alpha =  0.661578947368421 b =  -10795.46422061864 epoch =  111  loss = 7635.966  loss reduction = -1554.02  correctly classified = 72.3750%\n",
      "alpha =  0.661578947368421 b =  -10311.314131144956 epoch =  112  loss = 5992.158  loss reduction = 1643.808  correctly classified = 78.3250%\n",
      "alpha =  0.661578947368421 b =  -10862.44511956601 epoch =  113  loss = 7484.017  loss reduction = -1491.859  correctly classified = 72.9250%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.661578947368421 b =  -10396.782192197588 epoch =  114  loss = 5895.464  loss reduction = 1588.554  correctly classified = 78.6750%\n",
      "alpha =  0.661578947368421 b =  -10922.163204829167 epoch =  115  loss = 7269.908  loss reduction = -1374.444  correctly classified = 73.7000%\n",
      "alpha =  0.661578947368421 b =  -10480.269485881798 epoch =  116  loss = 5771.142  loss reduction = 1498.766  correctly classified = 79.1250%\n",
      "alpha =  0.661578947368421 b =  -10973.297964829166 epoch =  117  loss = 6945.291  loss reduction = -1174.148  correctly classified = 74.8750%\n",
      "alpha =  0.661578947368421 b =  -10545.269617460744 epoch =  118  loss = 5708.981  loss reduction = 1236.309  correctly classified = 79.3500%\n",
      "alpha =  0.661578947368421 b =  -11004.625051144954 epoch =  119  loss = 6648.3  loss reduction = -939.3186  correctly classified = 75.9500%\n",
      "alpha =  0.661578947368421 b =  -10589.141563776533 epoch =  120  loss = 5633.007  loss reduction = 1015.293  correctly classified = 79.6250%\n",
      "alpha =  0.661578947368421 b =  -11035.952137460743 epoch =  121  loss = 6544.699  loss reduction = -911.6916  correctly classified = 76.3250%\n",
      "alpha =  0.661578947368421 b =  -10622.449417460743 epoch =  122  loss = 5626.1  loss reduction = 918.5984  correctly classified = 79.6500%\n",
      "alpha =  0.661578947368421 b =  -11065.958712197584 epoch =  123  loss = 6510.165  loss reduction = -884.0646  correctly classified = 76.4500%\n",
      "alpha =  0.661578947368421 b =  -10653.776503776531 epoch =  124  loss = 5612.287  loss reduction = 897.8781  correctly classified = 79.7000%\n",
      "alpha =  0.661578947368421 b =  -11086.06145009232 epoch =  125  loss = 6434.191  loss reduction = -821.9038  correctly classified = 76.7250%\n",
      "alpha =  0.661578947368421 b =  -10677.84077640811 epoch =  126  loss = 5598.473  loss reduction = 835.7173  correctly classified = 79.7500%\n",
      "alpha =  0.661578947368421 b =  -11084.375746934425 epoch =  127  loss = 6220.081  loss reduction = -621.6079  correctly classified = 77.5000%\n",
      "alpha =  0.661578947368421 b =  -10684.738398513373 epoch =  128  loss = 5550.126  loss reduction = 669.9552  correctly classified = 79.9250%\n",
      "alpha =  0.661578947368421 b =  -11089.292601671268 epoch =  129  loss = 6199.361  loss reduction = -649.2349  correctly classified = 77.5750%\n",
      "alpha =  0.661578947368421 b =  -10689.655253250216 epoch =  130  loss = 5550.126  loss reduction = 649.2349  correctly classified = 79.9250%\n",
      "alpha =  0.661578947368421 b =  -11094.869712197584 epoch =  131  loss = 6192.454  loss reduction = -642.3282  correctly classified = 77.6000%\n",
      "alpha =  0.661578947368421 b =  -10695.892619566004 epoch =  132  loss = 5543.219  loss reduction = 649.2349  correctly classified = 79.9500%\n",
      "alpha =  0.661578947368421 b =  -11103.087845881793 epoch =  133  loss = 6185.548  loss reduction = -642.3282  correctly classified = 77.6250%\n",
      "alpha =  0.661578947368421 b =  -10702.790241671268 epoch =  134  loss = 5543.219  loss reduction = 642.3282  correctly classified = 79.9500%\n",
      "alpha =  0.661578947368421 b =  -11109.985467987057 epoch =  135  loss = 6171.734  loss reduction = -628.5147  correctly classified = 77.6750%\n",
      "alpha =  0.661578947368421 b =  -10708.367352197583 epoch =  136  loss = 5543.219  loss reduction = 628.5147  correctly classified = 79.9500%\n",
      "alpha =  0.661578947368421 b =  -11121.504880618635 epoch =  137  loss = 6220.081  loss reduction = -676.862  correctly classified = 77.5000%\n",
      "alpha =  0.661578947368421 b =  -10718.566253250214 epoch =  138  loss = 5543.219  loss reduction = 676.862  correctly classified = 79.9500%\n",
      "alpha =  0.661578947368421 b =  -11129.723014302845 epoch =  139  loss = 6213.175  loss reduction = -669.9552  correctly classified = 77.5250%\n",
      "alpha =  0.661578947368421 b =  -10726.784386934423 epoch =  140  loss = 5543.219  loss reduction = 669.9552  correctly classified = 79.9500%\n",
      "alpha =  0.661578947368421 b =  -11137.280892197581 epoch =  141  loss = 6220.081  loss reduction = -676.862  correctly classified = 77.5000%\n",
      "alpha =  0.661578947368421 b =  -10733.021753250212 epoch =  142  loss = 5529.406  loss reduction = 690.6755  correctly classified = 80.0000%\n",
      "alpha =  0.661578947368421 b =  -11144.838770092318 epoch =  143  loss = 6220.081  loss reduction = -690.6755  correctly classified = 77.5000%\n",
      "alpha =  0.661578947368421 b =  -10741.900142723896 epoch =  144  loss = 5529.406  loss reduction = 690.6755  correctly classified = 80.0000%\n",
      "alpha =  0.661578947368421 b =  -11150.415880618633 epoch =  145  loss = 6213.175  loss reduction = -683.7687  correctly classified = 77.5250%\n",
      "alpha =  0.661578947368421 b =  -10748.137509039685 epoch =  146  loss = 5522.499  loss reduction = 690.6755  correctly classified = 80.0250%\n",
      "alpha =  0.661578947368421 b =  -11150.71094482916 epoch =  147  loss = 6151.014  loss reduction = -628.5147  correctly classified = 77.7500%\n",
      "alpha =  0.661578947368421 b =  -10749.753084829159 epoch =  148  loss = 5508.686  loss reduction = 642.3282  correctly classified = 80.0750%\n",
      "alpha =  0.661578947368421 b =  -11151.006009039686 epoch =  149  loss = 6137.2  loss reduction = -628.5147  correctly classified = 77.8000%\n",
      "alpha =  0.661578947368421 b =  -10748.727637460737 epoch =  150  loss = 5494.872  loss reduction = 642.3282  correctly classified = 80.1250%\n",
      "alpha =  0.661578947368421 b =  -11144.698515355474 epoch =  151  loss = 6095.76  loss reduction = -600.8877  correctly classified = 77.9500%\n",
      "alpha =  0.661578947368421 b =  -10738.458609039684 epoch =  152  loss = 5494.872  loss reduction = 600.8877  correctly classified = 80.1250%\n",
      "alpha =  0.661578947368421 b =  -11135.089742723894 epoch =  153  loss = 6088.853  loss reduction = -593.9809  correctly classified = 77.9750%\n",
      "alpha =  0.661578947368421 b =  -10728.849836408104 epoch =  154  loss = 5494.872  loss reduction = 593.9809  correctly classified = 80.1250%\n",
      "alpha =  0.661578947368421 b =  -11125.480970092314 epoch =  155  loss = 6088.853  loss reduction = -593.9809  correctly classified = 77.9750%\n",
      "alpha =  0.661578947368421 b =  -10717.260296408103 epoch =  156  loss = 5487.965  loss reduction = 600.8877  correctly classified = 80.1500%\n",
      "alpha =  0.661578947368421 b =  -11121.154243776524 epoch =  157  loss = 6151.014  loss reduction = -663.0485  correctly classified = 77.7500%\n",
      "alpha =  0.661578947368421 b =  -10710.952802723892 epoch =  158  loss = 5494.872  loss reduction = 656.1417  correctly classified = 80.1250%\n",
      "alpha =  0.661578947368421 b =  -11114.846750092313 epoch =  159  loss = 6137.2  loss reduction = -642.3282  correctly classified = 77.8000%\n",
      "alpha =  0.661578947368421 b =  -10706.626076408102 epoch =  160  loss = 5474.152  loss reduction = 663.0485  correctly classified = 80.2000%\n",
      "alpha =  0.661578947368421 b =  -11108.539256408101 epoch =  161  loss = 6102.666  loss reduction = -628.5147  correctly classified = 77.9250%\n",
      "alpha =  0.661578947368421 b =  -10700.31858272389 epoch =  162  loss = 5474.152  loss reduction = 628.5147  correctly classified = 80.2000%\n",
      "alpha =  0.661578947368421 b =  -11102.23176272389 epoch =  163  loss = 6102.666  loss reduction = -628.5147  correctly classified = 77.9250%\n",
      "alpha =  0.661578947368421 b =  -10694.011089039679 epoch =  164  loss = 5460.338  loss reduction = 642.3282  correctly classified = 80.2500%\n",
      "alpha =  0.661578947368421 b =  -11095.924269039679 epoch =  165  loss = 6102.666  loss reduction = -642.3282  correctly classified = 77.9250%\n",
      "alpha =  0.661578947368421 b =  -10687.703595355468 epoch =  166  loss = 5460.338  loss reduction = 642.3282  correctly classified = 80.2500%\n",
      "alpha =  0.661578947368421 b =  -11090.937286934415 epoch =  167  loss = 6116.48  loss reduction = -656.1417  correctly classified = 77.8750%\n",
      "alpha =  0.661578947368421 b =  -10684.697380618625 epoch =  168  loss = 5439.618  loss reduction = 676.862  correctly classified = 80.3250%\n",
      "alpha =  0.661578947368421 b =  -11084.629793250204 epoch =  169  loss = 6081.946  loss reduction = -642.3282  correctly classified = 78.0000%\n",
      "alpha =  0.661578947368421 b =  -10679.710398513362 epoch =  170  loss = 5425.805  loss reduction = 656.1417  correctly classified = 80.3750%\n",
      "alpha =  0.661578947368421 b =  -11079.64281114494 epoch =  171  loss = 6081.946  loss reduction = -656.1417  correctly classified = 78.0000%\n",
      "alpha =  0.661578947368421 b =  -10672.742649039677 epoch =  172  loss = 5418.898  loss reduction = 663.0485  correctly classified = 80.4000%\n",
      "alpha =  0.661578947368421 b =  -11086.540433250204 epoch =  173  loss = 6185.548  loss reduction = -766.6498  correctly classified = 77.6250%\n",
      "alpha =  0.661578947368421 b =  -10672.37745746073 epoch =  174  loss = 5453.432  loss reduction = 732.116  correctly classified = 80.2750%\n",
      "alpha =  0.661578947368421 b =  -11090.797032197572 epoch =  175  loss = 6206.268  loss reduction = -752.8363  correctly classified = 77.5500%\n",
      "alpha =  0.661578947368421 b =  -10675.973800618623 epoch =  176  loss = 5446.525  loss reduction = 759.743  correctly classified = 80.3000%\n",
      "alpha =  0.661578947368421 b =  -11087.79081746073 epoch =  177  loss = 6151.014  loss reduction = -704.489  correctly classified = 77.7500%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.661578947368421 b =  -10676.929120618624 epoch =  178  loss = 5446.525  loss reduction = 704.489  correctly classified = 80.3000%\n",
      "alpha =  0.661578947368421 b =  -11092.047416408099 epoch =  179  loss = 6171.734  loss reduction = -725.2093  correctly classified = 77.6750%\n",
      "alpha =  0.661578947368421 b =  -10677.884440618625 epoch =  180  loss = 5439.618  loss reduction = 732.116  correctly classified = 80.3250%\n",
      "alpha =  0.661578947368421 b =  -11091.021969039677 epoch =  181  loss = 6151.014  loss reduction = -711.3957  correctly classified = 77.7500%\n",
      "alpha =  0.661578947368421 b =  -10677.519249039677 epoch =  182  loss = 5432.711  loss reduction = 718.3025  correctly classified = 80.3500%\n",
      "alpha =  0.661578947368421 b =  -11089.996521671255 epoch =  183  loss = 6157.921  loss reduction = -725.2093  correctly classified = 77.7250%\n",
      "alpha =  0.661578947368421 b =  -10677.15405746073 epoch =  184  loss = 5425.805  loss reduction = 732.116  correctly classified = 80.3750%\n",
      "alpha =  0.661578947368421 b =  -11092.932609039677 epoch =  185  loss = 6178.641  loss reduction = -752.8363  correctly classified = 77.6500%\n",
      "alpha =  0.661578947368421 b =  -10680.090144829152 epoch =  186  loss = 5425.805  loss reduction = 752.8363  correctly classified = 80.3750%\n",
      "alpha =  0.661578947368421 b =  -11093.887929039678 epoch =  187  loss = 6144.107  loss reduction = -718.3025  correctly classified = 77.7750%\n",
      "alpha =  0.661578947368421 b =  -10681.705720618625 epoch =  188  loss = 5418.898  loss reduction = 725.2093  correctly classified = 80.4000%\n",
      "alpha =  0.661578947368421 b =  -11096.8240164081 epoch =  189  loss = 6157.921  loss reduction = -739.0228  correctly classified = 77.7250%\n",
      "alpha =  0.661578947368421 b =  -10685.962319565995 epoch =  190  loss = 5418.898  loss reduction = 739.0228  correctly classified = 80.4000%\n",
      "alpha =  0.661578947368421 b =  -11095.79856903968 epoch =  191  loss = 6116.48  loss reduction = -697.5822  correctly classified = 77.8750%\n",
      "alpha =  0.661578947368421 b =  -10686.917639565996 epoch =  192  loss = 5398.177  loss reduction = 718.3025  correctly classified = 80.4750%\n",
      "alpha =  0.661578947368421 b =  -11088.170563776523 epoch =  193  loss = 6040.506  loss reduction = -642.3282  correctly classified = 78.1500%\n",
      "alpha =  0.661578947368421 b =  -10681.930657460733 epoch =  194  loss = 5370.55  loss reduction = 669.9552  correctly classified = 80.5750%\n",
      "alpha =  0.661578947368421 b =  -11083.18358167126 epoch =  195  loss = 6026.692  loss reduction = -656.1417  correctly classified = 78.2000%\n",
      "alpha =  0.661578947368421 b =  -10677.603931144944 epoch =  196  loss = 5363.644  loss reduction = 663.0485  correctly classified = 80.6000%\n",
      "alpha =  0.661578947368421 b =  -11076.87608798705 epoch =  197  loss = 6005.972  loss reduction = -642.3282  correctly classified = 78.2750%\n",
      "alpha =  0.661578947368421 b =  -10670.63618167126 epoch =  198  loss = 5356.737  loss reduction = 649.2349  correctly classified = 80.6250%\n",
      "alpha =  0.661578947368421 b =  -11069.908338513365 epoch =  199  loss = 6005.972  loss reduction = -649.2349  correctly classified = 78.2750%\n",
      "alpha =  0.661578947368421 b =  -10664.32868798705 epoch =  200  loss = 5349.83  loss reduction = 656.1417  correctly classified = 80.6500%\n",
      "alpha =  0.661578947368421 b =  -11064.261100618629 epoch =  201  loss = 5999.065  loss reduction = -649.2349  correctly classified = 78.3000%\n",
      "alpha =  0.661578947368421 b =  -10658.681450092314 epoch =  202  loss = 5349.83  loss reduction = 649.2349  correctly classified = 80.6500%\n",
      "alpha =  0.661578947368421 b =  -11059.274118513365 epoch =  203  loss = 6005.972  loss reduction = -656.1417  correctly classified = 78.2750%\n",
      "alpha =  0.661578947368421 b =  -10655.675235355471 epoch =  204  loss = 5329.11  loss reduction = 676.862  correctly classified = 80.7250%\n",
      "alpha =  0.661578947368421 b =  -11054.947392197577 epoch =  205  loss = 5992.158  loss reduction = -663.0485  correctly classified = 78.3250%\n",
      "alpha =  0.661578947368421 b =  -10650.688253250208 epoch =  206  loss = 5322.203  loss reduction = 669.9552  correctly classified = 80.7500%\n",
      "alpha =  0.661578947368421 b =  -11051.941177460734 epoch =  207  loss = 5985.252  loss reduction = -663.0485  correctly classified = 78.3500%\n",
      "alpha =  0.661578947368421 b =  -10647.682038513365 epoch =  208  loss = 5322.203  loss reduction = 663.0485  correctly classified = 80.7500%\n",
      "alpha =  0.661578947368421 b =  -11050.25547430284 epoch =  209  loss = 5957.625  loss reduction = -635.4214  correctly classified = 78.4500%\n",
      "alpha =  0.661578947368421 b =  -10647.316846934418 epoch =  210  loss = 5308.39  loss reduction = 649.2349  correctly classified = 80.8000%\n",
      "alpha =  0.661578947368421 b =  -11049.230026934418 epoch =  211  loss = 5936.904  loss reduction = -628.5147  correctly classified = 78.5250%\n",
      "alpha =  0.661578947368421 b =  -10647.611911144944 epoch =  212  loss = 5294.576  loss reduction = 642.3282  correctly classified = 80.8500%\n",
      "alpha =  0.661578947368421 b =  -11050.185346934419 epoch =  213  loss = 5943.811  loss reduction = -649.2349  correctly classified = 78.5000%\n",
      "alpha =  0.661578947368421 b =  -10647.906975355472 epoch =  214  loss = 5301.483  loss reduction = 642.3282  correctly classified = 80.8250%\n",
      "alpha =  0.661578947368421 b =  -11051.14066693442 epoch =  215  loss = 5950.718  loss reduction = -649.2349  correctly classified = 78.4750%\n",
      "alpha =  0.661578947368421 b =  -10646.88152798705 epoch =  216  loss = 5280.763  loss reduction = 669.9552  correctly classified = 80.9000%\n",
      "alpha =  0.661578947368421 b =  -11047.474196408104 epoch =  217  loss = 5923.091  loss reduction = -642.3282  correctly classified = 78.5750%\n",
      "alpha =  0.661578947368421 b =  -10644.535569039683 epoch =  218  loss = 5266.949  loss reduction = 656.1417  correctly classified = 80.9500%\n",
      "alpha =  0.661578947368421 b =  -11049.089772197578 epoch =  219  loss = 5950.718  loss reduction = -683.7687  correctly classified = 78.4750%\n",
      "alpha =  0.661578947368421 b =  -10644.830633250209 epoch =  220  loss = 5266.949  loss reduction = 683.7687  correctly classified = 80.9500%\n",
      "alpha =  0.661578947368421 b =  -11048.064324829156 epoch =  221  loss = 5923.091  loss reduction = -656.1417  correctly classified = 78.5750%\n",
      "alpha =  0.661578947368421 b =  -10643.805185881787 epoch =  222  loss = 5266.949  loss reduction = 656.1417  correctly classified = 80.9500%\n",
      "alpha =  0.661578947368421 b =  -11049.679900618628 epoch =  223  loss = 5936.904  loss reduction = -669.9552  correctly classified = 78.5250%\n",
      "alpha =  0.661578947368421 b =  -10643.439994302838 epoch =  224  loss = 5246.229  loss reduction = 690.6755  correctly classified = 81.0250%\n",
      "alpha =  0.661578947368421 b =  -11046.673685881786 epoch =  225  loss = 5923.091  loss reduction = -676.862  correctly classified = 78.5750%\n",
      "alpha =  0.661578947368421 b =  -10640.433779565996 epoch =  226  loss = 5246.229  loss reduction = 676.862  correctly classified = 81.0250%\n",
      "alpha =  0.661578947368421 b =  -11047.629005881785 epoch =  227  loss = 5950.718  loss reduction = -704.489  correctly classified = 78.4750%\n",
      "alpha =  0.661578947368421 b =  -10638.748076408101 epoch =  228  loss = 5246.229  loss reduction = 704.489  correctly classified = 81.0250%\n",
      "alpha =  0.661578947368421 b =  -11043.96253535547 epoch =  229  loss = 5929.998  loss reduction = -683.7687  correctly classified = 78.5500%\n",
      "alpha =  0.661578947368421 b =  -10634.42135009231 epoch =  230  loss = 5239.322  loss reduction = 690.6755  correctly classified = 81.0500%\n",
      "alpha =  0.661578947368421 b =  -11042.937087987048 epoch =  231  loss = 5936.904  loss reduction = -697.5822  correctly classified = 78.5250%\n",
      "alpha =  0.661578947368421 b =  -10634.716414302837 epoch =  232  loss = 5225.509  loss reduction = 711.3957  correctly classified = 81.1000%\n",
      "alpha =  0.661578947368421 b =  -11043.232152197574 epoch =  233  loss = 5936.904  loss reduction = -711.3957  correctly classified = 78.5250%\n",
      "alpha =  0.661578947368421 b =  -10635.011478513363 epoch =  234  loss = 5197.882  loss reduction = 739.0228  correctly classified = 81.2000%\n",
      "alpha =  0.661578947368421 b =  -11044.187472197573 epoch =  235  loss = 5943.811  loss reduction = -745.9295  correctly classified = 78.5000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.661578947368421 b =  -10637.28731009231 epoch =  236  loss = 5184.068  loss reduction = 759.743  correctly classified = 81.2500%\n",
      "alpha =  0.661578947368421 b =  -11039.20049009231 epoch =  237  loss = 5881.65  loss reduction = -697.5822  correctly classified = 78.7250%\n",
      "alpha =  0.661578947368421 b =  -10637.582374302836 epoch =  238  loss = 5184.068  loss reduction = 697.5822  correctly classified = 81.2500%\n",
      "alpha =  0.661578947368421 b =  -11021.668647987046 epoch =  239  loss = 5764.235  loss reduction = -580.1674  correctly classified = 79.1500%\n",
      "alpha =  0.661578947368421 b =  -10625.992834302835 epoch =  240  loss = 5135.721  loss reduction = 628.5147  correctly classified = 81.4250%\n",
      "alpha =  0.661578947368421 b =  -11000.17527114494 epoch =  241  loss = 5688.261  loss reduction = -552.5404  correctly classified = 79.4250%\n",
      "alpha =  0.661578947368421 b =  -10605.819969039678 epoch =  242  loss = 5121.907  loss reduction = 566.3539  correctly classified = 81.4750%\n",
      "alpha =  0.661578947368421 b =  -10981.32291746073 epoch =  243  loss = 5702.075  loss reduction = -580.1674  correctly classified = 79.3750%\n",
      "alpha =  0.661578947368421 b =  -10587.62787114494 epoch =  244  loss = 5101.187  loss reduction = 600.8877  correctly classified = 81.5500%\n",
      "alpha =  0.661578947368421 b =  -10958.509029039677 epoch =  245  loss = 5653.727  loss reduction = -552.5404  correctly classified = 79.5500%\n",
      "alpha =  0.661578947368421 b =  -10564.153726934413 epoch =  246  loss = 5108.094  loss reduction = 545.6336  correctly classified = 81.5250%\n",
      "alpha =  0.661578947368421 b =  -10937.675907987044 epoch =  247  loss = 5681.354  loss reduction = -573.2606  correctly classified = 79.4500%\n",
      "alpha =  0.661578947368421 b =  -10544.64111746073 epoch =  248  loss = 5094.28  loss reduction = 587.0742  correctly classified = 81.5750%\n",
      "alpha =  0.661578947368421 b =  -10915.522275355466 epoch =  249  loss = 5653.727  loss reduction = -559.4471  correctly classified = 79.5500%\n",
      "alpha =  0.661578947368421 b =  -10521.827229039676 epoch =  250  loss = 5101.187  loss reduction = 552.5404  correctly classified = 81.5500%\n",
      "alpha =  0.661578947368421 b =  -10894.689154302834 epoch =  251  loss = 5674.448  loss reduction = -573.2606  correctly classified = 79.4750%\n",
      "alpha =  0.661578947368421 b =  -10502.314619565992 epoch =  252  loss = 5101.187  loss reduction = 573.2606  correctly classified = 81.5500%\n",
      "alpha =  0.661578947368421 b =  -10872.535521671256 epoch =  253  loss = 5646.821  loss reduction = -545.6336  correctly classified = 79.5750%\n",
      "alpha =  0.661578947368421 b =  -10479.50073114494 epoch =  254  loss = 5108.094  loss reduction = 538.7269  correctly classified = 81.5250%\n",
      "alpha =  0.661578947368421 b =  -10853.022912197572 epoch =  255  loss = 5681.354  loss reduction = -573.2606  correctly classified = 79.4500%\n",
      "alpha =  0.661578947368421 b =  -10459.988121671257 epoch =  256  loss = 5108.094  loss reduction = 573.2606  correctly classified = 81.5250%\n",
      "alpha =  0.661578947368421 b =  -10834.170558513362 epoch =  257  loss = 5688.261  loss reduction = -580.1674  correctly classified = 79.4250%\n",
      "alpha =  0.661578947368421 b =  -10431.231931144941 epoch =  258  loss = 5004.492  loss reduction = 683.7687  correctly classified = 81.9000%\n",
      "alpha =  0.661578947368421 b =  -10807.395135355468 epoch =  259  loss = 5681.354  loss reduction = -676.862  correctly classified = 79.4500%\n",
      "alpha =  0.661578947368421 b =  -10404.456507987046 epoch =  260  loss = 5004.492  loss reduction = 676.862  correctly classified = 81.9000%\n",
      "alpha =  0.661578947368421 b =  -10779.959456408098 epoch =  261  loss = 5674.448  loss reduction = -669.9552  correctly classified = 79.4750%\n",
      "alpha =  0.661578947368421 b =  -10377.020829039677 epoch =  262  loss = 5004.492  loss reduction = 669.9552  correctly classified = 81.9000%\n",
      "alpha =  0.661578947368421 b =  -10753.184033250203 epoch =  263  loss = 5667.541  loss reduction = -663.0485  correctly classified = 79.5000%\n",
      "alpha =  0.661578947368421 b =  -10348.924894302834 epoch =  264  loss = 4990.679  loss reduction = 676.862  correctly classified = 81.9500%\n",
      "alpha =  0.661578947368421 b =  -10731.690656408098 epoch =  265  loss = 5695.168  loss reduction = -704.489  correctly classified = 79.4000%\n",
      "alpha =  0.661578947368421 b =  -10328.091773250204 epoch =  266  loss = 4997.586  loss reduction = 697.5822  correctly classified = 81.9250%\n",
      "alpha =  0.661578947368421 b =  -10706.896000618624 epoch =  267  loss = 5681.354  loss reduction = -683.7687  correctly classified = 79.4500%\n",
      "alpha =  0.661578947368421 b =  -10303.957373250203 epoch =  268  loss = 4990.679  loss reduction = 690.6755  correctly classified = 81.9500%\n",
      "alpha =  0.661578947368421 b =  -10678.139810092309 epoch =  269  loss = 5646.821  loss reduction = -656.1417  correctly classified = 79.5750%\n",
      "alpha =  0.661578947368421 b =  -10275.201182723888 epoch =  270  loss = 5004.492  loss reduction = 642.3282  correctly classified = 81.9000%\n",
      "alpha =  0.661578947368421 b =  -10655.986177460729 epoch =  271  loss = 5674.448  loss reduction = -669.9552  correctly classified = 79.4750%\n",
      "alpha =  0.661578947368421 b =  -10252.387294302835 epoch =  272  loss = 4997.586  loss reduction = 676.862  correctly classified = 81.9250%\n",
      "alpha =  0.661578947368421 b =  -10631.191521671255 epoch =  273  loss = 5667.541  loss reduction = -669.9552  correctly classified = 79.5000%\n",
      "alpha =  0.661578947368421 b =  -10227.59263851336 epoch =  274  loss = 4997.586  loss reduction = 669.9552  correctly classified = 81.9250%\n",
      "alpha =  0.661578947368421 b =  -10608.377633250202 epoch =  275  loss = 5660.634  loss reduction = -663.0485  correctly classified = 79.5250%\n",
      "alpha =  0.661578947368421 b =  -10202.797982723887 epoch =  276  loss = 4990.679  loss reduction = 669.9552  correctly classified = 81.9500%\n",
      "alpha =  0.661578947368421 b =  -10584.243233250203 epoch =  277  loss = 5639.914  loss reduction = -649.2349  correctly classified = 79.6000%\n",
      "alpha =  0.661578947368421 b =  -10178.663582723888 epoch =  278  loss = 4990.679  loss reduction = 649.2349  correctly classified = 81.9500%\n",
      "alpha =  0.661578947368421 b =  -10561.429344829152 epoch =  279  loss = 5639.914  loss reduction = -649.2349  correctly classified = 79.6000%\n",
      "alpha =  0.661578947368421 b =  -10155.849694302837 epoch =  280  loss = 4990.679  loss reduction = 649.2349  correctly classified = 81.9500%\n",
      "alpha =  0.661578947368421 b =  -10535.314177460732 epoch =  281  loss = 5633.007  loss reduction = -642.3282  correctly classified = 79.6250%\n",
      "alpha =  0.661578947368421 b =  -10129.734526934417 epoch =  282  loss = 4990.679  loss reduction = 642.3282  correctly classified = 81.9500%\n",
      "alpha =  0.661578947368421 b =  -10510.519521671258 epoch =  283  loss = 5633.007  loss reduction = -642.3282  correctly classified = 79.6250%\n",
      "alpha =  0.661578947368421 b =  -10104.279615355468 epoch =  284  loss = 4983.772  loss reduction = 649.2349  correctly classified = 81.9750%\n",
      "alpha =  0.661578947368421 b =  -10489.026144829153 epoch =  285  loss = 5633.007  loss reduction = -649.2349  correctly classified = 79.6250%\n",
      "alpha =  0.661578947368421 b =  -10082.786238513363 epoch =  286  loss = 4983.772  loss reduction = 649.2349  correctly classified = 81.9750%\n",
      "alpha =  0.661578947368421 b =  -10467.532767987048 epoch =  287  loss = 5633.007  loss reduction = -649.2349  correctly classified = 79.6250%\n",
      "alpha =  0.661578947368421 b =  -10061.292861671258 epoch =  288  loss = 4983.772  loss reduction = 649.2349  correctly classified = 81.9750%\n",
      "alpha =  0.661578947368421 b =  -10443.398367987047 epoch =  289  loss = 5605.38  loss reduction = -621.6079  correctly classified = 79.7250%\n",
      "alpha =  0.661578947368421 b =  -10037.818717460732 epoch =  290  loss = 4976.865  loss reduction = 628.5147  correctly classified = 82.0000%\n",
      "alpha =  0.661578947368421 b =  -10421.904991144942 epoch =  291  loss = 5612.287  loss reduction = -635.4214  correctly classified = 79.7000%\n",
      "alpha =  0.661578947368421 b =  -10016.325340618627 epoch =  292  loss = 4976.865  loss reduction = 635.4214  correctly classified = 82.0000%\n",
      "alpha =  0.661578947368421 b =  -10401.732125881785 epoch =  293  loss = 5612.287  loss reduction = -635.4214  correctly classified = 79.7000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.661578947368421 b =  -9996.15247535547 epoch =  294  loss = 4976.865  loss reduction = 635.4214  correctly classified = 82.0000%\n",
      "alpha =  0.661578947368421 b =  -10380.899004829154 epoch =  295  loss = 5619.194  loss reduction = -642.3282  correctly classified = 79.6750%\n",
      "alpha =  0.661578947368421 b =  -9974.659098513364 epoch =  296  loss = 4969.959  loss reduction = 649.2349  correctly classified = 82.0250%\n",
      "alpha =  0.661578947368421 b =  -10360.065883776522 epoch =  297  loss = 5598.473  loss reduction = -628.5147  correctly classified = 79.7500%\n",
      "alpha =  0.661578947368421 b =  -9954.486233250207 epoch =  298  loss = 4963.052  loss reduction = 635.4214  correctly classified = 82.0500%\n",
      "alpha =  0.661578947368421 b =  -10341.213530092313 epoch =  299  loss = 5598.473  loss reduction = -635.4214  correctly classified = 79.7500%\n",
      "alpha =  0.661578947368421 b =  -9936.29413535547 epoch =  300  loss = 4956.145  loss reduction = 642.3282  correctly classified = 82.0750%\n",
      "alpha =  0.661578947368421 b =  -10322.361176408102 epoch =  301  loss = 5605.38  loss reduction = -649.2349  correctly classified = 79.7250%\n",
      "alpha =  0.661578947368421 b =  -9918.102037460732 epoch =  302  loss = 4949.238  loss reduction = 656.1417  correctly classified = 82.1000%\n",
      "alpha =  0.661578947368421 b =  -10303.50882272389 epoch =  303  loss = 5598.473  loss reduction = -649.2349  correctly classified = 79.7500%\n",
      "alpha =  0.661578947368421 b =  -9899.249683776521 epoch =  304  loss = 4949.238  loss reduction = 649.2349  correctly classified = 82.1000%\n",
      "alpha =  0.661578947368421 b =  -10284.656469039679 epoch =  305  loss = 5598.473  loss reduction = -649.2349  correctly classified = 79.7500%\n",
      "alpha =  0.661578947368421 b =  -9880.39733009231 epoch =  306  loss = 4949.238  loss reduction = 649.2349  correctly classified = 82.1000%\n",
      "alpha =  0.661578947368421 b =  -10265.804115355468 epoch =  307  loss = 5598.473  loss reduction = -649.2349  correctly classified = 79.7500%\n",
      "alpha =  0.661578947368421 b =  -9861.544976408099 epoch =  308  loss = 4949.238  loss reduction = 649.2349  correctly classified = 82.1000%\n",
      "alpha =  0.661578947368421 b =  -10246.951761671256 epoch =  309  loss = 5598.473  loss reduction = -649.2349  correctly classified = 79.7500%\n",
      "alpha =  0.661578947368421 b =  -9842.032366934414 epoch =  310  loss = 4956.145  loss reduction = 642.3282  correctly classified = 82.0750%\n",
      "alpha =  0.661578947368421 b =  -10228.099407987045 epoch =  311  loss = 5605.38  loss reduction = -649.2349  correctly classified = 79.7250%\n",
      "alpha =  0.661578947368421 b =  -9823.180013250203 epoch =  312  loss = 4956.145  loss reduction = 649.2349  correctly classified = 82.0750%\n",
      "alpha =  0.661578947368421 b =  -10209.247054302834 epoch =  313  loss = 5605.38  loss reduction = -649.2349  correctly classified = 79.7250%\n",
      "alpha =  0.661578947368421 b =  -9804.327659565992 epoch =  314  loss = 4956.145  loss reduction = 649.2349  correctly classified = 82.0750%\n",
      "alpha =  0.661578947368421 b =  -10190.394700618623 epoch =  315  loss = 5605.38  loss reduction = -649.2349  correctly classified = 79.7250%\n",
      "alpha =  0.661578947368421 b =  -9787.456073250201 epoch =  316  loss = 4935.425  loss reduction = 669.9552  correctly classified = 82.1500%\n",
      "alpha =  0.661578947368421 b =  -10162.29876588178 epoch =  317  loss = 5501.779  loss reduction = -566.3539  correctly classified = 80.1000%\n",
      "alpha =  0.661578947368421 b =  -9765.962696408096 epoch =  318  loss = 4893.984  loss reduction = 607.7944  correctly classified = 82.3000%\n",
      "alpha =  0.661578947368421 b =  -10134.863086934412 epoch =  319  loss = 5467.245  loss reduction = -573.2606  correctly classified = 80.2250%\n",
      "alpha =  0.661578947368421 b =  -9745.129575355466 epoch =  320  loss = 4866.357  loss reduction = 600.8877  correctly classified = 82.4000%\n",
      "alpha =  0.661578947368421 b =  -10088.279990092307 epoch =  321  loss = 5239.322  loss reduction = -372.9648  correctly classified = 81.0500%\n",
      "alpha =  0.661578947368421 b =  -9706.469547987044 epoch =  322  loss = 4838.73  loss reduction = 400.5918  correctly classified = 82.5000%\n",
      "alpha =  0.661578947368421 b =  -10033.113567987044 epoch =  323  loss = 5121.907  loss reduction = -283.1769  correctly classified = 81.4750%\n",
      "alpha =  0.661578947368421 b =  -9663.187730092308 epoch =  324  loss = 4755.849  loss reduction = 366.058  correctly classified = 82.8000%\n",
      "alpha =  0.661578947368421 b =  -9962.761262723887 epoch =  325  loss = 4921.611  loss reduction = -165.7621  correctly classified = 82.2000%\n",
      "alpha =  0.661578947368421 b =  -9598.777726934413 epoch =  326  loss = 4721.316  loss reduction = 200.2959  correctly classified = 82.9250%\n",
      "alpha =  0.661578947368421 b =  -9897.030747987044 epoch =  327  loss = 4907.798  loss reduction = -186.4824  correctly classified = 82.2500%\n",
      "alpha =  0.661578947368421 b =  -9533.04721219757 epoch =  328  loss = 4721.316  loss reduction = 186.4824  correctly classified = 82.9250%\n",
      "alpha =  0.661578947368421 b =  -9831.300233250202 epoch =  329  loss = 4907.798  loss reduction = -186.4824  correctly classified = 82.2500%\n",
      "alpha =  0.661578947368421 b =  -9466.656441671255 epoch =  330  loss = 4714.409  loss reduction = 193.3891  correctly classified = 82.9500%\n",
      "alpha =  0.661578947368421 b =  -9766.890230092307 epoch =  331  loss = 4914.705  loss reduction = -200.2959  correctly classified = 82.2250%\n",
      "alpha =  0.661578947368421 b =  -9401.586182723886 epoch =  332  loss = 4721.316  loss reduction = 193.3891  correctly classified = 82.9250%\n",
      "alpha =  0.661578947368421 b =  -9702.480226934413 epoch =  333  loss = 4921.611  loss reduction = -200.2959  correctly classified = 82.2000%\n",
      "alpha =  0.661578947368421 b =  -9335.855667987043 epoch =  334  loss = 4721.316  loss reduction = 200.2959  correctly classified = 82.9250%\n",
      "alpha =  0.661578947368421 b =  -9638.070223776516 epoch =  335  loss = 4935.425  loss reduction = -214.1094  correctly classified = 82.1500%\n",
      "alpha =  0.661578947368421 b =  -9271.445664829147 epoch =  336  loss = 4721.316  loss reduction = 214.1094  correctly classified = 82.9250%\n",
      "alpha =  0.661578947368421 b =  -9573.66022061862 epoch =  337  loss = 4935.425  loss reduction = -214.1094  correctly classified = 82.1500%\n",
      "alpha =  0.661578947368421 b =  -9205.05489430283 epoch =  338  loss = 4728.222  loss reduction = 207.2026  correctly classified = 82.9000%\n",
      "alpha =  0.661578947368421 b =  -9515.85277535546 epoch =  339  loss = 4956.145  loss reduction = -227.9229  correctly classified = 82.0750%\n",
      "alpha =  0.661578947368421 b =  -9143.946170092302 epoch =  340  loss = 4735.129  loss reduction = 221.0162  correctly classified = 82.8750%\n",
      "alpha =  0.661578947368421 b =  -9467.288911144933 epoch =  341  loss = 5018.306  loss reduction = -283.1769  correctly classified = 81.8500%\n",
      "alpha =  0.661578947368421 b =  -9091.420771144933 epoch =  342  loss = 4748.943  loss reduction = 269.3634  correctly classified = 82.8250%\n",
      "alpha =  0.661578947368421 b =  -9431.93016272388 epoch =  343  loss = 5170.255  loss reduction = -421.312  correctly classified = 81.3000%\n",
      "alpha =  0.661578947368421 b =  -9050.119720618617 epoch =  344  loss = 4783.476  loss reduction = 386.7783  correctly classified = 82.7000%\n",
      "alpha =  0.661578947368421 b =  -9398.552181671248 epoch =  345  loss = 5225.509  loss reduction = -442.0323  correctly classified = 81.1000%\n",
      "alpha =  0.661578947368421 b =  -9016.741739565985 epoch =  346  loss = 4783.476  loss reduction = 442.0323  correctly classified = 82.7000%\n",
      "alpha =  0.661578947368421 b =  -9365.174200618616 epoch =  347  loss = 5225.509  loss reduction = -442.0323  correctly classified = 81.1000%\n",
      "alpha =  0.661578947368421 b =  -8981.382991144932 epoch =  348  loss = 4804.197  loss reduction = 421.312  correctly classified = 82.6250%\n",
      "alpha =  0.661578947368421 b =  -9329.815452197563 epoch =  349  loss = 5225.509  loss reduction = -421.312  correctly classified = 81.1000%\n",
      "alpha =  0.661578947368421 b =  -8947.344754302827 epoch =  350  loss = 4790.383  loss reduction = 435.1256  correctly classified = 82.6750%\n",
      "alpha =  0.661578947368421 b =  -9295.116959565985 epoch =  351  loss = 5218.602  loss reduction = -428.2188  correctly classified = 81.1250%\n",
      "alpha =  0.661578947368421 b =  -8913.306517460722 epoch =  352  loss = 4783.476  loss reduction = 435.1256  correctly classified = 82.7000%\n",
      "alpha =  0.661578947368421 b =  -9261.738978513353 epoch =  353  loss = 5211.695  loss reduction = -428.2188  correctly classified = 81.1500%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.661578947368421 b =  -8879.268280618617 epoch =  354  loss = 4790.383  loss reduction = 421.312  correctly classified = 82.6750%\n",
      "alpha =  0.661578947368421 b =  -9227.040485881775 epoch =  355  loss = 5204.788  loss reduction = -414.4053  correctly classified = 81.1750%\n",
      "alpha =  0.661578947368421 b =  -8844.569787987039 epoch =  356  loss = 4790.383  loss reduction = 414.4053  correctly classified = 82.6750%\n",
      "alpha =  0.661578947368421 b =  -9193.00224903967 epoch =  357  loss = 5197.882  loss reduction = -407.4985  correctly classified = 81.2000%\n",
      "alpha =  0.661578947368421 b =  -8811.191806934406 epoch =  358  loss = 4797.29  loss reduction = 400.5918  correctly classified = 82.6500%\n",
      "alpha =  0.661578947368421 b =  -9159.624267987037 epoch =  359  loss = 5197.882  loss reduction = -400.5918  correctly classified = 81.2000%\n",
      "alpha =  0.661578947368421 b =  -8777.813825881774 epoch =  360  loss = 4797.29  loss reduction = 400.5918  correctly classified = 82.6500%\n",
      "alpha =  0.661578947368421 b =  -9125.586031144932 epoch =  361  loss = 5190.975  loss reduction = -393.685  correctly classified = 81.2250%\n",
      "alpha =  0.661578947368421 b =  -8744.435844829142 epoch =  362  loss = 4790.383  loss reduction = 400.5918  correctly classified = 82.6750%\n",
      "alpha =  0.661578947368421 b =  -9090.887538513352 epoch =  363  loss = 5177.161  loss reduction = -386.7783  correctly classified = 81.2750%\n",
      "alpha =  0.661578947368421 b =  -8710.397607987037 epoch =  364  loss = 4783.476  loss reduction = 393.685  correctly classified = 82.7000%\n",
      "alpha =  0.661578947368421 b =  -9057.509557460722 epoch =  365  loss = 5184.068  loss reduction = -400.5918  correctly classified = 81.2500%\n",
      "alpha =  0.661578947368421 b =  -8675.699115355459 epoch =  366  loss = 4797.29  loss reduction = 386.7783  correctly classified = 82.6500%\n",
      "alpha =  0.661578947368421 b =  -9022.15080903967 epoch =  367  loss = 5177.161  loss reduction = -379.8715  correctly classified = 81.2750%\n",
      "alpha =  0.661578947368421 b =  -8641.660878513354 epoch =  368  loss = 4783.476  loss reduction = 393.685  correctly classified = 82.7000%\n",
      "alpha =  0.661578947368421 b =  -8988.772827987039 epoch =  369  loss = 5184.068  loss reduction = -400.5918  correctly classified = 81.2500%\n",
      "alpha =  0.661578947368421 b =  -8607.622641671249 epoch =  370  loss = 4790.383  loss reduction = 393.685  correctly classified = 82.6750%\n",
      "alpha =  0.661578947368421 b =  -8952.753823776511 epoch =  371  loss = 5163.348  loss reduction = -372.9648  correctly classified = 81.3250%\n",
      "alpha =  0.661578947368421 b =  -8574.244660618617 epoch =  372  loss = 4762.756  loss reduction = 400.5918  correctly classified = 82.7750%\n",
      "alpha =  0.661578947368421 b =  -8920.696354302827 epoch =  373  loss = 5177.161  loss reduction = -414.4053  correctly classified = 81.2750%\n",
      "alpha =  0.661578947368421 b =  -8541.526935355458 epoch =  374  loss = 4769.663  loss reduction = 407.4985  correctly classified = 82.7500%\n",
      "alpha =  0.661578947368421 b =  -8885.337605881774 epoch =  375  loss = 5149.534  loss reduction = -379.8715  correctly classified = 81.3750%\n",
      "alpha =  0.661578947368421 b =  -8506.82844272388 epoch =  376  loss = 4762.756  loss reduction = 386.7783  correctly classified = 82.7750%\n",
      "alpha =  0.661578947368421 b =  -8853.28013640809 epoch =  377  loss = 5177.161  loss reduction = -414.4053  correctly classified = 81.2750%\n",
      "alpha =  0.661578947368421 b =  -8474.770973250195 epoch =  378  loss = 4762.756  loss reduction = 414.4053  correctly classified = 82.7750%\n",
      "alpha =  0.661578947368421 b =  -8818.581643776512 epoch =  379  loss = 5135.721  loss reduction = -372.9648  correctly classified = 81.4250%\n",
      "alpha =  0.661578947368421 b =  -8440.072480618617 epoch =  380  loss = 4762.756  loss reduction = 372.9648  correctly classified = 82.7750%\n",
      "alpha =  0.661578947368421 b =  -8787.184430092302 epoch =  381  loss = 5156.441  loss reduction = -393.685  correctly classified = 81.3500%\n",
      "alpha =  0.661578947368421 b =  -8408.675266934408 epoch =  382  loss = 4762.756  loss reduction = 393.685  correctly classified = 82.7750%\n",
      "alpha =  0.661578947368421 b =  -8754.466704829145 epoch =  383  loss = 5142.628  loss reduction = -379.8715  correctly classified = 81.4000%\n",
      "alpha =  0.661578947368421 b =  -8375.95754167125 epoch =  384  loss = 4762.756  loss reduction = 379.8715  correctly classified = 82.7750%\n",
      "alpha =  0.661578947368421 b =  -8723.729746934408 epoch =  385  loss = 5163.348  loss reduction = -400.5918  correctly classified = 81.3250%\n",
      "alpha =  0.661578947368421 b =  -8345.220583776514 epoch =  386  loss = 4762.756  loss reduction = 400.5918  correctly classified = 82.7750%\n",
      "alpha =  0.661578947368421 b =  -8689.691510092303 epoch =  387  loss = 5128.814  loss reduction = -366.058  correctly classified = 81.4500%\n",
      "alpha =  0.661578947368421 b =  -8313.16311430283 epoch =  388  loss = 4742.036  loss reduction = 386.7783  correctly classified = 82.8500%\n",
      "alpha =  0.661578947368421 b =  -8663.576342723882 epoch =  389  loss = 5177.161  loss reduction = -435.1256  correctly classified = 81.2750%\n",
      "alpha =  0.661578947368421 b =  -8284.406923776512 epoch =  390  loss = 4755.849  loss reduction = 421.312  correctly classified = 82.8000%\n",
      "alpha =  0.661578947368421 b =  -8630.858617460723 epoch =  391  loss = 5135.721  loss reduction = -379.8715  correctly classified = 81.4250%\n",
      "alpha =  0.661578947368421 b =  -8254.33022167125 epoch =  392  loss = 4742.036  loss reduction = 393.685  correctly classified = 82.8500%\n",
      "alpha =  0.661578947368421 b =  -8604.083194302828 epoch =  393  loss = 5156.441  loss reduction = -414.4053  correctly classified = 81.3500%\n",
      "alpha =  0.661578947368421 b =  -8224.913775355459 epoch =  394  loss = 4755.849  loss reduction = 400.5918  correctly classified = 82.8000%\n",
      "alpha =  0.661578947368421 b =  -8574.006492197565 epoch =  395  loss = 5149.534  loss reduction = -393.685  correctly classified = 81.3750%\n",
      "alpha =  0.661578947368421 b =  -8196.157584829143 epoch =  396  loss = 4742.036  loss reduction = 407.4985  correctly classified = 82.8500%\n",
      "alpha =  0.661578947368421 b =  -8546.570813250195 epoch =  397  loss = 5149.534  loss reduction = -407.4985  correctly classified = 81.3750%\n",
      "alpha =  0.661578947368421 b =  -8167.401394302827 epoch =  398  loss = 4755.849  loss reduction = 393.685  correctly classified = 82.8000%\n",
      "alpha =  0.661578947368421 b =  -8514.51334377651 epoch =  399  loss = 5128.814  loss reduction = -372.9648  correctly classified = 81.4500%\n",
      "alpha =  0.661578947368421 b =  -8136.664436408089 epoch =  400  loss = 4742.036  loss reduction = 386.7783  correctly classified = 82.8500%\n",
      "alpha =  0.661578947368421 b =  -8484.436641671247 epoch =  401  loss = 5121.907  loss reduction = -379.8715  correctly classified = 81.4750%\n",
      "alpha =  0.661578947368421 b =  -8107.2479900923 epoch =  402  loss = 4735.129  loss reduction = 386.7783  correctly classified = 82.8750%\n",
      "alpha =  0.661578947368421 b =  -8455.680451144932 epoch =  403  loss = 5128.814  loss reduction = -393.685  correctly classified = 81.4500%\n",
      "alpha =  0.661578947368421 b =  -8078.491799565984 epoch =  404  loss = 4735.129  loss reduction = 393.685  correctly classified = 82.8750%\n",
      "alpha =  0.661578947368421 b =  -8426.924260618616 epoch =  405  loss = 5128.814  loss reduction = -393.685  correctly classified = 81.4500%\n",
      "alpha =  0.661578947368421 b =  -8049.735609039669 epoch =  406  loss = 4735.129  loss reduction = 393.685  correctly classified = 82.8750%\n",
      "alpha =  0.661578947368421 b =  -8396.18730272388 epoch =  407  loss = 5108.094  loss reduction = -372.9648  correctly classified = 81.5250%\n",
      "alpha =  0.661578947368421 b =  -8019.658906934406 epoch =  408  loss = 4728.222  loss reduction = 379.8715  correctly classified = 82.9000%\n",
      "alpha =  0.661578947368421 b =  -8366.770856408091 epoch =  409  loss = 5115.001  loss reduction = -386.7783  correctly classified = 81.5000%\n",
      "alpha =  0.661578947368421 b =  -7989.582204829144 epoch =  410  loss = 4721.316  loss reduction = 393.685  correctly classified = 82.9250%\n",
      "alpha =  0.661578947368421 b =  -8336.694154302828 epoch =  411  loss = 5115.001  loss reduction = -393.685  correctly classified = 81.5000%\n",
      "alpha =  0.661578947368421 b =  -7959.50550272388 epoch =  412  loss = 4721.316  loss reduction = 393.685  correctly classified = 82.9250%\n",
      "alpha =  0.661578947368421 b =  -8306.617452197564 epoch =  413  loss = 5115.001  loss reduction = -393.685  correctly classified = 81.5000%\n",
      "alpha =  0.661578947368421 b =  -7931.409567987038 epoch =  414  loss = 4700.595  loss reduction = 414.4053  correctly classified = 83.0000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.661578947368421 b =  -8277.201005881774 epoch =  415  loss = 5101.187  loss reduction = -400.5918  correctly classified = 81.5500%\n",
      "alpha =  0.661578947368421 b =  -7901.9931216712475 epoch =  416  loss = 4700.595  loss reduction = 400.5918  correctly classified = 83.0000%\n",
      "alpha =  0.661578947368421 b =  -8247.784559565984 epoch =  417  loss = 5101.187  loss reduction = -400.5918  correctly classified = 81.5500%\n",
      "alpha =  0.661578947368421 b =  -7872.576675355457 epoch =  418  loss = 4700.595  loss reduction = 400.5918  correctly classified = 83.0000%\n",
      "alpha =  0.661578947368421 b =  -8217.70785746072 epoch =  419  loss = 5094.28  loss reduction = -393.685  correctly classified = 81.5750%\n",
      "alpha =  0.661578947368421 b =  -7843.160229039668 epoch =  420  loss = 4693.688  loss reduction = 400.5918  correctly classified = 83.0250%\n",
      "alpha =  0.661578947368421 b =  -8188.291411144931 epoch =  421  loss = 5080.467  loss reduction = -386.7783  correctly classified = 81.6250%\n",
      "alpha =  0.661578947368421 b =  -7813.743782723878 epoch =  422  loss = 4693.688  loss reduction = 386.7783  correctly classified = 83.0250%\n",
      "alpha =  0.661578947368421 b =  -8158.874964829141 epoch =  423  loss = 5066.653  loss reduction = -372.9648  correctly classified = 81.6750%\n",
      "alpha =  0.661578947368421 b =  -7783.667080618615 epoch =  424  loss = 4686.782  loss reduction = 379.8715  correctly classified = 83.0500%\n",
      "alpha =  0.661578947368421 b =  -8128.798262723878 epoch =  425  loss = 5066.653  loss reduction = -379.8715  correctly classified = 81.6750%\n",
      "alpha =  0.661578947368421 b =  -7754.250634302825 epoch =  426  loss = 4679.875  loss reduction = 386.7783  correctly classified = 83.0750%\n",
      "alpha =  0.661578947368421 b =  -8100.042072197562 epoch =  427  loss = 5073.56  loss reduction = -393.685  correctly classified = 81.6500%\n",
      "alpha =  0.661578947368421 b =  -7724.173932197562 epoch =  428  loss = 4693.688  loss reduction = 379.8715  correctly classified = 83.0250%\n",
      "alpha =  0.661578947368421 b =  -8072.606393250194 epoch =  429  loss = 5073.56  loss reduction = -379.8715  correctly classified = 81.6500%\n",
      "alpha =  0.661578947368421 b =  -7698.719020618615 epoch =  430  loss = 4672.968  loss reduction = 400.5918  correctly classified = 83.1000%\n",
      "alpha =  0.661578947368421 b =  -8044.510458513352 epoch =  431  loss = 5059.746  loss reduction = -386.7783  correctly classified = 81.7000%\n",
      "alpha =  0.661578947368421 b =  -7669.9628300923 epoch =  432  loss = 4679.875  loss reduction = 379.8715  correctly classified = 83.0750%\n",
      "alpha =  0.661578947368421 b =  -8017.7350353554575 epoch =  433  loss = 5052.84  loss reduction = -372.9648  correctly classified = 81.7250%\n",
      "alpha =  0.661578947368421 b =  -7643.847662723879 epoch =  434  loss = 4659.155  loss reduction = 393.685  correctly classified = 83.1500%\n",
      "alpha =  0.661578947368421 b =  -7992.280123776511 epoch =  435  loss = 5059.746  loss reduction = -400.5918  correctly classified = 81.7000%\n",
      "alpha =  0.661578947368421 b =  -7618.392751144932 epoch =  436  loss = 4659.155  loss reduction = 400.5918  correctly classified = 83.1500%\n",
      "alpha =  0.661578947368421 b =  -7968.145723776511 epoch =  437  loss = 5073.56  loss reduction = -414.4053  correctly classified = 81.6500%\n",
      "alpha =  0.661578947368421 b =  -7594.918606934405 epoch =  438  loss = 4666.061  loss reduction = 407.4985  correctly classified = 83.1250%\n",
      "alpha =  0.661578947368421 b =  -7943.351067987037 epoch =  439  loss = 5059.746  loss reduction = -393.685  correctly classified = 81.7000%\n",
      "alpha =  0.661578947368421 b =  -7570.123951144931 epoch =  440  loss = 4666.061  loss reduction = 393.685  correctly classified = 83.1250%\n",
      "alpha =  0.661578947368421 b =  -7920.537179565984 epoch =  441  loss = 5080.467  loss reduction = -414.4053  correctly classified = 81.6250%\n",
      "alpha =  0.661578947368421 b =  -7542.028016408089 epoch =  442  loss = 4707.502  loss reduction = 372.9648  correctly classified = 82.9750%\n",
      "alpha =  0.661578947368421 b =  -7892.441244829141 epoch =  443  loss = 5080.467  loss reduction = -372.9648  correctly classified = 81.6250%\n",
      "alpha =  0.661578947368421 b =  -7515.912849039668 epoch =  444  loss = 4686.782  loss reduction = 393.685  correctly classified = 83.0500%\n",
      "alpha =  0.661578947368421 b =  -7861.704286934405 epoch =  445  loss = 5032.119  loss reduction = -345.3377  correctly classified = 81.8000%\n",
      "alpha =  0.661578947368421 b =  -7491.778449039668 epoch =  446  loss = 4631.528  loss reduction = 400.5918  correctly classified = 83.2500%\n",
      "alpha =  0.661578947368421 b =  -7838.230142723878 epoch =  447  loss = 5039.026  loss reduction = -407.4985  correctly classified = 81.7750%\n",
      "alpha =  0.661578947368421 b =  -7465.003025881772 epoch =  448  loss = 4666.061  loss reduction = 372.9648  correctly classified = 83.1250%\n",
      "alpha =  0.661578947368421 b =  -7811.4547195659825 epoch =  449  loss = 5039.026  loss reduction = -372.9648  correctly classified = 81.7750%\n",
      "alpha =  0.661578947368421 b =  -7438.887858513351 epoch =  450  loss = 4659.155  loss reduction = 379.8715  correctly classified = 83.1500%\n",
      "alpha =  0.661578947368421 b =  -7784.679296408088 epoch =  451  loss = 5032.119  loss reduction = -372.9648  correctly classified = 81.8000%\n",
      "alpha =  0.661578947368421 b =  -7412.112435355456 epoch =  452  loss = 4659.155  loss reduction = 372.9648  correctly classified = 83.1500%\n",
      "alpha =  0.661578947368421 b =  -7755.262850092298 epoch =  453  loss = 5004.492  loss reduction = -345.3377  correctly classified = 81.9000%\n",
      "alpha =  0.661578947368421 b =  -7386.657523776509 epoch =  454  loss = 4617.714  loss reduction = 386.7783  correctly classified = 83.3000%\n",
      "alpha =  0.661578947368421 b =  -7731.128450092298 epoch =  455  loss = 5018.306  loss reduction = -400.5918  correctly classified = 81.8500%\n",
      "alpha =  0.661578947368421 b =  -7359.8821006186145 epoch =  456  loss = 4645.341  loss reduction = 372.9648  correctly classified = 83.2000%\n",
      "alpha =  0.661578947368421 b =  -7703.69277114493 epoch =  457  loss = 5011.399  loss reduction = -366.058  correctly classified = 81.8750%\n",
      "alpha =  0.661578947368421 b =  -7332.446421671246 epoch =  458  loss = 4645.341  loss reduction = 366.058  correctly classified = 83.2000%\n",
      "alpha =  0.661578947368421 b =  -7676.917347987035 epoch =  459  loss = 5018.306  loss reduction = -372.9648  correctly classified = 81.8500%\n",
      "alpha =  0.661578947368421 b =  -7304.350486934403 epoch =  460  loss = 4645.341  loss reduction = 372.9648  correctly classified = 83.2000%\n",
      "alpha =  0.661578947368421 b =  -7648.821413250193 epoch =  461  loss = 5018.306  loss reduction = -372.9648  correctly classified = 81.8500%\n",
      "alpha =  0.661578947368421 b =  -7275.594296408087 epoch =  462  loss = 4638.434  loss reduction = 379.8715  correctly classified = 83.2250%\n",
      "alpha =  0.661578947368421 b =  -7620.065222723876 epoch =  463  loss = 5018.306  loss reduction = -379.8715  correctly classified = 81.8500%\n",
      "alpha =  0.661578947368421 b =  -7248.158617460718 epoch =  464  loss = 4638.434  loss reduction = 379.8715  correctly classified = 83.2250%\n",
      "alpha =  0.661578947368421 b =  -7591.969287987034 epoch =  465  loss = 5011.399  loss reduction = -372.9648  correctly classified = 81.8750%\n",
      "alpha =  0.661578947368421 b =  -7220.062682723876 epoch =  466  loss = 4624.621  loss reduction = 386.7783  correctly classified = 83.2750%\n",
      "alpha =  0.661578947368421 b =  -7564.533609039665 epoch =  467  loss = 5018.306  loss reduction = -393.685  correctly classified = 81.8500%\n",
      "alpha =  0.661578947368421 b =  -7193.287259565981 epoch =  468  loss = 4631.528  loss reduction = 386.7783  correctly classified = 83.2500%\n",
      "alpha =  0.661578947368421 b =  -7536.437674302823 epoch =  469  loss = 5004.492  loss reduction = -372.9648  correctly classified = 81.9000%\n",
      "alpha =  0.661578947368421 b =  -7165.191324829139 epoch =  470  loss = 4617.714  loss reduction = 386.7783  correctly classified = 83.3000%\n",
      "alpha =  0.661578947368421 b =  -7508.341739565982 epoch =  471  loss = 5004.492  loss reduction = -386.7783  correctly classified = 81.9000%\n",
      "alpha =  0.661578947368421 b =  -7135.77487851335 epoch =  472  loss = 4617.714  loss reduction = 386.7783  correctly classified = 83.3000%\n",
      "alpha =  0.661578947368421 b =  -7480.245804829139 epoch =  473  loss = 5018.306  loss reduction = -400.5918  correctly classified = 81.8500%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.661578947368421 b =  -7108.999455355455 epoch =  474  loss = 4603.901  loss reduction = 414.4053  correctly classified = 83.3500%\n",
      "alpha =  0.661578947368421 b =  -7452.1498700922975 epoch =  475  loss = 5004.492  loss reduction = -400.5918  correctly classified = 81.9000%\n",
      "alpha =  0.661578947368421 b =  -7079.583009039666 epoch =  476  loss = 4603.901  loss reduction = 400.5918  correctly classified = 83.3500%\n",
      "alpha =  0.661578947368421 b =  -7422.733423776508 epoch =  477  loss = 4990.679  loss reduction = -386.7783  correctly classified = 81.9500%\n",
      "alpha =  0.661578947368421 b =  -7052.147330092297 epoch =  478  loss = 4583.18  loss reduction = 407.4985  correctly classified = 83.4250%\n",
      "alpha =  0.661578947368421 b =  -7396.618256408086 epoch =  479  loss = 4976.865  loss reduction = -393.685  correctly classified = 82.0000%\n",
      "alpha =  0.661578947368421 b =  -7026.692418513349 epoch =  480  loss = 4576.274  loss reduction = 400.5918  correctly classified = 83.4500%\n",
      "alpha =  0.661578947368421 b =  -7369.842833250192 epoch =  481  loss = 4963.052  loss reduction = -386.7783  correctly classified = 82.0500%\n",
      "alpha =  0.661578947368421 b =  -6999.916995355455 epoch =  482  loss = 4576.274  loss reduction = 386.7783  correctly classified = 83.4500%\n",
      "alpha =  0.661578947368421 b =  -7343.067410092297 epoch =  483  loss = 4949.238  loss reduction = -372.9648  correctly classified = 82.1000%\n",
      "alpha =  0.661578947368421 b =  -6973.14157219756 epoch =  484  loss = 4576.274  loss reduction = 372.9648  correctly classified = 83.4500%\n",
      "alpha =  0.661578947368421 b =  -7316.952242723875 epoch =  485  loss = 4956.145  loss reduction = -379.8715  correctly classified = 82.0750%\n",
      "alpha =  0.661578947368421 b =  -6947.026404829138 epoch =  486  loss = 4576.274  loss reduction = 379.8715  correctly classified = 83.4500%\n",
      "alpha =  0.661578947368421 b =  -7290.837075355454 epoch =  487  loss = 4956.145  loss reduction = -379.8715  correctly classified = 82.0750%\n",
      "alpha =  0.661578947368421 b =  -6920.911237460717 epoch =  488  loss = 4590.087  loss reduction = 366.058  correctly classified = 83.4000%\n",
      "alpha =  0.661578947368421 b =  -7264.721907987032 epoch =  489  loss = 4956.145  loss reduction = -366.058  correctly classified = 82.0750%\n",
      "alpha =  0.661578947368421 b =  -6896.776837460716 epoch =  490  loss = 4569.367  loss reduction = 386.7783  correctly classified = 83.4750%\n",
      "alpha =  0.661578947368421 b =  -7231.3439269344 epoch =  491  loss = 4873.264  loss reduction = -303.8972  correctly classified = 82.3750%\n",
      "alpha =  0.661578947368421 b =  -6868.680902723873 epoch =  492  loss = 4527.926  loss reduction = 345.3377  correctly classified = 83.6250%\n",
      "alpha =  0.661578947368421 b =  -7184.100574302821 epoch =  493  loss = 4728.222  loss reduction = -200.2959  correctly classified = 82.9000%\n",
      "alpha =  0.661578947368421 b =  -6836.623433250189 epoch =  494  loss = 4424.325  loss reduction = 303.8972  correctly classified = 84.0000%\n",
      "alpha =  0.661578947368421 b =  -7103.184176408084 epoch =  495  loss = 4300.003  loss reduction = 124.3216  correctly classified = 84.4500%\n",
      "alpha =  0.661578947368421 b =  -6797.963405881768 epoch =  496  loss = 4106.614  loss reduction = 193.3891  correctly classified = 85.1500%\n",
      "alpha =  0.661578947368421 b =  -6968.126803776505 epoch =  497  loss = 3733.65  loss reduction = 372.9648  correctly classified = 86.5000%\n",
      "alpha =  0.661578947368421 b =  -6696.579078513347 epoch =  498  loss = 3920.132  loss reduction = -186.4824  correctly classified = 85.8250%\n",
      "alpha =  0.661578947368421 b =  -6801.377153250189 epoch =  499  loss = 3381.405  loss reduction = 538.7269  correctly classified = 87.7750%\n",
      "alpha =  0.661578947368421 b =  -6546.996078513346 epoch =  500  loss = 3809.624  loss reduction = -428.2188  correctly classified = 86.2250%\n",
      "alpha =  0.661578947368421 b =  -6579.826272197557 epoch =  501  loss = 3029.161  loss reduction = 780.4633  correctly classified = 89.0500%\n",
      "alpha =  0.661578947368421 b =  -6357.797731144926 epoch =  502  loss = 3650.769  loss reduction = -621.6079  correctly classified = 86.8000%\n",
      "alpha =  0.661578947368421 b =  -6369.499739565978 epoch =  503  loss = 3056.788  loss reduction = 593.9809  correctly classified = 88.9500%\n",
      "alpha =  0.661578947368421 b =  -6145.490431144925 epoch =  504  loss = 3657.675  loss reduction = -600.8877  correctly classified = 86.7750%\n",
      "alpha =  0.661578947368421 b =  -6162.474485881768 epoch =  505  loss = 3015.347  loss reduction = 642.3282  correctly classified = 89.1000%\n",
      "alpha =  0.661578947368421 b =  -5937.804921671242 epoch =  506  loss = 3650.769  loss reduction = -635.4214  correctly classified = 86.8000%\n",
      "alpha =  0.661578947368421 b =  -5958.750511144925 epoch =  507  loss = 3001.534  loss reduction = 649.2349  correctly classified = 89.1500%\n",
      "alpha =  0.661578947368421 b =  -5732.100179565978 epoch =  508  loss = 3630.048  loss reduction = -628.5147  correctly classified = 86.8750%\n",
      "alpha =  0.661578947368421 b =  -5757.007303776504 epoch =  509  loss = 2973.907  loss reduction = 656.1417  correctly classified = 89.2500%\n",
      "alpha =  0.661578947368421 b =  -5530.356972197556 epoch =  510  loss = 3630.048  loss reduction = -656.1417  correctly classified = 86.8750%\n",
      "alpha =  0.661578947368421 b =  -5556.58460798703 epoch =  511  loss = 2960.093  loss reduction = 669.9552  correctly classified = 89.3000%\n",
      "alpha =  0.661578947368421 b =  -5329.934276408082 epoch =  512  loss = 3630.048  loss reduction = -669.9552  correctly classified = 86.8750%\n",
      "alpha =  0.661578947368421 b =  -5356.1619121975555 epoch =  513  loss = 2960.093  loss reduction = 669.9552  correctly classified = 89.3000%\n",
      "alpha =  0.661578947368421 b =  -5130.171836408082 epoch =  514  loss = 3609.328  loss reduction = -649.2349  correctly classified = 86.9500%\n",
      "alpha =  0.661578947368421 b =  -5159.04049535545 epoch =  515  loss = 2960.093  loss reduction = 649.2349  correctly classified = 89.3000%\n",
      "alpha =  0.661578947368421 b =  -4933.71067535545 epoch =  516  loss = 3602.421  loss reduction = -642.3282  correctly classified = 86.9750%\n",
      "alpha =  0.661578947368421 b =  -4963.239590092292 epoch =  517  loss = 2953.186  loss reduction = 649.2349  correctly classified = 89.3250%\n",
      "alpha =  0.661578947368421 b =  -4738.570025881766 epoch =  518  loss = 3595.514  loss reduction = -642.3282  correctly classified = 87.0000%\n",
      "alpha =  0.661578947368421 b =  -4769.419452197555 epoch =  519  loss = 2953.186  loss reduction = 642.3282  correctly classified = 89.3250%\n",
      "alpha =  0.661578947368421 b =  -4538.807585881766 epoch =  520  loss = 3630.048  loss reduction = -676.862  correctly classified = 86.8750%\n",
      "alpha =  0.661578947368421 b =  -4580.221104829134 epoch =  521  loss = 2980.813  loss reduction = 649.2349  correctly classified = 89.2250%\n",
      "alpha =  0.661578947368421 b =  -4333.763099565976 epoch =  522  loss = 3726.743  loss reduction = -745.9295  correctly classified = 86.5250%\n",
      "alpha =  0.661578947368421 b =  -4389.041990092292 epoch =  523  loss = 2973.907  loss reduction = 752.8363  correctly classified = 89.2500%\n",
      "alpha =  0.661578947368421 b =  -4143.904496408081 epoch =  524  loss = 3712.929  loss reduction = -739.0228  correctly classified = 86.5750%\n",
      "alpha =  0.661578947368421 b =  -4202.484665881765 epoch =  525  loss = 2980.813  loss reduction = 732.116  correctly classified = 89.2250%\n",
      "alpha =  0.661578947368421 b =  -3957.3471721975543 epoch =  526  loss = 3712.929  loss reduction = -732.116  correctly classified = 86.5750%\n",
      "alpha =  0.661578947368421 b =  -4014.606830092291 epoch =  527  loss = 2967.0  loss reduction = 745.9295  correctly classified = 89.2750%\n",
      "alpha =  0.661578947368421 b =  -3769.4693364080804 epoch =  528  loss = 3712.929  loss reduction = -745.9295  correctly classified = 86.5750%\n",
      "alpha =  0.661578947368421 b =  -3830.0302732501855 epoch =  529  loss = 2987.72  loss reduction = 725.2093  correctly classified = 89.2000%\n",
      "alpha =  0.661578947368421 b =  -3584.2325237765012 epoch =  530  loss = 3706.023  loss reduction = -718.3025  correctly classified = 86.6000%\n",
      "alpha =  0.661578947368421 b =  -3644.133204829133 epoch =  531  loss = 2980.813  loss reduction = 725.2093  correctly classified = 89.2250%\n",
      "alpha =  0.661578947368421 b =  -3396.3546879870273 epoch =  532  loss = 3685.302  loss reduction = -704.489  correctly classified = 86.6750%\n",
      "alpha =  0.661578947368421 b =  -3461.5374153554485 epoch =  533  loss = 2994.627  loss reduction = 690.6755  correctly classified = 89.1750%\n",
      "alpha =  0.661578947368421 b =  -3214.419154302817 epoch =  534  loss = 3678.396  loss reduction = -683.7687  correctly classified = 86.7000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.661578947368421 b =  -3281.582649039659 epoch =  535  loss = 3015.347  loss reduction = 663.0485  correctly classified = 89.1000%\n",
      "alpha =  0.661578947368421 b =  -3029.1823416712377 epoch =  536  loss = 3719.836  loss reduction = -704.489  correctly classified = 86.5500%\n",
      "alpha =  0.661578947368421 b =  -3119.454789039659 epoch =  537  loss = 3160.389  loss reduction = 559.4471  correctly classified = 88.5750%\n",
      "alpha =  0.661578947368421 b =  -2852.528854302817 epoch =  538  loss = 3775.09  loss reduction = -614.7012  correctly classified = 86.3500%\n",
      "alpha =  0.661578947368421 b =  -3006.846113250185 epoch =  539  loss = 3429.752  loss reduction = 345.3377  correctly classified = 87.6000%\n",
      "alpha =  0.661578947368421 b =  -2704.266365881764 epoch =  540  loss = 3996.106  loss reduction = -566.3539  correctly classified = 85.5500%\n",
      "alpha =  0.661578947368421 b =  -2948.3784121975536 epoch =  541  loss = 3968.479  loss reduction = 27.62702  correctly classified = 85.6500%\n",
      "alpha =  0.661578947368421 b =  -2598.2602479870275 epoch =  542  loss = 4327.63  loss reduction = -359.1512  correctly classified = 84.3500%\n",
      "alpha =  0.661578947368421 b =  -2975.0837079870275 epoch =  543  loss = 5011.399  loss reduction = -683.7687  correctly classified = 81.8750%\n",
      "alpha =  0.661578947368421 b =  -2531.209221671238 epoch =  544  loss = 5018.306  loss reduction = -6.906755  correctly classified = 81.8500%\n",
      "alpha =  0.661578947368421 b =  -3102.8081395659747 epoch =  545  loss = 6827.876  loss reduction = -1809.57  correctly classified = 75.3000%\n",
      "alpha =  0.661578947368421 b =  -2564.5170753554485 epoch =  546  loss = 5826.396  loss reduction = 1001.479  correctly classified = 78.9250%\n",
      "alpha =  0.661578947368421 b =  -3394.9362627238697 epoch =  547  loss = 9300.494  loss reduction = -3474.098  correctly classified = 66.3500%\n",
      "alpha =  0.661578947368421 b =  -2756.946574302817 epoch =  548  loss = 6800.249  loss reduction = 2500.245  correctly classified = 75.4000%\n",
      "alpha =  0.661578947368421 b =  -3512.756857460712 epoch =  549  loss = 8589.098  loss reduction = -1788.849  correctly classified = 68.9250%\n",
      "alpha =  0.661578947368421 b =  -2906.4594469343965 epoch =  550  loss = 6468.724  loss reduction = 2120.374  correctly classified = 76.6000%\n",
      "alpha =  0.661578947368421 b =  -3696.6030311449226 epoch =  551  loss = 8920.622  loss reduction = -2451.898  correctly classified = 67.7250%\n",
      "alpha =  0.661578947368421 b =  -3086.344085881765 epoch =  552  loss = 6510.165  loss reduction = 2410.457  correctly classified = 76.4500%\n",
      "alpha =  0.661578947368421 b =  -3830.9300206186067 epoch =  553  loss = 8471.683  loss reduction = -1961.518  correctly classified = 69.3500%\n",
      "alpha =  0.661578947368421 b =  -3247.7415627238697 epoch =  554  loss = 6254.615  loss reduction = 2217.068  correctly classified = 77.3750%\n",
      "alpha =  0.661578947368421 b =  -3995.6287764080803 epoch =  555  loss = 8506.217  loss reduction = -2251.602  correctly classified = 69.2250%\n",
      "alpha =  0.661578947368421 b =  -3421.0236437765016 epoch =  556  loss = 6178.641  loss reduction = 2327.576  correctly classified = 77.6500%\n",
      "alpha =  0.661578947368421 b =  -4143.821137460713 epoch =  557  loss = 8257.574  loss reduction = -2078.933  correctly classified = 70.1250%\n",
      "alpha =  0.661578947368421 b =  -3591.004445881765 epoch =  558  loss = 5964.531  loss reduction = 2293.043  correctly classified = 78.4250%\n",
      "alpha =  0.661578947368421 b =  -4270.225057460712 epoch =  559  loss = 7829.355  loss reduction = -1864.824  correctly classified = 71.6750%\n",
      "alpha =  0.661578947368421 b =  -3747.7801321975544 epoch =  560  loss = 5674.448  loss reduction = 2154.907  correctly classified = 79.4750%\n",
      "alpha =  0.661578947368421 b =  -4342.4880027238705 epoch =  561  loss = 7041.985  loss reduction = -1367.537  correctly classified = 74.5250%\n",
      "alpha =  0.661578947368421 b =  -3861.6391921975546 epoch =  562  loss = 5322.203  loss reduction = 1719.782  correctly classified = 80.7500%\n",
      "alpha =  0.661578947368421 b =  -4357.3086943028175 epoch =  563  loss = 6116.48  loss reduction = -794.2768  correctly classified = 77.8750%\n",
      "alpha =  0.661578947368421 b =  -3932.581625881765 epoch =  564  loss = 4887.078  loss reduction = 1229.402  correctly classified = 82.3250%\n",
      "alpha =  0.661578947368421 b =  -4362.22554903966 epoch =  565  loss = 5522.499  loss reduction = -635.4214  correctly classified = 80.0250%\n",
      "alpha =  0.661578947368421 b =  -3965.2292237765023 epoch =  566  loss = 4666.061  loss reduction = 856.4376  correctly classified = 83.1250%\n",
      "alpha =  0.661578947368421 b =  -4358.5590785133445 epoch =  567  loss = 5184.068  loss reduction = -518.0066  correctly classified = 81.2500%\n",
      "alpha =  0.661578947368421 b =  -3978.7294037765023 epoch =  568  loss = 4514.113  loss reduction = 669.9552  correctly classified = 83.6750%\n",
      "alpha =  0.661578947368421 b =  -4332.443911144924 epoch =  569  loss = 4921.611  loss reduction = -407.4985  correctly classified = 82.2000%\n",
      "alpha =  0.661578947368421 b =  -3975.7231890396606 epoch =  570  loss = 4382.885  loss reduction = 538.7269  correctly classified = 84.1500%\n",
      "alpha =  0.661578947368421 b =  -4285.200558513345 epoch =  571  loss = 4555.553  loss reduction = -172.6689  correctly classified = 83.5250%\n",
      "alpha =  0.661578947368421 b =  -3970.0759511449237 epoch =  572  loss = 4099.708  loss reduction = 455.8458  correctly classified = 85.1750%\n",
      "alpha =  0.661578947368421 b =  -4187.777765881766 epoch =  573  loss = 3885.598  loss reduction = 214.1094  correctly classified = 85.9500%\n",
      "alpha =  0.661578947368421 b =  -3910.947994302818 epoch =  574  loss = 3851.064  loss reduction = 34.53377  correctly classified = 86.0750%\n",
      "alpha =  0.661578947368421 b =  -4023.6691385133445 epoch =  575  loss = 3367.592  loss reduction = 483.4728  correctly classified = 87.8250%\n",
      "alpha =  0.661578947368421 b =  -3779.1919006186076 epoch =  576  loss = 3678.396  loss reduction = -310.804  correctly classified = 86.7000%\n",
      "alpha =  0.661578947368421 b =  -3822.586186934397 epoch =  577  loss = 2932.466  loss reduction = 745.9295  correctly classified = 89.4000%\n",
      "alpha =  0.661578947368421 b =  -3600.5576458817654 epoch =  578  loss = 3554.074  loss reduction = -621.6079  correctly classified = 87.1500%\n",
      "alpha =  0.661578947368421 b =  -3616.22118903966 epoch =  579  loss = 2918.653  loss reduction = 635.4214  correctly classified = 89.4500%\n",
      "alpha =  0.661578947368421 b =  -3410.038786934397 epoch =  580  loss = 3443.566  loss reduction = -524.9134  correctly classified = 87.5500%\n",
      "alpha =  0.661578947368421 b =  -3405.2344006186077 epoch =  581  loss = 2897.932  loss reduction = 545.6336  correctly classified = 89.5250%\n",
      "alpha =  0.661578947368421 b =  -3226.1224858817654 epoch =  582  loss = 3270.897  loss reduction = -372.9648  correctly classified = 88.1750%\n",
      "alpha =  0.661578947368421 b =  -3198.8694027238707 epoch =  583  loss = 2842.678  loss reduction = 428.2188  correctly classified = 89.7250%\n",
      "alpha =  0.661578947368421 b =  -3027.680557460713 epoch =  584  loss = 3229.456  loss reduction = -386.7783  correctly classified = 88.3250%\n",
      "alpha =  0.661578947368421 b =  -2988.5428700922917 epoch =  585  loss = 2828.865  loss reduction = 400.5918  correctly classified = 89.7750%\n",
      "alpha =  0.661578947368421 b =  -2832.5399079870285 epoch =  586  loss = 3098.228  loss reduction = -269.3634  correctly classified = 88.8000%\n",
      "alpha =  0.661578947368421 b =  -2776.2355700922917 epoch =  587  loss = 2842.678  loss reduction = 255.5499  correctly classified = 89.7250%\n",
      "alpha =  0.661578947368421 b =  -2638.059514302818 epoch =  588  loss = 2994.627  loss reduction = -151.9486  correctly classified = 89.1750%\n",
      "alpha =  0.661578947368421 b =  -2566.5692932501865 epoch =  589  loss = 2849.585  loss reduction = 145.0419  correctly classified = 89.7000%\n",
      "alpha =  0.661578947368421 b =  -2440.938097460713 epoch =  590  loss = 2918.653  loss reduction = -69.06755  correctly classified = 89.4500%\n",
      "alpha =  0.661578947368421 b =  -2365.486341671239 epoch =  591  loss = 2863.398  loss reduction = 55.25404  correctly classified = 89.6500%\n",
      "alpha =  0.661578947368421 b =  -2238.534634302818 epoch =  592  loss = 2918.653  loss reduction = -55.25404  correctly classified = 89.4500%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.661578947368421 b =  -2166.3841574607127 epoch =  593  loss = 2828.865  loss reduction = 89.78781  correctly classified = 89.7750%\n",
      "alpha =  0.661578947368421 b =  -2036.791426934397 epoch =  594  loss = 2904.839  loss reduction = -75.9743  correctly classified = 89.5000%\n",
      "alpha =  0.661578947368421 b =  -1965.961461671239 epoch =  595  loss = 2801.238  loss reduction = 103.6013  correctly classified = 89.8750%\n",
      "alpha =  0.661578947368421 b =  -1835.0482195659758 epoch =  596  loss = 2918.653  loss reduction = -117.4148  correctly classified = 89.4500%\n",
      "alpha =  0.661578947368421 b =  -1765.5387658817654 epoch =  597  loss = 2787.424  loss reduction = 131.2283  correctly classified = 89.9250%\n",
      "alpha =  0.661578947368421 b =  -1635.9460353554496 epoch =  598  loss = 2904.839  loss reduction = -117.4148  correctly classified = 89.5000%\n",
      "alpha =  0.661578947368421 b =  -1563.7955585133443 epoch =  599  loss = 2787.424  loss reduction = 117.4148  correctly classified = 89.9250%\n",
      "alpha =  0.661578947368421 b =  -1442.1258974607126 epoch =  600  loss = 2891.025  loss reduction = -103.6013  correctly classified = 89.5500%\n",
      "alpha =  0.661578947368421 b =  -1371.2959321975547 epoch =  601  loss = 2773.611  loss reduction = 117.4148  correctly classified = 89.9750%\n",
      "alpha =  0.661578947368421 b =  -1250.9467827238705 epoch =  602  loss = 2877.212  loss reduction = -103.6013  correctly classified = 89.6000%\n",
      "alpha =  0.661578947368421 b =  -1178.7963058817652 epoch =  603  loss = 2759.797  loss reduction = 117.4148  correctly classified = 90.0250%\n",
      "alpha =  0.661578947368421 b =  -1063.7292027238705 epoch =  604  loss = 2877.212  loss reduction = -117.4148  correctly classified = 89.6000%\n",
      "alpha =  0.661578947368421 b =  -994.8800048291336 epoch =  605  loss = 2739.077  loss reduction = 138.1351  correctly classified = 90.1000%\n",
      "alpha =  0.661578947368421 b =  -880.4731574607124 epoch =  606  loss = 2870.305  loss reduction = -131.2283  correctly classified = 89.6250%\n",
      "alpha =  0.661578947368421 b =  -811.6239595659755 epoch =  607  loss = 2725.263  loss reduction = 145.0419  correctly classified = 90.1500%\n",
      "alpha =  0.661578947368421 b =  -697.877367987028 epoch =  608  loss = 2863.398  loss reduction = -138.1351  correctly classified = 89.6500%\n",
      "alpha =  0.661578947368421 b =  -630.3486816712385 epoch =  609  loss = 2711.45  loss reduction = 151.9486  correctly classified = 90.2000%\n",
      "alpha =  0.661578947368421 b =  -515.2815785133438 epoch =  610  loss = 2863.398  loss reduction = -151.9486  correctly classified = 89.6500%\n",
      "alpha =  0.661578947368421 b =  -447.7528921975543 epoch =  611  loss = 2711.45  loss reduction = 151.9486  correctly classified = 90.2000%\n",
      "alpha =  0.661578947368421 b =  -334.66655640808057 epoch =  612  loss = 2828.865  loss reduction = -117.4148  correctly classified = 89.7750%\n",
      "alpha =  0.661578947368421 b =  -266.47761430281736 epoch =  613  loss = 2718.357  loss reduction = 110.5081  correctly classified = 90.1750%\n",
      "alpha =  0.661578947368421 b =  -152.73102272386996 epoch =  614  loss = 2821.958  loss reduction = -103.6013  correctly classified = 89.8000%\n",
      "alpha =  0.661578947368421 b =  -85.20233640808044 epoch =  615  loss = 2725.263  loss reduction = 96.69457  correctly classified = 90.1500%\n",
      "alpha =  0.661578947368421 b =  29.864766749814336 epoch =  616  loss = 2835.771  loss reduction = -110.5081  correctly classified = 89.7500%\n",
      "alpha =  0.661578947368421 b =  95.4126856971828 epoch =  617  loss = 2732.17  loss reduction = 103.6013  correctly classified = 90.1250%\n",
      "alpha =  0.661578947368421 b =  208.49902148665652 epoch =  618  loss = 2815.051  loss reduction = -82.88106  correctly classified = 89.8250%\n",
      "alpha =  0.661578947368421 b =  276.027707802446 epoch =  619  loss = 2725.263  loss reduction = 89.78781  correctly classified = 90.1500%\n",
      "alpha =  0.661578947368421 b =  387.79497745632375 epoch =  620  loss = 2787.426  loss reduction = -62.16298  correctly classified = 89.9250%\n",
      "alpha =  0.661578947368421 b =  455.32366377211326 epoch =  621  loss = 2711.45  loss reduction = 75.97649  correctly classified = 90.2000%\n",
      "alpha =  0.661578947368421 b =  565.1087206142186 epoch =  622  loss = 2752.89  loss reduction = -41.44053  correctly classified = 90.0500%\n",
      "alpha =  0.661578947368421 b =  633.2976627194818 epoch =  623  loss = 2704.543  loss reduction = 48.34728  correctly classified = 90.2250%\n",
      "alpha =  0.661578947368421 b =  737.1404174563239 epoch =  624  loss = 2732.17  loss reduction = -27.62702  correctly classified = 90.1250%\n",
      "alpha =  0.661578947368421 b =  805.3293595615871 epoch =  625  loss = 2690.73  loss reduction = 41.44053  correctly classified = 90.2750%\n",
      "alpha =  0.661578947368421 b =  913.1336490352713 epoch =  626  loss = 2732.17  loss reduction = -41.44053  correctly classified = 90.1250%\n",
      "alpha =  0.661578947368421 b =  979.3418237721135 epoch =  627  loss = 2711.45  loss reduction = 20.72026  correctly classified = 90.2000%\n",
      "alpha =  0.661578947368421 b =  1085.1653458773767 epoch =  628  loss = 2725.263  loss reduction = -13.81351  correctly classified = 90.1500%\n",
      "alpha =  0.661578947368421 b =  1151.373520614219 epoch =  629  loss = 2697.636  loss reduction = 27.62702  correctly classified = 90.2500%\n",
      "alpha =  0.661578947368421 b =  1255.8765311405348 epoch =  630  loss = 2711.45  loss reduction = -13.81351  correctly classified = 90.2000%\n",
      "alpha =  0.661578947368421 b =  1326.046240614219 epoch =  631  loss = 2656.196  loss reduction = 55.25404  correctly classified = 90.4000%\n",
      "alpha =  0.661578947368421 b =  1428.5684837721137 epoch =  632  loss = 2718.357  loss reduction = -62.16079  correctly classified = 90.1750%\n",
      "alpha =  0.661578947368421 b =  1497.4176816668505 epoch =  633  loss = 2628.569  loss reduction = 89.78781  correctly classified = 90.5000%\n",
      "alpha =  0.661578947368421 b =  1599.2796690352716 epoch =  634  loss = 2711.45  loss reduction = -82.88106  correctly classified = 90.2000%\n",
      "alpha =  0.661578947368421 b =  1668.789122719482 epoch =  635  loss = 2621.662  loss reduction = 89.78781  correctly classified = 90.5250%\n",
      "alpha =  0.661578947368421 b =  1771.9716216668505 epoch =  636  loss = 2683.823  loss reduction = -62.16079  correctly classified = 90.3000%\n",
      "alpha =  0.661578947368421 b =  1842.8015869300084 epoch =  637  loss = 2621.662  loss reduction = 62.16079  correctly classified = 90.5250%\n",
      "alpha =  0.661578947368421 b =  1941.362295351061 epoch =  638  loss = 2663.103  loss reduction = -41.44053  correctly classified = 90.3750%\n",
      "alpha =  0.661578947368421 b =  2009.551237456324 epoch =  639  loss = 2635.476  loss reduction = 27.62702  correctly classified = 90.4750%\n",
      "alpha =  0.661578947368421 b =  2108.111945877377 epoch =  640  loss = 2663.103  loss reduction = -27.62702  correctly classified = 90.3750%\n",
      "alpha =  0.661578947368421 b =  2176.9611437721137 epoch =  641  loss = 2628.569  loss reduction = 34.53377  correctly classified = 90.5000%\n",
      "alpha =  0.661578947368421 b =  2275.5218521931665 epoch =  642  loss = 2663.103  loss reduction = -34.53377  correctly classified = 90.3750%\n",
      "alpha =  0.661578947368421 b =  2345.6915616668507 epoch =  643  loss = 2614.755  loss reduction = 48.34728  correctly classified = 90.5500%\n",
      "alpha =  0.661578947368421 b =  2437.6497121931666 epoch =  644  loss = 2649.289  loss reduction = -34.53377  correctly classified = 90.4250%\n",
      "alpha =  0.661578947368421 b =  2515.742491140535 epoch =  645  loss = 2628.569  loss reduction = 20.72026  correctly classified = 90.5000%\n",
      "alpha =  0.661578947368421 b =  2599.117316403693 epoch =  646  loss = 2628.569  loss reduction = 0.0  correctly classified = 90.5000%\n",
      "alpha =  0.6821052631578948 b =  2680.994503772114 epoch =  0  loss = 2614.755  loss reduction = 13.81351  correctly classified = 90.5500%\n",
      "alpha =  0.6821052631578948 b =  2759.467985877377 epoch =  1  loss = 2649.289  loss reduction = -34.53377  correctly classified = 90.4250%\n",
      "alpha =  0.6821052631578948 b =  2847.4718427194825 epoch =  2  loss = 2635.476  loss reduction = 13.81351  correctly classified = 90.4750%\n",
      "alpha =  0.6821052631578948 b =  2931.3912532457985 epoch =  3  loss = 2607.849  loss reduction = 27.62702  correctly classified = 90.5750%\n",
      "alpha =  0.6821052631578948 b =  3010.545476403693 epoch =  4  loss = 2628.569  loss reduction = -20.72026  correctly classified = 90.5000%\n",
      "alpha =  0.6821052631578948 b =  3091.741922719483 epoch =  5  loss = 2635.476  loss reduction = -6.906755  correctly classified = 90.4750%\n",
      "alpha =  0.6821052631578948 b =  3170.8961458773774 epoch =  6  loss = 2628.569  loss reduction = 6.906755  correctly classified = 90.5000%\n",
      "alpha =  0.6821052631578948 b =  3252.092592193167 epoch =  7  loss = 2635.476  loss reduction = -6.906755  correctly classified = 90.4750%\n",
      "alpha =  0.6821052631578948 b =  3333.2890385089568 epoch =  8  loss = 2635.476  loss reduction = 0.0  correctly classified = 90.4750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.7026315789473684 b =  3416.2276700879042 epoch =  0  loss = 2628.569  loss reduction = 6.906755  correctly classified = 90.5000%\n",
      "alpha =  0.7026315789473684 b =  3499.1663016668517 epoch =  1  loss = 2628.569  loss reduction = 0.0  correctly classified = 90.5000%\n",
      "alpha =  0.7231578947368421 b =  3585.9712827194835 epoch =  0  loss = 2642.382  loss reduction = -13.81351  correctly classified = 90.4500%\n",
      "alpha =  0.7231578947368421 b =  3670.611129035273 epoch =  1  loss = 2621.662  loss reduction = 20.72026  correctly classified = 90.5250%\n",
      "alpha =  0.7231578947368421 b =  3756.694398508957 epoch =  2  loss = 2635.476  loss reduction = -13.81351  correctly classified = 90.4750%\n",
      "alpha =  0.7231578947368421 b =  3839.1691100879043 epoch =  3  loss = 2614.755  loss reduction = 20.72026  correctly classified = 90.5500%\n",
      "alpha =  0.7231578947368421 b =  3926.6958027194833 epoch =  4  loss = 2621.662  loss reduction = -6.906755  correctly classified = 90.5250%\n",
      "alpha =  0.7231578947368421 b =  4008.4488027194834 epoch =  5  loss = 2607.849  loss reduction = 13.81351  correctly classified = 90.5750%\n",
      "alpha =  0.7231578947368421 b =  4094.5320721931676 epoch =  6  loss = 2621.662  loss reduction = -13.81351  correctly classified = 90.5250%\n",
      "alpha =  0.7231578947368421 b =  4180.615341666852 epoch =  7  loss = 2621.662  loss reduction = 0.0  correctly classified = 90.5250%\n",
      "alpha =  0.7436842105263157 b =  4267.657629035273 epoch =  0  loss = 2621.662  loss reduction = 0.0  correctly classified = 90.5250%\n",
      "alpha =  0.7642105263157895 b =  4357.102357456326 epoch =  0  loss = 2607.849  loss reduction = 13.81351  correctly classified = 90.5750%\n",
      "alpha =  0.7642105263157895 b =  4445.0217216668525 epoch =  1  loss = 2607.849  loss reduction = 0.0  correctly classified = 90.5750%\n",
      "alpha =  0.7847368421052632 b =  4536.868891140537 epoch =  0  loss = 2594.035  loss reduction = 13.81351  correctly classified = 90.6250%\n",
      "alpha =  0.7847368421052632 b =  4627.9328932458 epoch =  1  loss = 2587.128  loss reduction = 6.906755  correctly classified = 90.6500%\n",
      "alpha =  0.7847368421052632 b =  4722.912732193168 epoch =  2  loss = 2607.849  loss reduction = -20.72026  correctly classified = 90.5750%\n",
      "alpha =  0.7847368421052632 b =  4817.109403772116 epoch =  3  loss = 2600.942  loss reduction = 6.906755  correctly classified = 90.6000%\n",
      "alpha =  0.7847368421052632 b =  4912.089242719484 epoch =  4  loss = 2607.849  loss reduction = -6.906755  correctly classified = 90.5750%\n",
      "alpha =  0.7847368421052632 b =  5005.50274693001 epoch =  5  loss = 2594.035  loss reduction = 13.81351  correctly classified = 90.6250%\n",
      "alpha =  0.7847368421052632 b =  5101.2657532458 epoch =  6  loss = 2614.755  loss reduction = -20.72026  correctly classified = 90.5500%\n",
      "alpha =  0.7847368421052632 b =  5199.378261666852 epoch =  7  loss = 2607.849  loss reduction = 6.906755  correctly classified = 90.5750%\n",
      "alpha =  0.7847368421052632 b =  5288.875929035274 epoch =  8  loss = 2587.128  loss reduction = 20.72026  correctly classified = 90.6500%\n",
      "alpha =  0.7847368421052632 b =  5414.399295351063 epoch =  9  loss = 2670.009  loss reduction = -82.88106  correctly classified = 90.3500%\n",
      "alpha =  0.7847368421052632 b =  5460.822757456326 epoch =  10  loss = 2552.595  loss reduction = 117.4148  correctly classified = 90.7750%\n",
      "alpha =  0.7847368421052632 b =  5657.614354298432 epoch =  11  loss = 2773.611  loss reduction = -221.0162  correctly classified = 89.9750%\n",
      "alpha =  0.7847368421052632 b =  5564.634024824748 epoch =  12  loss = 2704.543  loss reduction = 69.06755  correctly classified = 90.2250%\n",
      "alpha =  0.7847368421052632 b =  6012.822346930011 epoch =  13  loss = 4382.885  loss reduction = -1678.341  correctly classified = 84.1500%\n",
      "alpha =  0.7847368421052632 b =  4947.14814587738 epoch =  14  loss = 9887.568  loss reduction = -5504.684  correctly classified = 64.2250%\n",
      "alpha =  0.7847368421052632 b =  5819.030014298432 epoch =  15  loss = 7732.661  loss reduction = 2154.907  correctly classified = 72.0250%\n",
      "alpha =  0.7847368421052632 b =  4765.886491140538 epoch =  16  loss = 9763.247  loss reduction = -2030.586  correctly classified = 64.6750%\n",
      "alpha =  0.7847368421052632 b =  5635.418857456328 epoch =  17  loss = 7711.94  loss reduction = 2051.306  correctly classified = 72.1000%\n",
      "alpha =  0.7847368421052632 b =  4571.310991140538 epoch =  18  loss = 9873.755  loss reduction = -2161.814  correctly classified = 64.2750%\n",
      "alpha =  0.7847368421052632 b =  5436.1443532458015 epoch =  19  loss = 7684.313  loss reduction = 2189.441  correctly classified = 72.2000%\n",
      "alpha =  0.7847368421052632 b =  4402.5800142984335 epoch =  20  loss = 9604.391  loss reduction = -1920.078  correctly classified = 65.2500%\n",
      "alpha =  0.7847368421052632 b =  5256.449033245802 epoch =  21  loss = 7587.619  loss reduction = 2016.772  correctly classified = 72.5500%\n",
      "alpha =  0.7847368421052632 b =  4193.1243342984335 epoch =  22  loss = 9866.848  loss reduction = -2279.229  correctly classified = 64.3000%\n",
      "alpha =  0.7847368421052632 b =  5043.077516403697 epoch =  23  loss = 7553.085  loss reduction = 2313.763  correctly classified = 72.6750%\n",
      "alpha =  0.7847368421052632 b =  4022.0438553510653 epoch =  24  loss = 9493.883  loss reduction = -1940.798  correctly classified = 65.6500%\n",
      "alpha =  0.7847368421052632 b =  4857.116857456329 epoch =  25  loss = 7421.857  loss reduction = 2072.026  correctly classified = 73.1500%\n",
      "alpha =  0.7847368421052632 b =  3800.84066482475 epoch =  26  loss = 9804.687  loss reduction = -2382.83  correctly classified = 64.5250%\n",
      "alpha =  0.7847368421052632 b =  4632.780997456329 epoch =  27  loss = 7394.23  loss reduction = 2410.457  correctly classified = 73.2500%\n",
      "alpha =  0.7847368421052632 b =  3654.821541666855 epoch =  28  loss = 9127.825  loss reduction = -1733.595  correctly classified = 66.9750%\n",
      "alpha =  0.7847368421052632 b =  4465.616355351066 epoch =  29  loss = 7207.747  loss reduction = 1920.078  correctly classified = 73.9250%\n",
      "alpha =  0.7847368421052632 b =  3380.3629700879083 epoch =  30  loss = 10060.24  loss reduction = -2852.49  correctly classified = 63.6000%\n",
      "alpha =  0.7847368421052632 b =  4207.604298508961 epoch =  31  loss = 7352.789  loss reduction = 2707.448  correctly classified = 73.4000%\n",
      "alpha =  0.7847368421052632 b =  3334.589270087908 epoch =  32  loss = 8285.201  loss reduction = -932.4119  correctly classified = 70.0250%\n",
      "alpha =  0.7847368421052632 b =  4095.261372193171 epoch =  33  loss = 6807.155  loss reduction = 1478.046  correctly classified = 75.3750%\n",
      "alpha =  0.7847368421052632 b =  2939.5229237721187 epoch =  34  loss = 10681.84  loss reduction = -3874.689  correctly classified = 61.3500%\n",
      "alpha =  0.7847368421052632 b =  3766.764252193171 epoch =  35  loss = 7352.789  loss reduction = 3329.056  correctly classified = 73.4000%\n",
      "alpha =  0.7847368421052632 b =  2998.6936511405397 epoch =  36  loss = 7414.95  loss reduction = -62.16079  correctly classified = 73.1750%\n",
      "alpha =  0.7847368421052632 b =  3696.712363772119 epoch =  37  loss = 6296.056  loss reduction = 1118.894  correctly classified = 77.2250%\n",
      "alpha =  0.7847368421052632 b =  2557.4204300879082 epoch =  38  loss = 10536.8  loss reduction = -4240.747  correctly classified = 61.8750%\n",
      "alpha =  0.7847368421052632 b =  3373.6974153510664 epoch =  39  loss = 7256.095  loss reduction = 3280.709  correctly classified = 73.7500%\n",
      "alpha =  0.7847368421052632 b =  2600.9278100879087 epoch =  40  loss = 7456.39  loss reduction = -200.2959  correctly classified = 73.0250%\n",
      "alpha =  0.7847368421052632 b =  3278.58417114054 epoch =  41  loss = 6116.48  loss reduction = 1339.91  correctly classified = 77.8750%\n",
      "alpha =  0.7847368421052632 b =  2255.201007982645 epoch =  42  loss = 9583.671  loss reduction = -3467.191  correctly classified = 65.3250%\n",
      "alpha =  0.7847368421052632 b =  3029.186955351066 epoch =  43  loss = 6910.757  loss reduction = 2672.914  correctly classified = 75.0000%\n",
      "alpha =  0.7847368421052632 b =  2105.266047982645 epoch =  44  loss = 8747.954  loss reduction = -1837.197  correctly classified = 68.3500%\n",
      "alpha =  0.7847368421052632 b =  2827.5629490352767 epoch =  45  loss = 6496.351  loss reduction = 2251.602  correctly classified = 76.5000%\n",
      "alpha =  0.7847368421052632 b =  1879.3638532458028 epoch =  46  loss = 8948.249  loss reduction = -2451.898  correctly classified = 67.6250%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.7847368421052632 b =  2600.8775869300134 epoch =  47  loss = 6489.445  loss reduction = 2458.805  correctly classified = 76.5250%\n",
      "alpha =  0.7847368421052632 b =  1694.9695290352765 epoch =  48  loss = 8602.912  loss reduction = -2113.467  correctly classified = 68.8750%\n",
      "alpha =  0.7847368421052632 b =  2391.4219069300134 epoch =  49  loss = 6282.242  loss reduction = 2320.67  correctly classified = 77.2750%\n",
      "alpha =  0.7847368421052632 b =  1497.2613595615921 epoch =  50  loss = 8499.31  loss reduction = -2217.068  correctly classified = 69.2500%\n",
      "alpha =  0.7847368421052632 b =  2181.9662269300134 epoch =  51  loss = 6178.641  loss reduction = 2320.67  correctly classified = 77.6500%\n",
      "alpha =  0.7847368421052632 b =  1322.2650437721188 epoch =  52  loss = 8195.413  loss reduction = -2016.772  correctly classified = 70.3500%\n",
      "alpha =  0.7847368421052632 b =  1972.5105469300136 epoch =  53  loss = 5888.557  loss reduction = 2306.856  correctly classified = 78.7000%\n",
      "alpha =  0.7847368421052632 b =  1225.5854648247505 epoch =  54  loss = 7269.908  loss reduction = -1381.351  correctly classified = 73.7000%\n",
      "alpha =  0.7847368421052632 b =  1824.9250890352769 epoch =  55  loss = 5481.059  loss reduction = 1788.849  correctly classified = 80.1750%\n",
      "alpha =  0.7847368421052632 b =  1182.9444342984348 epoch =  56  loss = 6454.911  loss reduction = -973.8524  correctly classified = 76.6500%\n",
      "alpha =  0.7847368421052632 b =  1719.630669035277 epoch =  57  loss = 5011.399  loss reduction = 1443.512  correctly classified = 81.8750%\n",
      "alpha =  0.7847368421052632 b =  1119.1578848247507 epoch =  58  loss = 6116.48  loss reduction = -1105.081  correctly classified = 77.8750%\n",
      "alpha =  0.7847368421052632 b =  1635.4817679826456 epoch =  59  loss = 4887.078  loss reduction = 1229.402  correctly classified = 82.3250%\n",
      "alpha =  0.7847368421052632 b =  1072.6010174563298 epoch =  60  loss = 5867.837  loss reduction = -980.7592  correctly classified = 78.7750%\n",
      "alpha =  0.7847368421052632 b =  1563.0803774563299 epoch =  61  loss = 4686.782  loss reduction = 1181.055  correctly classified = 83.0500%\n",
      "alpha =  0.7847368421052632 b =  1023.6946479826456 epoch =  62  loss = 5688.261  loss reduction = -1001.479  correctly classified = 79.4250%\n",
      "alpha =  0.7847368421052632 b =  1504.775999561593 epoch =  63  loss = 4631.528  loss reduction = 1056.733  correctly classified = 83.2500%\n",
      "alpha =  0.7847368421052632 b =  986.5357890352773 epoch =  64  loss = 5543.219  loss reduction = -911.6916  correctly classified = 79.9500%\n",
      "alpha =  0.7847368421052632 b =  1463.7013037721194 epoch =  65  loss = 4610.807  loss reduction = 932.4119  correctly classified = 83.3250%\n",
      "alpha =  0.7847368421052632 b =  944.6779258773827 epoch =  66  loss = 5536.313  loss reduction = -925.5051  correctly classified = 79.9750%\n",
      "alpha =  0.7847368421052632 b =  1422.626607982646 epoch =  67  loss = 4617.714  loss reduction = 918.5984  correctly classified = 83.3000%\n",
      "alpha =  0.7847368421052632 b =  901.253727982646 epoch =  68  loss = 5557.033  loss reduction = -939.3186  correctly classified = 79.9000%\n",
      "alpha =  0.7847368421052632 b =  1379.2024100879091 epoch =  69  loss = 4617.714  loss reduction = 939.3186  correctly classified = 83.3000%\n",
      "alpha =  0.7847368421052632 b =  857.0463627194881 epoch =  70  loss = 5563.94  loss reduction = -946.2254  correctly classified = 79.8750%\n",
      "alpha =  0.7847368421052632 b =  1334.2118774563303 epoch =  71  loss = 4610.807  loss reduction = 953.1322  correctly classified = 83.3250%\n",
      "alpha =  0.7847368421052632 b =  818.3211690352776 epoch =  72  loss = 5522.499  loss reduction = -911.6916  correctly classified = 80.0250%\n",
      "alpha =  0.7847368421052632 b =  1293.1371816668566 epoch =  73  loss = 4603.901  loss reduction = 918.5984  correctly classified = 83.3500%\n",
      "alpha =  0.7847368421052632 b =  781.1623100879092 epoch =  74  loss = 5501.779  loss reduction = -897.8781  correctly classified = 80.1000%\n",
      "alpha =  0.7847368421052632 b =  1250.4961511405409 epoch =  75  loss = 4555.553  loss reduction = 946.2254  correctly classified = 83.5250%\n",
      "alpha =  0.7847368421052632 b =  751.8351248247513 epoch =  76  loss = 5425.805  loss reduction = -870.2511  correctly classified = 80.3750%\n",
      "alpha =  0.7847368421052632 b =  1215.6867942984356 epoch =  77  loss = 4534.833  loss reduction = 890.9714  correctly classified = 83.6000%\n",
      "alpha =  0.7847368421052632 b =  760.8831406142251 epoch =  78  loss = 5094.28  loss reduction = -559.4471  correctly classified = 81.5750%\n",
      "alpha =  0.7847368421052632 b =  1191.8417806142252 epoch =  79  loss = 4369.071  loss reduction = 725.2093  correctly classified = 84.2000%\n",
      "alpha =  0.7847368421052632 b =  785.5945037721199 epoch =  80  loss = 4776.57  loss reduction = -407.4985  correctly classified = 82.7250%\n",
      "alpha =  0.7847368421052632 b =  1205.5888006142252 epoch =  81  loss = 4313.817  loss reduction = 462.7526  correctly classified = 84.4000%\n",
      "alpha =  0.7847368421052632 b =  812.6553690352779 epoch =  82  loss = 4659.155  loss reduction = -345.3377  correctly classified = 83.1500%\n",
      "alpha =  0.7847368421052632 b =  1213.853649035278 epoch =  83  loss = 4189.495  loss reduction = 469.6593  correctly classified = 84.8500%\n",
      "alpha =  0.7847368421052632 b =  888.2726111405412 epoch =  84  loss = 4286.19  loss reduction = -96.69457  correctly classified = 84.5000%\n",
      "alpha =  0.7847368421052632 b =  1269.108539561594 epoch =  85  loss = 4037.547  loss reduction = 248.6432  correctly classified = 85.4000%\n",
      "alpha =  0.7847368421052632 b =  980.3363679826466 epoch =  86  loss = 4044.454  loss reduction = -6.906755  correctly classified = 85.3750%\n",
      "alpha =  0.7847368421052632 b =  1343.9426142984362 epoch =  87  loss = 3982.293  loss reduction = 62.16079  correctly classified = 85.6000%\n",
      "alpha =  0.7847368421052632 b =  1086.497137456331 epoch =  88  loss = 3837.251  loss reduction = 145.0419  correctly classified = 86.1250%\n",
      "alpha =  0.7847368421052632 b =  1445.4043795615944 epoch =  89  loss = 3954.666  loss reduction = -117.4148  correctly classified = 85.7000%\n",
      "alpha =  0.7847368421052632 b =  1192.6579069300155 epoch =  90  loss = 3795.81  loss reduction = 158.8554  correctly classified = 86.2750%\n",
      "alpha =  0.7847368421052632 b =  1549.2156469300157 epoch =  91  loss = 3947.759  loss reduction = -151.9486  correctly classified = 85.7250%\n",
      "alpha =  0.7847368421052632 b =  1309.7830195615948 epoch =  92  loss = 3692.209  loss reduction = 255.5499  correctly classified = 86.6500%\n",
      "alpha =  0.7847368421052632 b =  1655.3764164037002 epoch =  93  loss = 3864.878  loss reduction = -172.6689  correctly classified = 86.0250%\n",
      "alpha =  0.7847368421052632 b =  1423.7754627194897 epoch =  94  loss = 3623.142  loss reduction = 241.7364  correctly classified = 86.9000%\n",
      "alpha =  0.7847368421052632 b =  1767.802524824753 epoch =  95  loss = 3851.064  loss reduction = -227.9229  correctly classified = 86.0750%\n",
      "alpha =  0.7847368421052632 b =  1547.9490816668583 epoch =  96  loss = 3616.235  loss reduction = 234.8297  correctly classified = 86.9250%\n",
      "alpha =  0.7847368421052632 b =  1886.4939721931742 epoch =  97  loss = 3802.717  loss reduction = -186.4824  correctly classified = 86.2500%\n",
      "alpha =  0.7847368421052632 b =  1676.038537456332 epoch =  98  loss = 3547.167  loss reduction = 255.5499  correctly classified = 87.1750%\n",
      "alpha =  0.7847368421052632 b =  2009.8844237721216 epoch =  99  loss = 3775.09  loss reduction = -227.9229  correctly classified = 86.3500%\n",
      "alpha =  0.7847368421052632 b =  1803.344825877385 epoch =  100  loss = 3526.447  loss reduction = 248.6432  correctly classified = 87.2500%\n",
      "alpha =  0.7847368421052632 b =  2135.6243774563322 epoch =  101  loss = 3775.09  loss reduction = -248.6432  correctly classified = 86.3500%\n",
      "alpha =  0.7847368421052632 b =  1930.6511142984375 epoch =  102  loss = 3512.633  loss reduction = 262.4567  correctly classified = 87.3000%\n",
      "alpha =  0.7847368421052632 b =  2264.497000614227 epoch =  103  loss = 3775.09  loss reduction = -262.4567  correctly classified = 86.3500%\n",
      "alpha =  0.7847368421052632 b =  2054.824733245806 epoch =  104  loss = 3540.26  loss reduction = 234.8297  correctly classified = 87.2000%\n",
      "alpha =  0.7847368421052632 b =  2390.2369542984375 epoch =  105  loss = 3788.904  loss reduction = -248.6432  correctly classified = 86.3000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.7847368421052632 b =  2176.6488500879113 epoch =  106  loss = 3533.354  loss reduction = 255.5499  correctly classified = 87.2250%\n",
      "alpha =  0.7847368421052632 b =  2512.844238508964 epoch =  107  loss = 3795.81  loss reduction = -262.4567  correctly classified = 86.2750%\n",
      "alpha =  0.7847368421052632 b =  2292.207627982648 epoch =  108  loss = 3567.887  loss reduction = 227.9229  correctly classified = 87.1000%\n",
      "alpha =  0.7847368421052632 b =  2631.535685877385 epoch =  109  loss = 3795.81  loss reduction = -227.9229  correctly classified = 86.2750%\n",
      "alpha =  0.7847368421052632 b =  2410.899075351069 epoch =  110  loss = 3567.887  loss reduction = 227.9229  correctly classified = 87.1000%\n",
      "alpha =  0.7847368421052632 b =  2765.890480614227 epoch =  111  loss = 3823.437  loss reduction = -255.5499  correctly classified = 86.1750%\n",
      "alpha =  0.7847368421052632 b =  2508.4450037721217 epoch =  112  loss = 3768.183  loss reduction = 55.25404  correctly classified = 86.3750%\n",
      "alpha =  0.7847368421052632 b =  2868.135413245806 epoch =  113  loss = 3851.064  loss reduction = -82.88106  correctly classified = 86.0750%\n",
      "alpha =  0.7847368421052632 b =  2610.689936403701 epoch =  114  loss = 3768.183  loss reduction = 82.88106  correctly classified = 86.3750%\n",
      "alpha =  0.7847368421052632 b =  2973.513015351069 epoch =  115  loss = 3878.691  loss reduction = -110.5081  correctly classified = 85.9750%\n",
      "alpha =  0.7847368421052632 b =  2700.404191140543 epoch =  116  loss = 3851.064  loss reduction = 27.62702  correctly classified = 86.0750%\n",
      "alpha =  0.7847368421052632 b =  3074.9747806142273 epoch =  117  loss = 3968.479  loss reduction = -117.4148  correctly classified = 85.6500%\n",
      "alpha =  0.7847368421052632 b =  2755.659081666859 epoch =  118  loss = 4065.174  loss reduction = -96.69457  correctly classified = 85.3000%\n",
      "alpha =  0.7847368421052632 b =  3158.4236964037013 epoch =  119  loss = 4120.428  loss reduction = -55.25404  correctly classified = 85.1000%\n",
      "alpha =  0.7847368421052632 b =  2788.2021185089643 epoch =  120  loss = 4417.418  loss reduction = -296.9905  correctly classified = 84.0250%\n",
      "alpha =  0.7847368421052632 b =  3220.7270932458064 epoch =  121  loss = 4341.444  loss reduction = 75.9743  correctly classified = 84.3000%\n",
      "alpha =  0.7847368421052632 b =  2772.971945877385 epoch =  122  loss = 4935.425  loss reduction = -593.9809  correctly classified = 82.1500%\n",
      "alpha =  0.7847368421052632 b =  3236.0404479826484 epoch =  123  loss = 4514.113  loss reduction = 421.312  correctly classified = 83.6750%\n",
      "alpha =  0.7847368421052632 b =  2717.0170700879116 epoch =  124  loss = 5425.805  loss reduction = -911.6916  correctly classified = 80.3750%\n",
      "alpha =  0.7847368421052632 b =  3227.075614298438 epoch =  125  loss = 4845.637  loss reduction = 580.1674  correctly classified = 82.4750%\n",
      "alpha =  0.7847368421052632 b =  2621.120658508964 epoch =  126  loss = 6109.573  loss reduction = -1263.936  correctly classified = 77.9000%\n",
      "alpha =  0.7847368421052632 b =  3159.373227982648 epoch =  127  loss = 5052.84  loss reduction = 1056.733  correctly classified = 81.7250%\n",
      "alpha =  0.7847368421052632 b =  2533.055920614227 epoch =  128  loss = 6275.335  loss reduction = -1222.496  correctly classified = 77.3000%\n",
      "alpha =  0.7847368421052632 b =  3083.839167982648 epoch =  129  loss = 5135.721  loss reduction = 1139.615  correctly classified = 81.4250%\n",
      "alpha =  0.7847368421052632 b =  2458.3050279826484 epoch =  130  loss = 6268.429  loss reduction = -1132.708  correctly classified = 77.3250%\n",
      "alpha =  0.7847368421052632 b =  3002.822936403701 epoch =  131  loss = 5080.467  loss reduction = 1187.962  correctly classified = 81.6250%\n",
      "alpha =  0.7847368421052632 b =  2395.3016458773855 epoch =  132  loss = 6123.387  loss reduction = -1042.92  correctly classified = 77.8500%\n",
      "alpha =  0.7847368421052632 b =  2928.0720437721225 epoch =  133  loss = 5004.492  loss reduction = 1118.894  correctly classified = 81.9000%\n",
      "alpha =  0.7847368421052632 b =  2316.6349164037015 epoch =  134  loss = 6157.921  loss reduction = -1153.428  correctly classified = 77.7250%\n",
      "alpha =  0.7847368421052632 b =  2847.8389795615963 epoch =  135  loss = 4990.679  loss reduction = 1167.242  correctly classified = 81.9500%\n",
      "alpha =  0.7847368421052632 b =  2256.7642037721225 epoch =  136  loss = 6019.785  loss reduction = -1029.106  correctly classified = 78.2250%\n",
      "alpha =  0.7847368421052632 b =  2773.088086930017 epoch =  137  loss = 4873.264  loss reduction = 1146.521  correctly classified = 82.3750%\n",
      "alpha =  0.7847368421052632 b =  2200.0261606142276 epoch =  138  loss = 5860.93  loss reduction = -987.6659  correctly classified = 78.8000%\n",
      "alpha =  0.7847368421052632 b =  2699.1203616668595 epoch =  139  loss = 4748.943  loss reduction = 1111.988  correctly classified = 82.8250%\n",
      "alpha =  0.7847368421052632 b =  2165.999971140544 epoch =  140  loss = 5536.313  loss reduction = -787.37  correctly classified = 79.9750%\n",
      "alpha =  0.7847368421052632 b =  2654.912996403702 epoch =  141  loss = 4672.968  loss reduction = 863.3443  correctly classified = 83.1000%\n",
      "alpha =  0.7847368421052632 b =  2141.371790087913 epoch =  142  loss = 5405.084  loss reduction = -732.116  correctly classified = 80.4500%\n",
      "alpha =  0.7847368421052632 b =  2610.7056311405445 epoch =  143  loss = 4569.367  loss reduction = 835.7173  correctly classified = 83.4750%\n",
      "alpha =  0.7847368421052632 b =  2127.707952193176 epoch =  144  loss = 5218.602  loss reduction = -649.2349  correctly classified = 81.1250%\n",
      "alpha =  0.7847368421052632 b =  2576.6794416668604 epoch =  145  loss = 4458.859  loss reduction = 759.743  correctly classified = 83.8750%\n",
      "alpha =  0.7847368421052632 b =  2156.3351521931763 epoch =  146  loss = 4762.756  loss reduction = -303.8972  correctly classified = 82.7750%\n",
      "alpha =  0.7847368421052632 b =  2585.7274574563344 epoch =  147  loss = 4313.817  loss reduction = 448.9391  correctly classified = 84.4000%\n",
      "alpha =  0.7847368421052632 b =  2191.227691140545 epoch =  148  loss = 4590.087  loss reduction = -276.2702  correctly classified = 83.4000%\n",
      "alpha =  0.7847368421052632 b =  2607.3061511405454 epoch =  149  loss = 4224.029  loss reduction = 366.058  correctly classified = 84.7250%\n",
      "alpha =  0.7847368421052632 b =  2257.446924824756 epoch =  150  loss = 4306.91  loss reduction = -82.88106  correctly classified = 84.4250%\n",
      "alpha =  0.7847368421052632 b =  2642.198690087914 epoch =  151  loss = 4016.827  loss reduction = 290.0837  correctly classified = 85.4750%\n",
      "alpha =  0.7847368421052632 b =  2344.028510087914 epoch =  152  loss = 3961.572  loss reduction = 55.25404  correctly classified = 85.6750%\n",
      "alpha =  0.7847368421052632 b =  2705.2852542984406 epoch =  153  loss = 3864.878  loss reduction = 96.69457  correctly classified = 86.0250%\n",
      "alpha =  0.7847368421052632 b =  2480.7328069300197 epoch =  154  loss = 3547.167  loss reduction = 317.7107  correctly classified = 87.1750%\n",
      "alpha =  0.7847368421052632 b =  2802.8311827194934 epoch =  155  loss = 3671.489  loss reduction = -124.3216  correctly classified = 86.7250%\n",
      "alpha =  0.7847368421052632 b =  2660.511309035283 epoch =  156  loss = 3125.855  loss reduction = 545.6336  correctly classified = 88.7000%\n",
      "alpha =  0.7847368421052632 b =  2951.2829900879146 epoch =  157  loss = 3505.727  loss reduction = -379.8715  correctly classified = 87.3250%\n",
      "alpha =  0.7847368421052632 b =  2880.2313469300198 epoch =  158  loss = 2842.678  loss reduction = 663.0485  correctly classified = 89.7250%\n",
      "alpha =  0.7847368421052632 b =  3152.207011140546 epoch =  159  loss = 3381.405  loss reduction = -538.7269  correctly classified = 87.7750%\n",
      "alpha =  0.7847368421052632 b =  3099.9513848247566 epoch =  160  loss = 2787.424  loss reduction = 593.9809  correctly classified = 89.9250%\n",
      "alpha =  0.7847368421052632 b =  3367.2280448247566 epoch =  161  loss = 3353.778  loss reduction = -566.3539  correctly classified = 87.8750%\n",
      "alpha =  0.7847368421052632 b =  3314.1892511405463 epoch =  162  loss = 2780.517  loss reduction = 573.2606  correctly classified = 89.9500%\n",
      "alpha =  0.7847368421052632 b =  3584.5985806142307 epoch =  163  loss = 3367.592  loss reduction = -587.0742  correctly classified = 87.8250%\n",
      "alpha =  0.7847368421052632 b =  3532.3429542984413 epoch =  164  loss = 2773.611  loss reduction = 593.9809  correctly classified = 89.9750%\n",
      "alpha =  0.7847368421052632 b =  3804.3186185089676 epoch =  165  loss = 3381.405  loss reduction = -607.7944  correctly classified = 87.7750%\n",
      "alpha =  0.7847368421052632 b =  3752.062992193178 epoch =  166  loss = 2759.797  loss reduction = 621.6079  correctly classified = 90.0250%\n",
      "alpha =  0.7847368421052632 b =  4024.8218237721258 epoch =  167  loss = 3388.312  loss reduction = -628.5147  correctly classified = 87.7500%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.7847368421052632 b =  3970.999862719494 epoch =  168  loss = 2773.611  loss reduction = 614.7012  correctly classified = 89.9750%\n",
      "alpha =  0.7847368421052632 b =  4241.409192193179 epoch =  169  loss = 3381.405  loss reduction = -607.7944  correctly classified = 87.7750%\n",
      "alpha =  0.7847368421052632 b =  4187.587231140547 epoch =  170  loss = 2759.797  loss reduction = 621.6079  correctly classified = 90.0250%\n",
      "alpha =  0.7847368421052632 b =  4456.43022587739 epoch =  171  loss = 3367.592  loss reduction = -607.7944  correctly classified = 87.8250%\n",
      "alpha =  0.7847368421052632 b =  4401.825097456337 epoch =  172  loss = 2752.89  loss reduction = 614.7012  correctly classified = 90.0500%\n",
      "alpha =  0.7847368421052632 b =  4670.668092193179 epoch =  173  loss = 3353.778  loss reduction = -600.8877  correctly classified = 87.8750%\n",
      "alpha =  0.7847368421052632 b =  4615.279796403705 epoch =  174  loss = 2759.797  loss reduction = 593.9809  correctly classified = 90.0250%\n",
      "alpha =  0.7847368421052632 b =  4882.556456403706 epoch =  175  loss = 3339.965  loss reduction = -580.1674  correctly classified = 87.9250%\n",
      "alpha =  0.7847368421052632 b =  4827.168160614232 epoch =  176  loss = 2745.984  loss reduction = 593.9809  correctly classified = 90.0750%\n",
      "alpha =  0.7847368421052632 b =  5096.7943227194955 epoch =  177  loss = 3360.685  loss reduction = -614.7012  correctly classified = 87.8500%\n",
      "alpha =  0.7847368421052632 b =  5021.826842719495 epoch =  178  loss = 2794.331  loss reduction = 566.3539  correctly classified = 89.9000%\n",
      "alpha =  0.7847368421052632 b =  5307.899519561601 epoch =  179  loss = 3409.032  loss reduction = -614.7012  correctly classified = 87.6750%\n",
      "alpha =  0.7847368421052632 b =  5203.954846930022 epoch =  180  loss = 2856.492  loss reduction = 552.5404  correctly classified = 89.6750%\n",
      "alpha =  0.7847368421052632 b =  5488.461189035284 epoch =  181  loss = 3395.219  loss reduction = -538.7269  correctly classified = 87.7250%\n",
      "alpha =  0.7847368421052632 b =  5379.817512193179 epoch =  182  loss = 2828.865  loss reduction = 566.3539  correctly classified = 89.7750%\n",
      "alpha =  0.7847368421052632 b =  5669.022858508969 epoch =  183  loss = 3409.032  loss reduction = -580.1674  correctly classified = 87.6750%\n",
      "alpha =  0.7847368421052632 b =  5554.113842719496 epoch =  184  loss = 2815.051  loss reduction = 593.9809  correctly classified = 89.8250%\n",
      "alpha =  0.7847368421052632 b =  5844.885523772127 epoch =  185  loss = 3395.219  loss reduction = -580.1674  correctly classified = 87.7250%\n",
      "alpha =  0.7847368421052632 b =  5726.843838508969 epoch =  186  loss = 2828.865  loss reduction = 566.3539  correctly classified = 89.7750%\n",
      "alpha =  0.7847368421052632 b =  6021.531356403706 epoch =  187  loss = 3402.125  loss reduction = -573.2606  correctly classified = 87.7000%\n",
      "alpha =  0.7847368421052632 b =  5891.7421606142325 epoch =  188  loss = 2891.025  loss reduction = 511.0999  correctly classified = 89.5500%\n",
      "alpha =  0.7847368421052632 b =  6195.044519561601 epoch =  189  loss = 3422.846  loss reduction = -531.8201  correctly classified = 87.6250%\n",
      "alpha =  0.7847368421052632 b =  6026.880122719496 epoch =  190  loss = 2980.813  loss reduction = 442.0323  correctly classified = 89.2250%\n",
      "alpha =  0.7847368421052632 b =  6361.509176403707 epoch =  191  loss = 3588.608  loss reduction = -607.7944  correctly classified = 87.0250%\n",
      "alpha =  0.7847368421052632 b =  6155.752745877391 epoch =  192  loss = 3201.829  loss reduction = 386.7783  correctly classified = 88.4250%\n",
      "alpha =  0.7847368421052632 b =  6504.478812193181 epoch =  193  loss = 3685.302  loss reduction = -483.4728  correctly classified = 86.6750%\n",
      "alpha =  0.7847368421052632 b =  6250.949172193181 epoch =  194  loss = 3471.193  loss reduction = 214.1094  correctly classified = 87.4500%\n",
      "alpha =  0.7847368421052632 b =  6623.170259561602 epoch =  195  loss = 3892.505  loss reduction = -421.312  correctly classified = 85.9250%\n",
      "alpha =  0.7847368421052632 b =  6260.780355351076 epoch =  196  loss = 4196.402  loss reduction = -303.8972  correctly classified = 84.8250%\n",
      "alpha =  0.7847368421052632 b =  6701.920171140549 epoch =  197  loss = 4320.724  loss reduction = -124.3216  correctly classified = 84.3750%\n",
      "alpha =  0.7847368421052632 b =  6177.414621666865 epoch =  198  loss = 5432.711  loss reduction = -1111.988  correctly classified = 80.3500%\n",
      "alpha =  0.7847368421052632 b =  6707.8355174563385 epoch =  199  loss = 4969.959  loss reduction = 462.7526  correctly classified = 82.0250%\n",
      "alpha =  0.7847368421052632 b =  6042.359841666865 epoch =  200  loss = 6551.606  loss reduction = -1581.647  correctly classified = 76.3000%\n",
      "alpha =  0.7847368421052632 b =  6638.566796403707 epoch =  201  loss = 5467.245  loss reduction = 1084.361  correctly classified = 80.2250%\n",
      "alpha =  0.7847368421052632 b =  5879.111036403707 epoch =  202  loss = 7297.535  loss reduction = -1830.29  correctly classified = 73.6000%\n",
      "alpha =  0.7847368421052632 b =  6522.308033245812 epoch =  203  loss = 5826.396  loss reduction = 1471.139  correctly classified = 78.9250%\n",
      "alpha =  0.7847368421052632 b =  5682.186034298444 epoch =  204  loss = 7981.304  loss reduction = -2154.907  correctly classified = 71.1250%\n",
      "alpha =  0.7847368421052632 b =  6347.311717456339 epoch =  205  loss = 6019.785  loss reduction = 1961.518  correctly classified = 78.2250%\n",
      "alpha =  0.7847368421052632 b =  5504.057049035286 epoch =  206  loss = 8008.931  loss reduction = -1989.145  correctly classified = 71.0250%\n",
      "alpha =  0.7847368421052632 b =  6162.134225877391 epoch =  207  loss = 5957.625  loss reduction = 2051.306  correctly classified = 78.4500%\n",
      "alpha =  0.7847368421052632 b =  5374.484440614233 epoch =  208  loss = 7532.365  loss reduction = -1574.74  correctly classified = 72.7500%\n",
      "alpha =  0.7847368421052632 b =  6000.451755351075 epoch =  209  loss = 5688.261  loss reduction = 1844.104  correctly classified = 79.4250%\n",
      "alpha =  0.7847368421052632 b =  5262.924681666865 epoch =  210  loss = 7159.4  loss reduction = -1471.139  correctly classified = 74.1000%\n",
      "alpha =  0.7847368421052632 b =  5857.565301666865 epoch =  211  loss = 5439.618  loss reduction = 1719.782  correctly classified = 80.3250%\n",
      "alpha =  0.7847368421052632 b =  5196.788630087917 epoch =  212  loss = 6523.979  loss reduction = -1084.361  correctly classified = 76.4000%\n",
      "alpha =  0.7847368421052632 b =  5734.25803219318 epoch =  213  loss = 5018.306  loss reduction = 1505.673  correctly classified = 81.8500%\n",
      "alpha =  0.7847368421052632 b =  5154.930766930022 epoch =  214  loss = 5888.557  loss reduction = -870.2511  correctly classified = 78.7000%\n",
      "alpha =  0.7847368421052632 b =  5643.0606248247595 epoch =  215  loss = 4679.875  loss reduction = 1208.682  correctly classified = 83.0750%\n",
      "alpha =  0.7847368421052632 b =  5130.302585877391 epoch =  216  loss = 5370.55  loss reduction = -690.6755  correctly classified = 80.5750%\n",
      "alpha =  0.7847368421052632 b =  5601.202761666865 epoch =  217  loss = 4527.926  loss reduction = 842.6241  correctly classified = 83.6250%\n",
      "alpha =  0.7847368421052632 b =  5104.108070087917 epoch =  218  loss = 5246.229  loss reduction = -718.3025  correctly classified = 81.0250%\n",
      "alpha =  0.7847368421052632 b =  5558.561731140549 epoch =  219  loss = 4424.325  loss reduction = 821.9038  correctly classified = 84.0000%\n",
      "alpha =  0.7847368421052632 b =  5104.54124482476 epoch =  220  loss = 4893.984  loss reduction = -469.6593  correctly classified = 82.3000%\n",
      "alpha =  0.7847368421052632 b =  5537.066219561602 epoch =  221  loss = 4313.817  loss reduction = 580.1674  correctly classified = 84.4000%\n",
      "alpha =  0.7847368421052632 b =  5127.686273245813 epoch =  222  loss = 4569.367  loss reduction = -255.5499  correctly classified = 83.4750%\n",
      "alpha =  0.7847368421052632 b =  5539.0657290352865 epoch =  223  loss = 4141.148  loss reduction = 428.2188  correctly classified = 85.0250%\n",
      "alpha =  0.7847368421052632 b =  5186.073833245813 epoch =  224  loss = 4237.843  loss reduction = -96.69457  correctly classified = 84.6750%\n",
      "alpha =  0.7847368421052632 b =  5562.993924824761 epoch =  225  loss = 3906.318  loss reduction = 331.5242  correctly classified = 85.8750%\n",
      "alpha =  0.7847368421052632 b =  5321.994962719498 epoch =  226  loss = 3512.633  loss reduction = 393.685  correctly classified = 87.3000%\n",
      "alpha =  0.7847368421052632 b =  5640.9606690352875 epoch =  227  loss = 3574.794  loss reduction = -62.16079  correctly classified = 87.0750%\n",
      "alpha =  0.7847368421052632 b =  5502.556632193182 epoch =  228  loss = 2953.186  loss reduction = 621.6079  correctly classified = 89.3250%\n",
      "alpha =  0.7847368421052632 b =  5790.195643772129 epoch =  229  loss = 3450.473  loss reduction = -497.2863  correctly classified = 87.5250%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.7847368421052632 b =  5712.095494298445 epoch =  230  loss = 2725.263  loss reduction = 725.2093  correctly classified = 90.1500%\n",
      "alpha =  0.7847368421052632 b =  5975.45631745634 epoch =  231  loss = 3305.431  loss reduction = -580.1674  correctly classified = 88.0500%\n",
      "alpha =  0.7847368421052632 b =  5926.333360614235 epoch =  232  loss = 2704.543  loss reduction = 600.8877  correctly classified = 90.2250%\n",
      "alpha =  0.7847368421052632 b =  6184.212012193182 epoch =  233  loss = 3270.897  loss reduction = -566.3539  correctly classified = 88.1750%\n",
      "alpha =  0.7847368421052632 b =  6139.788059561603 epoch =  234  loss = 2718.357  loss reduction = 552.5404  correctly classified = 90.1750%\n",
      "alpha =  0.7847368421052632 b =  6389.051870087919 epoch =  235  loss = 3222.55  loss reduction = -504.1931  correctly classified = 88.3500%\n",
      "alpha =  0.7847368421052632 b =  6357.941762719498 epoch =  236  loss = 2711.45  loss reduction = 511.0999  correctly classified = 90.2000%\n",
      "alpha =  0.7847368421052632 b =  6597.807564824761 epoch =  237  loss = 3167.296  loss reduction = -455.8458  correctly classified = 88.5500%\n",
      "alpha =  0.7847368421052632 b =  6569.830126930025 epoch =  238  loss = 2711.45  loss reduction = 455.8458  correctly classified = 90.2000%\n",
      "alpha =  0.7847368421052632 b =  6812.045431140551 epoch =  239  loss = 3174.202  loss reduction = -462.7526  correctly classified = 88.5250%\n",
      "alpha =  0.7847368421052632 b =  6780.93532377213 epoch =  240  loss = 2697.636  loss reduction = 476.5661  correctly classified = 90.2500%\n",
      "alpha =  0.7847368421052632 b =  7022.367460614235 epoch =  241  loss = 3167.296  loss reduction = -469.6593  correctly classified = 88.5500%\n",
      "alpha =  0.7847368421052632 b =  6983.425679561604 epoch =  242  loss = 2683.823  loss reduction = 483.4728  correctly classified = 90.3000%\n",
      "alpha =  0.7847368421052632 b =  7232.68949008792 epoch =  243  loss = 3194.923  loss reduction = -511.0999  correctly classified = 88.4500%\n",
      "alpha =  0.7847368421052632 b =  7183.566533245815 epoch =  244  loss = 2649.289  loss reduction = 545.6336  correctly classified = 90.4250%\n",
      "alpha =  0.7847368421052632 b =  7435.963013245815 epoch =  245  loss = 3222.55  loss reduction = -573.2606  correctly classified = 88.3500%\n",
      "alpha =  0.7847368421052632 b =  7383.707386930026 epoch =  246  loss = 2663.103  loss reduction = 559.4471  correctly classified = 90.3750%\n",
      "alpha =  0.7847368421052632 b =  7640.019703772131 epoch =  247  loss = 3229.456  loss reduction = -566.3539  correctly classified = 88.3250%\n",
      "alpha =  0.7847368421052632 b =  7585.414575351078 epoch =  248  loss = 2656.196  loss reduction = 573.2606  correctly classified = 90.4000%\n",
      "alpha =  0.7847368421052632 b =  7850.341733245816 epoch =  249  loss = 3263.99  loss reduction = -607.7944  correctly classified = 88.2000%\n",
      "alpha =  0.7847368421052632 b =  7777.723755351079 epoch =  250  loss = 2649.289  loss reduction = 614.7012  correctly classified = 90.4250%\n",
      "alpha =  0.7847368421052632 b =  8050.482586930026 epoch =  251  loss = 3277.804  loss reduction = -628.5147  correctly classified = 88.1500%\n",
      "alpha =  0.7847368421052632 b =  7961.418094298447 epoch =  252  loss = 2670.009  loss reduction = 607.7944  correctly classified = 90.3500%\n",
      "alpha =  0.7847368421052632 b =  8239.659097456342 epoch =  253  loss = 3284.711  loss reduction = -614.7012  correctly classified = 88.1250%\n",
      "alpha =  0.7847368421052632 b =  8123.183746930026 epoch =  254  loss = 2704.543  loss reduction = 580.1674  correctly classified = 90.2250%\n",
      "alpha =  0.7847368421052632 b =  8413.955427982657 epoch =  255  loss = 3326.151  loss reduction = -621.6079  correctly classified = 87.9750%\n",
      "alpha =  0.7847368421052632 b =  8281.0335627195 epoch =  256  loss = 2766.704  loss reduction = 559.4471  correctly classified = 90.0000%\n",
      "alpha =  0.7847368421052632 b =  8574.154745877395 epoch =  257  loss = 3333.058  loss reduction = -566.3539  correctly classified = 87.9500%\n",
      "alpha =  0.7847368421052632 b =  8441.232880614238 epoch =  258  loss = 2766.704  loss reduction = 566.3539  correctly classified = 90.0000%\n",
      "alpha =  0.7847368421052632 b =  8734.354063772133 epoch =  259  loss = 3319.244  loss reduction = -552.5404  correctly classified = 88.0000%\n",
      "alpha =  0.7847368421052632 b =  8602.215365877395 epoch =  260  loss = 2745.984  loss reduction = 573.2606  correctly classified = 90.0750%\n",
      "alpha =  0.7847368421052632 b =  8892.203879561606 epoch =  261  loss = 3305.431  loss reduction = -559.4471  correctly classified = 88.0500%\n",
      "alpha =  0.7847368421052632 b =  8756.149344824764 epoch =  262  loss = 2739.077  loss reduction = 566.3539  correctly classified = 90.1000%\n",
      "alpha =  0.7847368421052632 b =  9055.535866930028 epoch =  263  loss = 3346.871  loss reduction = -607.7944  correctly classified = 87.9000%\n",
      "alpha =  0.7847368421052632 b =  8895.203143772133 epoch =  264  loss = 2884.119  loss reduction = 462.7526  correctly classified = 89.5750%\n",
      "alpha =  0.7847368421052632 b =  9222.000523772133 epoch =  265  loss = 3491.913  loss reduction = -607.7944  correctly classified = 87.3750%\n",
      "alpha =  0.7847368421052632 b =  9021.726264824763 epoch =  266  loss = 3029.161  loss reduction = 462.7526  correctly classified = 89.0500%\n",
      "alpha =  0.7847368421052632 b =  9359.487987982659 epoch =  267  loss = 3574.794  loss reduction = -545.6336  correctly classified = 87.0750%\n",
      "alpha =  0.7847368421052632 b =  9137.2850427195 epoch =  268  loss = 3194.923  loss reduction = 379.8715  correctly classified = 88.4500%\n",
      "alpha =  0.7847368421052632 b =  9480.528937456344 epoch =  269  loss = 3623.142  loss reduction = -428.2188  correctly classified = 86.9000%\n",
      "alpha =  0.7847368421052632 b =  9245.012146930028 epoch =  270  loss = 3243.27  loss reduction = 379.8715  correctly classified = 88.2750%\n",
      "alpha =  0.7847368421052632 b =  9599.220384824765 epoch =  271  loss = 3706.023  loss reduction = -462.7526  correctly classified = 86.6000%\n",
      "alpha =  0.7847368421052632 b =  9351.172916403711 epoch =  272  loss = 3339.965  loss reduction = 366.058  correctly classified = 87.9250%\n",
      "alpha =  0.7847368421052632 b =  9710.863325877395 epoch =  273  loss = 3740.556  loss reduction = -400.5918  correctly classified = 86.4750%\n",
      "alpha =  0.7847368421052632 b =  9398.596133245816 epoch =  274  loss = 3754.37  loss reduction = -13.81351  correctly classified = 86.4250%\n",
      "alpha =  0.7847368421052632 b =  9802.9270827195 epoch =  275  loss = 4023.733  loss reduction = -269.3634  correctly classified = 85.4500%\n",
      "alpha =  0.7847368421052632 b =  9385.7154627195 epoch =  276  loss = 4541.74  loss reduction = -518.0066  correctly classified = 83.5750%\n",
      "alpha =  0.7847368421052632 b =  9838.602789035289 epoch =  277  loss = 4369.071  loss reduction = 172.6689  correctly classified = 84.2000%\n",
      "alpha =  0.7847368421052632 b =  9287.46954903529 epoch =  278  loss = 5570.846  loss reduction = -1201.775  correctly classified = 79.8500%\n",
      "alpha =  0.7847368421052632 b =  9818.673612193184 epoch =  279  loss = 4976.865  loss reduction = 593.9809  correctly classified = 82.0000%\n",
      "alpha =  0.7847368421052632 b =  9152.41476903529 epoch =  280  loss = 6503.258  loss reduction = -1526.393  correctly classified = 76.4750%\n",
      "alpha =  0.7847368421052632 b =  9746.272221666868 epoch =  281  loss = 5460.338  loss reduction = 1042.92  correctly classified = 80.2500%\n",
      "alpha =  0.7847368421052632 b =  8977.418453245815 epoch =  282  loss = 7338.976  loss reduction = -1878.637  correctly classified = 73.4500%\n",
      "alpha =  0.7847368421052632 b =  9620.61545008792 epoch =  283  loss = 5826.396  loss reduction = 1512.579  correctly classified = 78.9250%\n",
      "alpha =  0.7847368421052632 b =  8775.794446930026 epoch =  284  loss = 7981.304  loss reduction = -2154.907  correctly classified = 71.1250%\n",
      "alpha =  0.7847368421052632 b =  9436.221125877393 epoch =  285  loss = 5978.345  loss reduction = 2002.959  correctly classified = 78.3750%\n",
      "alpha =  0.7847368421052632 b =  8603.147633245815 epoch =  286  loss = 7891.516  loss reduction = -1913.171  correctly classified = 71.4500%\n",
      "alpha =  0.7847368421052632 b =  9253.39313640371 epoch =  287  loss = 5888.557  loss reduction = 2002.959  correctly classified = 78.7000%\n",
      "alpha =  0.7847368421052632 b =  8468.092853245817 epoch =  288  loss = 7470.204  loss reduction = -1581.647  correctly classified = 72.9750%\n",
      "alpha =  0.7847368421052632 b =  9087.01166166687 epoch =  289  loss = 5639.914  loss reduction = 1830.29  correctly classified = 79.6000%\n",
      "alpha =  0.7847368421052632 b =  8378.461780614238 epoch =  290  loss = 6848.596  loss reduction = -1208.682  correctly classified = 75.2250%\n",
      "alpha =  0.7847368421052632 b =  8937.076701666869 epoch =  291  loss = 5190.975  loss reduction = 1657.621  correctly classified = 81.2250%\n",
      "alpha =  0.7847368421052632 b =  8330.338578508974 epoch =  292  loss = 6033.599  loss reduction = -842.6241  correctly classified = 78.1750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.7847368421052632 b =  8833.348616403711 epoch =  293  loss = 4742.036  loss reduction = 1291.563  correctly classified = 82.8500%\n",
      "alpha =  0.7847368421052632 b =  8297.09555640371 epoch =  294  loss = 5536.313  loss reduction = -794.2768  correctly classified = 79.9750%\n",
      "alpha =  0.7847368421052632 b =  8757.03138903529 epoch =  295  loss = 4431.232  loss reduction = 1105.081  correctly classified = 83.9750%\n",
      "alpha =  0.7847368421052632 b =  8271.684207982658 epoch =  296  loss = 5115.001  loss reduction = -683.7687  correctly classified = 81.5000%\n",
      "alpha =  0.7847368421052632 b =  8714.390358508974 epoch =  297  loss = 4320.724  loss reduction = 794.2768  correctly classified = 84.3750%\n",
      "alpha =  0.7847368421052632 b =  8267.418378508974 epoch =  298  loss = 4804.197  loss reduction = -483.4728  correctly classified = 82.6250%\n",
      "alpha =  0.7847368421052632 b =  8682.713671140553 epoch =  299  loss = 4148.055  loss reduction = 656.1417  correctly classified = 85.0000%\n",
      "alpha =  0.7847368421052632 b =  8297.611913245815 epoch =  300  loss = 4369.071  loss reduction = -221.0162  correctly classified = 84.2000%\n",
      "alpha =  0.7847368421052632 b =  8695.67752377213 epoch =  301  loss = 4009.92  loss reduction = 359.1512  correctly classified = 85.5000%\n",
      "alpha =  0.7847368421052632 b =  8357.565807982657 epoch =  302  loss = 4037.547  loss reduction = -27.62702  correctly classified = 85.4000%\n",
      "alpha =  0.7847368421052632 b =  8729.003727982657 epoch =  303  loss = 3844.158  loss reduction = 193.3891  correctly classified = 86.1000%\n",
      "alpha =  0.7847368421052632 b =  8493.486937456342 epoch =  304  loss = 3270.897  loss reduction = 573.2606  correctly classified = 88.1750%\n",
      "alpha =  0.7847368421052632 b =  8808.536806930026 epoch =  305  loss = 3457.379  loss reduction = -186.4824  correctly classified = 87.5000%\n",
      "alpha =  0.7847368421052632 b =  8662.30109640371 epoch =  306  loss = 2870.305  loss reduction = 587.0742  correctly classified = 89.6250%\n",
      "alpha =  0.7847368421052632 b =  8952.28961008792 epoch =  307  loss = 3346.871  loss reduction = -476.5661  correctly classified = 87.9000%\n",
      "alpha =  0.7847368421052632 b =  8852.260774298447 epoch =  308  loss = 2656.196  loss reduction = 690.6755  correctly classified = 90.4000%\n",
      "alpha =  0.7847368421052632 b =  9117.187932193185 epoch =  309  loss = 3222.55  loss reduction = -566.3539  correctly classified = 88.3500%\n",
      "alpha =  0.7847368421052632 b =  9059.450134298448 epoch =  310  loss = 2573.315  loss reduction = 649.2349  correctly classified = 90.7000%\n",
      "alpha =  0.7847368421052632 b =  9297.749601666868 epoch =  311  loss = 3056.788  loss reduction = -483.4728  correctly classified = 88.9500%\n",
      "alpha =  0.7847368421052632 b =  9268.205829035289 epoch =  312  loss = 2573.315  loss reduction = 483.4728  correctly classified = 90.7000%\n",
      "alpha =  0.7847368421052632 b =  9500.239957456342 epoch =  313  loss = 3029.161  loss reduction = -455.8458  correctly classified = 89.0500%\n",
      "alpha =  0.7847368421052632 b =  9469.913017456342 epoch =  314  loss = 2552.595  loss reduction = 476.5661  correctly classified = 90.7750%\n",
      "alpha =  0.7847368421052632 b =  9704.296647982657 epoch =  315  loss = 3049.881  loss reduction = -497.2863  correctly classified = 88.9750%\n",
      "alpha =  0.7847368421052632 b =  9670.837038508973 epoch =  316  loss = 2524.967  loss reduction = 524.9134  correctly classified = 90.8750%\n",
      "alpha =  0.7847368421052632 b =  9906.00383640371 epoch =  317  loss = 3042.974  loss reduction = -518.0066  correctly classified = 89.0000%\n",
      "alpha =  0.7847368421052632 b =  9869.411557456342 epoch =  318  loss = 2524.967  loss reduction = 518.0066  correctly classified = 90.8750%\n",
      "alpha =  0.7847368421052632 b =  10110.060526930027 epoch =  319  loss = 3077.508  loss reduction = -552.5404  correctly classified = 88.8750%\n",
      "alpha =  0.7847368421052632 b =  10052.32272903529 epoch =  320  loss = 2531.874  loss reduction = 545.6336  correctly classified = 90.8500%\n",
      "alpha =  0.7847368421052632 b =  10296.104367982658 epoch =  321  loss = 3091.321  loss reduction = -559.4471  correctly classified = 88.8250%\n",
      "alpha =  0.7847368421052632 b =  10237.5834027195 epoch =  322  loss = 2524.967  loss reduction = 566.3539  correctly classified = 90.8750%\n",
      "alpha =  0.7847368421052632 b =  10481.365041666868 epoch =  323  loss = 3091.321  loss reduction = -566.3539  correctly classified = 88.8250%\n",
      "alpha =  0.7847368421052632 b =  10422.060909035288 epoch =  324  loss = 2518.061  loss reduction = 573.2606  correctly classified = 90.9000%\n",
      "alpha =  0.7847368421052632 b =  10665.842547982656 epoch =  325  loss = 3091.321  loss reduction = -573.2606  correctly classified = 88.8250%\n",
      "alpha =  0.7847368421052632 b =  10605.755247982657 epoch =  326  loss = 2497.34  loss reduction = 593.9809  correctly classified = 90.9750%\n",
      "alpha =  0.7847368421052632 b =  10844.054715351078 epoch =  327  loss = 3042.974  loss reduction = -545.6336  correctly classified = 89.0000%\n",
      "alpha =  0.7847368421052632 b =  10785.53375008792 epoch =  328  loss = 2455.9  loss reduction = 587.0742  correctly classified = 91.1250%\n",
      "alpha =  0.7847368421052632 b =  11026.182719561604 epoch =  329  loss = 3049.881  loss reduction = -593.9809  correctly classified = 88.9750%\n",
      "alpha =  0.7847368421052632 b =  10966.878586930025 epoch =  330  loss = 2462.807  loss reduction = 587.0742  correctly classified = 91.1000%\n",
      "alpha =  0.7847368421052632 b =  11206.744389035288 epoch =  331  loss = 3042.974  loss reduction = -580.1674  correctly classified = 89.0000%\n",
      "alpha =  0.7847368421052632 b =  11143.524419561603 epoch =  332  loss = 2469.713  loss reduction = 573.2606  correctly classified = 91.0750%\n",
      "alpha =  0.7847368421052632 b =  11396.704066930024 epoch =  333  loss = 3077.508  loss reduction = -607.7944  correctly classified = 88.8750%\n",
      "alpha =  0.7847368421052632 b =  11307.639574298446 epoch =  334  loss = 2545.688  loss reduction = 531.8201  correctly classified = 90.8000%\n",
      "alpha =  0.7847368421052632 b =  11585.88057745634 epoch =  335  loss = 3146.575  loss reduction = -600.8877  correctly classified = 88.6250%\n",
      "alpha =  0.7847368421052632 b =  11461.573553245815 epoch =  336  loss = 2566.408  loss reduction = 580.1674  correctly classified = 90.7250%\n",
      "alpha =  0.7847368421052632 b =  11756.261071140552 epoch =  337  loss = 3250.177  loss reduction = -683.7687  correctly classified = 88.2500%\n",
      "alpha =  0.7847368421052632 b =  11599.061017456343 epoch =  338  loss = 2745.984  loss reduction = 504.1931  correctly classified = 90.0750%\n",
      "alpha =  0.7847368421052632 b =  11906.279213245816 epoch =  339  loss = 3319.244  loss reduction = -573.2606  correctly classified = 88.0000%\n",
      "alpha =  0.7847368421052632 b =  11720.885134298447 epoch =  340  loss = 2897.932  loss reduction = 421.312  correctly classified = 89.5250%\n",
      "alpha =  0.7847368421052632 b =  12049.24884903529 epoch =  341  loss = 3478.1  loss reduction = -580.1674  correctly classified = 87.4250%\n",
      "alpha =  0.7847368421052632 b =  11835.660744824763 epoch =  342  loss = 3063.694  loss reduction = 414.4053  correctly classified = 88.9250%\n",
      "alpha =  0.7847368421052632 b =  12164.807626930027 epoch =  343  loss = 3485.006  loss reduction = -421.312  correctly classified = 87.4000%\n",
      "alpha =  0.7847368421052632 b =  11953.569024824765 epoch =  344  loss = 3042.974  loss reduction = 442.0323  correctly classified = 89.0000%\n",
      "alpha =  0.7847368421052632 b =  12282.715906930029 epoch =  345  loss = 3485.006  loss reduction = -442.0323  correctly classified = 87.4000%\n",
      "alpha =  0.7847368421052632 b =  12069.910970087923 epoch =  346  loss = 3029.161  loss reduction = 455.8458  correctly classified = 89.0500%\n",
      "alpha =  0.7847368421052632 b =  12402.973689035292 epoch =  347  loss = 3491.913  loss reduction = -462.7526  correctly classified = 87.3750%\n",
      "alpha =  0.7847368421052632 b =  12183.120245877397 epoch =  348  loss = 3063.694  loss reduction = 428.2188  correctly classified = 88.9250%\n",
      "alpha =  0.7847368421052632 b =  12516.966132193187 epoch =  349  loss = 3498.82  loss reduction = -435.1256  correctly classified = 87.3500%\n",
      "alpha =  0.7847368421052632 b =  12297.895856403713 epoch =  350  loss = 3056.788  loss reduction = 442.0323  correctly classified = 88.9500%\n",
      "alpha =  0.7847368421052632 b =  12632.524910087923 epoch =  351  loss = 3505.727  loss reduction = -448.9391  correctly classified = 87.3250%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.7847368421052632 b =  12413.454634298449 epoch =  352  loss = 3056.788  loss reduction = 448.9391  correctly classified = 88.9500%\n",
      "alpha =  0.7847368421052632 b =  12744.951018508975 epoch =  353  loss = 3478.1  loss reduction = -421.312  correctly classified = 87.4250%\n",
      "alpha =  0.7847368421052632 b =  12532.14608166687 epoch =  354  loss = 3001.534  loss reduction = 476.5661  correctly classified = 89.1500%\n",
      "alpha =  0.7847368421052632 b =  12865.208800614238 epoch =  355  loss = 3491.913  loss reduction = -490.3796  correctly classified = 87.3750%\n",
      "alpha =  0.7847368421052632 b =  12644.572190087923 epoch =  356  loss = 3070.601  loss reduction = 421.312  correctly classified = 88.9000%\n",
      "alpha =  0.7847368421052632 b =  12979.984411140555 epoch =  357  loss = 3512.633  loss reduction = -442.0323  correctly classified = 87.3000%\n",
      "alpha =  0.7847368421052632 b =  12760.130967982659 epoch =  358  loss = 3063.694  loss reduction = 448.9391  correctly classified = 88.9250%\n",
      "alpha =  0.7847368421052632 b =  13094.760021666869 epoch =  359  loss = 3505.727  loss reduction = -442.0323  correctly classified = 87.3250%\n",
      "alpha =  0.7847368421052632 b =  12875.689745877395 epoch =  360  loss = 3056.788  loss reduction = 448.9391  correctly classified = 88.9500%\n",
      "alpha =  0.7847368421052632 b =  13211.101966930026 epoch =  361  loss = 3512.633  loss reduction = -455.8458  correctly classified = 87.3000%\n",
      "alpha =  0.7847368421052632 b =  12990.46535640371 epoch =  362  loss = 3070.601  loss reduction = 442.0323  correctly classified = 88.9000%\n",
      "alpha =  0.7847368421052632 b =  13327.443912193185 epoch =  363  loss = 3526.447  loss reduction = -455.8458  correctly classified = 87.2500%\n",
      "alpha =  0.7847368421052632 b =  13100.5419627195 epoch =  364  loss = 3112.042  loss reduction = 414.4053  correctly classified = 88.7500%\n",
      "alpha =  0.7847368421052632 b =  13446.135359561606 epoch =  365  loss = 3588.608  loss reduction = -476.5661  correctly classified = 87.0250%\n",
      "alpha =  0.7847368421052632 b =  13147.182012193185 epoch =  366  loss = 3636.955  loss reduction = -48.34728  correctly classified = 86.8500%\n",
      "alpha =  0.7847368421052632 b =  13542.114953245817 epoch =  367  loss = 3940.852  loss reduction = -303.8972  correctly classified = 85.7500%\n",
      "alpha =  0.7847368421052632 b =  13133.518174298448 epoch =  368  loss = 4424.325  loss reduction = -483.4728  correctly classified = 84.0000%\n",
      "alpha =  0.7847368421052632 b =  13588.755002719501 epoch =  369  loss = 4403.605  loss reduction = 20.72026  correctly classified = 84.0750%\n",
      "alpha =  0.7847368421052632 b =  13028.223754298448 epoch =  370  loss = 5598.473  loss reduction = -1194.869  correctly classified = 79.7500%\n",
      "alpha =  0.7847368421052632 b =  13561.777319561606 epoch =  371  loss = 4983.772  loss reduction = 614.7012  correctly classified = 81.9750%\n",
      "alpha =  0.7847368421052632 b =  12864.974949035292 epoch =  372  loss = 6689.741  loss reduction = -1705.968  correctly classified = 75.8000%\n",
      "alpha =  0.7847368421052632 b =  13469.796744824765 epoch =  373  loss = 5543.219  loss reduction = 1146.521  correctly classified = 79.9500%\n",
      "alpha =  0.7847368421052632 b =  12660.218273245819 epoch =  374  loss = 7656.686  loss reduction = -2113.467  correctly classified = 72.3000%\n",
      "alpha =  0.7847368421052632 b =  13315.16278061424 epoch =  375  loss = 5943.811  loss reduction = 1712.875  correctly classified = 78.5000%\n",
      "alpha =  0.7847368421052632 b =  12410.821057456345 epoch =  376  loss = 8478.59  loss reduction = -2534.779  correctly classified = 69.3250%\n",
      "alpha =  0.7847368421052632 b =  13108.056602719504 epoch =  377  loss = 6275.335  loss reduction = 2203.255  correctly classified = 77.3000%\n",
      "alpha =  0.7847368421052632 b =  12202.148544824768 epoch =  378  loss = 8492.404  loss reduction = -2217.068  correctly classified = 69.2750%\n",
      "alpha =  0.7847368421052632 b =  12887.63657956161 epoch =  379  loss = 6185.548  loss reduction = 2306.856  correctly classified = 77.6250%\n",
      "alpha =  0.7847368421052632 b =  12027.152229035293 epoch =  380  loss = 8091.812  loss reduction = -1906.264  correctly classified = 70.7250%\n",
      "alpha =  0.7847368421052632 b =  12677.397732193189 epoch =  381  loss = 5888.557  loss reduction = 2203.255  correctly classified = 78.7000%\n",
      "alpha =  0.7847368421052632 b =  11918.72513956161 epoch =  382  loss = 7235.374  loss reduction = -1346.817  correctly classified = 73.8250%\n",
      "alpha =  0.7847368421052632 b =  12505.5340858774 epoch =  383  loss = 5398.177  loss reduction = 1837.197  correctly classified = 80.4750%\n",
      "alpha =  0.7847368421052632 b =  11850.2395858774 epoch =  384  loss = 6365.123  loss reduction = -966.9457  correctly classified = 76.9750%\n",
      "alpha =  0.7847368421052632 b =  12361.864464824768 epoch =  385  loss = 4804.197  loss reduction = 1560.927  correctly classified = 82.6250%\n",
      "alpha =  0.7847368421052632 b =  11808.381722719505 epoch =  386  loss = 5591.567  loss reduction = -787.37  correctly classified = 79.7750%\n",
      "alpha =  0.7847368421052632 b =  12262.835383772137 epoch =  387  loss = 4369.071  loss reduction = 1222.496  correctly classified = 84.2000%\n",
      "alpha =  0.7847368421052632 b =  11800.983223772137 epoch =  388  loss = 4893.984  loss reduction = -524.9134  correctly classified = 82.3000%\n",
      "alpha =  0.7847368421052632 b =  12216.278516403716 epoch =  389  loss = 4106.614  loss reduction = 787.37  correctly classified = 85.1500%\n",
      "alpha =  0.7847368421052632 b =  11843.707436403716 epoch =  390  loss = 4230.936  loss reduction = -124.3216  correctly classified = 84.7000%\n",
      "alpha =  0.7847368421052632 b =  12227.676034298453 epoch =  391  loss = 3885.598  loss reduction = 345.3377  correctly classified = 85.9500%\n",
      "alpha =  0.7847368421052632 b =  11974.929561666873 epoch =  392  loss = 3326.151  loss reduction = 559.4471  correctly classified = 87.9750%\n",
      "alpha =  0.7847368421052632 b =  12283.71409219319 epoch =  393  loss = 3346.871  loss reduction = -20.72026  correctly classified = 87.9000%\n",
      "alpha =  0.7847368421052632 b =  12137.478381666873 epoch =  394  loss = 2745.984  loss reduction = 600.8877  correctly classified = 90.0750%\n",
      "alpha =  0.7847368421052632 b =  12417.28571956161 epoch =  395  loss = 3229.456  loss reduction = -483.4728  correctly classified = 88.3250%\n",
      "alpha =  0.7847368421052632 b =  12315.690549035295 epoch =  396  loss = 2573.315  loss reduction = 656.1417  correctly classified = 90.7000%\n",
      "alpha =  0.7847368421052632 b =  12565.737526930032 epoch =  397  loss = 3049.881  loss reduction = -476.5661  correctly classified = 88.9750%\n",
      "alpha =  0.7847368421052632 b =  12511.9155658774 epoch =  398  loss = 2414.459  loss reduction = 635.4214  correctly classified = 91.2750%\n",
      "alpha =  0.7847368421052632 b =  12733.76851850898 epoch =  399  loss = 2897.932  loss reduction = -483.4728  correctly classified = 89.5250%\n",
      "alpha =  0.7847368421052632 b =  12708.140582719507 epoch =  400  loss = 2442.086  loss reduction = 455.8458  correctly classified = 91.1750%\n",
      "alpha =  0.7847368421052632 b =  12918.24602482477 epoch =  401  loss = 2821.958  loss reduction = -379.8715  correctly classified = 89.8000%\n",
      "alpha =  0.7847368421052632 b =  12925.51111850898 epoch =  402  loss = 2428.273  loss reduction = 393.685  correctly classified = 91.2250%\n",
      "alpha =  0.7847368421052632 b =  13073.746338508981 epoch =  403  loss = 2552.595  loss reduction = -124.3216  correctly classified = 90.7750%\n",
      "alpha =  0.7847368421052632 b =  13144.447989035298 epoch =  404  loss = 2324.672  loss reduction = 227.9229  correctly classified = 91.6000%\n",
      "alpha =  0.7847368421052632 b =  13260.573346930034 epoch =  405  loss = 2435.18  loss reduction = -110.5081  correctly classified = 91.2000%\n",
      "alpha =  0.7847368421052632 b =  13343.805675351086 epoch =  406  loss = 2352.299  loss reduction = 82.88106  correctly classified = 91.5000%\n",
      "alpha =  0.7847368421052632 b =  13451.316192193191 epoch =  407  loss = 2428.273  loss reduction = -75.9743  correctly classified = 91.2250%\n",
      "alpha =  0.7847368421052632 b =  13546.29603114056 epoch =  408  loss = 2373.019  loss reduction = 55.25404  correctly classified = 91.4250%\n",
      "alpha =  0.7847368421052632 b =  13638.143200614244 epoch =  409  loss = 2359.205  loss reduction = 13.81351  correctly classified = 91.4750%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  0.7847368421052632 b =  13735.472541666875 epoch =  410  loss = 2366.112  loss reduction = -6.906755  correctly classified = 91.4500%\n",
      "alpha =  0.7847368421052632 b =  13828.10287850898 epoch =  411  loss = 2352.299  loss reduction = 13.81351  correctly classified = 91.5000%\n",
      "alpha =  0.7847368421052632 b =  13923.86588482477 epoch =  412  loss = 2366.112  loss reduction = -13.81351  correctly classified = 91.4500%\n",
      "alpha =  0.7847368421052632 b =  14018.84572377214 epoch =  413  loss = 2373.019  loss reduction = -6.906755  correctly classified = 91.4250%\n",
      "alpha =  0.7847368421052632 b =  14113.042395351087 epoch =  414  loss = 2366.112  loss reduction = 6.906755  correctly classified = 91.4500%\n",
      "alpha =  0.7847368421052632 b =  14210.371736403718 epoch =  415  loss = 2366.112  loss reduction = 0.0  correctly classified = 91.4500%\n",
      "alpha =  0.8052631578947368 b =  14306.228652193193 epoch =  0  loss = 2359.205  loss reduction = 6.906755  correctly classified = 91.4750%\n",
      "alpha =  0.8052631578947368 b =  14405.300178508982 epoch =  1  loss = 2359.205  loss reduction = 0.0  correctly classified = 91.4750%\n",
      "alpha =  0.8257894736842105 b =  14504.42464377214 epoch =  0  loss = 2352.299  loss reduction = 6.906755  correctly classified = 91.5000%\n",
      "alpha =  0.8257894736842105 b =  14607.669798508981 epoch =  1  loss = 2373.019  loss reduction = -20.72026  correctly classified = 91.4250%\n",
      "alpha =  0.8257894736842105 b =  14708.442539561613 epoch =  2  loss = 2366.112  loss reduction = 6.906755  correctly classified = 91.4500%\n",
      "alpha =  0.8257894736842105 b =  14812.511832193191 epoch =  3  loss = 2366.112  loss reduction = 0.0  correctly classified = 91.4500%\n",
      "alpha =  0.8463157894736841 b =  14909.87707850898 epoch =  0  loss = 2331.578  loss reduction = 34.53377  correctly classified = 91.5750%\n",
      "alpha =  0.8463157894736841 b =  15017.377802719506 epoch =  1  loss = 2359.205  loss reduction = -27.62702  correctly classified = 91.4750%\n",
      "alpha =  0.8463157894736841 b =  15107.986063772138 epoch =  2  loss = 2303.951  loss reduction = 55.25404  correctly classified = 91.6750%\n",
      "alpha =  0.8463157894736841 b =  15214.642164824769 epoch =  3  loss = 2338.485  loss reduction = -34.53377  correctly classified = 91.5500%\n",
      "alpha =  0.8463157894736841 b =  15310.318164824768 epoch =  4  loss = 2331.578  loss reduction = 6.906755  correctly classified = 91.5750%\n",
      "alpha =  0.8463157894736841 b =  15411.906526930032 epoch =  5  loss = 2352.299  loss reduction = -20.72026  correctly classified = 91.5000%\n",
      "alpha =  0.8463157894736841 b =  15513.494889035295 epoch =  6  loss = 2352.299  loss reduction = 0.0  correctly classified = 91.5000%\n",
      "alpha =  0.8668421052631579 b =  15617.547147982663 epoch =  0  loss = 2352.299  loss reduction = 0.0  correctly classified = 91.5000%\n",
      "alpha =  0.8873684210526316 b =  15724.948897456346 epoch =  0  loss = 2331.578  loss reduction = 20.72026  correctly classified = 91.5750%\n",
      "alpha =  0.8873684210526316 b =  15828.808272193188 epoch =  1  loss = 2303.951  loss reduction = 27.62702  correctly classified = 91.6750%\n",
      "alpha =  0.8873684210526316 b =  15932.66764693003 epoch =  2  loss = 2303.951  loss reduction = 0.0  correctly classified = 91.6750%\n",
      "alpha =  0.9078947368421053 b =  16038.023383772135 epoch =  0  loss = 2283.231  loss reduction = 20.72026  correctly classified = 91.7500%\n",
      "alpha =  0.9078947368421053 b =  16139.754804824766 epoch =  1  loss = 2297.045  loss reduction = -13.81351  correctly classified = 91.7000%\n",
      "alpha =  0.9078947368421053 b =  16245.110541666872 epoch =  2  loss = 2283.231  loss reduction = 13.81351  correctly classified = 91.7500%\n",
      "alpha =  0.9078947368421053 b =  16348.654120614241 epoch =  3  loss = 2283.231  loss reduction = 0.0  correctly classified = 91.7500%\n",
      "alpha =  0.9284210526315789 b =  16451.758992193187 epoch =  0  loss = 2276.324  loss reduction = 6.906755  correctly classified = 91.7750%\n",
      "alpha =  0.9284210526315789 b =  16555.79042798266 epoch =  1  loss = 2269.418  loss reduction = 6.906755  correctly classified = 91.8000%\n",
      "alpha =  0.9284210526315789 b =  16658.89529956161 epoch =  2  loss = 2262.511  loss reduction = 6.906755  correctly classified = 91.8250%\n",
      "alpha =  0.9284210526315789 b =  16762.926735351084 epoch =  3  loss = 2269.418  loss reduction = -6.906755  correctly classified = 91.8000%\n",
      "alpha =  0.9284210526315789 b =  16866.03160693003 epoch =  4  loss = 2262.511  loss reduction = 6.906755  correctly classified = 91.8250%\n",
      "alpha =  0.9284210526315789 b =  16972.842735351085 epoch =  5  loss = 2276.324  loss reduction = -13.81351  correctly classified = 91.7750%\n",
      "alpha =  0.9284210526315789 b =  17071.314785877403 epoch =  6  loss = 2241.791  loss reduction = 34.53377  correctly classified = 91.9000%\n",
      "alpha =  0.9284210526315789 b =  17181.832171140562 epoch =  7  loss = 2276.324  loss reduction = -34.53377  correctly classified = 91.7750%\n",
      "alpha =  0.9284210526315789 b =  17273.818272193195 epoch =  8  loss = 2234.884  loss reduction = 41.44053  correctly classified = 91.9250%\n",
      "alpha =  0.9284210526315789 b =  17385.26222166688 epoch =  9  loss = 2255.604  loss reduction = -20.72026  correctly classified = 91.8500%\n",
      "alpha =  0.9284210526315789 b =  17465.20298798267 epoch =  10  loss = 2200.35  loss reduction = 55.25404  correctly classified = 92.0500%\n",
      "alpha =  0.9284210526315789 b =  17579.42663008793 epoch =  11  loss = 2234.884  loss reduction = -34.53377  correctly classified = 91.9250%\n",
      "alpha =  0.9284210526315789 b =  17657.514267982668 epoch =  12  loss = 2200.35  loss reduction = 34.53377  correctly classified = 92.0500%\n",
      "alpha =  0.9284210526315789 b =  17768.031653245827 epoch =  13  loss = 2207.257  loss reduction = -6.906755  correctly classified = 92.0250%\n",
      "alpha =  0.9284210526315789 b =  17846.119291140563 epoch =  14  loss = 2200.35  loss reduction = 6.906755  correctly classified = 92.0500%\n",
      "alpha =  0.9284210526315789 b =  17952.930419561617 epoch =  15  loss = 2179.63  loss reduction = 20.72026  correctly classified = 92.1250%\n",
      "alpha =  0.9284210526315789 b =  18031.94462166688 epoch =  16  loss = 2193.443  loss reduction = -13.81351  correctly classified = 92.0750%\n",
      "alpha =  0.9284210526315789 b =  18137.829185877406 epoch =  17  loss = 2172.723  loss reduction = 20.72026  correctly classified = 92.1500%\n",
      "alpha =  0.9284210526315789 b =  18217.769952193197 epoch =  18  loss = 2186.537  loss reduction = -13.81351  correctly classified = 92.1000%\n",
      "alpha =  0.9284210526315789 b =  18319.948259561617 epoch =  19  loss = 2186.537  loss reduction = 0.0  correctly classified = 92.1000%\n",
      "alpha =  0.9489473684210525 b =  18411.126918508984 epoch =  0  loss = 2158.909  loss reduction = 27.62702  correctly classified = 92.2000%\n",
      "alpha =  0.9489473684210525 b =  18505.146725877406 epoch =  1  loss = 2152.003  loss reduction = 6.906755  correctly classified = 92.2250%\n",
      "alpha =  0.9489473684210525 b =  18597.27243429846 epoch =  2  loss = 2138.189  loss reduction = 13.81351  correctly classified = 92.2750%\n",
      "alpha =  0.9489473684210525 b =  18689.39814271951 epoch =  3  loss = 2138.189  loss reduction = 0.0  correctly classified = 92.2750%\n",
      "alpha =  0.9694736842105263 b =  18782.549052193193 epoch =  0  loss = 2145.096  loss reduction = -6.906755  correctly classified = 92.2500%\n",
      "alpha =  0.9694736842105263 b =  18879.570100614244 epoch =  1  loss = 2131.282  loss reduction = 13.81351  correctly classified = 92.3000%\n",
      "alpha =  0.9694736842105263 b =  18973.68854482477 epoch =  2  loss = 2138.189  loss reduction = -6.906755  correctly classified = 92.2750%\n",
      "alpha =  0.9694736842105263 b =  19069.742058508982 epoch =  3  loss = 2124.376  loss reduction = 13.81351  correctly classified = 92.3250%\n",
      "alpha =  0.9694736842105263 b =  19164.82803745635 epoch =  4  loss = 2117.469  loss reduction = 6.906755  correctly classified = 92.3500%\n",
      "alpha =  0.9694736842105263 b =  19259.91401640372 epoch =  5  loss = 2117.469  loss reduction = 0.0  correctly classified = 92.3500%\n",
      "alpha =  0.99 b =  19357.01321640372 epoch =  0  loss = 2117.469  loss reduction = 0.0  correctly classified = 92.3500%\n",
      "     pred  true_label\n",
      "0     1.0           1\n",
      "1     0.0           0\n",
      "2     0.0           0\n",
      "3     1.0           1\n",
      "4     0.0           0\n",
      "..    ...         ...\n",
      "995   0.0           0\n",
      "996   1.0           0\n",
      "997   1.0           0\n",
      "998   0.0           0\n",
      "999   0.0           0\n",
      "\n",
      "[1000 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b2/8cn96b9x6qz0b7b79dn_n_1h0000gn/T/ipykernel_13453/3879921196.py:49: RuntimeWarning: overflow encountered in exp\n",
      "  test_pred = 1/(1+np.exp(-test_a))\n"
     ]
    }
   ],
   "source": [
    "lr1, lr1_test_pred = logistic_regression(fold_1_test, np.delete(all_index, fold_1_test))\n",
    "lr2 = logistic_regression(fold_2_test, np.delete(all_index, fold_2_test))\n",
    "lr3 = logistic_regression(fold_3_test, np.delete(all_index, fold_3_test))\n",
    "lr4 = logistic_regression(fold_4_test, np.delete(all_index, fold_4_test))\n",
    "lr5 = logistic_regression(fold_5_test, np.delete(all_index, fold_5_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "887293bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "{} &  fold &  accuracy &  precision &    recall \\\\\n",
      "\\midrule\n",
      "0 &     1 &     0.910 &   0.873563 &  0.800000 \\\\\n",
      "1 &     2 &     0.896 &   0.847390 &  0.761733 \\\\\n",
      "2 &     3 &     0.904 &   0.898305 &  0.746479 \\\\\n",
      "3 &     4 &     0.876 &   0.851240 &  0.700680 \\\\\n",
      "4 &     5 &     0.869 &   0.807018 &  0.751634 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b2/8cn96b9x6qz0b7b79dn_n_1h0000gn/T/ipykernel_13453/4025595111.py:6: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(lr_results.to_latex())\n"
     ]
    }
   ],
   "source": [
    "lr3[0][0]\n",
    "lr_results = pd.DataFrame({'fold':(1, 2, 3, 4, 5), 'accuracy': (lr1[0], lr2[0][0], lr3[0][0], lr4[0][0], lr5[0][0]),\n",
    "                         'precision':(lr1[1], lr2[0][1], lr3[0][1], lr4[0][1], lr5[0][1]), 'recall':(lr1[2], lr2[0][2], lr3[0][2], lr4[0][2], lr5[0][2])})\n",
    "# # final_lr = pd.concat([lr1, lr2, lr3, lr4, lr5])\n",
    "# # final_lr['fold'] = [1, 2, 3, 4, 5]\n",
    "print(lr_results.to_latex())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "ef9bda3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     the  to  ect  and  for  of    a  you  hou  in  ...  connevey  jay  \\\n",
      "0      0   0    1    0    0   0    2    0    0   0  ...         0    0   \n",
      "1      8  13   24    6    6   2  102    1   27  18  ...         0    0   \n",
      "2      0   0    1    0    0   0    8    0    0   4  ...         0    0   \n",
      "3      0   5   22    0    5   1   51    2   10   1  ...         0    0   \n",
      "4      7   6   17    1    5   2   57    0    9   3  ...         0    0   \n",
      "..   ...  ..  ...  ...  ...  ..  ...  ...  ...  ..  ...       ...  ...   \n",
      "995    6   7    1    1    2   1   28    1    0  11  ...         0    0   \n",
      "996    0   0    1    0    0   1    3    0    0   0  ...         0    0   \n",
      "997    5   7   14    2    4   2   83    2    6   7  ...         0    0   \n",
      "998    8   3    2    0    4   4   40    3    0   5  ...         0    0   \n",
      "999    0   0    1    0    0   0    4    1    0   3  ...         0    0   \n",
      "\n",
      "     valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
      "0         0    0               0         0         0   0    0           0  \n",
      "1         0    0               0         0         0   1    0           0  \n",
      "2         0    0               0         0         0   0    0           0  \n",
      "3         0    0               0         0         0   0    0           0  \n",
      "4         0    0               0         0         0   1    0           0  \n",
      "..      ...  ...             ...       ...       ...  ..  ...         ...  \n",
      "995       0    0               0         0         0   0    0           0  \n",
      "996       0    0               0         0         0   1    0           1  \n",
      "997       0    0               0         0         0   2    0           0  \n",
      "998       0    0               0         0         0   0    0           0  \n",
      "999       0    0               0         0         0   0    0           0  \n",
      "\n",
      "[1000 rows x 3001 columns]\n",
      "      the  to  ect  and  for  of    a  you  hou  in  ...  connevey  jay  \\\n",
      "1000   17  15    9   13   21   6  144    9    5  53  ...         0    0   \n",
      "1001    3   2    1    0    1   0   29    2    0   8  ...         0    0   \n",
      "1002    2   3   15    1    2   0   46    1    7   1  ...         0    0   \n",
      "1003   17  11   13    5    3   2   49    4    5  13  ...         0    0   \n",
      "1004    0   8    1    1    0   0   49    2    0   7  ...         0    0   \n",
      "...   ...  ..  ...  ...  ...  ..  ...  ...  ...  ..  ...       ...  ...   \n",
      "4995   20   6    3    1    1   1   34    0    0  15  ...         0    0   \n",
      "4996    0   7    1    0    0   0   20    1    1   0  ...         0    0   \n",
      "4997    6   8    1    3    2   1   64    7    1  16  ...         0    0   \n",
      "4998    8   6    2    5    6   1   51    4    0   4  ...         0    0   \n",
      "4999   13  12    3    7    6   4   96    9    1  10  ...         0    0   \n",
      "\n",
      "      valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
      "1000       0    0               0         0         0   2    0           0  \n",
      "1001       0    0               0         0         0   0    0           0  \n",
      "1002       0    0               0         0         0   0    0           0  \n",
      "1003       0    0               0         0         0   0    0           0  \n",
      "1004       0    0               0         0         0   1    0           1  \n",
      "...      ...  ...             ...       ...       ...  ..  ...         ...  \n",
      "4995       0    0               0         0         0   1    0           0  \n",
      "4996       0    1               0         0         0   0    0           0  \n",
      "4997       0    0               0         0         0   0    0           0  \n",
      "4998       0    0               0         0         0   0    0           0  \n",
      "4999       0    0               0         0         0   0    0           0  \n",
      "\n",
      "[4000 rows x 3001 columns]\n",
      "(4000, 3001)\n",
      "(1000, 3001)\n",
      "    0     1     2     3     4     5     6     7     8     9    ...   990  \\\n",
      "0  2537  2405   442  2621  1138  2172   322  1551   668  1369  ...   331   \n",
      "1  3596  1219    58    63  1437  2937  2053  1646  3417   916  ...  3923   \n",
      "2   459  3739  2069  1537  1399   587   665   878   836    24  ...  2182   \n",
      "\n",
      "    991   992   993   994   995   996   997   998   999  \n",
      "0  2883  3169    24   896  2949  1270  2310  2850   227  \n",
      "1  2894  2683   697   277  2954  1774  2483  2854  1755  \n",
      "2   776  3167  1146  3493  3617  1721  2305   377  2870  \n",
      "\n",
      "[3 rows x 1000 columns]\n",
      "   0    1    2    3    4    5    6    7    8    9    ...  990  991  992  993  \\\n",
      "0    0    1    0    0    0    1    0    1    1    0  ...    0    0    0    0   \n",
      "1    0    0    0    0    0    1    0    1    0    0  ...    1    0    0    0   \n",
      "2    0    1    0    0    0    1    1    1    1    0  ...    1    0    0    0   \n",
      "\n",
      "   994  995  996  997  998  999  \n",
      "0    1    0    1    0    0    1  \n",
      "1    1    0    1    0    0    1  \n",
      "2    0    0    1    0    1    1  \n",
      "\n",
      "[3 rows x 1000 columns]\n",
      "0      0\n",
      "1      1\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "995    0\n",
      "996    1\n",
      "997    0\n",
      "998    0\n",
      "999    1\n",
      "Name: 0, Length: 1000, dtype: int64\n",
      "     the  to  ect  and  for  of    a  you  hou  in  ...  jay  valued  lay  \\\n",
      "0      0   0    1    0    0   0    2    0    0   0  ...    0       0    0   \n",
      "1      8  13   24    6    6   2  102    1   27  18  ...    0       0    0   \n",
      "2      0   0    1    0    0   0    8    0    0   4  ...    0       0    0   \n",
      "3      0   5   22    0    5   1   51    2   10   1  ...    0       0    0   \n",
      "4      7   6   17    1    5   2   57    0    9   3  ...    0       0    0   \n",
      "..   ...  ..  ...  ...  ...  ..  ...  ...  ...  ..  ...  ...     ...  ...   \n",
      "995    6   7    1    1    2   1   28    1    0  11  ...    0       0    0   \n",
      "996    0   0    1    0    0   1    3    0    0   0  ...    0       0    0   \n",
      "997    5   7   14    2    4   2   83    2    6   7  ...    0       0    0   \n",
      "998    8   3    2    0    4   4   40    3    0   5  ...    0       0    0   \n",
      "999    0   0    1    0    0   0    4    1    0   3  ...    0       0    0   \n",
      "\n",
      "     infrastructure  military  allowing  ff  dry  Prediction  pred  \n",
      "0                 0         0         0   0    0           0     0  \n",
      "1                 0         0         0   1    0           0     1  \n",
      "2                 0         0         0   0    0           0     0  \n",
      "3                 0         0         0   0    0           0     0  \n",
      "4                 0         0         0   1    0           0     0  \n",
      "..              ...       ...       ...  ..  ...         ...   ...  \n",
      "995               0         0         0   0    0           0     0  \n",
      "996               0         0         0   1    0           1     1  \n",
      "997               0         0         0   2    0           0     0  \n",
      "998               0         0         0   0    0           0     0  \n",
      "999               0         0         0   0    0           0     1  \n",
      "\n",
      "[1000 rows x 3002 columns]\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
      " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
      " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
      " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
      " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
      " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
      " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
      " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
      " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
      " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
      " 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n",
      " 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n",
      " 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n",
      " 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503\n",
      " 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521\n",
      " 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539\n",
      " 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557\n",
      " 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575\n",
      " 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593\n",
      " 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611\n",
      " 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629\n",
      " 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647\n",
      " 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665\n",
      " 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683\n",
      " 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701\n",
      " 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719\n",
      " 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737\n",
      " 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755\n",
      " 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773\n",
      " 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791\n",
      " 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809\n",
      " 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827\n",
      " 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845\n",
      " 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863\n",
      " 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881\n",
      " 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899\n",
      " 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917\n",
      " 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935\n",
      " 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953\n",
      " 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971\n",
      " 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989\n",
      " 990 991 992 993 994 995 996 997 998 999]\n",
      "     the  to  ect  and  for  of    a  you  hou  in  ...  valued  lay  \\\n",
      "0      0   0    1    0    0   0    2    0    0   0  ...       0    0   \n",
      "1      8  13   24    6    6   2  102    1   27  18  ...       0    0   \n",
      "2      0   0    1    0    0   0    8    0    0   4  ...       0    0   \n",
      "3      0   5   22    0    5   1   51    2   10   1  ...       0    0   \n",
      "4      7   6   17    1    5   2   57    0    9   3  ...       0    0   \n",
      "..   ...  ..  ...  ...  ...  ..  ...  ...  ...  ..  ...     ...  ...   \n",
      "995    6   7    1    1    2   1   28    1    0  11  ...       0    0   \n",
      "996    0   0    1    0    0   1    3    0    0   0  ...       0    0   \n",
      "997    5   7   14    2    4   2   83    2    6   7  ...       0    0   \n",
      "998    8   3    2    0    4   4   40    3    0   5  ...       0    0   \n",
      "999    0   0    1    0    0   0    4    1    0   3  ...       0    0   \n",
      "\n",
      "     infrastructure  military  allowing  ff  dry  Prediction  pred  true_label  \n",
      "0                 0         0         0   0    0           0     0           0  \n",
      "1                 0         0         0   1    0           0     1           0  \n",
      "2                 0         0         0   0    0           0     0           0  \n",
      "3                 0         0         0   0    0           0     0           0  \n",
      "4                 0         0         0   1    0           0     0           0  \n",
      "..              ...       ...       ...  ..  ...         ...   ...         ...  \n",
      "995               0         0         0   0    0           0     0           0  \n",
      "996               0         0         0   1    0           1     1           1  \n",
      "997               0         0         0   2    0           0     0           0  \n",
      "998               0         0         0   0    0           0     0           0  \n",
      "999               0         0         0   0    0           0     1           0  \n",
      "\n",
      "[1000 rows x 3003 columns]\n",
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "995    0\n",
      "996    1\n",
      "997    0\n",
      "998    0\n",
      "999    0\n",
      "Name: Prediction, Length: 1000, dtype: int64\n",
      "[0.845, 0.6775956284153005, 0.8701754385964913]\n",
      "      the  to  ect  and  for  of    a  you  hou  in  ...  connevey  jay  \\\n",
      "1000   17  15    9   13   21   6  144    9    5  53  ...         0    0   \n",
      "1001    3   2    1    0    1   0   29    2    0   8  ...         0    0   \n",
      "1002    2   3   15    1    2   0   46    1    7   1  ...         0    0   \n",
      "1003   17  11   13    5    3   2   49    4    5  13  ...         0    0   \n",
      "1004    0   8    1    1    0   0   49    2    0   7  ...         0    0   \n",
      "...   ...  ..  ...  ...  ...  ..  ...  ...  ...  ..  ...       ...  ...   \n",
      "1995   11  14    6   10    9   5  111    7    1  29  ...         0    0   \n",
      "1996   38  37    9   24   16  20  313   49    1  64  ...         0    0   \n",
      "1997    5   4    4    2    0   0   22    0    2   5  ...         0    0   \n",
      "1998    0   0    2    0    1   0    8    0    0   0  ...         0    0   \n",
      "1999    1   4    1    2    0   1   13    2    0   2  ...         0    0   \n",
      "\n",
      "      valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
      "1000       0    0               0         0         0   2    0           0  \n",
      "1001       0    0               0         0         0   0    0           0  \n",
      "1002       0    0               0         0         0   0    0           0  \n",
      "1003       0    0               0         0         0   0    0           0  \n",
      "1004       0    0               0         0         0   1    0           1  \n",
      "...      ...  ...             ...       ...       ...  ..  ...         ...  \n",
      "1995       0    1               0         0         0   1    0           1  \n",
      "1996       0    0               0         0         0   2    0           0  \n",
      "1997       0    0               0         0         0   0    0           0  \n",
      "1998       0    0               0         0         0   0    0           0  \n",
      "1999       0    0               0         0         0   0    0           1  \n",
      "\n",
      "[1000 rows x 3001 columns]\n",
      "      the  to  ect  and  for  of    a  you  hou  in  ...  connevey  jay  \\\n",
      "0       0   0    1    0    0   0    2    0    0   0  ...         0    0   \n",
      "1       8  13   24    6    6   2  102    1   27  18  ...         0    0   \n",
      "2       0   0    1    0    0   0    8    0    0   4  ...         0    0   \n",
      "3       0   5   22    0    5   1   51    2   10   1  ...         0    0   \n",
      "4       7   6   17    1    5   2   57    0    9   3  ...         0    0   \n",
      "...   ...  ..  ...  ...  ...  ..  ...  ...  ...  ..  ...       ...  ...   \n",
      "4995   20   6    3    1    1   1   34    0    0  15  ...         0    0   \n",
      "4996    0   7    1    0    0   0   20    1    1   0  ...         0    0   \n",
      "4997    6   8    1    3    2   1   64    7    1  16  ...         0    0   \n",
      "4998    8   6    2    5    6   1   51    4    0   4  ...         0    0   \n",
      "4999   13  12    3    7    6   4   96    9    1  10  ...         0    0   \n",
      "\n",
      "      valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
      "0          0    0               0         0         0   0    0           0  \n",
      "1          0    0               0         0         0   1    0           0  \n",
      "2          0    0               0         0         0   0    0           0  \n",
      "3          0    0               0         0         0   0    0           0  \n",
      "4          0    0               0         0         0   1    0           0  \n",
      "...      ...  ...             ...       ...       ...  ..  ...         ...  \n",
      "4995       0    0               0         0         0   1    0           0  \n",
      "4996       0    1               0         0         0   0    0           0  \n",
      "4997       0    0               0         0         0   0    0           0  \n",
      "4998       0    0               0         0         0   0    0           0  \n",
      "4999       0    0               0         0         0   0    0           0  \n",
      "\n",
      "[4000 rows x 3001 columns]\n",
      "(4000, 3001)\n",
      "(1000, 3001)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0     1     2     3     4     5     6    7     8     9    ...   990   991  \\\n",
      "0  2913   752  1438  1737   568  2281  3719  873  1753   982  ...   700  1009   \n",
      "1  2906  3810  2468   428  2383   381  3614  968   945  3506  ...  1711   596   \n",
      "2  1469  1783  2139  2008  1812    87   323  892  1752   347  ...  2313  1896   \n",
      "\n",
      "    992   993   994   995   996   997   998   999  \n",
      "0  1164   590   555  3881   976   924  1202   434  \n",
      "1  1096   154   845  2643  3914  1355  1000  3979  \n",
      "2  1959  1736  2484  3736  1282   872  1772   750  \n",
      "\n",
      "[3 rows x 1000 columns]\n",
      "   0    1    2    3    4    5    6    7    8    9    ...  990  991  992  993  \\\n",
      "0    0    0    0    0    1    0    1    1    0    0  ...    0    0    1    0   \n",
      "1    0    0    0    0    1    0    1    1    0    0  ...    0    0    1    0   \n",
      "2    0    1    0    1    1    1    1    1    0    0  ...    0    0    1    0   \n",
      "\n",
      "   994  995  996  997  998  999  \n",
      "0    0    1    1    0    0    0  \n",
      "1    0    1    0    0    0    0  \n",
      "2    0    1    1    0    0    1  \n",
      "\n",
      "[3 rows x 1000 columns]\n",
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      1\n",
      "      ..\n",
      "995    1\n",
      "996    1\n",
      "997    0\n",
      "998    0\n",
      "999    0\n",
      "Name: 0, Length: 1000, dtype: int64\n",
      "     the  to  ect  and  for  of    a  you  hou  in  ...  jay  valued  lay  \\\n",
      "0     17  15    9   13   21   6  144    9    5  53  ...    0       0    0   \n",
      "1      3   2    1    0    1   0   29    2    0   8  ...    0       0    0   \n",
      "2      2   3   15    1    2   0   46    1    7   1  ...    0       0    0   \n",
      "3     17  11   13    5    3   2   49    4    5  13  ...    0       0    0   \n",
      "4      0   8    1    1    0   0   49    2    0   7  ...    0       0    0   \n",
      "..   ...  ..  ...  ...  ...  ..  ...  ...  ...  ..  ...  ...     ...  ...   \n",
      "995   11  14    6   10    9   5  111    7    1  29  ...    0       0    1   \n",
      "996   38  37    9   24   16  20  313   49    1  64  ...    0       0    0   \n",
      "997    5   4    4    2    0   0   22    0    2   5  ...    0       0    0   \n",
      "998    0   0    2    0    1   0    8    0    0   0  ...    0       0    0   \n",
      "999    1   4    1    2    0   1   13    2    0   2  ...    0       0    0   \n",
      "\n",
      "     infrastructure  military  allowing  ff  dry  Prediction  pred  \n",
      "0                 0         0         0   2    0           0     0  \n",
      "1                 0         0         0   0    0           0     0  \n",
      "2                 0         0         0   0    0           0     0  \n",
      "3                 0         0         0   0    0           0     0  \n",
      "4                 0         0         0   1    0           1     1  \n",
      "..              ...       ...       ...  ..  ...         ...   ...  \n",
      "995               0         0         0   1    0           1     1  \n",
      "996               0         0         0   2    0           0     1  \n",
      "997               0         0         0   0    0           0     0  \n",
      "998               0         0         0   0    0           0     0  \n",
      "999               0         0         0   0    0           1     0  \n",
      "\n",
      "[1000 rows x 3002 columns]\n",
      "[1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013\n",
      " 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027\n",
      " 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041\n",
      " 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055\n",
      " 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069\n",
      " 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083\n",
      " 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097\n",
      " 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111\n",
      " 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125\n",
      " 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139\n",
      " 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153\n",
      " 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167\n",
      " 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181\n",
      " 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195\n",
      " 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209\n",
      " 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223\n",
      " 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237\n",
      " 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251\n",
      " 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265\n",
      " 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279\n",
      " 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293\n",
      " 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307\n",
      " 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321\n",
      " 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335\n",
      " 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349\n",
      " 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363\n",
      " 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377\n",
      " 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391\n",
      " 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405\n",
      " 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419\n",
      " 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433\n",
      " 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447\n",
      " 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461\n",
      " 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475\n",
      " 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489\n",
      " 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503\n",
      " 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517\n",
      " 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531\n",
      " 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545\n",
      " 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557 1558 1559\n",
      " 1560 1561 1562 1563 1564 1565 1566 1567 1568 1569 1570 1571 1572 1573\n",
      " 1574 1575 1576 1577 1578 1579 1580 1581 1582 1583 1584 1585 1586 1587\n",
      " 1588 1589 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 1600 1601\n",
      " 1602 1603 1604 1605 1606 1607 1608 1609 1610 1611 1612 1613 1614 1615\n",
      " 1616 1617 1618 1619 1620 1621 1622 1623 1624 1625 1626 1627 1628 1629\n",
      " 1630 1631 1632 1633 1634 1635 1636 1637 1638 1639 1640 1641 1642 1643\n",
      " 1644 1645 1646 1647 1648 1649 1650 1651 1652 1653 1654 1655 1656 1657\n",
      " 1658 1659 1660 1661 1662 1663 1664 1665 1666 1667 1668 1669 1670 1671\n",
      " 1672 1673 1674 1675 1676 1677 1678 1679 1680 1681 1682 1683 1684 1685\n",
      " 1686 1687 1688 1689 1690 1691 1692 1693 1694 1695 1696 1697 1698 1699\n",
      " 1700 1701 1702 1703 1704 1705 1706 1707 1708 1709 1710 1711 1712 1713\n",
      " 1714 1715 1716 1717 1718 1719 1720 1721 1722 1723 1724 1725 1726 1727\n",
      " 1728 1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 1739 1740 1741\n",
      " 1742 1743 1744 1745 1746 1747 1748 1749 1750 1751 1752 1753 1754 1755\n",
      " 1756 1757 1758 1759 1760 1761 1762 1763 1764 1765 1766 1767 1768 1769\n",
      " 1770 1771 1772 1773 1774 1775 1776 1777 1778 1779 1780 1781 1782 1783\n",
      " 1784 1785 1786 1787 1788 1789 1790 1791 1792 1793 1794 1795 1796 1797\n",
      " 1798 1799 1800 1801 1802 1803 1804 1805 1806 1807 1808 1809 1810 1811\n",
      " 1812 1813 1814 1815 1816 1817 1818 1819 1820 1821 1822 1823 1824 1825\n",
      " 1826 1827 1828 1829 1830 1831 1832 1833 1834 1835 1836 1837 1838 1839\n",
      " 1840 1841 1842 1843 1844 1845 1846 1847 1848 1849 1850 1851 1852 1853\n",
      " 1854 1855 1856 1857 1858 1859 1860 1861 1862 1863 1864 1865 1866 1867\n",
      " 1868 1869 1870 1871 1872 1873 1874 1875 1876 1877 1878 1879 1880 1881\n",
      " 1882 1883 1884 1885 1886 1887 1888 1889 1890 1891 1892 1893 1894 1895\n",
      " 1896 1897 1898 1899 1900 1901 1902 1903 1904 1905 1906 1907 1908 1909\n",
      " 1910 1911 1912 1913 1914 1915 1916 1917 1918 1919 1920 1921 1922 1923\n",
      " 1924 1925 1926 1927 1928 1929 1930 1931 1932 1933 1934 1935 1936 1937\n",
      " 1938 1939 1940 1941 1942 1943 1944 1945 1946 1947 1948 1949 1950 1951\n",
      " 1952 1953 1954 1955 1956 1957 1958 1959 1960 1961 1962 1963 1964 1965\n",
      " 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 1976 1977 1978 1979\n",
      " 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993\n",
      " 1994 1995 1996 1997 1998 1999]\n",
      "     the  to  ect  and  for  of    a  you  hou  in  ...  valued  lay  \\\n",
      "0     17  15    9   13   21   6  144    9    5  53  ...       0    0   \n",
      "1      3   2    1    0    1   0   29    2    0   8  ...       0    0   \n",
      "2      2   3   15    1    2   0   46    1    7   1  ...       0    0   \n",
      "3     17  11   13    5    3   2   49    4    5  13  ...       0    0   \n",
      "4      0   8    1    1    0   0   49    2    0   7  ...       0    0   \n",
      "..   ...  ..  ...  ...  ...  ..  ...  ...  ...  ..  ...     ...  ...   \n",
      "995   11  14    6   10    9   5  111    7    1  29  ...       0    1   \n",
      "996   38  37    9   24   16  20  313   49    1  64  ...       0    0   \n",
      "997    5   4    4    2    0   0   22    0    2   5  ...       0    0   \n",
      "998    0   0    2    0    1   0    8    0    0   0  ...       0    0   \n",
      "999    1   4    1    2    0   1   13    2    0   2  ...       0    0   \n",
      "\n",
      "     infrastructure  military  allowing  ff  dry  Prediction  pred  true_label  \n",
      "0                 0         0         0   2    0           0     0           0  \n",
      "1                 0         0         0   0    0           0     0           0  \n",
      "2                 0         0         0   0    0           0     0           0  \n",
      "3                 0         0         0   0    0           0     0           0  \n",
      "4                 0         0         0   1    0           1     1           1  \n",
      "..              ...       ...       ...  ..  ...         ...   ...         ...  \n",
      "995               0         0         0   1    0           1     1           1  \n",
      "996               0         0         0   2    0           0     1           0  \n",
      "997               0         0         0   0    0           0     0           0  \n",
      "998               0         0         0   0    0           0     0           0  \n",
      "999               0         0         0   0    0           1     0           1  \n",
      "\n",
      "[1000 rows x 3003 columns]\n",
      "1000    0\n",
      "1001    0\n",
      "1002    0\n",
      "1003    0\n",
      "1004    1\n",
      "       ..\n",
      "1995    1\n",
      "1996    0\n",
      "1997    0\n",
      "1998    0\n",
      "1999    1\n",
      "Name: Prediction, Length: 1000, dtype: int64\n",
      "[0.85, 0.6953846153846154, 0.8158844765342961]\n",
      "      the  to  ect  and  for  of   a  you  hou  in  ...  connevey  jay  \\\n",
      "2000    0   0    2    0    1   0   7    0    0   0  ...         0    0   \n",
      "2001    2   1    1    2    2   2  25    0    0   2  ...         0    0   \n",
      "2002    0   0    1    0    1   0   3    0    0   0  ...         0    0   \n",
      "2003    0   0    1    0    1   0   4    0    0   0  ...         0    0   \n",
      "2004    0   0    1    0    0   0   7    0    0   0  ...         0    0   \n",
      "...   ...  ..  ...  ...  ...  ..  ..  ...  ...  ..  ...       ...  ...   \n",
      "2995    0   1    2    0    0   0  14    0    1   4  ...         0    0   \n",
      "2996    5   6    9    9    3   7  85    1    4  21  ...         0    0   \n",
      "2997    5   1    1    2    2   5  30    2    0   3  ...         0    0   \n",
      "2998    9   9    4    6    3   3  78    3    1   5  ...         0    0   \n",
      "2999    0   0    1    0    1   0   5    0    0   0  ...         0    0   \n",
      "\n",
      "      valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
      "2000       0    0               0         0         0   0    0           0  \n",
      "2001       0    0               0         0         0   2    0           1  \n",
      "2002       0    0               0         0         0   0    0           0  \n",
      "2003       0    0               0         0         0   0    0           0  \n",
      "2004       0    0               0         0         0   0    0           0  \n",
      "...      ...  ...             ...       ...       ...  ..  ...         ...  \n",
      "2995       0    0               0         0         0   0    0           0  \n",
      "2996       0    0               0         0         0   1    0           0  \n",
      "2997       0    0               0         0         0   2    0           0  \n",
      "2998       0    0               0         0         0   0    0           0  \n",
      "2999       0    0               0         0         0   0    0           0  \n",
      "\n",
      "[1000 rows x 3001 columns]\n",
      "      the  to  ect  and  for  of    a  you  hou  in  ...  connevey  jay  \\\n",
      "0       0   0    1    0    0   0    2    0    0   0  ...         0    0   \n",
      "1       8  13   24    6    6   2  102    1   27  18  ...         0    0   \n",
      "2       0   0    1    0    0   0    8    0    0   4  ...         0    0   \n",
      "3       0   5   22    0    5   1   51    2   10   1  ...         0    0   \n",
      "4       7   6   17    1    5   2   57    0    9   3  ...         0    0   \n",
      "...   ...  ..  ...  ...  ...  ..  ...  ...  ...  ..  ...       ...  ...   \n",
      "4995   20   6    3    1    1   1   34    0    0  15  ...         0    0   \n",
      "4996    0   7    1    0    0   0   20    1    1   0  ...         0    0   \n",
      "4997    6   8    1    3    2   1   64    7    1  16  ...         0    0   \n",
      "4998    8   6    2    5    6   1   51    4    0   4  ...         0    0   \n",
      "4999   13  12    3    7    6   4   96    9    1  10  ...         0    0   \n",
      "\n",
      "      valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
      "0          0    0               0         0         0   0    0           0  \n",
      "1          0    0               0         0         0   1    0           0  \n",
      "2          0    0               0         0         0   0    0           0  \n",
      "3          0    0               0         0         0   0    0           0  \n",
      "4          0    0               0         0         0   1    0           0  \n",
      "...      ...  ...             ...       ...       ...  ..  ...         ...  \n",
      "4995       0    0               0         0         0   1    0           0  \n",
      "4996       0    1               0         0         0   0    0           0  \n",
      "4997       0    0               0         0         0   0    0           0  \n",
      "4998       0    0               0         0         0   0    0           0  \n",
      "4999       0    0               0         0         0   0    0           0  \n",
      "\n",
      "[4000 rows x 3001 columns]\n",
      "(4000, 3001)\n",
      "(1000, 3001)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0     1     2     3     4     5     6     7     8     9    ...   990  \\\n",
      "0  1936   666  1863  1968   946   666  2906  1565   380  2495  ...  2116   \n",
      "1  1998  1502  1897  1924  1027  1947  2913  3698  3596  1991  ...  2138   \n",
      "2  1983  1947  1966  1864  1156  1502  3396  2305     0  3359  ...  2154   \n",
      "\n",
      "    991   992   993   994   995   996   997   998   999  \n",
      "0  1181  2279   354  1775  2629  1021    30  2003  1241  \n",
      "1  2038  3498  3594  2035  3620  2661  1893  2072  2063  \n",
      "2  3519  3045   299  3060  3252  1415  3423  2080  2121  \n",
      "\n",
      "[3 rows x 1000 columns]\n",
      "   0    1    2    3    4    5    6    7    8    9    ...  990  991  992  993  \\\n",
      "0    0    1    0    0    0    1    0    0    1    0  ...    0    1    0    0   \n",
      "1    0    1    0    0    0    1    0    0    0    0  ...    0    0    0    0   \n",
      "2    0    1    0    0    0    1    0    0    0    0  ...    0    1    0    0   \n",
      "\n",
      "   994  995  996  997  998  999  \n",
      "0    0    0    0    0    0    0  \n",
      "1    0    0    0    0    0    0  \n",
      "2    1    0    1    1    0    0  \n",
      "\n",
      "[3 rows x 1000 columns]\n",
      "0      0\n",
      "1      1\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "995    0\n",
      "996    0\n",
      "997    0\n",
      "998    0\n",
      "999    0\n",
      "Name: 0, Length: 1000, dtype: int64\n",
      "     the  to  ect  and  for  of   a  you  hou  in  ...  jay  valued  lay  \\\n",
      "0      0   0    2    0    1   0   7    0    0   0  ...    0       0    0   \n",
      "1      2   1    1    2    2   2  25    0    0   2  ...    0       0    0   \n",
      "2      0   0    1    0    1   0   3    0    0   0  ...    0       0    0   \n",
      "3      0   0    1    0    1   0   4    0    0   0  ...    0       0    0   \n",
      "4      0   0    1    0    0   0   7    0    0   0  ...    0       0    0   \n",
      "..   ...  ..  ...  ...  ...  ..  ..  ...  ...  ..  ...  ...     ...  ...   \n",
      "995    0   1    2    0    0   0  14    0    1   4  ...    0       0    0   \n",
      "996    5   6    9    9    3   7  85    1    4  21  ...    0       0    0   \n",
      "997    5   1    1    2    2   5  30    2    0   3  ...    0       0    0   \n",
      "998    9   9    4    6    3   3  78    3    1   5  ...    0       0    0   \n",
      "999    0   0    1    0    1   0   5    0    0   0  ...    0       0    0   \n",
      "\n",
      "     infrastructure  military  allowing  ff  dry  Prediction  pred  \n",
      "0                 0         0         0   0    0           0     0  \n",
      "1                 0         0         0   2    0           1     1  \n",
      "2                 0         0         0   0    0           0     0  \n",
      "3                 0         0         0   0    0           0     0  \n",
      "4                 0         0         0   0    0           0     0  \n",
      "..              ...       ...       ...  ..  ...         ...   ...  \n",
      "995               0         0         0   0    0           0     0  \n",
      "996               0         0         0   1    0           0     0  \n",
      "997               0         0         0   2    0           0     0  \n",
      "998               0         0         0   0    0           0     0  \n",
      "999               0         0         0   0    0           0     0  \n",
      "\n",
      "[1000 rows x 3002 columns]\n",
      "[2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013\n",
      " 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 2025 2026 2027\n",
      " 2028 2029 2030 2031 2032 2033 2034 2035 2036 2037 2038 2039 2040 2041\n",
      " 2042 2043 2044 2045 2046 2047 2048 2049 2050 2051 2052 2053 2054 2055\n",
      " 2056 2057 2058 2059 2060 2061 2062 2063 2064 2065 2066 2067 2068 2069\n",
      " 2070 2071 2072 2073 2074 2075 2076 2077 2078 2079 2080 2081 2082 2083\n",
      " 2084 2085 2086 2087 2088 2089 2090 2091 2092 2093 2094 2095 2096 2097\n",
      " 2098 2099 2100 2101 2102 2103 2104 2105 2106 2107 2108 2109 2110 2111\n",
      " 2112 2113 2114 2115 2116 2117 2118 2119 2120 2121 2122 2123 2124 2125\n",
      " 2126 2127 2128 2129 2130 2131 2132 2133 2134 2135 2136 2137 2138 2139\n",
      " 2140 2141 2142 2143 2144 2145 2146 2147 2148 2149 2150 2151 2152 2153\n",
      " 2154 2155 2156 2157 2158 2159 2160 2161 2162 2163 2164 2165 2166 2167\n",
      " 2168 2169 2170 2171 2172 2173 2174 2175 2176 2177 2178 2179 2180 2181\n",
      " 2182 2183 2184 2185 2186 2187 2188 2189 2190 2191 2192 2193 2194 2195\n",
      " 2196 2197 2198 2199 2200 2201 2202 2203 2204 2205 2206 2207 2208 2209\n",
      " 2210 2211 2212 2213 2214 2215 2216 2217 2218 2219 2220 2221 2222 2223\n",
      " 2224 2225 2226 2227 2228 2229 2230 2231 2232 2233 2234 2235 2236 2237\n",
      " 2238 2239 2240 2241 2242 2243 2244 2245 2246 2247 2248 2249 2250 2251\n",
      " 2252 2253 2254 2255 2256 2257 2258 2259 2260 2261 2262 2263 2264 2265\n",
      " 2266 2267 2268 2269 2270 2271 2272 2273 2274 2275 2276 2277 2278 2279\n",
      " 2280 2281 2282 2283 2284 2285 2286 2287 2288 2289 2290 2291 2292 2293\n",
      " 2294 2295 2296 2297 2298 2299 2300 2301 2302 2303 2304 2305 2306 2307\n",
      " 2308 2309 2310 2311 2312 2313 2314 2315 2316 2317 2318 2319 2320 2321\n",
      " 2322 2323 2324 2325 2326 2327 2328 2329 2330 2331 2332 2333 2334 2335\n",
      " 2336 2337 2338 2339 2340 2341 2342 2343 2344 2345 2346 2347 2348 2349\n",
      " 2350 2351 2352 2353 2354 2355 2356 2357 2358 2359 2360 2361 2362 2363\n",
      " 2364 2365 2366 2367 2368 2369 2370 2371 2372 2373 2374 2375 2376 2377\n",
      " 2378 2379 2380 2381 2382 2383 2384 2385 2386 2387 2388 2389 2390 2391\n",
      " 2392 2393 2394 2395 2396 2397 2398 2399 2400 2401 2402 2403 2404 2405\n",
      " 2406 2407 2408 2409 2410 2411 2412 2413 2414 2415 2416 2417 2418 2419\n",
      " 2420 2421 2422 2423 2424 2425 2426 2427 2428 2429 2430 2431 2432 2433\n",
      " 2434 2435 2436 2437 2438 2439 2440 2441 2442 2443 2444 2445 2446 2447\n",
      " 2448 2449 2450 2451 2452 2453 2454 2455 2456 2457 2458 2459 2460 2461\n",
      " 2462 2463 2464 2465 2466 2467 2468 2469 2470 2471 2472 2473 2474 2475\n",
      " 2476 2477 2478 2479 2480 2481 2482 2483 2484 2485 2486 2487 2488 2489\n",
      " 2490 2491 2492 2493 2494 2495 2496 2497 2498 2499 2500 2501 2502 2503\n",
      " 2504 2505 2506 2507 2508 2509 2510 2511 2512 2513 2514 2515 2516 2517\n",
      " 2518 2519 2520 2521 2522 2523 2524 2525 2526 2527 2528 2529 2530 2531\n",
      " 2532 2533 2534 2535 2536 2537 2538 2539 2540 2541 2542 2543 2544 2545\n",
      " 2546 2547 2548 2549 2550 2551 2552 2553 2554 2555 2556 2557 2558 2559\n",
      " 2560 2561 2562 2563 2564 2565 2566 2567 2568 2569 2570 2571 2572 2573\n",
      " 2574 2575 2576 2577 2578 2579 2580 2581 2582 2583 2584 2585 2586 2587\n",
      " 2588 2589 2590 2591 2592 2593 2594 2595 2596 2597 2598 2599 2600 2601\n",
      " 2602 2603 2604 2605 2606 2607 2608 2609 2610 2611 2612 2613 2614 2615\n",
      " 2616 2617 2618 2619 2620 2621 2622 2623 2624 2625 2626 2627 2628 2629\n",
      " 2630 2631 2632 2633 2634 2635 2636 2637 2638 2639 2640 2641 2642 2643\n",
      " 2644 2645 2646 2647 2648 2649 2650 2651 2652 2653 2654 2655 2656 2657\n",
      " 2658 2659 2660 2661 2662 2663 2664 2665 2666 2667 2668 2669 2670 2671\n",
      " 2672 2673 2674 2675 2676 2677 2678 2679 2680 2681 2682 2683 2684 2685\n",
      " 2686 2687 2688 2689 2690 2691 2692 2693 2694 2695 2696 2697 2698 2699\n",
      " 2700 2701 2702 2703 2704 2705 2706 2707 2708 2709 2710 2711 2712 2713\n",
      " 2714 2715 2716 2717 2718 2719 2720 2721 2722 2723 2724 2725 2726 2727\n",
      " 2728 2729 2730 2731 2732 2733 2734 2735 2736 2737 2738 2739 2740 2741\n",
      " 2742 2743 2744 2745 2746 2747 2748 2749 2750 2751 2752 2753 2754 2755\n",
      " 2756 2757 2758 2759 2760 2761 2762 2763 2764 2765 2766 2767 2768 2769\n",
      " 2770 2771 2772 2773 2774 2775 2776 2777 2778 2779 2780 2781 2782 2783\n",
      " 2784 2785 2786 2787 2788 2789 2790 2791 2792 2793 2794 2795 2796 2797\n",
      " 2798 2799 2800 2801 2802 2803 2804 2805 2806 2807 2808 2809 2810 2811\n",
      " 2812 2813 2814 2815 2816 2817 2818 2819 2820 2821 2822 2823 2824 2825\n",
      " 2826 2827 2828 2829 2830 2831 2832 2833 2834 2835 2836 2837 2838 2839\n",
      " 2840 2841 2842 2843 2844 2845 2846 2847 2848 2849 2850 2851 2852 2853\n",
      " 2854 2855 2856 2857 2858 2859 2860 2861 2862 2863 2864 2865 2866 2867\n",
      " 2868 2869 2870 2871 2872 2873 2874 2875 2876 2877 2878 2879 2880 2881\n",
      " 2882 2883 2884 2885 2886 2887 2888 2889 2890 2891 2892 2893 2894 2895\n",
      " 2896 2897 2898 2899 2900 2901 2902 2903 2904 2905 2906 2907 2908 2909\n",
      " 2910 2911 2912 2913 2914 2915 2916 2917 2918 2919 2920 2921 2922 2923\n",
      " 2924 2925 2926 2927 2928 2929 2930 2931 2932 2933 2934 2935 2936 2937\n",
      " 2938 2939 2940 2941 2942 2943 2944 2945 2946 2947 2948 2949 2950 2951\n",
      " 2952 2953 2954 2955 2956 2957 2958 2959 2960 2961 2962 2963 2964 2965\n",
      " 2966 2967 2968 2969 2970 2971 2972 2973 2974 2975 2976 2977 2978 2979\n",
      " 2980 2981 2982 2983 2984 2985 2986 2987 2988 2989 2990 2991 2992 2993\n",
      " 2994 2995 2996 2997 2998 2999]\n",
      "     the  to  ect  and  for  of   a  you  hou  in  ...  valued  lay  \\\n",
      "0      0   0    2    0    1   0   7    0    0   0  ...       0    0   \n",
      "1      2   1    1    2    2   2  25    0    0   2  ...       0    0   \n",
      "2      0   0    1    0    1   0   3    0    0   0  ...       0    0   \n",
      "3      0   0    1    0    1   0   4    0    0   0  ...       0    0   \n",
      "4      0   0    1    0    0   0   7    0    0   0  ...       0    0   \n",
      "..   ...  ..  ...  ...  ...  ..  ..  ...  ...  ..  ...     ...  ...   \n",
      "995    0   1    2    0    0   0  14    0    1   4  ...       0    0   \n",
      "996    5   6    9    9    3   7  85    1    4  21  ...       0    0   \n",
      "997    5   1    1    2    2   5  30    2    0   3  ...       0    0   \n",
      "998    9   9    4    6    3   3  78    3    1   5  ...       0    0   \n",
      "999    0   0    1    0    1   0   5    0    0   0  ...       0    0   \n",
      "\n",
      "     infrastructure  military  allowing  ff  dry  Prediction  pred  true_label  \n",
      "0                 0         0         0   0    0           0     0           0  \n",
      "1                 0         0         0   2    0           1     1           1  \n",
      "2                 0         0         0   0    0           0     0           0  \n",
      "3                 0         0         0   0    0           0     0           0  \n",
      "4                 0         0         0   0    0           0     0           0  \n",
      "..              ...       ...       ...  ..  ...         ...   ...         ...  \n",
      "995               0         0         0   0    0           0     0           0  \n",
      "996               0         0         0   1    0           0     0           0  \n",
      "997               0         0         0   2    0           0     0           0  \n",
      "998               0         0         0   0    0           0     0           0  \n",
      "999               0         0         0   0    0           0     0           0  \n",
      "\n",
      "[1000 rows x 3003 columns]\n",
      "2000    0\n",
      "2001    1\n",
      "2002    0\n",
      "2003    0\n",
      "2004    0\n",
      "       ..\n",
      "2995    0\n",
      "2996    0\n",
      "2997    0\n",
      "2998    0\n",
      "2999    0\n",
      "Name: Prediction, Length: 1000, dtype: int64\n",
      "[0.859, 0.7241379310344828, 0.8133802816901409]\n",
      "      the  to  ect  and  for  of   a  you  hou  in  ...  connevey  jay  \\\n",
      "3000    0   2    2    0    1   0  27    0    0   6  ...         0    0   \n",
      "3001    3   2    1    1    2   2  13    0    0   4  ...         0    0   \n",
      "3002    0   0    1    0    1   0   2    0    0   0  ...         0    0   \n",
      "3003    9   9    4    6    3   3  78    3    1   5  ...         0    0   \n",
      "3004    4   2    2    1    3   1  33    0    1  12  ...         0    0   \n",
      "...   ...  ..  ...  ...  ...  ..  ..  ...  ...  ..  ...       ...  ...   \n",
      "3995    6   3   15    2    7   1  67    4    6   7  ...         0    0   \n",
      "3996    4   1    4    4    2   0  26    2    2   5  ...         0    0   \n",
      "3997    2   1    1    1    1   0   9    0    0   2  ...         0    0   \n",
      "3998   11   4    1    6    1   3  75    3    3   9  ...         0    0   \n",
      "3999    2   1    1    1    1   0   9    0    0   2  ...         0    0   \n",
      "\n",
      "      valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
      "3000       0    0               0         0         0   0    0           1  \n",
      "3001       0    0               0         0         0   1    0           0  \n",
      "3002       0    0               0         0         0   0    0           0  \n",
      "3003       0    0               0         0         0   0    0           0  \n",
      "3004       0    0               0         0         0   0    0           1  \n",
      "...      ...  ...             ...       ...       ...  ..  ...         ...  \n",
      "3995       0    0               0         0         0   2    0           0  \n",
      "3996       0    0               0         0         0   0    0           0  \n",
      "3997       0    0               0         0         0   0    0           0  \n",
      "3998       0    0               0         0         0   1    0           0  \n",
      "3999       0    0               0         0         0   0    0           0  \n",
      "\n",
      "[1000 rows x 3001 columns]\n",
      "      the  to  ect  and  for  of    a  you  hou  in  ...  connevey  jay  \\\n",
      "0       0   0    1    0    0   0    2    0    0   0  ...         0    0   \n",
      "1       8  13   24    6    6   2  102    1   27  18  ...         0    0   \n",
      "2       0   0    1    0    0   0    8    0    0   4  ...         0    0   \n",
      "3       0   5   22    0    5   1   51    2   10   1  ...         0    0   \n",
      "4       7   6   17    1    5   2   57    0    9   3  ...         0    0   \n",
      "...   ...  ..  ...  ...  ...  ..  ...  ...  ...  ..  ...       ...  ...   \n",
      "4995   20   6    3    1    1   1   34    0    0  15  ...         0    0   \n",
      "4996    0   7    1    0    0   0   20    1    1   0  ...         0    0   \n",
      "4997    6   8    1    3    2   1   64    7    1  16  ...         0    0   \n",
      "4998    8   6    2    5    6   1   51    4    0   4  ...         0    0   \n",
      "4999   13  12    3    7    6   4   96    9    1  10  ...         0    0   \n",
      "\n",
      "      valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
      "0          0    0               0         0         0   0    0           0  \n",
      "1          0    0               0         0         0   1    0           0  \n",
      "2          0    0               0         0         0   0    0           0  \n",
      "3          0    0               0         0         0   0    0           0  \n",
      "4          0    0               0         0         0   1    0           0  \n",
      "...      ...  ...             ...       ...       ...  ..  ...         ...  \n",
      "4995       0    0               0         0         0   1    0           0  \n",
      "4996       0    1               0         0         0   0    0           0  \n",
      "4997       0    0               0         0         0   0    0           0  \n",
      "4998       0    0               0         0         0   0    0           0  \n",
      "4999       0    0               0         0         0   0    0           0  \n",
      "\n",
      "[4000 rows x 3001 columns]\n",
      "(4000, 3001)\n",
      "(1000, 3001)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0     1     2     3     4     5    6     7     8     9    ...   990   991  \\\n",
      "0  2751  3695  2978  2328  3491  2311  996  1777   456  3897  ...   891  3019   \n",
      "1  1716  1594  2989  2998  3083   126  490  2987  2510  1731  ...  3688  3018   \n",
      "2  2674  1713  2981  2333  3081   550  152  3987  1587  2928  ...  3912   590   \n",
      "\n",
      "    992   993   994   995   996   997   998   999  \n",
      "0  3194  2364  3194  3019   891  2864  3802  2864  \n",
      "1  3186  2659  3186  3018  3688   592  3001   592  \n",
      "2  2510  2366  2510   590  3912  3971  3940  3971  \n",
      "\n",
      "[3 rows x 1000 columns]\n",
      "   0    1    2    3    4    5    6    7    8    9    ...  990  991  992  993  \\\n",
      "0    1    0    0    0    0    0    1    1    0    1  ...    0    0    0    1   \n",
      "1    1    0    0    0    0    0    0    1    1    1  ...    1    0    0    1   \n",
      "2    0    0    0    0    0    0    1    1    1    1  ...    1    0    1    1   \n",
      "\n",
      "   994  995  996  997  998  999  \n",
      "0    0    0    0    0    1    0  \n",
      "1    0    0    1    0    0    0  \n",
      "2    1    0    1    0    0    0  \n",
      "\n",
      "[3 rows x 1000 columns]\n",
      "0      1\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "995    0\n",
      "996    1\n",
      "997    0\n",
      "998    0\n",
      "999    0\n",
      "Name: 0, Length: 1000, dtype: int64\n",
      "     the  to  ect  and  for  of   a  you  hou  in  ...  jay  valued  lay  \\\n",
      "0      0   2    2    0    1   0  27    0    0   6  ...    0       0    0   \n",
      "1      3   2    1    1    2   2  13    0    0   4  ...    0       0    0   \n",
      "2      0   0    1    0    1   0   2    0    0   0  ...    0       0    0   \n",
      "3      9   9    4    6    3   3  78    3    1   5  ...    0       0    0   \n",
      "4      4   2    2    1    3   1  33    0    1  12  ...    0       0    0   \n",
      "..   ...  ..  ...  ...  ...  ..  ..  ...  ...  ..  ...  ...     ...  ...   \n",
      "995    6   3   15    2    7   1  67    4    6   7  ...    0       0    0   \n",
      "996    4   1    4    4    2   0  26    2    2   5  ...    0       0    0   \n",
      "997    2   1    1    1    1   0   9    0    0   2  ...    0       0    0   \n",
      "998   11   4    1    6    1   3  75    3    3   9  ...    0       0    0   \n",
      "999    2   1    1    1    1   0   9    0    0   2  ...    0       0    0   \n",
      "\n",
      "     infrastructure  military  allowing  ff  dry  Prediction  pred  \n",
      "0                 0         0         0   0    0           1     1  \n",
      "1                 0         0         0   1    0           0     0  \n",
      "2                 0         0         0   0    0           0     0  \n",
      "3                 0         0         0   0    0           0     0  \n",
      "4                 0         0         0   0    0           1     0  \n",
      "..              ...       ...       ...  ..  ...         ...   ...  \n",
      "995               0         0         0   2    0           0     0  \n",
      "996               0         0         0   0    0           0     1  \n",
      "997               0         0         0   0    0           0     0  \n",
      "998               0         0         0   1    0           0     0  \n",
      "999               0         0         0   0    0           0     0  \n",
      "\n",
      "[1000 rows x 3002 columns]\n",
      "[3000 3001 3002 3003 3004 3005 3006 3007 3008 3009 3010 3011 3012 3013\n",
      " 3014 3015 3016 3017 3018 3019 3020 3021 3022 3023 3024 3025 3026 3027\n",
      " 3028 3029 3030 3031 3032 3033 3034 3035 3036 3037 3038 3039 3040 3041\n",
      " 3042 3043 3044 3045 3046 3047 3048 3049 3050 3051 3052 3053 3054 3055\n",
      " 3056 3057 3058 3059 3060 3061 3062 3063 3064 3065 3066 3067 3068 3069\n",
      " 3070 3071 3072 3073 3074 3075 3076 3077 3078 3079 3080 3081 3082 3083\n",
      " 3084 3085 3086 3087 3088 3089 3090 3091 3092 3093 3094 3095 3096 3097\n",
      " 3098 3099 3100 3101 3102 3103 3104 3105 3106 3107 3108 3109 3110 3111\n",
      " 3112 3113 3114 3115 3116 3117 3118 3119 3120 3121 3122 3123 3124 3125\n",
      " 3126 3127 3128 3129 3130 3131 3132 3133 3134 3135 3136 3137 3138 3139\n",
      " 3140 3141 3142 3143 3144 3145 3146 3147 3148 3149 3150 3151 3152 3153\n",
      " 3154 3155 3156 3157 3158 3159 3160 3161 3162 3163 3164 3165 3166 3167\n",
      " 3168 3169 3170 3171 3172 3173 3174 3175 3176 3177 3178 3179 3180 3181\n",
      " 3182 3183 3184 3185 3186 3187 3188 3189 3190 3191 3192 3193 3194 3195\n",
      " 3196 3197 3198 3199 3200 3201 3202 3203 3204 3205 3206 3207 3208 3209\n",
      " 3210 3211 3212 3213 3214 3215 3216 3217 3218 3219 3220 3221 3222 3223\n",
      " 3224 3225 3226 3227 3228 3229 3230 3231 3232 3233 3234 3235 3236 3237\n",
      " 3238 3239 3240 3241 3242 3243 3244 3245 3246 3247 3248 3249 3250 3251\n",
      " 3252 3253 3254 3255 3256 3257 3258 3259 3260 3261 3262 3263 3264 3265\n",
      " 3266 3267 3268 3269 3270 3271 3272 3273 3274 3275 3276 3277 3278 3279\n",
      " 3280 3281 3282 3283 3284 3285 3286 3287 3288 3289 3290 3291 3292 3293\n",
      " 3294 3295 3296 3297 3298 3299 3300 3301 3302 3303 3304 3305 3306 3307\n",
      " 3308 3309 3310 3311 3312 3313 3314 3315 3316 3317 3318 3319 3320 3321\n",
      " 3322 3323 3324 3325 3326 3327 3328 3329 3330 3331 3332 3333 3334 3335\n",
      " 3336 3337 3338 3339 3340 3341 3342 3343 3344 3345 3346 3347 3348 3349\n",
      " 3350 3351 3352 3353 3354 3355 3356 3357 3358 3359 3360 3361 3362 3363\n",
      " 3364 3365 3366 3367 3368 3369 3370 3371 3372 3373 3374 3375 3376 3377\n",
      " 3378 3379 3380 3381 3382 3383 3384 3385 3386 3387 3388 3389 3390 3391\n",
      " 3392 3393 3394 3395 3396 3397 3398 3399 3400 3401 3402 3403 3404 3405\n",
      " 3406 3407 3408 3409 3410 3411 3412 3413 3414 3415 3416 3417 3418 3419\n",
      " 3420 3421 3422 3423 3424 3425 3426 3427 3428 3429 3430 3431 3432 3433\n",
      " 3434 3435 3436 3437 3438 3439 3440 3441 3442 3443 3444 3445 3446 3447\n",
      " 3448 3449 3450 3451 3452 3453 3454 3455 3456 3457 3458 3459 3460 3461\n",
      " 3462 3463 3464 3465 3466 3467 3468 3469 3470 3471 3472 3473 3474 3475\n",
      " 3476 3477 3478 3479 3480 3481 3482 3483 3484 3485 3486 3487 3488 3489\n",
      " 3490 3491 3492 3493 3494 3495 3496 3497 3498 3499 3500 3501 3502 3503\n",
      " 3504 3505 3506 3507 3508 3509 3510 3511 3512 3513 3514 3515 3516 3517\n",
      " 3518 3519 3520 3521 3522 3523 3524 3525 3526 3527 3528 3529 3530 3531\n",
      " 3532 3533 3534 3535 3536 3537 3538 3539 3540 3541 3542 3543 3544 3545\n",
      " 3546 3547 3548 3549 3550 3551 3552 3553 3554 3555 3556 3557 3558 3559\n",
      " 3560 3561 3562 3563 3564 3565 3566 3567 3568 3569 3570 3571 3572 3573\n",
      " 3574 3575 3576 3577 3578 3579 3580 3581 3582 3583 3584 3585 3586 3587\n",
      " 3588 3589 3590 3591 3592 3593 3594 3595 3596 3597 3598 3599 3600 3601\n",
      " 3602 3603 3604 3605 3606 3607 3608 3609 3610 3611 3612 3613 3614 3615\n",
      " 3616 3617 3618 3619 3620 3621 3622 3623 3624 3625 3626 3627 3628 3629\n",
      " 3630 3631 3632 3633 3634 3635 3636 3637 3638 3639 3640 3641 3642 3643\n",
      " 3644 3645 3646 3647 3648 3649 3650 3651 3652 3653 3654 3655 3656 3657\n",
      " 3658 3659 3660 3661 3662 3663 3664 3665 3666 3667 3668 3669 3670 3671\n",
      " 3672 3673 3674 3675 3676 3677 3678 3679 3680 3681 3682 3683 3684 3685\n",
      " 3686 3687 3688 3689 3690 3691 3692 3693 3694 3695 3696 3697 3698 3699\n",
      " 3700 3701 3702 3703 3704 3705 3706 3707 3708 3709 3710 3711 3712 3713\n",
      " 3714 3715 3716 3717 3718 3719 3720 3721 3722 3723 3724 3725 3726 3727\n",
      " 3728 3729 3730 3731 3732 3733 3734 3735 3736 3737 3738 3739 3740 3741\n",
      " 3742 3743 3744 3745 3746 3747 3748 3749 3750 3751 3752 3753 3754 3755\n",
      " 3756 3757 3758 3759 3760 3761 3762 3763 3764 3765 3766 3767 3768 3769\n",
      " 3770 3771 3772 3773 3774 3775 3776 3777 3778 3779 3780 3781 3782 3783\n",
      " 3784 3785 3786 3787 3788 3789 3790 3791 3792 3793 3794 3795 3796 3797\n",
      " 3798 3799 3800 3801 3802 3803 3804 3805 3806 3807 3808 3809 3810 3811\n",
      " 3812 3813 3814 3815 3816 3817 3818 3819 3820 3821 3822 3823 3824 3825\n",
      " 3826 3827 3828 3829 3830 3831 3832 3833 3834 3835 3836 3837 3838 3839\n",
      " 3840 3841 3842 3843 3844 3845 3846 3847 3848 3849 3850 3851 3852 3853\n",
      " 3854 3855 3856 3857 3858 3859 3860 3861 3862 3863 3864 3865 3866 3867\n",
      " 3868 3869 3870 3871 3872 3873 3874 3875 3876 3877 3878 3879 3880 3881\n",
      " 3882 3883 3884 3885 3886 3887 3888 3889 3890 3891 3892 3893 3894 3895\n",
      " 3896 3897 3898 3899 3900 3901 3902 3903 3904 3905 3906 3907 3908 3909\n",
      " 3910 3911 3912 3913 3914 3915 3916 3917 3918 3919 3920 3921 3922 3923\n",
      " 3924 3925 3926 3927 3928 3929 3930 3931 3932 3933 3934 3935 3936 3937\n",
      " 3938 3939 3940 3941 3942 3943 3944 3945 3946 3947 3948 3949 3950 3951\n",
      " 3952 3953 3954 3955 3956 3957 3958 3959 3960 3961 3962 3963 3964 3965\n",
      " 3966 3967 3968 3969 3970 3971 3972 3973 3974 3975 3976 3977 3978 3979\n",
      " 3980 3981 3982 3983 3984 3985 3986 3987 3988 3989 3990 3991 3992 3993\n",
      " 3994 3995 3996 3997 3998 3999]\n",
      "     the  to  ect  and  for  of   a  you  hou  in  ...  valued  lay  \\\n",
      "0      0   2    2    0    1   0  27    0    0   6  ...       0    0   \n",
      "1      3   2    1    1    2   2  13    0    0   4  ...       0    0   \n",
      "2      0   0    1    0    1   0   2    0    0   0  ...       0    0   \n",
      "3      9   9    4    6    3   3  78    3    1   5  ...       0    0   \n",
      "4      4   2    2    1    3   1  33    0    1  12  ...       0    0   \n",
      "..   ...  ..  ...  ...  ...  ..  ..  ...  ...  ..  ...     ...  ...   \n",
      "995    6   3   15    2    7   1  67    4    6   7  ...       0    0   \n",
      "996    4   1    4    4    2   0  26    2    2   5  ...       0    0   \n",
      "997    2   1    1    1    1   0   9    0    0   2  ...       0    0   \n",
      "998   11   4    1    6    1   3  75    3    3   9  ...       0    0   \n",
      "999    2   1    1    1    1   0   9    0    0   2  ...       0    0   \n",
      "\n",
      "     infrastructure  military  allowing  ff  dry  Prediction  pred  true_label  \n",
      "0                 0         0         0   0    0           1     1           1  \n",
      "1                 0         0         0   1    0           0     0           0  \n",
      "2                 0         0         0   0    0           0     0           0  \n",
      "3                 0         0         0   0    0           0     0           0  \n",
      "4                 0         0         0   0    0           1     0           1  \n",
      "..              ...       ...       ...  ..  ...         ...   ...         ...  \n",
      "995               0         0         0   2    0           0     0           0  \n",
      "996               0         0         0   0    0           0     1           0  \n",
      "997               0         0         0   0    0           0     0           0  \n",
      "998               0         0         0   1    0           0     0           0  \n",
      "999               0         0         0   0    0           0     0           0  \n",
      "\n",
      "[1000 rows x 3003 columns]\n",
      "3000    1\n",
      "3001    0\n",
      "3002    0\n",
      "3003    0\n",
      "3004    1\n",
      "       ..\n",
      "3995    0\n",
      "3996    0\n",
      "3997    0\n",
      "3998    0\n",
      "3999    0\n",
      "Name: Prediction, Length: 1000, dtype: int64\n",
      "[0.879, 0.7763578274760383, 0.826530612244898]\n",
      "      the  to  ect  and  for  of   a  you  hou  in  ...  connevey  jay  \\\n",
      "4000    0   2    2    0    0   1  40    1    0   4  ...         0    0   \n",
      "4001   11   4    1    6    1   3  75    3    3   9  ...         0    0   \n",
      "4002    0   5    2    0    2   0  18    0    0   4  ...         0    0   \n",
      "4003    0   0    1    0    0   0  22    0    0   9  ...         0    0   \n",
      "4004    0   0    1    0    1   0   3    0    0   0  ...         0    0   \n",
      "...   ...  ..  ...  ...  ...  ..  ..  ...  ...  ..  ...       ...  ...   \n",
      "4995   20   6    3    1    1   1  34    0    0  15  ...         0    0   \n",
      "4996    0   7    1    0    0   0  20    1    1   0  ...         0    0   \n",
      "4997    6   8    1    3    2   1  64    7    1  16  ...         0    0   \n",
      "4998    8   6    2    5    6   1  51    4    0   4  ...         0    0   \n",
      "4999   13  12    3    7    6   4  96    9    1  10  ...         0    0   \n",
      "\n",
      "      valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
      "4000       0    0               0         0         0   1    0           1  \n",
      "4001       0    0               0         0         0   1    0           0  \n",
      "4002       0    0               0         0         0   0    0           0  \n",
      "4003       0    0               0         0         0   0    0           1  \n",
      "4004       0    0               0         0         0   0    0           0  \n",
      "...      ...  ...             ...       ...       ...  ..  ...         ...  \n",
      "4995       0    0               0         0         0   1    0           0  \n",
      "4996       0    1               0         0         0   0    0           0  \n",
      "4997       0    0               0         0         0   0    0           0  \n",
      "4998       0    0               0         0         0   0    0           0  \n",
      "4999       0    0               0         0         0   0    0           0  \n",
      "\n",
      "[1000 rows x 3001 columns]\n",
      "      the  to  ect  and  for  of    a  you  hou  in  ...  connevey  jay  \\\n",
      "0       0   0    1    0    0   0    2    0    0   0  ...         0    0   \n",
      "1       8  13   24    6    6   2  102    1   27  18  ...         0    0   \n",
      "2       0   0    1    0    0   0    8    0    0   4  ...         0    0   \n",
      "3       0   5   22    0    5   1   51    2   10   1  ...         0    0   \n",
      "4       7   6   17    1    5   2   57    0    9   3  ...         0    0   \n",
      "...   ...  ..  ...  ...  ...  ..  ...  ...  ...  ..  ...       ...  ...   \n",
      "3995    6   3   15    2    7   1   67    4    6   7  ...         0    0   \n",
      "3996    4   1    4    4    2   0   26    2    2   5  ...         0    0   \n",
      "3997    2   1    1    1    1   0    9    0    0   2  ...         0    0   \n",
      "3998   11   4    1    6    1   3   75    3    3   9  ...         0    0   \n",
      "3999    2   1    1    1    1   0    9    0    0   2  ...         0    0   \n",
      "\n",
      "      valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
      "0          0    0               0         0         0   0    0           0  \n",
      "1          0    0               0         0         0   1    0           0  \n",
      "2          0    0               0         0         0   0    0           0  \n",
      "3          0    0               0         0         0   0    0           0  \n",
      "4          0    0               0         0         0   1    0           0  \n",
      "...      ...  ...             ...       ...       ...  ..  ...         ...  \n",
      "3995       0    0               0         0         0   2    0           0  \n",
      "3996       0    0               0         0         0   0    0           0  \n",
      "3997       0    0               0         0         0   0    0           0  \n",
      "3998       0    0               0         0         0   1    0           0  \n",
      "3999       0    0               0         0         0   0    0           0  \n",
      "\n",
      "[4000 rows x 3001 columns]\n",
      "(4000, 3001)\n",
      "(1000, 3001)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0     1     2     3     4     5     6     7     8     9    ...   990  \\\n",
      "0    68  3998  3863  3034  3941  3863  3941  2760  2523  2760  ...   789   \n",
      "1  3620  3237  3868  3123  3807  3868  3807  3662  3145  3662  ...  2586   \n",
      "2  2651   733  3682  3320  3809  3682  3809  2674  1700  2674  ...    57   \n",
      "\n",
      "    991  992   993   994   995   996   997   998   999  \n",
      "0   366  323  1545  3381  2138  2637   323   928  3106  \n",
      "1  2839  289  3246   289   337   681   952  1080   405  \n",
      "2   657  461   221  3048  3406  2415  2732  1104   480  \n",
      "\n",
      "[3 rows x 1000 columns]\n",
      "   0    1    2    3    4    5    6    7    8    9    ...  990  991  992  993  \\\n",
      "0    1    0    0    1    0    0    0    0    0    0  ...    0    1    1    0   \n",
      "1    1    1    0    1    0    0    0    0    0    0  ...    0    1    1    1   \n",
      "2    1    1    0    1    0    0    0    0    1    0  ...    1    1    1    0   \n",
      "\n",
      "   994  995  996  997  998  999  \n",
      "0    0    0    1    1    0    1  \n",
      "1    1    0    1    1    0    0  \n",
      "2    1    0    1    1    0    0  \n",
      "\n",
      "[3 rows x 1000 columns]\n",
      "0      1\n",
      "1      1\n",
      "2      0\n",
      "3      1\n",
      "4      0\n",
      "      ..\n",
      "995    0\n",
      "996    1\n",
      "997    1\n",
      "998    0\n",
      "999    0\n",
      "Name: 0, Length: 1000, dtype: int64\n",
      "     the  to  ect  and  for  of   a  you  hou  in  ...  jay  valued  lay  \\\n",
      "0      0   2    2    0    0   1  40    1    0   4  ...    0       0    0   \n",
      "1     11   4    1    6    1   3  75    3    3   9  ...    0       0    0   \n",
      "2      0   5    2    0    2   0  18    0    0   4  ...    0       0    0   \n",
      "3      0   0    1    0    0   0  22    0    0   9  ...    0       0    0   \n",
      "4      0   0    1    0    1   0   3    0    0   0  ...    0       0    0   \n",
      "..   ...  ..  ...  ...  ...  ..  ..  ...  ...  ..  ...  ...     ...  ...   \n",
      "995   20   6    3    1    1   1  34    0    0  15  ...    0       0    0   \n",
      "996    0   7    1    0    0   0  20    1    1   0  ...    0       0    1   \n",
      "997    6   8    1    3    2   1  64    7    1  16  ...    0       0    0   \n",
      "998    8   6    2    5    6   1  51    4    0   4  ...    0       0    0   \n",
      "999   13  12    3    7    6   4  96    9    1  10  ...    0       0    0   \n",
      "\n",
      "     infrastructure  military  allowing  ff  dry  Prediction  pred  \n",
      "0                 0         0         0   1    0           1     1  \n",
      "1                 0         0         0   1    0           0     1  \n",
      "2                 0         0         0   0    0           0     0  \n",
      "3                 0         0         0   0    0           1     1  \n",
      "4                 0         0         0   0    0           0     0  \n",
      "..              ...       ...       ...  ..  ...         ...   ...  \n",
      "995               0         0         0   1    0           0     0  \n",
      "996               0         0         0   0    0           0     1  \n",
      "997               0         0         0   0    0           0     1  \n",
      "998               0         0         0   0    0           0     0  \n",
      "999               0         0         0   0    0           0     0  \n",
      "\n",
      "[1000 rows x 3002 columns]\n",
      "[4000 4001 4002 4003 4004 4005 4006 4007 4008 4009 4010 4011 4012 4013\n",
      " 4014 4015 4016 4017 4018 4019 4020 4021 4022 4023 4024 4025 4026 4027\n",
      " 4028 4029 4030 4031 4032 4033 4034 4035 4036 4037 4038 4039 4040 4041\n",
      " 4042 4043 4044 4045 4046 4047 4048 4049 4050 4051 4052 4053 4054 4055\n",
      " 4056 4057 4058 4059 4060 4061 4062 4063 4064 4065 4066 4067 4068 4069\n",
      " 4070 4071 4072 4073 4074 4075 4076 4077 4078 4079 4080 4081 4082 4083\n",
      " 4084 4085 4086 4087 4088 4089 4090 4091 4092 4093 4094 4095 4096 4097\n",
      " 4098 4099 4100 4101 4102 4103 4104 4105 4106 4107 4108 4109 4110 4111\n",
      " 4112 4113 4114 4115 4116 4117 4118 4119 4120 4121 4122 4123 4124 4125\n",
      " 4126 4127 4128 4129 4130 4131 4132 4133 4134 4135 4136 4137 4138 4139\n",
      " 4140 4141 4142 4143 4144 4145 4146 4147 4148 4149 4150 4151 4152 4153\n",
      " 4154 4155 4156 4157 4158 4159 4160 4161 4162 4163 4164 4165 4166 4167\n",
      " 4168 4169 4170 4171 4172 4173 4174 4175 4176 4177 4178 4179 4180 4181\n",
      " 4182 4183 4184 4185 4186 4187 4188 4189 4190 4191 4192 4193 4194 4195\n",
      " 4196 4197 4198 4199 4200 4201 4202 4203 4204 4205 4206 4207 4208 4209\n",
      " 4210 4211 4212 4213 4214 4215 4216 4217 4218 4219 4220 4221 4222 4223\n",
      " 4224 4225 4226 4227 4228 4229 4230 4231 4232 4233 4234 4235 4236 4237\n",
      " 4238 4239 4240 4241 4242 4243 4244 4245 4246 4247 4248 4249 4250 4251\n",
      " 4252 4253 4254 4255 4256 4257 4258 4259 4260 4261 4262 4263 4264 4265\n",
      " 4266 4267 4268 4269 4270 4271 4272 4273 4274 4275 4276 4277 4278 4279\n",
      " 4280 4281 4282 4283 4284 4285 4286 4287 4288 4289 4290 4291 4292 4293\n",
      " 4294 4295 4296 4297 4298 4299 4300 4301 4302 4303 4304 4305 4306 4307\n",
      " 4308 4309 4310 4311 4312 4313 4314 4315 4316 4317 4318 4319 4320 4321\n",
      " 4322 4323 4324 4325 4326 4327 4328 4329 4330 4331 4332 4333 4334 4335\n",
      " 4336 4337 4338 4339 4340 4341 4342 4343 4344 4345 4346 4347 4348 4349\n",
      " 4350 4351 4352 4353 4354 4355 4356 4357 4358 4359 4360 4361 4362 4363\n",
      " 4364 4365 4366 4367 4368 4369 4370 4371 4372 4373 4374 4375 4376 4377\n",
      " 4378 4379 4380 4381 4382 4383 4384 4385 4386 4387 4388 4389 4390 4391\n",
      " 4392 4393 4394 4395 4396 4397 4398 4399 4400 4401 4402 4403 4404 4405\n",
      " 4406 4407 4408 4409 4410 4411 4412 4413 4414 4415 4416 4417 4418 4419\n",
      " 4420 4421 4422 4423 4424 4425 4426 4427 4428 4429 4430 4431 4432 4433\n",
      " 4434 4435 4436 4437 4438 4439 4440 4441 4442 4443 4444 4445 4446 4447\n",
      " 4448 4449 4450 4451 4452 4453 4454 4455 4456 4457 4458 4459 4460 4461\n",
      " 4462 4463 4464 4465 4466 4467 4468 4469 4470 4471 4472 4473 4474 4475\n",
      " 4476 4477 4478 4479 4480 4481 4482 4483 4484 4485 4486 4487 4488 4489\n",
      " 4490 4491 4492 4493 4494 4495 4496 4497 4498 4499 4500 4501 4502 4503\n",
      " 4504 4505 4506 4507 4508 4509 4510 4511 4512 4513 4514 4515 4516 4517\n",
      " 4518 4519 4520 4521 4522 4523 4524 4525 4526 4527 4528 4529 4530 4531\n",
      " 4532 4533 4534 4535 4536 4537 4538 4539 4540 4541 4542 4543 4544 4545\n",
      " 4546 4547 4548 4549 4550 4551 4552 4553 4554 4555 4556 4557 4558 4559\n",
      " 4560 4561 4562 4563 4564 4565 4566 4567 4568 4569 4570 4571 4572 4573\n",
      " 4574 4575 4576 4577 4578 4579 4580 4581 4582 4583 4584 4585 4586 4587\n",
      " 4588 4589 4590 4591 4592 4593 4594 4595 4596 4597 4598 4599 4600 4601\n",
      " 4602 4603 4604 4605 4606 4607 4608 4609 4610 4611 4612 4613 4614 4615\n",
      " 4616 4617 4618 4619 4620 4621 4622 4623 4624 4625 4626 4627 4628 4629\n",
      " 4630 4631 4632 4633 4634 4635 4636 4637 4638 4639 4640 4641 4642 4643\n",
      " 4644 4645 4646 4647 4648 4649 4650 4651 4652 4653 4654 4655 4656 4657\n",
      " 4658 4659 4660 4661 4662 4663 4664 4665 4666 4667 4668 4669 4670 4671\n",
      " 4672 4673 4674 4675 4676 4677 4678 4679 4680 4681 4682 4683 4684 4685\n",
      " 4686 4687 4688 4689 4690 4691 4692 4693 4694 4695 4696 4697 4698 4699\n",
      " 4700 4701 4702 4703 4704 4705 4706 4707 4708 4709 4710 4711 4712 4713\n",
      " 4714 4715 4716 4717 4718 4719 4720 4721 4722 4723 4724 4725 4726 4727\n",
      " 4728 4729 4730 4731 4732 4733 4734 4735 4736 4737 4738 4739 4740 4741\n",
      " 4742 4743 4744 4745 4746 4747 4748 4749 4750 4751 4752 4753 4754 4755\n",
      " 4756 4757 4758 4759 4760 4761 4762 4763 4764 4765 4766 4767 4768 4769\n",
      " 4770 4771 4772 4773 4774 4775 4776 4777 4778 4779 4780 4781 4782 4783\n",
      " 4784 4785 4786 4787 4788 4789 4790 4791 4792 4793 4794 4795 4796 4797\n",
      " 4798 4799 4800 4801 4802 4803 4804 4805 4806 4807 4808 4809 4810 4811\n",
      " 4812 4813 4814 4815 4816 4817 4818 4819 4820 4821 4822 4823 4824 4825\n",
      " 4826 4827 4828 4829 4830 4831 4832 4833 4834 4835 4836 4837 4838 4839\n",
      " 4840 4841 4842 4843 4844 4845 4846 4847 4848 4849 4850 4851 4852 4853\n",
      " 4854 4855 4856 4857 4858 4859 4860 4861 4862 4863 4864 4865 4866 4867\n",
      " 4868 4869 4870 4871 4872 4873 4874 4875 4876 4877 4878 4879 4880 4881\n",
      " 4882 4883 4884 4885 4886 4887 4888 4889 4890 4891 4892 4893 4894 4895\n",
      " 4896 4897 4898 4899 4900 4901 4902 4903 4904 4905 4906 4907 4908 4909\n",
      " 4910 4911 4912 4913 4914 4915 4916 4917 4918 4919 4920 4921 4922 4923\n",
      " 4924 4925 4926 4927 4928 4929 4930 4931 4932 4933 4934 4935 4936 4937\n",
      " 4938 4939 4940 4941 4942 4943 4944 4945 4946 4947 4948 4949 4950 4951\n",
      " 4952 4953 4954 4955 4956 4957 4958 4959 4960 4961 4962 4963 4964 4965\n",
      " 4966 4967 4968 4969 4970 4971 4972 4973 4974 4975 4976 4977 4978 4979\n",
      " 4980 4981 4982 4983 4984 4985 4986 4987 4988 4989 4990 4991 4992 4993\n",
      " 4994 4995 4996 4997 4998 4999]\n",
      "     the  to  ect  and  for  of   a  you  hou  in  ...  valued  lay  \\\n",
      "0      0   2    2    0    0   1  40    1    0   4  ...       0    0   \n",
      "1     11   4    1    6    1   3  75    3    3   9  ...       0    0   \n",
      "2      0   5    2    0    2   0  18    0    0   4  ...       0    0   \n",
      "3      0   0    1    0    0   0  22    0    0   9  ...       0    0   \n",
      "4      0   0    1    0    1   0   3    0    0   0  ...       0    0   \n",
      "..   ...  ..  ...  ...  ...  ..  ..  ...  ...  ..  ...     ...  ...   \n",
      "995   20   6    3    1    1   1  34    0    0  15  ...       0    0   \n",
      "996    0   7    1    0    0   0  20    1    1   0  ...       0    1   \n",
      "997    6   8    1    3    2   1  64    7    1  16  ...       0    0   \n",
      "998    8   6    2    5    6   1  51    4    0   4  ...       0    0   \n",
      "999   13  12    3    7    6   4  96    9    1  10  ...       0    0   \n",
      "\n",
      "     infrastructure  military  allowing  ff  dry  Prediction  pred  true_label  \n",
      "0                 0         0         0   1    0           1     1           1  \n",
      "1                 0         0         0   1    0           0     1           0  \n",
      "2                 0         0         0   0    0           0     0           0  \n",
      "3                 0         0         0   0    0           1     1           1  \n",
      "4                 0         0         0   0    0           0     0           0  \n",
      "..              ...       ...       ...  ..  ...         ...   ...         ...  \n",
      "995               0         0         0   1    0           0     0           0  \n",
      "996               0         0         0   0    0           0     1           0  \n",
      "997               0         0         0   0    0           0     1           0  \n",
      "998               0         0         0   0    0           0     0           0  \n",
      "999               0         0         0   0    0           0     0           0  \n",
      "\n",
      "[1000 rows x 3003 columns]\n",
      "4000    1\n",
      "4001    0\n",
      "4002    0\n",
      "4003    1\n",
      "4004    0\n",
      "       ..\n",
      "4995    0\n",
      "4996    0\n",
      "4997    0\n",
      "4998    0\n",
      "4999    0\n",
      "Name: Prediction, Length: 1000, dtype: int64\n",
      "[0.775, 0.6097560975609756, 0.7352941176470589]\n",
      "     the  to  ect  and  for  of    a  you  hou  in  ...  connevey  jay  \\\n",
      "0      0   0    1    0    0   0    2    0    0   0  ...         0    0   \n",
      "1      8  13   24    6    6   2  102    1   27  18  ...         0    0   \n",
      "2      0   0    1    0    0   0    8    0    0   4  ...         0    0   \n",
      "3      0   5   22    0    5   1   51    2   10   1  ...         0    0   \n",
      "4      7   6   17    1    5   2   57    0    9   3  ...         0    0   \n",
      "..   ...  ..  ...  ...  ...  ..  ...  ...  ...  ..  ...       ...  ...   \n",
      "995    6   7    1    1    2   1   28    1    0  11  ...         0    0   \n",
      "996    0   0    1    0    0   1    3    0    0   0  ...         0    0   \n",
      "997    5   7   14    2    4   2   83    2    6   7  ...         0    0   \n",
      "998    8   3    2    0    4   4   40    3    0   5  ...         0    0   \n",
      "999    0   0    1    0    0   0    4    1    0   3  ...         0    0   \n",
      "\n",
      "     valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
      "0         0    0               0         0         0   0    0           0  \n",
      "1         0    0               0         0         0   1    0           0  \n",
      "2         0    0               0         0         0   0    0           0  \n",
      "3         0    0               0         0         0   0    0           0  \n",
      "4         0    0               0         0         0   1    0           0  \n",
      "..      ...  ...             ...       ...       ...  ..  ...         ...  \n",
      "995       0    0               0         0         0   0    0           0  \n",
      "996       0    0               0         0         0   1    0           1  \n",
      "997       0    0               0         0         0   2    0           0  \n",
      "998       0    0               0         0         0   0    0           0  \n",
      "999       0    0               0         0         0   0    0           0  \n",
      "\n",
      "[1000 rows x 3001 columns]\n",
      "      the  to  ect  and  for  of    a  you  hou  in  ...  connevey  jay  \\\n",
      "1000   17  15    9   13   21   6  144    9    5  53  ...         0    0   \n",
      "1001    3   2    1    0    1   0   29    2    0   8  ...         0    0   \n",
      "1002    2   3   15    1    2   0   46    1    7   1  ...         0    0   \n",
      "1003   17  11   13    5    3   2   49    4    5  13  ...         0    0   \n",
      "1004    0   8    1    1    0   0   49    2    0   7  ...         0    0   \n",
      "...   ...  ..  ...  ...  ...  ..  ...  ...  ...  ..  ...       ...  ...   \n",
      "4995   20   6    3    1    1   1   34    0    0  15  ...         0    0   \n",
      "4996    0   7    1    0    0   0   20    1    1   0  ...         0    0   \n",
      "4997    6   8    1    3    2   1   64    7    1  16  ...         0    0   \n",
      "4998    8   6    2    5    6   1   51    4    0   4  ...         0    0   \n",
      "4999   13  12    3    7    6   4   96    9    1  10  ...         0    0   \n",
      "\n",
      "      valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
      "1000       0    0               0         0         0   2    0           0  \n",
      "1001       0    0               0         0         0   0    0           0  \n",
      "1002       0    0               0         0         0   0    0           0  \n",
      "1003       0    0               0         0         0   0    0           0  \n",
      "1004       0    0               0         0         0   1    0           1  \n",
      "...      ...  ...             ...       ...       ...  ..  ...         ...  \n",
      "4995       0    0               0         0         0   1    0           0  \n",
      "4996       0    1               0         0         0   0    0           0  \n",
      "4997       0    0               0         0         0   0    0           0  \n",
      "4998       0    0               0         0         0   0    0           0  \n",
      "4999       0    0               0         0         0   0    0           0  \n",
      "\n",
      "[4000 rows x 3001 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 3001)\n",
      "(1000, 3001)\n",
      "    0     1     2     3     4     5     6     7     8     9    ...   990  \\\n",
      "0   459  2405   442  1537  1138  2172  2895  1706   836  1369  ...   331   \n",
      "1  1166  1219    58    63  1767  2937  2053   878   668   916  ...  3923   \n",
      "2  3596  3739  1167  2621  1399   587   665   641  2802   914  ...  2182   \n",
      "3  2537   352  2069  1085  1437  2221   322  1551   616    24  ...   631   \n",
      "4  1008  3366   178  1098  1883  1446  2881  1646  3417  1982  ...  1746   \n",
      "\n",
      "    991   992   993   994   995   996   997   998   999  \n",
      "0   770  3169    24   277  3617  1774  2305  2854   227  \n",
      "1  2883  2683   697  3493  1297  1027  1272  1651  1755  \n",
      "2   776  3167  1146   896  2949  3056  2483  2850  2870  \n",
      "3  2894  3368  1369  1657  1022  1270    90   377  1082  \n",
      "4   654   620  1634  3692  2954  1721  2310  3040  1416  \n",
      "\n",
      "[5 rows x 1000 columns]\n",
      "   0    1    2    3    4    5    6    7    8    9    ...  990  991  992  993  \\\n",
      "0    0    1    0    0    0    1    0    1    1    0  ...    0    0    0    0   \n",
      "1    1    0    0    0    0    1    0    1    1    0  ...    1    0    0    0   \n",
      "2    0    1    0    0    0    1    1    1    1    0  ...    1    0    0    0   \n",
      "3    0    0    0    0    0    1    0    1    0    0  ...    1    0    0    0   \n",
      "4    0    0    0    0    0    1    0    1    0    0  ...    1    0    0    0   \n",
      "\n",
      "   994  995  996  997  998  999  \n",
      "0    1    0    1    0    0    1  \n",
      "1    0    0    1    0    1    1  \n",
      "2    1    0    1    0    0    1  \n",
      "3    1    0    1    0    1    1  \n",
      "4    0    0    1    0    1    1  \n",
      "\n",
      "[5 rows x 1000 columns]\n",
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "995    0\n",
      "996    1\n",
      "997    0\n",
      "998    1\n",
      "999    1\n",
      "Name: 0, Length: 1000, dtype: int64\n",
      "     the  to  ect  and  for  of    a  you  hou  in  ...  jay  valued  lay  \\\n",
      "0      0   0    1    0    0   0    2    0    0   0  ...    0       0    0   \n",
      "1      8  13   24    6    6   2  102    1   27  18  ...    0       0    0   \n",
      "2      0   0    1    0    0   0    8    0    0   4  ...    0       0    0   \n",
      "3      0   5   22    0    5   1   51    2   10   1  ...    0       0    0   \n",
      "4      7   6   17    1    5   2   57    0    9   3  ...    0       0    0   \n",
      "..   ...  ..  ...  ...  ...  ..  ...  ...  ...  ..  ...  ...     ...  ...   \n",
      "995    6   7    1    1    2   1   28    1    0  11  ...    0       0    0   \n",
      "996    0   0    1    0    0   1    3    0    0   0  ...    0       0    0   \n",
      "997    5   7   14    2    4   2   83    2    6   7  ...    0       0    0   \n",
      "998    8   3    2    0    4   4   40    3    0   5  ...    0       0    0   \n",
      "999    0   0    1    0    0   0    4    1    0   3  ...    0       0    0   \n",
      "\n",
      "     infrastructure  military  allowing  ff  dry  Prediction  pred  \n",
      "0                 0         0         0   0    0           0     0  \n",
      "1                 0         0         0   1    0           0     0  \n",
      "2                 0         0         0   0    0           0     0  \n",
      "3                 0         0         0   0    0           0     0  \n",
      "4                 0         0         0   1    0           0     0  \n",
      "..              ...       ...       ...  ..  ...         ...   ...  \n",
      "995               0         0         0   0    0           0     0  \n",
      "996               0         0         0   1    0           1     1  \n",
      "997               0         0         0   2    0           0     0  \n",
      "998               0         0         0   0    0           0     1  \n",
      "999               0         0         0   0    0           0     1  \n",
      "\n",
      "[1000 rows x 3002 columns]\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
      " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
      " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
      " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
      " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
      " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
      " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
      " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
      " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
      " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
      " 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n",
      " 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n",
      " 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n",
      " 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503\n",
      " 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521\n",
      " 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539\n",
      " 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557\n",
      " 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575\n",
      " 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593\n",
      " 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611\n",
      " 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629\n",
      " 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647\n",
      " 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665\n",
      " 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683\n",
      " 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701\n",
      " 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719\n",
      " 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737\n",
      " 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755\n",
      " 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773\n",
      " 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791\n",
      " 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809\n",
      " 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827\n",
      " 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845\n",
      " 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863\n",
      " 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881\n",
      " 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899\n",
      " 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917\n",
      " 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935\n",
      " 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953\n",
      " 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971\n",
      " 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989\n",
      " 990 991 992 993 994 995 996 997 998 999]\n",
      "     the  to  ect  and  for  of    a  you  hou  in  ...  valued  lay  \\\n",
      "0      0   0    1    0    0   0    2    0    0   0  ...       0    0   \n",
      "1      8  13   24    6    6   2  102    1   27  18  ...       0    0   \n",
      "2      0   0    1    0    0   0    8    0    0   4  ...       0    0   \n",
      "3      0   5   22    0    5   1   51    2   10   1  ...       0    0   \n",
      "4      7   6   17    1    5   2   57    0    9   3  ...       0    0   \n",
      "..   ...  ..  ...  ...  ...  ..  ...  ...  ...  ..  ...     ...  ...   \n",
      "995    6   7    1    1    2   1   28    1    0  11  ...       0    0   \n",
      "996    0   0    1    0    0   1    3    0    0   0  ...       0    0   \n",
      "997    5   7   14    2    4   2   83    2    6   7  ...       0    0   \n",
      "998    8   3    2    0    4   4   40    3    0   5  ...       0    0   \n",
      "999    0   0    1    0    0   0    4    1    0   3  ...       0    0   \n",
      "\n",
      "     infrastructure  military  allowing  ff  dry  Prediction  pred  true_label  \n",
      "0                 0         0         0   0    0           0     0           0  \n",
      "1                 0         0         0   1    0           0     0           0  \n",
      "2                 0         0         0   0    0           0     0           0  \n",
      "3                 0         0         0   0    0           0     0           0  \n",
      "4                 0         0         0   1    0           0     0           0  \n",
      "..              ...       ...       ...  ..  ...         ...   ...         ...  \n",
      "995               0         0         0   0    0           0     0           0  \n",
      "996               0         0         0   1    0           1     1           1  \n",
      "997               0         0         0   2    0           0     0           0  \n",
      "998               0         0         0   0    0           0     1           0  \n",
      "999               0         0         0   0    0           0     1           0  \n",
      "\n",
      "[1000 rows x 3003 columns]\n",
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "995    0\n",
      "996    1\n",
      "997    0\n",
      "998    0\n",
      "999    0\n",
      "Name: Prediction, Length: 1000, dtype: int64\n",
      "[0.837, 0.6685082872928176, 0.8491228070175438]\n",
      "      the  to  ect  and  for  of    a  you  hou  in  ...  connevey  jay  \\\n",
      "1000   17  15    9   13   21   6  144    9    5  53  ...         0    0   \n",
      "1001    3   2    1    0    1   0   29    2    0   8  ...         0    0   \n",
      "1002    2   3   15    1    2   0   46    1    7   1  ...         0    0   \n",
      "1003   17  11   13    5    3   2   49    4    5  13  ...         0    0   \n",
      "1004    0   8    1    1    0   0   49    2    0   7  ...         0    0   \n",
      "...   ...  ..  ...  ...  ...  ..  ...  ...  ...  ..  ...       ...  ...   \n",
      "1995   11  14    6   10    9   5  111    7    1  29  ...         0    0   \n",
      "1996   38  37    9   24   16  20  313   49    1  64  ...         0    0   \n",
      "1997    5   4    4    2    0   0   22    0    2   5  ...         0    0   \n",
      "1998    0   0    2    0    1   0    8    0    0   0  ...         0    0   \n",
      "1999    1   4    1    2    0   1   13    2    0   2  ...         0    0   \n",
      "\n",
      "      valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
      "1000       0    0               0         0         0   2    0           0  \n",
      "1001       0    0               0         0         0   0    0           0  \n",
      "1002       0    0               0         0         0   0    0           0  \n",
      "1003       0    0               0         0         0   0    0           0  \n",
      "1004       0    0               0         0         0   1    0           1  \n",
      "...      ...  ...             ...       ...       ...  ..  ...         ...  \n",
      "1995       0    1               0         0         0   1    0           1  \n",
      "1996       0    0               0         0         0   2    0           0  \n",
      "1997       0    0               0         0         0   0    0           0  \n",
      "1998       0    0               0         0         0   0    0           0  \n",
      "1999       0    0               0         0         0   0    0           1  \n",
      "\n",
      "[1000 rows x 3001 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      the  to  ect  and  for  of    a  you  hou  in  ...  connevey  jay  \\\n",
      "0       0   0    1    0    0   0    2    0    0   0  ...         0    0   \n",
      "1       8  13   24    6    6   2  102    1   27  18  ...         0    0   \n",
      "2       0   0    1    0    0   0    8    0    0   4  ...         0    0   \n",
      "3       0   5   22    0    5   1   51    2   10   1  ...         0    0   \n",
      "4       7   6   17    1    5   2   57    0    9   3  ...         0    0   \n",
      "...   ...  ..  ...  ...  ...  ..  ...  ...  ...  ..  ...       ...  ...   \n",
      "4995   20   6    3    1    1   1   34    0    0  15  ...         0    0   \n",
      "4996    0   7    1    0    0   0   20    1    1   0  ...         0    0   \n",
      "4997    6   8    1    3    2   1   64    7    1  16  ...         0    0   \n",
      "4998    8   6    2    5    6   1   51    4    0   4  ...         0    0   \n",
      "4999   13  12    3    7    6   4   96    9    1  10  ...         0    0   \n",
      "\n",
      "      valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
      "0          0    0               0         0         0   0    0           0  \n",
      "1          0    0               0         0         0   1    0           0  \n",
      "2          0    0               0         0         0   0    0           0  \n",
      "3          0    0               0         0         0   0    0           0  \n",
      "4          0    0               0         0         0   1    0           0  \n",
      "...      ...  ...             ...       ...       ...  ..  ...         ...  \n",
      "4995       0    0               0         0         0   1    0           0  \n",
      "4996       0    1               0         0         0   0    0           0  \n",
      "4997       0    0               0         0         0   0    0           0  \n",
      "4998       0    0               0         0         0   0    0           0  \n",
      "4999       0    0               0         0         0   0    0           0  \n",
      "\n",
      "[4000 rows x 3001 columns]\n",
      "(4000, 3001)\n",
      "(1000, 3001)\n",
      "    0     1     2     3     4     5     6     7     8     9    ...   990  \\\n",
      "0  2913  3939  1438  1305   568  2281  3719   873  1753   982  ...   700   \n",
      "1  2906  1783  2468  1737  2383   381   323   968   945  3506  ...  1711   \n",
      "2  1469  2366   278   428  1812    87  3597   892  1752   347  ...  2313   \n",
      "3  3535   752  2139  1309   448     0  3853  1286  1607  1335  ...  1853   \n",
      "4  1158  3810    19  2008  3509   420  3614   894  1870  3362  ...  1862   \n",
      "\n",
      "    991   992   993   994   995   996   997   998   999  \n",
      "0  1009  1959   154   555  3881  3705   705  1202  3979  \n",
      "1   596   152   590   845  2643   976   872  1000   750  \n",
      "2  1896  1164  1736  2484  3736  1282   924  1772  1579  \n",
      "3  3044  1096  2616   142  3481  2725  1355  1055   434  \n",
      "4  3049  1763  2494  1863  1025  3914  1694  2063  2733  \n",
      "\n",
      "[5 rows x 1000 columns]\n",
      "   0    1    2    3    4    5    6    7    8    9    ...  990  991  992  993  \\\n",
      "0    0    1    0    0    1    0    1    1    0    0  ...    0    0    1    0   \n",
      "1    0    1    0    0    1    0    1    1    0    0  ...    0    0    1    0   \n",
      "2    0    1    0    0    1    1    1    1    0    0  ...    0    0    1    0   \n",
      "3    0    0    0    0    1    0    1    1    0    0  ...    0    0    1    0   \n",
      "4    0    0    0    1    1    0    1    1    0    1  ...    0    0    1    0   \n",
      "\n",
      "   994  995  996  997  998  999  \n",
      "0    0    1    0    0    0    0  \n",
      "1    0    1    1    0    0    1  \n",
      "2    0    1    1    0    0    1  \n",
      "3    0    1    1    0    0    0  \n",
      "4    0    1    0    0    0    0  \n",
      "\n",
      "[5 rows x 1000 columns]\n",
      "0      0\n",
      "1      1\n",
      "2      0\n",
      "3      0\n",
      "4      1\n",
      "      ..\n",
      "995    1\n",
      "996    1\n",
      "997    0\n",
      "998    0\n",
      "999    0\n",
      "Name: 0, Length: 1000, dtype: int64\n",
      "     the  to  ect  and  for  of    a  you  hou  in  ...  jay  valued  lay  \\\n",
      "0     17  15    9   13   21   6  144    9    5  53  ...    0       0    0   \n",
      "1      3   2    1    0    1   0   29    2    0   8  ...    0       0    0   \n",
      "2      2   3   15    1    2   0   46    1    7   1  ...    0       0    0   \n",
      "3     17  11   13    5    3   2   49    4    5  13  ...    0       0    0   \n",
      "4      0   8    1    1    0   0   49    2    0   7  ...    0       0    0   \n",
      "..   ...  ..  ...  ...  ...  ..  ...  ...  ...  ..  ...  ...     ...  ...   \n",
      "995   11  14    6   10    9   5  111    7    1  29  ...    0       0    1   \n",
      "996   38  37    9   24   16  20  313   49    1  64  ...    0       0    0   \n",
      "997    5   4    4    2    0   0   22    0    2   5  ...    0       0    0   \n",
      "998    0   0    2    0    1   0    8    0    0   0  ...    0       0    0   \n",
      "999    1   4    1    2    0   1   13    2    0   2  ...    0       0    0   \n",
      "\n",
      "     infrastructure  military  allowing  ff  dry  Prediction  pred  \n",
      "0                 0         0         0   2    0           0     0  \n",
      "1                 0         0         0   0    0           0     1  \n",
      "2                 0         0         0   0    0           0     0  \n",
      "3                 0         0         0   0    0           0     0  \n",
      "4                 0         0         0   1    0           1     1  \n",
      "..              ...       ...       ...  ..  ...         ...   ...  \n",
      "995               0         0         0   1    0           1     1  \n",
      "996               0         0         0   2    0           0     1  \n",
      "997               0         0         0   0    0           0     0  \n",
      "998               0         0         0   0    0           0     0  \n",
      "999               0         0         0   0    0           1     0  \n",
      "\n",
      "[1000 rows x 3002 columns]\n",
      "[1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013\n",
      " 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027\n",
      " 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041\n",
      " 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055\n",
      " 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069\n",
      " 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083\n",
      " 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097\n",
      " 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111\n",
      " 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125\n",
      " 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139\n",
      " 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153\n",
      " 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167\n",
      " 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181\n",
      " 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195\n",
      " 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209\n",
      " 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223\n",
      " 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237\n",
      " 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251\n",
      " 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265\n",
      " 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279\n",
      " 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293\n",
      " 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307\n",
      " 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321\n",
      " 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335\n",
      " 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349\n",
      " 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363\n",
      " 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377\n",
      " 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391\n",
      " 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405\n",
      " 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419\n",
      " 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433\n",
      " 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447\n",
      " 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461\n",
      " 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475\n",
      " 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489\n",
      " 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503\n",
      " 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517\n",
      " 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531\n",
      " 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545\n",
      " 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557 1558 1559\n",
      " 1560 1561 1562 1563 1564 1565 1566 1567 1568 1569 1570 1571 1572 1573\n",
      " 1574 1575 1576 1577 1578 1579 1580 1581 1582 1583 1584 1585 1586 1587\n",
      " 1588 1589 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 1600 1601\n",
      " 1602 1603 1604 1605 1606 1607 1608 1609 1610 1611 1612 1613 1614 1615\n",
      " 1616 1617 1618 1619 1620 1621 1622 1623 1624 1625 1626 1627 1628 1629\n",
      " 1630 1631 1632 1633 1634 1635 1636 1637 1638 1639 1640 1641 1642 1643\n",
      " 1644 1645 1646 1647 1648 1649 1650 1651 1652 1653 1654 1655 1656 1657\n",
      " 1658 1659 1660 1661 1662 1663 1664 1665 1666 1667 1668 1669 1670 1671\n",
      " 1672 1673 1674 1675 1676 1677 1678 1679 1680 1681 1682 1683 1684 1685\n",
      " 1686 1687 1688 1689 1690 1691 1692 1693 1694 1695 1696 1697 1698 1699\n",
      " 1700 1701 1702 1703 1704 1705 1706 1707 1708 1709 1710 1711 1712 1713\n",
      " 1714 1715 1716 1717 1718 1719 1720 1721 1722 1723 1724 1725 1726 1727\n",
      " 1728 1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 1739 1740 1741\n",
      " 1742 1743 1744 1745 1746 1747 1748 1749 1750 1751 1752 1753 1754 1755\n",
      " 1756 1757 1758 1759 1760 1761 1762 1763 1764 1765 1766 1767 1768 1769\n",
      " 1770 1771 1772 1773 1774 1775 1776 1777 1778 1779 1780 1781 1782 1783\n",
      " 1784 1785 1786 1787 1788 1789 1790 1791 1792 1793 1794 1795 1796 1797\n",
      " 1798 1799 1800 1801 1802 1803 1804 1805 1806 1807 1808 1809 1810 1811\n",
      " 1812 1813 1814 1815 1816 1817 1818 1819 1820 1821 1822 1823 1824 1825\n",
      " 1826 1827 1828 1829 1830 1831 1832 1833 1834 1835 1836 1837 1838 1839\n",
      " 1840 1841 1842 1843 1844 1845 1846 1847 1848 1849 1850 1851 1852 1853\n",
      " 1854 1855 1856 1857 1858 1859 1860 1861 1862 1863 1864 1865 1866 1867\n",
      " 1868 1869 1870 1871 1872 1873 1874 1875 1876 1877 1878 1879 1880 1881\n",
      " 1882 1883 1884 1885 1886 1887 1888 1889 1890 1891 1892 1893 1894 1895\n",
      " 1896 1897 1898 1899 1900 1901 1902 1903 1904 1905 1906 1907 1908 1909\n",
      " 1910 1911 1912 1913 1914 1915 1916 1917 1918 1919 1920 1921 1922 1923\n",
      " 1924 1925 1926 1927 1928 1929 1930 1931 1932 1933 1934 1935 1936 1937\n",
      " 1938 1939 1940 1941 1942 1943 1944 1945 1946 1947 1948 1949 1950 1951\n",
      " 1952 1953 1954 1955 1956 1957 1958 1959 1960 1961 1962 1963 1964 1965\n",
      " 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 1976 1977 1978 1979\n",
      " 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993\n",
      " 1994 1995 1996 1997 1998 1999]\n",
      "     the  to  ect  and  for  of    a  you  hou  in  ...  valued  lay  \\\n",
      "0     17  15    9   13   21   6  144    9    5  53  ...       0    0   \n",
      "1      3   2    1    0    1   0   29    2    0   8  ...       0    0   \n",
      "2      2   3   15    1    2   0   46    1    7   1  ...       0    0   \n",
      "3     17  11   13    5    3   2   49    4    5  13  ...       0    0   \n",
      "4      0   8    1    1    0   0   49    2    0   7  ...       0    0   \n",
      "..   ...  ..  ...  ...  ...  ..  ...  ...  ...  ..  ...     ...  ...   \n",
      "995   11  14    6   10    9   5  111    7    1  29  ...       0    1   \n",
      "996   38  37    9   24   16  20  313   49    1  64  ...       0    0   \n",
      "997    5   4    4    2    0   0   22    0    2   5  ...       0    0   \n",
      "998    0   0    2    0    1   0    8    0    0   0  ...       0    0   \n",
      "999    1   4    1    2    0   1   13    2    0   2  ...       0    0   \n",
      "\n",
      "     infrastructure  military  allowing  ff  dry  Prediction  pred  true_label  \n",
      "0                 0         0         0   2    0           0     0           0  \n",
      "1                 0         0         0   0    0           0     1           0  \n",
      "2                 0         0         0   0    0           0     0           0  \n",
      "3                 0         0         0   0    0           0     0           0  \n",
      "4                 0         0         0   1    0           1     1           1  \n",
      "..              ...       ...       ...  ..  ...         ...   ...         ...  \n",
      "995               0         0         0   1    0           1     1           1  \n",
      "996               0         0         0   2    0           0     1           0  \n",
      "997               0         0         0   0    0           0     0           0  \n",
      "998               0         0         0   0    0           0     0           0  \n",
      "999               0         0         0   0    0           1     0           1  \n",
      "\n",
      "[1000 rows x 3003 columns]\n",
      "1000    0\n",
      "1001    0\n",
      "1002    0\n",
      "1003    0\n",
      "1004    1\n",
      "       ..\n",
      "1995    1\n",
      "1996    0\n",
      "1997    0\n",
      "1998    0\n",
      "1999    1\n",
      "Name: Prediction, Length: 1000, dtype: int64\n",
      "[0.85, 0.7068403908794788, 0.7833935018050542]\n",
      "      the  to  ect  and  for  of   a  you  hou  in  ...  connevey  jay  \\\n",
      "2000    0   0    2    0    1   0   7    0    0   0  ...         0    0   \n",
      "2001    2   1    1    2    2   2  25    0    0   2  ...         0    0   \n",
      "2002    0   0    1    0    1   0   3    0    0   0  ...         0    0   \n",
      "2003    0   0    1    0    1   0   4    0    0   0  ...         0    0   \n",
      "2004    0   0    1    0    0   0   7    0    0   0  ...         0    0   \n",
      "...   ...  ..  ...  ...  ...  ..  ..  ...  ...  ..  ...       ...  ...   \n",
      "2995    0   1    2    0    0   0  14    0    1   4  ...         0    0   \n",
      "2996    5   6    9    9    3   7  85    1    4  21  ...         0    0   \n",
      "2997    5   1    1    2    2   5  30    2    0   3  ...         0    0   \n",
      "2998    9   9    4    6    3   3  78    3    1   5  ...         0    0   \n",
      "2999    0   0    1    0    1   0   5    0    0   0  ...         0    0   \n",
      "\n",
      "      valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
      "2000       0    0               0         0         0   0    0           0  \n",
      "2001       0    0               0         0         0   2    0           1  \n",
      "2002       0    0               0         0         0   0    0           0  \n",
      "2003       0    0               0         0         0   0    0           0  \n",
      "2004       0    0               0         0         0   0    0           0  \n",
      "...      ...  ...             ...       ...       ...  ..  ...         ...  \n",
      "2995       0    0               0         0         0   0    0           0  \n",
      "2996       0    0               0         0         0   1    0           0  \n",
      "2997       0    0               0         0         0   2    0           0  \n",
      "2998       0    0               0         0         0   0    0           0  \n",
      "2999       0    0               0         0         0   0    0           0  \n",
      "\n",
      "[1000 rows x 3001 columns]\n",
      "      the  to  ect  and  for  of    a  you  hou  in  ...  connevey  jay  \\\n",
      "0       0   0    1    0    0   0    2    0    0   0  ...         0    0   \n",
      "1       8  13   24    6    6   2  102    1   27  18  ...         0    0   \n",
      "2       0   0    1    0    0   0    8    0    0   4  ...         0    0   \n",
      "3       0   5   22    0    5   1   51    2   10   1  ...         0    0   \n",
      "4       7   6   17    1    5   2   57    0    9   3  ...         0    0   \n",
      "...   ...  ..  ...  ...  ...  ..  ...  ...  ...  ..  ...       ...  ...   \n",
      "4995   20   6    3    1    1   1   34    0    0  15  ...         0    0   \n",
      "4996    0   7    1    0    0   0   20    1    1   0  ...         0    0   \n",
      "4997    6   8    1    3    2   1   64    7    1  16  ...         0    0   \n",
      "4998    8   6    2    5    6   1   51    4    0   4  ...         0    0   \n",
      "4999   13  12    3    7    6   4   96    9    1  10  ...         0    0   \n",
      "\n",
      "      valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
      "0          0    0               0         0         0   0    0           0  \n",
      "1          0    0               0         0         0   1    0           0  \n",
      "2          0    0               0         0         0   0    0           0  \n",
      "3          0    0               0         0         0   0    0           0  \n",
      "4          0    0               0         0         0   1    0           0  \n",
      "...      ...  ...             ...       ...       ...  ..  ...         ...  \n",
      "4995       0    0               0         0         0   1    0           0  \n",
      "4996       0    1               0         0         0   0    0           0  \n",
      "4997       0    0               0         0         0   0    0           0  \n",
      "4998       0    0               0         0         0   0    0           0  \n",
      "4999       0    0               0         0         0   0    0           0  \n",
      "\n",
      "[4000 rows x 3001 columns]\n",
      "(4000, 3001)\n",
      "(1000, 3001)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0     1     2     3     4     5     6     7     8     9    ...   990  \\\n",
      "0  1936   666  1966  1968   946   666  2906  3698   380  2495  ...  2138   \n",
      "1  1998  1502  1838  1924  1027  1947  2913  1565  3596  1991  ...  2116   \n",
      "2  1983  1947  1897  1864  1156  1502  3396  3716     0  3359  ...  2154   \n",
      "3  1721  1959  1863  1912    90  1211  3787   971   307  2309  ...  2168   \n",
      "4  1571   970  1926  1960  1873  1959  2449  2305    87  3295  ...  1201   \n",
      "\n",
      "    991   992   993   994   995   996   997   998   999  \n",
      "0   424  2279  2155  1775  2629  2661    30  2003  1241  \n",
      "1  1181  3498   299  2035  3620  3653  1893  2072  2063  \n",
      "2  3519  3045   877  3060  3252  1415  3423   120  2121  \n",
      "3  3864  3244   354  1683  2763  1357  2525  2080  1501  \n",
      "4  2038  3240  3594  1695  1979  1021  3214  3980  1489  \n",
      "\n",
      "[5 rows x 1000 columns]\n",
      "   0    1    2    3    4    5    6    7    8    9    ...  990  991  992  993  \\\n",
      "0    0    1    0    0    0    1    0    0    1    0  ...    0    0    0    0   \n",
      "1    0    1    0    0    0    1    0    0    0    0  ...    0    1    0    0   \n",
      "2    0    1    0    0    0    1    0    0    0    0  ...    0    1    0    0   \n",
      "3    0    1    0    0    0    1    0    0    1    0  ...    0    0    0    0   \n",
      "4    0    1    0    0    1    1    0    0    1    0  ...    0    0    0    0   \n",
      "\n",
      "   994  995  996  997  998  999  \n",
      "0    0    0    0    0    0    0  \n",
      "1    0    0    0    0    0    0  \n",
      "2    1    0    1    1    0    0  \n",
      "3    0    0    0    1    0    0  \n",
      "4    0    0    0    0    0    0  \n",
      "\n",
      "[5 rows x 1000 columns]\n",
      "0      0\n",
      "1      1\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "995    0\n",
      "996    0\n",
      "997    0\n",
      "998    0\n",
      "999    0\n",
      "Name: 0, Length: 1000, dtype: int64\n",
      "     the  to  ect  and  for  of   a  you  hou  in  ...  jay  valued  lay  \\\n",
      "0      0   0    2    0    1   0   7    0    0   0  ...    0       0    0   \n",
      "1      2   1    1    2    2   2  25    0    0   2  ...    0       0    0   \n",
      "2      0   0    1    0    1   0   3    0    0   0  ...    0       0    0   \n",
      "3      0   0    1    0    1   0   4    0    0   0  ...    0       0    0   \n",
      "4      0   0    1    0    0   0   7    0    0   0  ...    0       0    0   \n",
      "..   ...  ..  ...  ...  ...  ..  ..  ...  ...  ..  ...  ...     ...  ...   \n",
      "995    0   1    2    0    0   0  14    0    1   4  ...    0       0    0   \n",
      "996    5   6    9    9    3   7  85    1    4  21  ...    0       0    0   \n",
      "997    5   1    1    2    2   5  30    2    0   3  ...    0       0    0   \n",
      "998    9   9    4    6    3   3  78    3    1   5  ...    0       0    0   \n",
      "999    0   0    1    0    1   0   5    0    0   0  ...    0       0    0   \n",
      "\n",
      "     infrastructure  military  allowing  ff  dry  Prediction  pred  \n",
      "0                 0         0         0   0    0           0     0  \n",
      "1                 0         0         0   2    0           1     1  \n",
      "2                 0         0         0   0    0           0     0  \n",
      "3                 0         0         0   0    0           0     0  \n",
      "4                 0         0         0   0    0           0     0  \n",
      "..              ...       ...       ...  ..  ...         ...   ...  \n",
      "995               0         0         0   0    0           0     0  \n",
      "996               0         0         0   1    0           0     0  \n",
      "997               0         0         0   2    0           0     0  \n",
      "998               0         0         0   0    0           0     0  \n",
      "999               0         0         0   0    0           0     0  \n",
      "\n",
      "[1000 rows x 3002 columns]\n",
      "[2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013\n",
      " 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 2025 2026 2027\n",
      " 2028 2029 2030 2031 2032 2033 2034 2035 2036 2037 2038 2039 2040 2041\n",
      " 2042 2043 2044 2045 2046 2047 2048 2049 2050 2051 2052 2053 2054 2055\n",
      " 2056 2057 2058 2059 2060 2061 2062 2063 2064 2065 2066 2067 2068 2069\n",
      " 2070 2071 2072 2073 2074 2075 2076 2077 2078 2079 2080 2081 2082 2083\n",
      " 2084 2085 2086 2087 2088 2089 2090 2091 2092 2093 2094 2095 2096 2097\n",
      " 2098 2099 2100 2101 2102 2103 2104 2105 2106 2107 2108 2109 2110 2111\n",
      " 2112 2113 2114 2115 2116 2117 2118 2119 2120 2121 2122 2123 2124 2125\n",
      " 2126 2127 2128 2129 2130 2131 2132 2133 2134 2135 2136 2137 2138 2139\n",
      " 2140 2141 2142 2143 2144 2145 2146 2147 2148 2149 2150 2151 2152 2153\n",
      " 2154 2155 2156 2157 2158 2159 2160 2161 2162 2163 2164 2165 2166 2167\n",
      " 2168 2169 2170 2171 2172 2173 2174 2175 2176 2177 2178 2179 2180 2181\n",
      " 2182 2183 2184 2185 2186 2187 2188 2189 2190 2191 2192 2193 2194 2195\n",
      " 2196 2197 2198 2199 2200 2201 2202 2203 2204 2205 2206 2207 2208 2209\n",
      " 2210 2211 2212 2213 2214 2215 2216 2217 2218 2219 2220 2221 2222 2223\n",
      " 2224 2225 2226 2227 2228 2229 2230 2231 2232 2233 2234 2235 2236 2237\n",
      " 2238 2239 2240 2241 2242 2243 2244 2245 2246 2247 2248 2249 2250 2251\n",
      " 2252 2253 2254 2255 2256 2257 2258 2259 2260 2261 2262 2263 2264 2265\n",
      " 2266 2267 2268 2269 2270 2271 2272 2273 2274 2275 2276 2277 2278 2279\n",
      " 2280 2281 2282 2283 2284 2285 2286 2287 2288 2289 2290 2291 2292 2293\n",
      " 2294 2295 2296 2297 2298 2299 2300 2301 2302 2303 2304 2305 2306 2307\n",
      " 2308 2309 2310 2311 2312 2313 2314 2315 2316 2317 2318 2319 2320 2321\n",
      " 2322 2323 2324 2325 2326 2327 2328 2329 2330 2331 2332 2333 2334 2335\n",
      " 2336 2337 2338 2339 2340 2341 2342 2343 2344 2345 2346 2347 2348 2349\n",
      " 2350 2351 2352 2353 2354 2355 2356 2357 2358 2359 2360 2361 2362 2363\n",
      " 2364 2365 2366 2367 2368 2369 2370 2371 2372 2373 2374 2375 2376 2377\n",
      " 2378 2379 2380 2381 2382 2383 2384 2385 2386 2387 2388 2389 2390 2391\n",
      " 2392 2393 2394 2395 2396 2397 2398 2399 2400 2401 2402 2403 2404 2405\n",
      " 2406 2407 2408 2409 2410 2411 2412 2413 2414 2415 2416 2417 2418 2419\n",
      " 2420 2421 2422 2423 2424 2425 2426 2427 2428 2429 2430 2431 2432 2433\n",
      " 2434 2435 2436 2437 2438 2439 2440 2441 2442 2443 2444 2445 2446 2447\n",
      " 2448 2449 2450 2451 2452 2453 2454 2455 2456 2457 2458 2459 2460 2461\n",
      " 2462 2463 2464 2465 2466 2467 2468 2469 2470 2471 2472 2473 2474 2475\n",
      " 2476 2477 2478 2479 2480 2481 2482 2483 2484 2485 2486 2487 2488 2489\n",
      " 2490 2491 2492 2493 2494 2495 2496 2497 2498 2499 2500 2501 2502 2503\n",
      " 2504 2505 2506 2507 2508 2509 2510 2511 2512 2513 2514 2515 2516 2517\n",
      " 2518 2519 2520 2521 2522 2523 2524 2525 2526 2527 2528 2529 2530 2531\n",
      " 2532 2533 2534 2535 2536 2537 2538 2539 2540 2541 2542 2543 2544 2545\n",
      " 2546 2547 2548 2549 2550 2551 2552 2553 2554 2555 2556 2557 2558 2559\n",
      " 2560 2561 2562 2563 2564 2565 2566 2567 2568 2569 2570 2571 2572 2573\n",
      " 2574 2575 2576 2577 2578 2579 2580 2581 2582 2583 2584 2585 2586 2587\n",
      " 2588 2589 2590 2591 2592 2593 2594 2595 2596 2597 2598 2599 2600 2601\n",
      " 2602 2603 2604 2605 2606 2607 2608 2609 2610 2611 2612 2613 2614 2615\n",
      " 2616 2617 2618 2619 2620 2621 2622 2623 2624 2625 2626 2627 2628 2629\n",
      " 2630 2631 2632 2633 2634 2635 2636 2637 2638 2639 2640 2641 2642 2643\n",
      " 2644 2645 2646 2647 2648 2649 2650 2651 2652 2653 2654 2655 2656 2657\n",
      " 2658 2659 2660 2661 2662 2663 2664 2665 2666 2667 2668 2669 2670 2671\n",
      " 2672 2673 2674 2675 2676 2677 2678 2679 2680 2681 2682 2683 2684 2685\n",
      " 2686 2687 2688 2689 2690 2691 2692 2693 2694 2695 2696 2697 2698 2699\n",
      " 2700 2701 2702 2703 2704 2705 2706 2707 2708 2709 2710 2711 2712 2713\n",
      " 2714 2715 2716 2717 2718 2719 2720 2721 2722 2723 2724 2725 2726 2727\n",
      " 2728 2729 2730 2731 2732 2733 2734 2735 2736 2737 2738 2739 2740 2741\n",
      " 2742 2743 2744 2745 2746 2747 2748 2749 2750 2751 2752 2753 2754 2755\n",
      " 2756 2757 2758 2759 2760 2761 2762 2763 2764 2765 2766 2767 2768 2769\n",
      " 2770 2771 2772 2773 2774 2775 2776 2777 2778 2779 2780 2781 2782 2783\n",
      " 2784 2785 2786 2787 2788 2789 2790 2791 2792 2793 2794 2795 2796 2797\n",
      " 2798 2799 2800 2801 2802 2803 2804 2805 2806 2807 2808 2809 2810 2811\n",
      " 2812 2813 2814 2815 2816 2817 2818 2819 2820 2821 2822 2823 2824 2825\n",
      " 2826 2827 2828 2829 2830 2831 2832 2833 2834 2835 2836 2837 2838 2839\n",
      " 2840 2841 2842 2843 2844 2845 2846 2847 2848 2849 2850 2851 2852 2853\n",
      " 2854 2855 2856 2857 2858 2859 2860 2861 2862 2863 2864 2865 2866 2867\n",
      " 2868 2869 2870 2871 2872 2873 2874 2875 2876 2877 2878 2879 2880 2881\n",
      " 2882 2883 2884 2885 2886 2887 2888 2889 2890 2891 2892 2893 2894 2895\n",
      " 2896 2897 2898 2899 2900 2901 2902 2903 2904 2905 2906 2907 2908 2909\n",
      " 2910 2911 2912 2913 2914 2915 2916 2917 2918 2919 2920 2921 2922 2923\n",
      " 2924 2925 2926 2927 2928 2929 2930 2931 2932 2933 2934 2935 2936 2937\n",
      " 2938 2939 2940 2941 2942 2943 2944 2945 2946 2947 2948 2949 2950 2951\n",
      " 2952 2953 2954 2955 2956 2957 2958 2959 2960 2961 2962 2963 2964 2965\n",
      " 2966 2967 2968 2969 2970 2971 2972 2973 2974 2975 2976 2977 2978 2979\n",
      " 2980 2981 2982 2983 2984 2985 2986 2987 2988 2989 2990 2991 2992 2993\n",
      " 2994 2995 2996 2997 2998 2999]\n",
      "     the  to  ect  and  for  of   a  you  hou  in  ...  valued  lay  \\\n",
      "0      0   0    2    0    1   0   7    0    0   0  ...       0    0   \n",
      "1      2   1    1    2    2   2  25    0    0   2  ...       0    0   \n",
      "2      0   0    1    0    1   0   3    0    0   0  ...       0    0   \n",
      "3      0   0    1    0    1   0   4    0    0   0  ...       0    0   \n",
      "4      0   0    1    0    0   0   7    0    0   0  ...       0    0   \n",
      "..   ...  ..  ...  ...  ...  ..  ..  ...  ...  ..  ...     ...  ...   \n",
      "995    0   1    2    0    0   0  14    0    1   4  ...       0    0   \n",
      "996    5   6    9    9    3   7  85    1    4  21  ...       0    0   \n",
      "997    5   1    1    2    2   5  30    2    0   3  ...       0    0   \n",
      "998    9   9    4    6    3   3  78    3    1   5  ...       0    0   \n",
      "999    0   0    1    0    1   0   5    0    0   0  ...       0    0   \n",
      "\n",
      "     infrastructure  military  allowing  ff  dry  Prediction  pred  true_label  \n",
      "0                 0         0         0   0    0           0     0           0  \n",
      "1                 0         0         0   2    0           1     1           1  \n",
      "2                 0         0         0   0    0           0     0           0  \n",
      "3                 0         0         0   0    0           0     0           0  \n",
      "4                 0         0         0   0    0           0     0           0  \n",
      "..              ...       ...       ...  ..  ...         ...   ...         ...  \n",
      "995               0         0         0   0    0           0     0           0  \n",
      "996               0         0         0   1    0           0     0           0  \n",
      "997               0         0         0   2    0           0     0           0  \n",
      "998               0         0         0   0    0           0     0           0  \n",
      "999               0         0         0   0    0           0     0           0  \n",
      "\n",
      "[1000 rows x 3003 columns]\n",
      "2000    0\n",
      "2001    1\n",
      "2002    0\n",
      "2003    0\n",
      "2004    0\n",
      "       ..\n",
      "2995    0\n",
      "2996    0\n",
      "2997    0\n",
      "2998    0\n",
      "2999    0\n",
      "Name: Prediction, Length: 1000, dtype: int64\n",
      "[0.869, 0.7475728155339806, 0.8133802816901409]\n",
      "      the  to  ect  and  for  of   a  you  hou  in  ...  connevey  jay  \\\n",
      "3000    0   2    2    0    1   0  27    0    0   6  ...         0    0   \n",
      "3001    3   2    1    1    2   2  13    0    0   4  ...         0    0   \n",
      "3002    0   0    1    0    1   0   2    0    0   0  ...         0    0   \n",
      "3003    9   9    4    6    3   3  78    3    1   5  ...         0    0   \n",
      "3004    4   2    2    1    3   1  33    0    1  12  ...         0    0   \n",
      "...   ...  ..  ...  ...  ...  ..  ..  ...  ...  ..  ...       ...  ...   \n",
      "3995    6   3   15    2    7   1  67    4    6   7  ...         0    0   \n",
      "3996    4   1    4    4    2   0  26    2    2   5  ...         0    0   \n",
      "3997    2   1    1    1    1   0   9    0    0   2  ...         0    0   \n",
      "3998   11   4    1    6    1   3  75    3    3   9  ...         0    0   \n",
      "3999    2   1    1    1    1   0   9    0    0   2  ...         0    0   \n",
      "\n",
      "      valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
      "3000       0    0               0         0         0   0    0           1  \n",
      "3001       0    0               0         0         0   1    0           0  \n",
      "3002       0    0               0         0         0   0    0           0  \n",
      "3003       0    0               0         0         0   0    0           0  \n",
      "3004       0    0               0         0         0   0    0           1  \n",
      "...      ...  ...             ...       ...       ...  ..  ...         ...  \n",
      "3995       0    0               0         0         0   2    0           0  \n",
      "3996       0    0               0         0         0   0    0           0  \n",
      "3997       0    0               0         0         0   0    0           0  \n",
      "3998       0    0               0         0         0   1    0           0  \n",
      "3999       0    0               0         0         0   0    0           0  \n",
      "\n",
      "[1000 rows x 3001 columns]\n",
      "      the  to  ect  and  for  of    a  you  hou  in  ...  connevey  jay  \\\n",
      "0       0   0    1    0    0   0    2    0    0   0  ...         0    0   \n",
      "1       8  13   24    6    6   2  102    1   27  18  ...         0    0   \n",
      "2       0   0    1    0    0   0    8    0    0   4  ...         0    0   \n",
      "3       0   5   22    0    5   1   51    2   10   1  ...         0    0   \n",
      "4       7   6   17    1    5   2   57    0    9   3  ...         0    0   \n",
      "...   ...  ..  ...  ...  ...  ..  ...  ...  ...  ..  ...       ...  ...   \n",
      "4995   20   6    3    1    1   1   34    0    0  15  ...         0    0   \n",
      "4996    0   7    1    0    0   0   20    1    1   0  ...         0    0   \n",
      "4997    6   8    1    3    2   1   64    7    1  16  ...         0    0   \n",
      "4998    8   6    2    5    6   1   51    4    0   4  ...         0    0   \n",
      "4999   13  12    3    7    6   4   96    9    1  10  ...         0    0   \n",
      "\n",
      "      valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
      "0          0    0               0         0         0   0    0           0  \n",
      "1          0    0               0         0         0   1    0           0  \n",
      "2          0    0               0         0         0   0    0           0  \n",
      "3          0    0               0         0         0   0    0           0  \n",
      "4          0    0               0         0         0   1    0           0  \n",
      "...      ...  ...             ...       ...       ...  ..  ...         ...  \n",
      "4995       0    0               0         0         0   1    0           0  \n",
      "4996       0    1               0         0         0   0    0           0  \n",
      "4997       0    0               0         0         0   0    0           0  \n",
      "4998       0    0               0         0         0   0    0           0  \n",
      "4999       0    0               0         0         0   0    0           0  \n",
      "\n",
      "[4000 rows x 3001 columns]\n",
      "(4000, 3001)\n",
      "(1000, 3001)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0     1     2     3     4     5     6     7     8     9    ...   990  \\\n",
      "0  2674  3695  2978  2328  3491  2311  2628  2987  2510  3897  ...  3688   \n",
      "1  1716  1594  2989  2998  3083   126  2680  3987   415  1731  ...  1070   \n",
      "2  2751  1713  2981  2333  3081   550   490  1777   456  2928  ...   891   \n",
      "3   102   750  2944   120   324   321   996  3732  1587  1147  ...  3912   \n",
      "4  2246  1562  2921  3980  3174  1637   152  2684   127   839  ...  1656   \n",
      "\n",
      "    991   992   993   994   995   996   997   998   999  \n",
      "0  3019  3194  2364  3194  3019  3688   592  3802   592  \n",
      "1  3018  3186  2659  3186  3018  1070   425  3001   425  \n",
      "2   590  2510  2366  2510   590   891  2864  3940  2864  \n",
      "3   241  3698  1230  3698   241  3912  3961  1777  3961  \n",
      "4   747  3762  1449  3762   747  1656  3971   733  3971  \n",
      "\n",
      "[5 rows x 1000 columns]\n",
      "   0    1    2    3    4    5    6    7    8    9    ...  990  991  992  993  \\\n",
      "0    0    0    0    0    0    0    1    1    1    1  ...    1    0    0    1   \n",
      "1    1    0    0    0    0    0    1    1    0    1  ...    0    0    0    1   \n",
      "2    1    0    0    0    0    0    0    1    0    1  ...    0    0    1    1   \n",
      "3    1    1    0    0    1    0    1    1    1    1  ...    1    0    0    1   \n",
      "4    1    0    0    0    1    0    1    0    0    1  ...    0    0    0    1   \n",
      "\n",
      "   994  995  996  997  998  999  \n",
      "0    0    0    1    0    1    0  \n",
      "1    0    0    0    0    0    0  \n",
      "2    1    0    0    0    0    0  \n",
      "3    0    0    1    0    1    0  \n",
      "4    0    0    0    0    1    0  \n",
      "\n",
      "[5 rows x 1000 columns]\n",
      "0      1\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "995    0\n",
      "996    0\n",
      "997    0\n",
      "998    1\n",
      "999    0\n",
      "Name: 0, Length: 1000, dtype: int64\n",
      "     the  to  ect  and  for  of   a  you  hou  in  ...  jay  valued  lay  \\\n",
      "0      0   2    2    0    1   0  27    0    0   6  ...    0       0    0   \n",
      "1      3   2    1    1    2   2  13    0    0   4  ...    0       0    0   \n",
      "2      0   0    1    0    1   0   2    0    0   0  ...    0       0    0   \n",
      "3      9   9    4    6    3   3  78    3    1   5  ...    0       0    0   \n",
      "4      4   2    2    1    3   1  33    0    1  12  ...    0       0    0   \n",
      "..   ...  ..  ...  ...  ...  ..  ..  ...  ...  ..  ...  ...     ...  ...   \n",
      "995    6   3   15    2    7   1  67    4    6   7  ...    0       0    0   \n",
      "996    4   1    4    4    2   0  26    2    2   5  ...    0       0    0   \n",
      "997    2   1    1    1    1   0   9    0    0   2  ...    0       0    0   \n",
      "998   11   4    1    6    1   3  75    3    3   9  ...    0       0    0   \n",
      "999    2   1    1    1    1   0   9    0    0   2  ...    0       0    0   \n",
      "\n",
      "     infrastructure  military  allowing  ff  dry  Prediction  pred  \n",
      "0                 0         0         0   0    0           1     1  \n",
      "1                 0         0         0   1    0           0     0  \n",
      "2                 0         0         0   0    0           0     0  \n",
      "3                 0         0         0   0    0           0     0  \n",
      "4                 0         0         0   0    0           1     0  \n",
      "..              ...       ...       ...  ..  ...         ...   ...  \n",
      "995               0         0         0   2    0           0     0  \n",
      "996               0         0         0   0    0           0     0  \n",
      "997               0         0         0   0    0           0     0  \n",
      "998               0         0         0   1    0           0     1  \n",
      "999               0         0         0   0    0           0     0  \n",
      "\n",
      "[1000 rows x 3002 columns]\n",
      "[3000 3001 3002 3003 3004 3005 3006 3007 3008 3009 3010 3011 3012 3013\n",
      " 3014 3015 3016 3017 3018 3019 3020 3021 3022 3023 3024 3025 3026 3027\n",
      " 3028 3029 3030 3031 3032 3033 3034 3035 3036 3037 3038 3039 3040 3041\n",
      " 3042 3043 3044 3045 3046 3047 3048 3049 3050 3051 3052 3053 3054 3055\n",
      " 3056 3057 3058 3059 3060 3061 3062 3063 3064 3065 3066 3067 3068 3069\n",
      " 3070 3071 3072 3073 3074 3075 3076 3077 3078 3079 3080 3081 3082 3083\n",
      " 3084 3085 3086 3087 3088 3089 3090 3091 3092 3093 3094 3095 3096 3097\n",
      " 3098 3099 3100 3101 3102 3103 3104 3105 3106 3107 3108 3109 3110 3111\n",
      " 3112 3113 3114 3115 3116 3117 3118 3119 3120 3121 3122 3123 3124 3125\n",
      " 3126 3127 3128 3129 3130 3131 3132 3133 3134 3135 3136 3137 3138 3139\n",
      " 3140 3141 3142 3143 3144 3145 3146 3147 3148 3149 3150 3151 3152 3153\n",
      " 3154 3155 3156 3157 3158 3159 3160 3161 3162 3163 3164 3165 3166 3167\n",
      " 3168 3169 3170 3171 3172 3173 3174 3175 3176 3177 3178 3179 3180 3181\n",
      " 3182 3183 3184 3185 3186 3187 3188 3189 3190 3191 3192 3193 3194 3195\n",
      " 3196 3197 3198 3199 3200 3201 3202 3203 3204 3205 3206 3207 3208 3209\n",
      " 3210 3211 3212 3213 3214 3215 3216 3217 3218 3219 3220 3221 3222 3223\n",
      " 3224 3225 3226 3227 3228 3229 3230 3231 3232 3233 3234 3235 3236 3237\n",
      " 3238 3239 3240 3241 3242 3243 3244 3245 3246 3247 3248 3249 3250 3251\n",
      " 3252 3253 3254 3255 3256 3257 3258 3259 3260 3261 3262 3263 3264 3265\n",
      " 3266 3267 3268 3269 3270 3271 3272 3273 3274 3275 3276 3277 3278 3279\n",
      " 3280 3281 3282 3283 3284 3285 3286 3287 3288 3289 3290 3291 3292 3293\n",
      " 3294 3295 3296 3297 3298 3299 3300 3301 3302 3303 3304 3305 3306 3307\n",
      " 3308 3309 3310 3311 3312 3313 3314 3315 3316 3317 3318 3319 3320 3321\n",
      " 3322 3323 3324 3325 3326 3327 3328 3329 3330 3331 3332 3333 3334 3335\n",
      " 3336 3337 3338 3339 3340 3341 3342 3343 3344 3345 3346 3347 3348 3349\n",
      " 3350 3351 3352 3353 3354 3355 3356 3357 3358 3359 3360 3361 3362 3363\n",
      " 3364 3365 3366 3367 3368 3369 3370 3371 3372 3373 3374 3375 3376 3377\n",
      " 3378 3379 3380 3381 3382 3383 3384 3385 3386 3387 3388 3389 3390 3391\n",
      " 3392 3393 3394 3395 3396 3397 3398 3399 3400 3401 3402 3403 3404 3405\n",
      " 3406 3407 3408 3409 3410 3411 3412 3413 3414 3415 3416 3417 3418 3419\n",
      " 3420 3421 3422 3423 3424 3425 3426 3427 3428 3429 3430 3431 3432 3433\n",
      " 3434 3435 3436 3437 3438 3439 3440 3441 3442 3443 3444 3445 3446 3447\n",
      " 3448 3449 3450 3451 3452 3453 3454 3455 3456 3457 3458 3459 3460 3461\n",
      " 3462 3463 3464 3465 3466 3467 3468 3469 3470 3471 3472 3473 3474 3475\n",
      " 3476 3477 3478 3479 3480 3481 3482 3483 3484 3485 3486 3487 3488 3489\n",
      " 3490 3491 3492 3493 3494 3495 3496 3497 3498 3499 3500 3501 3502 3503\n",
      " 3504 3505 3506 3507 3508 3509 3510 3511 3512 3513 3514 3515 3516 3517\n",
      " 3518 3519 3520 3521 3522 3523 3524 3525 3526 3527 3528 3529 3530 3531\n",
      " 3532 3533 3534 3535 3536 3537 3538 3539 3540 3541 3542 3543 3544 3545\n",
      " 3546 3547 3548 3549 3550 3551 3552 3553 3554 3555 3556 3557 3558 3559\n",
      " 3560 3561 3562 3563 3564 3565 3566 3567 3568 3569 3570 3571 3572 3573\n",
      " 3574 3575 3576 3577 3578 3579 3580 3581 3582 3583 3584 3585 3586 3587\n",
      " 3588 3589 3590 3591 3592 3593 3594 3595 3596 3597 3598 3599 3600 3601\n",
      " 3602 3603 3604 3605 3606 3607 3608 3609 3610 3611 3612 3613 3614 3615\n",
      " 3616 3617 3618 3619 3620 3621 3622 3623 3624 3625 3626 3627 3628 3629\n",
      " 3630 3631 3632 3633 3634 3635 3636 3637 3638 3639 3640 3641 3642 3643\n",
      " 3644 3645 3646 3647 3648 3649 3650 3651 3652 3653 3654 3655 3656 3657\n",
      " 3658 3659 3660 3661 3662 3663 3664 3665 3666 3667 3668 3669 3670 3671\n",
      " 3672 3673 3674 3675 3676 3677 3678 3679 3680 3681 3682 3683 3684 3685\n",
      " 3686 3687 3688 3689 3690 3691 3692 3693 3694 3695 3696 3697 3698 3699\n",
      " 3700 3701 3702 3703 3704 3705 3706 3707 3708 3709 3710 3711 3712 3713\n",
      " 3714 3715 3716 3717 3718 3719 3720 3721 3722 3723 3724 3725 3726 3727\n",
      " 3728 3729 3730 3731 3732 3733 3734 3735 3736 3737 3738 3739 3740 3741\n",
      " 3742 3743 3744 3745 3746 3747 3748 3749 3750 3751 3752 3753 3754 3755\n",
      " 3756 3757 3758 3759 3760 3761 3762 3763 3764 3765 3766 3767 3768 3769\n",
      " 3770 3771 3772 3773 3774 3775 3776 3777 3778 3779 3780 3781 3782 3783\n",
      " 3784 3785 3786 3787 3788 3789 3790 3791 3792 3793 3794 3795 3796 3797\n",
      " 3798 3799 3800 3801 3802 3803 3804 3805 3806 3807 3808 3809 3810 3811\n",
      " 3812 3813 3814 3815 3816 3817 3818 3819 3820 3821 3822 3823 3824 3825\n",
      " 3826 3827 3828 3829 3830 3831 3832 3833 3834 3835 3836 3837 3838 3839\n",
      " 3840 3841 3842 3843 3844 3845 3846 3847 3848 3849 3850 3851 3852 3853\n",
      " 3854 3855 3856 3857 3858 3859 3860 3861 3862 3863 3864 3865 3866 3867\n",
      " 3868 3869 3870 3871 3872 3873 3874 3875 3876 3877 3878 3879 3880 3881\n",
      " 3882 3883 3884 3885 3886 3887 3888 3889 3890 3891 3892 3893 3894 3895\n",
      " 3896 3897 3898 3899 3900 3901 3902 3903 3904 3905 3906 3907 3908 3909\n",
      " 3910 3911 3912 3913 3914 3915 3916 3917 3918 3919 3920 3921 3922 3923\n",
      " 3924 3925 3926 3927 3928 3929 3930 3931 3932 3933 3934 3935 3936 3937\n",
      " 3938 3939 3940 3941 3942 3943 3944 3945 3946 3947 3948 3949 3950 3951\n",
      " 3952 3953 3954 3955 3956 3957 3958 3959 3960 3961 3962 3963 3964 3965\n",
      " 3966 3967 3968 3969 3970 3971 3972 3973 3974 3975 3976 3977 3978 3979\n",
      " 3980 3981 3982 3983 3984 3985 3986 3987 3988 3989 3990 3991 3992 3993\n",
      " 3994 3995 3996 3997 3998 3999]\n",
      "     the  to  ect  and  for  of   a  you  hou  in  ...  valued  lay  \\\n",
      "0      0   2    2    0    1   0  27    0    0   6  ...       0    0   \n",
      "1      3   2    1    1    2   2  13    0    0   4  ...       0    0   \n",
      "2      0   0    1    0    1   0   2    0    0   0  ...       0    0   \n",
      "3      9   9    4    6    3   3  78    3    1   5  ...       0    0   \n",
      "4      4   2    2    1    3   1  33    0    1  12  ...       0    0   \n",
      "..   ...  ..  ...  ...  ...  ..  ..  ...  ...  ..  ...     ...  ...   \n",
      "995    6   3   15    2    7   1  67    4    6   7  ...       0    0   \n",
      "996    4   1    4    4    2   0  26    2    2   5  ...       0    0   \n",
      "997    2   1    1    1    1   0   9    0    0   2  ...       0    0   \n",
      "998   11   4    1    6    1   3  75    3    3   9  ...       0    0   \n",
      "999    2   1    1    1    1   0   9    0    0   2  ...       0    0   \n",
      "\n",
      "     infrastructure  military  allowing  ff  dry  Prediction  pred  true_label  \n",
      "0                 0         0         0   0    0           1     1           1  \n",
      "1                 0         0         0   1    0           0     0           0  \n",
      "2                 0         0         0   0    0           0     0           0  \n",
      "3                 0         0         0   0    0           0     0           0  \n",
      "4                 0         0         0   0    0           1     0           1  \n",
      "..              ...       ...       ...  ..  ...         ...   ...         ...  \n",
      "995               0         0         0   2    0           0     0           0  \n",
      "996               0         0         0   0    0           0     0           0  \n",
      "997               0         0         0   0    0           0     0           0  \n",
      "998               0         0         0   1    0           0     1           0  \n",
      "999               0         0         0   0    0           0     0           0  \n",
      "\n",
      "[1000 rows x 3003 columns]\n",
      "3000    1\n",
      "3001    0\n",
      "3002    0\n",
      "3003    0\n",
      "3004    1\n",
      "       ..\n",
      "3995    0\n",
      "3996    0\n",
      "3997    0\n",
      "3998    0\n",
      "3999    0\n",
      "Name: Prediction, Length: 1000, dtype: int64\n",
      "[0.869, 0.7620578778135049, 0.8061224489795918]\n",
      "      the  to  ect  and  for  of   a  you  hou  in  ...  connevey  jay  \\\n",
      "4000    0   2    2    0    0   1  40    1    0   4  ...         0    0   \n",
      "4001   11   4    1    6    1   3  75    3    3   9  ...         0    0   \n",
      "4002    0   5    2    0    2   0  18    0    0   4  ...         0    0   \n",
      "4003    0   0    1    0    0   0  22    0    0   9  ...         0    0   \n",
      "4004    0   0    1    0    1   0   3    0    0   0  ...         0    0   \n",
      "...   ...  ..  ...  ...  ...  ..  ..  ...  ...  ..  ...       ...  ...   \n",
      "4995   20   6    3    1    1   1  34    0    0  15  ...         0    0   \n",
      "4996    0   7    1    0    0   0  20    1    1   0  ...         0    0   \n",
      "4997    6   8    1    3    2   1  64    7    1  16  ...         0    0   \n",
      "4998    8   6    2    5    6   1  51    4    0   4  ...         0    0   \n",
      "4999   13  12    3    7    6   4  96    9    1  10  ...         0    0   \n",
      "\n",
      "      valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
      "4000       0    0               0         0         0   1    0           1  \n",
      "4001       0    0               0         0         0   1    0           0  \n",
      "4002       0    0               0         0         0   0    0           0  \n",
      "4003       0    0               0         0         0   0    0           1  \n",
      "4004       0    0               0         0         0   0    0           0  \n",
      "...      ...  ...             ...       ...       ...  ..  ...         ...  \n",
      "4995       0    0               0         0         0   1    0           0  \n",
      "4996       0    1               0         0         0   0    0           0  \n",
      "4997       0    0               0         0         0   0    0           0  \n",
      "4998       0    0               0         0         0   0    0           0  \n",
      "4999       0    0               0         0         0   0    0           0  \n",
      "\n",
      "[1000 rows x 3001 columns]\n",
      "      the  to  ect  and  for  of    a  you  hou  in  ...  connevey  jay  \\\n",
      "0       0   0    1    0    0   0    2    0    0   0  ...         0    0   \n",
      "1       8  13   24    6    6   2  102    1   27  18  ...         0    0   \n",
      "2       0   0    1    0    0   0    8    0    0   4  ...         0    0   \n",
      "3       0   5   22    0    5   1   51    2   10   1  ...         0    0   \n",
      "4       7   6   17    1    5   2   57    0    9   3  ...         0    0   \n",
      "...   ...  ..  ...  ...  ...  ..  ...  ...  ...  ..  ...       ...  ...   \n",
      "3995    6   3   15    2    7   1   67    4    6   7  ...         0    0   \n",
      "3996    4   1    4    4    2   0   26    2    2   5  ...         0    0   \n",
      "3997    2   1    1    1    1   0    9    0    0   2  ...         0    0   \n",
      "3998   11   4    1    6    1   3   75    3    3   9  ...         0    0   \n",
      "3999    2   1    1    1    1   0    9    0    0   2  ...         0    0   \n",
      "\n",
      "      valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
      "0          0    0               0         0         0   0    0           0  \n",
      "1          0    0               0         0         0   1    0           0  \n",
      "2          0    0               0         0         0   0    0           0  \n",
      "3          0    0               0         0         0   0    0           0  \n",
      "4          0    0               0         0         0   1    0           0  \n",
      "...      ...  ...             ...       ...       ...  ..  ...         ...  \n",
      "3995       0    0               0         0         0   2    0           0  \n",
      "3996       0    0               0         0         0   0    0           0  \n",
      "3997       0    0               0         0         0   0    0           0  \n",
      "3998       0    0               0         0         0   1    0           0  \n",
      "3999       0    0               0         0         0   0    0           0  \n",
      "\n",
      "[4000 rows x 3001 columns]\n",
      "(4000, 3001)\n",
      "(1000, 3001)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0     1     2     3     4     5     6     7     8     9    ...   990  \\\n",
      "0    68  3237  3682  3034  3809  3682  3809  3662  2523  3662  ...   789   \n",
      "1  3620  1777  3695  1722  3832  3695  3832   536  3145   536  ...  2586   \n",
      "2  2651  3998  3863  3320  3807  3863  3807  2674  1700  2674  ...    57   \n",
      "3   559   733  3868  3123  3941  3868  3941  2760  1449  2760  ...  3892   \n",
      "4  2558  2819  3690  2513  3938  3690  3938  3303  2402  3303  ...  3228   \n",
      "\n",
      "    991   992   993   994   995   996   997   998   999  \n",
      "0   366   323  1545  3381  2138   450  2732  3304  3106  \n",
      "1  1242   289  3246   289   337  2415  1278   928   405  \n",
      "2   657   461   221  3048  3406  2637   952  1104   480  \n",
      "3  2839  3772  2708   568  1831   681   323  1080   335  \n",
      "4  1765  2518   767  1278  2377  3387  2836  3766  2121  \n",
      "\n",
      "[5 rows x 1000 columns]\n",
      "   0    1    2    3    4    5    6    7    8    9    ...  990  991  992  993  \\\n",
      "0    1    1    0    1    0    0    0    0    0    0  ...    0    1    1    0   \n",
      "1    1    1    0    1    0    0    0    0    0    0  ...    0    1    1    1   \n",
      "2    1    0    0    1    0    0    0    0    1    0  ...    1    1    1    0   \n",
      "3    0    1    0    1    0    0    0    0    1    0  ...    1    1    1    1   \n",
      "4    0    0    0    1    0    0    0    1    1    1  ...    0    1    0    0   \n",
      "\n",
      "   994  995  996  997  998  999  \n",
      "0    0    0    1    1    0    1  \n",
      "1    1    0    1    0    0    0  \n",
      "2    1    0    1    1    0    0  \n",
      "3    1    0    1    1    0    0  \n",
      "4    0    0    1    1    0    1  \n",
      "\n",
      "[5 rows x 1000 columns]\n",
      "0      1\n",
      "1      1\n",
      "2      0\n",
      "3      1\n",
      "4      0\n",
      "      ..\n",
      "995    0\n",
      "996    1\n",
      "997    1\n",
      "998    0\n",
      "999    0\n",
      "Name: 0, Length: 1000, dtype: int64\n",
      "     the  to  ect  and  for  of   a  you  hou  in  ...  jay  valued  lay  \\\n",
      "0      0   2    2    0    0   1  40    1    0   4  ...    0       0    0   \n",
      "1     11   4    1    6    1   3  75    3    3   9  ...    0       0    0   \n",
      "2      0   5    2    0    2   0  18    0    0   4  ...    0       0    0   \n",
      "3      0   0    1    0    0   0  22    0    0   9  ...    0       0    0   \n",
      "4      0   0    1    0    1   0   3    0    0   0  ...    0       0    0   \n",
      "..   ...  ..  ...  ...  ...  ..  ..  ...  ...  ..  ...  ...     ...  ...   \n",
      "995   20   6    3    1    1   1  34    0    0  15  ...    0       0    0   \n",
      "996    0   7    1    0    0   0  20    1    1   0  ...    0       0    1   \n",
      "997    6   8    1    3    2   1  64    7    1  16  ...    0       0    0   \n",
      "998    8   6    2    5    6   1  51    4    0   4  ...    0       0    0   \n",
      "999   13  12    3    7    6   4  96    9    1  10  ...    0       0    0   \n",
      "\n",
      "     infrastructure  military  allowing  ff  dry  Prediction  pred  \n",
      "0                 0         0         0   1    0           1     1  \n",
      "1                 0         0         0   1    0           0     1  \n",
      "2                 0         0         0   0    0           0     0  \n",
      "3                 0         0         0   0    0           1     1  \n",
      "4                 0         0         0   0    0           0     0  \n",
      "..              ...       ...       ...  ..  ...         ...   ...  \n",
      "995               0         0         0   1    0           0     0  \n",
      "996               0         0         0   0    0           0     1  \n",
      "997               0         0         0   0    0           0     1  \n",
      "998               0         0         0   0    0           0     0  \n",
      "999               0         0         0   0    0           0     0  \n",
      "\n",
      "[1000 rows x 3002 columns]\n",
      "[4000 4001 4002 4003 4004 4005 4006 4007 4008 4009 4010 4011 4012 4013\n",
      " 4014 4015 4016 4017 4018 4019 4020 4021 4022 4023 4024 4025 4026 4027\n",
      " 4028 4029 4030 4031 4032 4033 4034 4035 4036 4037 4038 4039 4040 4041\n",
      " 4042 4043 4044 4045 4046 4047 4048 4049 4050 4051 4052 4053 4054 4055\n",
      " 4056 4057 4058 4059 4060 4061 4062 4063 4064 4065 4066 4067 4068 4069\n",
      " 4070 4071 4072 4073 4074 4075 4076 4077 4078 4079 4080 4081 4082 4083\n",
      " 4084 4085 4086 4087 4088 4089 4090 4091 4092 4093 4094 4095 4096 4097\n",
      " 4098 4099 4100 4101 4102 4103 4104 4105 4106 4107 4108 4109 4110 4111\n",
      " 4112 4113 4114 4115 4116 4117 4118 4119 4120 4121 4122 4123 4124 4125\n",
      " 4126 4127 4128 4129 4130 4131 4132 4133 4134 4135 4136 4137 4138 4139\n",
      " 4140 4141 4142 4143 4144 4145 4146 4147 4148 4149 4150 4151 4152 4153\n",
      " 4154 4155 4156 4157 4158 4159 4160 4161 4162 4163 4164 4165 4166 4167\n",
      " 4168 4169 4170 4171 4172 4173 4174 4175 4176 4177 4178 4179 4180 4181\n",
      " 4182 4183 4184 4185 4186 4187 4188 4189 4190 4191 4192 4193 4194 4195\n",
      " 4196 4197 4198 4199 4200 4201 4202 4203 4204 4205 4206 4207 4208 4209\n",
      " 4210 4211 4212 4213 4214 4215 4216 4217 4218 4219 4220 4221 4222 4223\n",
      " 4224 4225 4226 4227 4228 4229 4230 4231 4232 4233 4234 4235 4236 4237\n",
      " 4238 4239 4240 4241 4242 4243 4244 4245 4246 4247 4248 4249 4250 4251\n",
      " 4252 4253 4254 4255 4256 4257 4258 4259 4260 4261 4262 4263 4264 4265\n",
      " 4266 4267 4268 4269 4270 4271 4272 4273 4274 4275 4276 4277 4278 4279\n",
      " 4280 4281 4282 4283 4284 4285 4286 4287 4288 4289 4290 4291 4292 4293\n",
      " 4294 4295 4296 4297 4298 4299 4300 4301 4302 4303 4304 4305 4306 4307\n",
      " 4308 4309 4310 4311 4312 4313 4314 4315 4316 4317 4318 4319 4320 4321\n",
      " 4322 4323 4324 4325 4326 4327 4328 4329 4330 4331 4332 4333 4334 4335\n",
      " 4336 4337 4338 4339 4340 4341 4342 4343 4344 4345 4346 4347 4348 4349\n",
      " 4350 4351 4352 4353 4354 4355 4356 4357 4358 4359 4360 4361 4362 4363\n",
      " 4364 4365 4366 4367 4368 4369 4370 4371 4372 4373 4374 4375 4376 4377\n",
      " 4378 4379 4380 4381 4382 4383 4384 4385 4386 4387 4388 4389 4390 4391\n",
      " 4392 4393 4394 4395 4396 4397 4398 4399 4400 4401 4402 4403 4404 4405\n",
      " 4406 4407 4408 4409 4410 4411 4412 4413 4414 4415 4416 4417 4418 4419\n",
      " 4420 4421 4422 4423 4424 4425 4426 4427 4428 4429 4430 4431 4432 4433\n",
      " 4434 4435 4436 4437 4438 4439 4440 4441 4442 4443 4444 4445 4446 4447\n",
      " 4448 4449 4450 4451 4452 4453 4454 4455 4456 4457 4458 4459 4460 4461\n",
      " 4462 4463 4464 4465 4466 4467 4468 4469 4470 4471 4472 4473 4474 4475\n",
      " 4476 4477 4478 4479 4480 4481 4482 4483 4484 4485 4486 4487 4488 4489\n",
      " 4490 4491 4492 4493 4494 4495 4496 4497 4498 4499 4500 4501 4502 4503\n",
      " 4504 4505 4506 4507 4508 4509 4510 4511 4512 4513 4514 4515 4516 4517\n",
      " 4518 4519 4520 4521 4522 4523 4524 4525 4526 4527 4528 4529 4530 4531\n",
      " 4532 4533 4534 4535 4536 4537 4538 4539 4540 4541 4542 4543 4544 4545\n",
      " 4546 4547 4548 4549 4550 4551 4552 4553 4554 4555 4556 4557 4558 4559\n",
      " 4560 4561 4562 4563 4564 4565 4566 4567 4568 4569 4570 4571 4572 4573\n",
      " 4574 4575 4576 4577 4578 4579 4580 4581 4582 4583 4584 4585 4586 4587\n",
      " 4588 4589 4590 4591 4592 4593 4594 4595 4596 4597 4598 4599 4600 4601\n",
      " 4602 4603 4604 4605 4606 4607 4608 4609 4610 4611 4612 4613 4614 4615\n",
      " 4616 4617 4618 4619 4620 4621 4622 4623 4624 4625 4626 4627 4628 4629\n",
      " 4630 4631 4632 4633 4634 4635 4636 4637 4638 4639 4640 4641 4642 4643\n",
      " 4644 4645 4646 4647 4648 4649 4650 4651 4652 4653 4654 4655 4656 4657\n",
      " 4658 4659 4660 4661 4662 4663 4664 4665 4666 4667 4668 4669 4670 4671\n",
      " 4672 4673 4674 4675 4676 4677 4678 4679 4680 4681 4682 4683 4684 4685\n",
      " 4686 4687 4688 4689 4690 4691 4692 4693 4694 4695 4696 4697 4698 4699\n",
      " 4700 4701 4702 4703 4704 4705 4706 4707 4708 4709 4710 4711 4712 4713\n",
      " 4714 4715 4716 4717 4718 4719 4720 4721 4722 4723 4724 4725 4726 4727\n",
      " 4728 4729 4730 4731 4732 4733 4734 4735 4736 4737 4738 4739 4740 4741\n",
      " 4742 4743 4744 4745 4746 4747 4748 4749 4750 4751 4752 4753 4754 4755\n",
      " 4756 4757 4758 4759 4760 4761 4762 4763 4764 4765 4766 4767 4768 4769\n",
      " 4770 4771 4772 4773 4774 4775 4776 4777 4778 4779 4780 4781 4782 4783\n",
      " 4784 4785 4786 4787 4788 4789 4790 4791 4792 4793 4794 4795 4796 4797\n",
      " 4798 4799 4800 4801 4802 4803 4804 4805 4806 4807 4808 4809 4810 4811\n",
      " 4812 4813 4814 4815 4816 4817 4818 4819 4820 4821 4822 4823 4824 4825\n",
      " 4826 4827 4828 4829 4830 4831 4832 4833 4834 4835 4836 4837 4838 4839\n",
      " 4840 4841 4842 4843 4844 4845 4846 4847 4848 4849 4850 4851 4852 4853\n",
      " 4854 4855 4856 4857 4858 4859 4860 4861 4862 4863 4864 4865 4866 4867\n",
      " 4868 4869 4870 4871 4872 4873 4874 4875 4876 4877 4878 4879 4880 4881\n",
      " 4882 4883 4884 4885 4886 4887 4888 4889 4890 4891 4892 4893 4894 4895\n",
      " 4896 4897 4898 4899 4900 4901 4902 4903 4904 4905 4906 4907 4908 4909\n",
      " 4910 4911 4912 4913 4914 4915 4916 4917 4918 4919 4920 4921 4922 4923\n",
      " 4924 4925 4926 4927 4928 4929 4930 4931 4932 4933 4934 4935 4936 4937\n",
      " 4938 4939 4940 4941 4942 4943 4944 4945 4946 4947 4948 4949 4950 4951\n",
      " 4952 4953 4954 4955 4956 4957 4958 4959 4960 4961 4962 4963 4964 4965\n",
      " 4966 4967 4968 4969 4970 4971 4972 4973 4974 4975 4976 4977 4978 4979\n",
      " 4980 4981 4982 4983 4984 4985 4986 4987 4988 4989 4990 4991 4992 4993\n",
      " 4994 4995 4996 4997 4998 4999]\n",
      "     the  to  ect  and  for  of   a  you  hou  in  ...  valued  lay  \\\n",
      "0      0   2    2    0    0   1  40    1    0   4  ...       0    0   \n",
      "1     11   4    1    6    1   3  75    3    3   9  ...       0    0   \n",
      "2      0   5    2    0    2   0  18    0    0   4  ...       0    0   \n",
      "3      0   0    1    0    0   0  22    0    0   9  ...       0    0   \n",
      "4      0   0    1    0    1   0   3    0    0   0  ...       0    0   \n",
      "..   ...  ..  ...  ...  ...  ..  ..  ...  ...  ..  ...     ...  ...   \n",
      "995   20   6    3    1    1   1  34    0    0  15  ...       0    0   \n",
      "996    0   7    1    0    0   0  20    1    1   0  ...       0    1   \n",
      "997    6   8    1    3    2   1  64    7    1  16  ...       0    0   \n",
      "998    8   6    2    5    6   1  51    4    0   4  ...       0    0   \n",
      "999   13  12    3    7    6   4  96    9    1  10  ...       0    0   \n",
      "\n",
      "     infrastructure  military  allowing  ff  dry  Prediction  pred  true_label  \n",
      "0                 0         0         0   1    0           1     1           1  \n",
      "1                 0         0         0   1    0           0     1           0  \n",
      "2                 0         0         0   0    0           0     0           0  \n",
      "3                 0         0         0   0    0           1     1           1  \n",
      "4                 0         0         0   0    0           0     0           0  \n",
      "..              ...       ...       ...  ..  ...         ...   ...         ...  \n",
      "995               0         0         0   1    0           0     0           0  \n",
      "996               0         0         0   0    0           0     1           0  \n",
      "997               0         0         0   0    0           0     1           0  \n",
      "998               0         0         0   0    0           0     0           0  \n",
      "999               0         0         0   0    0           0     0           0  \n",
      "\n",
      "[1000 rows x 3003 columns]\n",
      "4000    1\n",
      "4001    0\n",
      "4002    0\n",
      "4003    1\n",
      "4004    0\n",
      "       ..\n",
      "4995    0\n",
      "4996    0\n",
      "4997    0\n",
      "4998    0\n",
      "4999    0\n",
      "Name: Prediction, Length: 1000, dtype: int64\n",
      "[0.779, 0.613941018766756, 0.7483660130718954]\n",
      "     the  to  ect  and  for  of    a  you  hou  in  ...  connevey  jay  \\\n",
      "0      0   0    1    0    0   0    2    0    0   0  ...         0    0   \n",
      "1      8  13   24    6    6   2  102    1   27  18  ...         0    0   \n",
      "2      0   0    1    0    0   0    8    0    0   4  ...         0    0   \n",
      "3      0   5   22    0    5   1   51    2   10   1  ...         0    0   \n",
      "4      7   6   17    1    5   2   57    0    9   3  ...         0    0   \n",
      "..   ...  ..  ...  ...  ...  ..  ...  ...  ...  ..  ...       ...  ...   \n",
      "995    6   7    1    1    2   1   28    1    0  11  ...         0    0   \n",
      "996    0   0    1    0    0   1    3    0    0   0  ...         0    0   \n",
      "997    5   7   14    2    4   2   83    2    6   7  ...         0    0   \n",
      "998    8   3    2    0    4   4   40    3    0   5  ...         0    0   \n",
      "999    0   0    1    0    0   0    4    1    0   3  ...         0    0   \n",
      "\n",
      "     valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
      "0         0    0               0         0         0   0    0           0  \n",
      "1         0    0               0         0         0   1    0           0  \n",
      "2         0    0               0         0         0   0    0           0  \n",
      "3         0    0               0         0         0   0    0           0  \n",
      "4         0    0               0         0         0   1    0           0  \n",
      "..      ...  ...             ...       ...       ...  ..  ...         ...  \n",
      "995       0    0               0         0         0   0    0           0  \n",
      "996       0    0               0         0         0   1    0           1  \n",
      "997       0    0               0         0         0   2    0           0  \n",
      "998       0    0               0         0         0   0    0           0  \n",
      "999       0    0               0         0         0   0    0           0  \n",
      "\n",
      "[1000 rows x 3001 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      the  to  ect  and  for  of    a  you  hou  in  ...  connevey  jay  \\\n",
      "1000   17  15    9   13   21   6  144    9    5  53  ...         0    0   \n",
      "1001    3   2    1    0    1   0   29    2    0   8  ...         0    0   \n",
      "1002    2   3   15    1    2   0   46    1    7   1  ...         0    0   \n",
      "1003   17  11   13    5    3   2   49    4    5  13  ...         0    0   \n",
      "1004    0   8    1    1    0   0   49    2    0   7  ...         0    0   \n",
      "...   ...  ..  ...  ...  ...  ..  ...  ...  ...  ..  ...       ...  ...   \n",
      "4995   20   6    3    1    1   1   34    0    0  15  ...         0    0   \n",
      "4996    0   7    1    0    0   0   20    1    1   0  ...         0    0   \n",
      "4997    6   8    1    3    2   1   64    7    1  16  ...         0    0   \n",
      "4998    8   6    2    5    6   1   51    4    0   4  ...         0    0   \n",
      "4999   13  12    3    7    6   4   96    9    1  10  ...         0    0   \n",
      "\n",
      "      valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
      "1000       0    0               0         0         0   2    0           0  \n",
      "1001       0    0               0         0         0   0    0           0  \n",
      "1002       0    0               0         0         0   0    0           0  \n",
      "1003       0    0               0         0         0   0    0           0  \n",
      "1004       0    0               0         0         0   1    0           1  \n",
      "...      ...  ...             ...       ...       ...  ..  ...         ...  \n",
      "4995       0    0               0         0         0   1    0           0  \n",
      "4996       0    1               0         0         0   0    0           0  \n",
      "4997       0    0               0         0         0   0    0           0  \n",
      "4998       0    0               0         0         0   0    0           0  \n",
      "4999       0    0               0         0         0   0    0           0  \n",
      "\n",
      "[4000 rows x 3001 columns]\n",
      "(4000, 3001)\n",
      "(1000, 3001)\n",
      "    0     1     2     3     4     5     6     7     8     9    ...   990  \\\n",
      "0   459  2405   442  1537  1138  1446  2895  1706   836  1369  ...   331   \n",
      "1  1166  1219    58    63  1767  2616  2053   878   668   916  ...  3923   \n",
      "2  3596  3739  2069  2621  1399   587   665   641  2802   914  ...  2182   \n",
      "3  2537   352  1167  1085  1437  2937   322  1551   616    24  ...   631   \n",
      "4  1008  3366   178  1098  1883  2396  2881  1646  3417  1982  ...  1746   \n",
      "5  3458  1576  2870   886    63  2172  1875  3858   699    90  ...  1660   \n",
      "6  3782  1218  2394  2494  1599  2221  3796  1397  2422  1533  ...    16   \n",
      "\n",
      "    991   992   993   994   995   996   997   998   999  \n",
      "0   770  2683    24  3517  3617  1774  2305  2854   227  \n",
      "1  2883  3169   697   896  1297  1027  1272  1651  1755  \n",
      "2   776  3167  1369  3692  2949  3056  2483  2850  2870  \n",
      "3  2894  1156  2157  1657  1022  1270    90   377  1082  \n",
      "4   654  2286  1634   277  2954  1721  2310  3040  1416  \n",
      "5  1935   620  1146  3493   684  2287  3584  1731   140  \n",
      "6  3285  3368  2132  3034  1689   401  1550   880  1235  \n",
      "\n",
      "[7 rows x 1000 columns]\n",
      "   0    1    2    3    4    5    6    7    8    9    ...  990  991  992  993  \\\n",
      "0    0    1    0    0    0    1    0    1    1    0  ...    0    0    0    0   \n",
      "1    1    0    0    0    0    0    0    1    1    0  ...    1    0    0    0   \n",
      "2    0    1    0    0    0    1    1    1    1    0  ...    1    0    0    0   \n",
      "3    0    0    0    0    0    1    0    1    0    0  ...    1    0    0    0   \n",
      "4    0    0    0    0    0    1    0    1    0    0  ...    1    0    0    0   \n",
      "5    1    0    1    0    0    1    0    1    0    0  ...    0    0    0    0   \n",
      "6    0    0    1    0    0    1    0    1    0    0  ...    0    1    0    0   \n",
      "\n",
      "   994  995  996  997  998  999  \n",
      "0    1    0    1    0    0    1  \n",
      "1    1    0    1    0    1    1  \n",
      "2    0    0    1    0    0    1  \n",
      "3    1    0    1    0    1    1  \n",
      "4    1    0    1    0    1    1  \n",
      "5    0    0    1    0    0    1  \n",
      "6    1    0    1    0    1    0  \n",
      "\n",
      "[7 rows x 1000 columns]\n",
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "995    0\n",
      "996    1\n",
      "997    0\n",
      "998    1\n",
      "999    1\n",
      "Name: 0, Length: 1000, dtype: int64\n",
      "     the  to  ect  and  for  of    a  you  hou  in  ...  jay  valued  lay  \\\n",
      "0      0   0    1    0    0   0    2    0    0   0  ...    0       0    0   \n",
      "1      8  13   24    6    6   2  102    1   27  18  ...    0       0    0   \n",
      "2      0   0    1    0    0   0    8    0    0   4  ...    0       0    0   \n",
      "3      0   5   22    0    5   1   51    2   10   1  ...    0       0    0   \n",
      "4      7   6   17    1    5   2   57    0    9   3  ...    0       0    0   \n",
      "..   ...  ..  ...  ...  ...  ..  ...  ...  ...  ..  ...  ...     ...  ...   \n",
      "995    6   7    1    1    2   1   28    1    0  11  ...    0       0    0   \n",
      "996    0   0    1    0    0   1    3    0    0   0  ...    0       0    0   \n",
      "997    5   7   14    2    4   2   83    2    6   7  ...    0       0    0   \n",
      "998    8   3    2    0    4   4   40    3    0   5  ...    0       0    0   \n",
      "999    0   0    1    0    0   0    4    1    0   3  ...    0       0    0   \n",
      "\n",
      "     infrastructure  military  allowing  ff  dry  Prediction  pred  \n",
      "0                 0         0         0   0    0           0     0  \n",
      "1                 0         0         0   1    0           0     0  \n",
      "2                 0         0         0   0    0           0     0  \n",
      "3                 0         0         0   0    0           0     0  \n",
      "4                 0         0         0   1    0           0     0  \n",
      "..              ...       ...       ...  ..  ...         ...   ...  \n",
      "995               0         0         0   0    0           0     0  \n",
      "996               0         0         0   1    0           1     1  \n",
      "997               0         0         0   2    0           0     0  \n",
      "998               0         0         0   0    0           0     1  \n",
      "999               0         0         0   0    0           0     1  \n",
      "\n",
      "[1000 rows x 3002 columns]\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
      " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
      " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
      " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
      " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
      " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
      " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
      " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
      " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
      " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
      " 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n",
      " 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n",
      " 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n",
      " 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503\n",
      " 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521\n",
      " 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539\n",
      " 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557\n",
      " 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575\n",
      " 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593\n",
      " 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611\n",
      " 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629\n",
      " 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647\n",
      " 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665\n",
      " 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683\n",
      " 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701\n",
      " 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719\n",
      " 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737\n",
      " 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755\n",
      " 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773\n",
      " 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791\n",
      " 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809\n",
      " 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827\n",
      " 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845\n",
      " 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863\n",
      " 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881\n",
      " 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899\n",
      " 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917\n",
      " 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935\n",
      " 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953\n",
      " 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971\n",
      " 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989\n",
      " 990 991 992 993 994 995 996 997 998 999]\n",
      "     the  to  ect  and  for  of    a  you  hou  in  ...  valued  lay  \\\n",
      "0      0   0    1    0    0   0    2    0    0   0  ...       0    0   \n",
      "1      8  13   24    6    6   2  102    1   27  18  ...       0    0   \n",
      "2      0   0    1    0    0   0    8    0    0   4  ...       0    0   \n",
      "3      0   5   22    0    5   1   51    2   10   1  ...       0    0   \n",
      "4      7   6   17    1    5   2   57    0    9   3  ...       0    0   \n",
      "..   ...  ..  ...  ...  ...  ..  ...  ...  ...  ..  ...     ...  ...   \n",
      "995    6   7    1    1    2   1   28    1    0  11  ...       0    0   \n",
      "996    0   0    1    0    0   1    3    0    0   0  ...       0    0   \n",
      "997    5   7   14    2    4   2   83    2    6   7  ...       0    0   \n",
      "998    8   3    2    0    4   4   40    3    0   5  ...       0    0   \n",
      "999    0   0    1    0    0   0    4    1    0   3  ...       0    0   \n",
      "\n",
      "     infrastructure  military  allowing  ff  dry  Prediction  pred  true_label  \n",
      "0                 0         0         0   0    0           0     0           0  \n",
      "1                 0         0         0   1    0           0     0           0  \n",
      "2                 0         0         0   0    0           0     0           0  \n",
      "3                 0         0         0   0    0           0     0           0  \n",
      "4                 0         0         0   1    0           0     0           0  \n",
      "..              ...       ...       ...  ..  ...         ...   ...         ...  \n",
      "995               0         0         0   0    0           0     0           0  \n",
      "996               0         0         0   1    0           1     1           1  \n",
      "997               0         0         0   2    0           0     0           0  \n",
      "998               0         0         0   0    0           0     1           0  \n",
      "999               0         0         0   0    0           0     1           0  \n",
      "\n",
      "[1000 rows x 3003 columns]\n",
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "995    0\n",
      "996    1\n",
      "997    0\n",
      "998    0\n",
      "999    0\n",
      "Name: Prediction, Length: 1000, dtype: int64\n",
      "[0.839, 0.6712707182320442, 0.8526315789473684]\n",
      "      the  to  ect  and  for  of    a  you  hou  in  ...  connevey  jay  \\\n",
      "1000   17  15    9   13   21   6  144    9    5  53  ...         0    0   \n",
      "1001    3   2    1    0    1   0   29    2    0   8  ...         0    0   \n",
      "1002    2   3   15    1    2   0   46    1    7   1  ...         0    0   \n",
      "1003   17  11   13    5    3   2   49    4    5  13  ...         0    0   \n",
      "1004    0   8    1    1    0   0   49    2    0   7  ...         0    0   \n",
      "...   ...  ..  ...  ...  ...  ..  ...  ...  ...  ..  ...       ...  ...   \n",
      "1995   11  14    6   10    9   5  111    7    1  29  ...         0    0   \n",
      "1996   38  37    9   24   16  20  313   49    1  64  ...         0    0   \n",
      "1997    5   4    4    2    0   0   22    0    2   5  ...         0    0   \n",
      "1998    0   0    2    0    1   0    8    0    0   0  ...         0    0   \n",
      "1999    1   4    1    2    0   1   13    2    0   2  ...         0    0   \n",
      "\n",
      "      valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
      "1000       0    0               0         0         0   2    0           0  \n",
      "1001       0    0               0         0         0   0    0           0  \n",
      "1002       0    0               0         0         0   0    0           0  \n",
      "1003       0    0               0         0         0   0    0           0  \n",
      "1004       0    0               0         0         0   1    0           1  \n",
      "...      ...  ...             ...       ...       ...  ..  ...         ...  \n",
      "1995       0    1               0         0         0   1    0           1  \n",
      "1996       0    0               0         0         0   2    0           0  \n",
      "1997       0    0               0         0         0   0    0           0  \n",
      "1998       0    0               0         0         0   0    0           0  \n",
      "1999       0    0               0         0         0   0    0           1  \n",
      "\n",
      "[1000 rows x 3001 columns]\n",
      "      the  to  ect  and  for  of    a  you  hou  in  ...  connevey  jay  \\\n",
      "0       0   0    1    0    0   0    2    0    0   0  ...         0    0   \n",
      "1       8  13   24    6    6   2  102    1   27  18  ...         0    0   \n",
      "2       0   0    1    0    0   0    8    0    0   4  ...         0    0   \n",
      "3       0   5   22    0    5   1   51    2   10   1  ...         0    0   \n",
      "4       7   6   17    1    5   2   57    0    9   3  ...         0    0   \n",
      "...   ...  ..  ...  ...  ...  ..  ...  ...  ...  ..  ...       ...  ...   \n",
      "4995   20   6    3    1    1   1   34    0    0  15  ...         0    0   \n",
      "4996    0   7    1    0    0   0   20    1    1   0  ...         0    0   \n",
      "4997    6   8    1    3    2   1   64    7    1  16  ...         0    0   \n",
      "4998    8   6    2    5    6   1   51    4    0   4  ...         0    0   \n",
      "4999   13  12    3    7    6   4   96    9    1  10  ...         0    0   \n",
      "\n",
      "      valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
      "0          0    0               0         0         0   0    0           0  \n",
      "1          0    0               0         0         0   1    0           0  \n",
      "2          0    0               0         0         0   0    0           0  \n",
      "3          0    0               0         0         0   0    0           0  \n",
      "4          0    0               0         0         0   1    0           0  \n",
      "...      ...  ...             ...       ...       ...  ..  ...         ...  \n",
      "4995       0    0               0         0         0   1    0           0  \n",
      "4996       0    1               0         0         0   0    0           0  \n",
      "4997       0    0               0         0         0   0    0           0  \n",
      "4998       0    0               0         0         0   0    0           0  \n",
      "4999       0    0               0         0         0   0    0           0  \n",
      "\n",
      "[4000 rows x 3001 columns]\n",
      "(4000, 3001)\n",
      "(1000, 3001)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0     1     2     3     4     5     6     7     8     9    ...   990  \\\n",
      "0  2913  3939  1438  1305   568   381  3719  1214  1753   347  ...   700   \n",
      "1  2906  1783  2468  1737  2383  2281   323   892   945  3362  ...  1711   \n",
      "2  1469  2366   278   428  1812   959  3597   968  1752  3506  ...  2313   \n",
      "3  3535   752  2139  1309   448     0  3853   894  1607  1335  ...  1853   \n",
      "4  1158  3810    19  2008  1050   420  3614   873  1870   982  ...  1862   \n",
      "5  3804  2012  3172   456  3509    87  2765  1286  2906  3102  ...   590   \n",
      "6   762  3886  3176  2305  2440   103   927  1821  2913  3099  ...   928   \n",
      "\n",
      "    991   992   993   994   995   996   997   998   999  \n",
      "0  1009  1959   154   555  3736  3705   705  1202  3979  \n",
      "1   596   152   590   845  1025   976   872  1000   750  \n",
      "2  1896  1164  1736  2484  2643  1282   924  1772  1579  \n",
      "3  3044  1096  2616   142  3481  2725  1355  1055   434  \n",
      "4  3049  1763  2494   601  2351  3914  1694  2236  2733  \n",
      "5  1076  1046  3152  1863  3881  2030  1840  2063  3572  \n",
      "6  2495  1774  3150    85  3934   140  1421  2121   885  \n",
      "\n",
      "[7 rows x 1000 columns]\n",
      "   0    1    2    3    4    5    6    7    8    9    ...  990  991  992  993  \\\n",
      "0    0    1    0    0    1    0    1    1    0    0  ...    0    0    1    0   \n",
      "1    0    1    0    0    1    0    1    1    0    1  ...    0    0    1    0   \n",
      "2    0    1    0    0    1    0    1    1    0    0  ...    0    0    1    0   \n",
      "3    0    0    0    0    1    0    1    1    0    0  ...    0    0    1    0   \n",
      "4    0    0    0    1    1    0    1    1    0    0  ...    0    0    1    0   \n",
      "5    0    1    0    0    1    1    1    1    0    0  ...    0    0    1    0   \n",
      "6    1    1    0    0    1    1    1    1    0    0  ...    0    0    1    0   \n",
      "\n",
      "   994  995  996  997  998  999  \n",
      "0    0    1    0    0    0    0  \n",
      "1    0    1    1    0    0    1  \n",
      "2    0    1    1    0    0    1  \n",
      "3    0    1    1    0    0    0  \n",
      "4    0    1    0    0    0    0  \n",
      "5    0    1    1    0    0    0  \n",
      "6    0    1    0    0    0    0  \n",
      "\n",
      "[7 rows x 1000 columns]\n",
      "0      0\n",
      "1      1\n",
      "2      0\n",
      "3      0\n",
      "4      1\n",
      "      ..\n",
      "995    1\n",
      "996    1\n",
      "997    0\n",
      "998    0\n",
      "999    0\n",
      "Name: 0, Length: 1000, dtype: int64\n",
      "     the  to  ect  and  for  of    a  you  hou  in  ...  jay  valued  lay  \\\n",
      "0     17  15    9   13   21   6  144    9    5  53  ...    0       0    0   \n",
      "1      3   2    1    0    1   0   29    2    0   8  ...    0       0    0   \n",
      "2      2   3   15    1    2   0   46    1    7   1  ...    0       0    0   \n",
      "3     17  11   13    5    3   2   49    4    5  13  ...    0       0    0   \n",
      "4      0   8    1    1    0   0   49    2    0   7  ...    0       0    0   \n",
      "..   ...  ..  ...  ...  ...  ..  ...  ...  ...  ..  ...  ...     ...  ...   \n",
      "995   11  14    6   10    9   5  111    7    1  29  ...    0       0    1   \n",
      "996   38  37    9   24   16  20  313   49    1  64  ...    0       0    0   \n",
      "997    5   4    4    2    0   0   22    0    2   5  ...    0       0    0   \n",
      "998    0   0    2    0    1   0    8    0    0   0  ...    0       0    0   \n",
      "999    1   4    1    2    0   1   13    2    0   2  ...    0       0    0   \n",
      "\n",
      "     infrastructure  military  allowing  ff  dry  Prediction  pred  \n",
      "0                 0         0         0   2    0           0     0  \n",
      "1                 0         0         0   0    0           0     1  \n",
      "2                 0         0         0   0    0           0     0  \n",
      "3                 0         0         0   0    0           0     0  \n",
      "4                 0         0         0   1    0           1     1  \n",
      "..              ...       ...       ...  ..  ...         ...   ...  \n",
      "995               0         0         0   1    0           1     1  \n",
      "996               0         0         0   2    0           0     1  \n",
      "997               0         0         0   0    0           0     0  \n",
      "998               0         0         0   0    0           0     0  \n",
      "999               0         0         0   0    0           1     0  \n",
      "\n",
      "[1000 rows x 3002 columns]\n",
      "[1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013\n",
      " 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027\n",
      " 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041\n",
      " 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055\n",
      " 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069\n",
      " 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083\n",
      " 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097\n",
      " 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111\n",
      " 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125\n",
      " 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139\n",
      " 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153\n",
      " 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167\n",
      " 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181\n",
      " 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195\n",
      " 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209\n",
      " 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223\n",
      " 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237\n",
      " 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251\n",
      " 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265\n",
      " 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279\n",
      " 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293\n",
      " 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307\n",
      " 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321\n",
      " 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335\n",
      " 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349\n",
      " 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363\n",
      " 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377\n",
      " 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391\n",
      " 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405\n",
      " 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419\n",
      " 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433\n",
      " 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447\n",
      " 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461\n",
      " 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475\n",
      " 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489\n",
      " 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503\n",
      " 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517\n",
      " 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531\n",
      " 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545\n",
      " 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557 1558 1559\n",
      " 1560 1561 1562 1563 1564 1565 1566 1567 1568 1569 1570 1571 1572 1573\n",
      " 1574 1575 1576 1577 1578 1579 1580 1581 1582 1583 1584 1585 1586 1587\n",
      " 1588 1589 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 1600 1601\n",
      " 1602 1603 1604 1605 1606 1607 1608 1609 1610 1611 1612 1613 1614 1615\n",
      " 1616 1617 1618 1619 1620 1621 1622 1623 1624 1625 1626 1627 1628 1629\n",
      " 1630 1631 1632 1633 1634 1635 1636 1637 1638 1639 1640 1641 1642 1643\n",
      " 1644 1645 1646 1647 1648 1649 1650 1651 1652 1653 1654 1655 1656 1657\n",
      " 1658 1659 1660 1661 1662 1663 1664 1665 1666 1667 1668 1669 1670 1671\n",
      " 1672 1673 1674 1675 1676 1677 1678 1679 1680 1681 1682 1683 1684 1685\n",
      " 1686 1687 1688 1689 1690 1691 1692 1693 1694 1695 1696 1697 1698 1699\n",
      " 1700 1701 1702 1703 1704 1705 1706 1707 1708 1709 1710 1711 1712 1713\n",
      " 1714 1715 1716 1717 1718 1719 1720 1721 1722 1723 1724 1725 1726 1727\n",
      " 1728 1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 1739 1740 1741\n",
      " 1742 1743 1744 1745 1746 1747 1748 1749 1750 1751 1752 1753 1754 1755\n",
      " 1756 1757 1758 1759 1760 1761 1762 1763 1764 1765 1766 1767 1768 1769\n",
      " 1770 1771 1772 1773 1774 1775 1776 1777 1778 1779 1780 1781 1782 1783\n",
      " 1784 1785 1786 1787 1788 1789 1790 1791 1792 1793 1794 1795 1796 1797\n",
      " 1798 1799 1800 1801 1802 1803 1804 1805 1806 1807 1808 1809 1810 1811\n",
      " 1812 1813 1814 1815 1816 1817 1818 1819 1820 1821 1822 1823 1824 1825\n",
      " 1826 1827 1828 1829 1830 1831 1832 1833 1834 1835 1836 1837 1838 1839\n",
      " 1840 1841 1842 1843 1844 1845 1846 1847 1848 1849 1850 1851 1852 1853\n",
      " 1854 1855 1856 1857 1858 1859 1860 1861 1862 1863 1864 1865 1866 1867\n",
      " 1868 1869 1870 1871 1872 1873 1874 1875 1876 1877 1878 1879 1880 1881\n",
      " 1882 1883 1884 1885 1886 1887 1888 1889 1890 1891 1892 1893 1894 1895\n",
      " 1896 1897 1898 1899 1900 1901 1902 1903 1904 1905 1906 1907 1908 1909\n",
      " 1910 1911 1912 1913 1914 1915 1916 1917 1918 1919 1920 1921 1922 1923\n",
      " 1924 1925 1926 1927 1928 1929 1930 1931 1932 1933 1934 1935 1936 1937\n",
      " 1938 1939 1940 1941 1942 1943 1944 1945 1946 1947 1948 1949 1950 1951\n",
      " 1952 1953 1954 1955 1956 1957 1958 1959 1960 1961 1962 1963 1964 1965\n",
      " 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 1976 1977 1978 1979\n",
      " 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993\n",
      " 1994 1995 1996 1997 1998 1999]\n",
      "     the  to  ect  and  for  of    a  you  hou  in  ...  valued  lay  \\\n",
      "0     17  15    9   13   21   6  144    9    5  53  ...       0    0   \n",
      "1      3   2    1    0    1   0   29    2    0   8  ...       0    0   \n",
      "2      2   3   15    1    2   0   46    1    7   1  ...       0    0   \n",
      "3     17  11   13    5    3   2   49    4    5  13  ...       0    0   \n",
      "4      0   8    1    1    0   0   49    2    0   7  ...       0    0   \n",
      "..   ...  ..  ...  ...  ...  ..  ...  ...  ...  ..  ...     ...  ...   \n",
      "995   11  14    6   10    9   5  111    7    1  29  ...       0    1   \n",
      "996   38  37    9   24   16  20  313   49    1  64  ...       0    0   \n",
      "997    5   4    4    2    0   0   22    0    2   5  ...       0    0   \n",
      "998    0   0    2    0    1   0    8    0    0   0  ...       0    0   \n",
      "999    1   4    1    2    0   1   13    2    0   2  ...       0    0   \n",
      "\n",
      "     infrastructure  military  allowing  ff  dry  Prediction  pred  true_label  \n",
      "0                 0         0         0   2    0           0     0           0  \n",
      "1                 0         0         0   0    0           0     1           0  \n",
      "2                 0         0         0   0    0           0     0           0  \n",
      "3                 0         0         0   0    0           0     0           0  \n",
      "4                 0         0         0   1    0           1     1           1  \n",
      "..              ...       ...       ...  ..  ...         ...   ...         ...  \n",
      "995               0         0         0   1    0           1     1           1  \n",
      "996               0         0         0   2    0           0     1           0  \n",
      "997               0         0         0   0    0           0     0           0  \n",
      "998               0         0         0   0    0           0     0           0  \n",
      "999               0         0         0   0    0           1     0           1  \n",
      "\n",
      "[1000 rows x 3003 columns]\n",
      "1000    0\n",
      "1001    0\n",
      "1002    0\n",
      "1003    0\n",
      "1004    1\n",
      "       ..\n",
      "1995    1\n",
      "1996    0\n",
      "1997    0\n",
      "1998    0\n",
      "1999    1\n",
      "Name: Prediction, Length: 1000, dtype: int64\n",
      "[0.864, 0.7252396166134185, 0.8194945848375451]\n",
      "      the  to  ect  and  for  of   a  you  hou  in  ...  connevey  jay  \\\n",
      "2000    0   0    2    0    1   0   7    0    0   0  ...         0    0   \n",
      "2001    2   1    1    2    2   2  25    0    0   2  ...         0    0   \n",
      "2002    0   0    1    0    1   0   3    0    0   0  ...         0    0   \n",
      "2003    0   0    1    0    1   0   4    0    0   0  ...         0    0   \n",
      "2004    0   0    1    0    0   0   7    0    0   0  ...         0    0   \n",
      "...   ...  ..  ...  ...  ...  ..  ..  ...  ...  ..  ...       ...  ...   \n",
      "2995    0   1    2    0    0   0  14    0    1   4  ...         0    0   \n",
      "2996    5   6    9    9    3   7  85    1    4  21  ...         0    0   \n",
      "2997    5   1    1    2    2   5  30    2    0   3  ...         0    0   \n",
      "2998    9   9    4    6    3   3  78    3    1   5  ...         0    0   \n",
      "2999    0   0    1    0    1   0   5    0    0   0  ...         0    0   \n",
      "\n",
      "      valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
      "2000       0    0               0         0         0   0    0           0  \n",
      "2001       0    0               0         0         0   2    0           1  \n",
      "2002       0    0               0         0         0   0    0           0  \n",
      "2003       0    0               0         0         0   0    0           0  \n",
      "2004       0    0               0         0         0   0    0           0  \n",
      "...      ...  ...             ...       ...       ...  ..  ...         ...  \n",
      "2995       0    0               0         0         0   0    0           0  \n",
      "2996       0    0               0         0         0   1    0           0  \n",
      "2997       0    0               0         0         0   2    0           0  \n",
      "2998       0    0               0         0         0   0    0           0  \n",
      "2999       0    0               0         0         0   0    0           0  \n",
      "\n",
      "[1000 rows x 3001 columns]\n",
      "      the  to  ect  and  for  of    a  you  hou  in  ...  connevey  jay  \\\n",
      "0       0   0    1    0    0   0    2    0    0   0  ...         0    0   \n",
      "1       8  13   24    6    6   2  102    1   27  18  ...         0    0   \n",
      "2       0   0    1    0    0   0    8    0    0   4  ...         0    0   \n",
      "3       0   5   22    0    5   1   51    2   10   1  ...         0    0   \n",
      "4       7   6   17    1    5   2   57    0    9   3  ...         0    0   \n",
      "...   ...  ..  ...  ...  ...  ..  ...  ...  ...  ..  ...       ...  ...   \n",
      "4995   20   6    3    1    1   1   34    0    0  15  ...         0    0   \n",
      "4996    0   7    1    0    0   0   20    1    1   0  ...         0    0   \n",
      "4997    6   8    1    3    2   1   64    7    1  16  ...         0    0   \n",
      "4998    8   6    2    5    6   1   51    4    0   4  ...         0    0   \n",
      "4999   13  12    3    7    6   4   96    9    1  10  ...         0    0   \n",
      "\n",
      "      valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
      "0          0    0               0         0         0   0    0           0  \n",
      "1          0    0               0         0         0   1    0           0  \n",
      "2          0    0               0         0         0   0    0           0  \n",
      "3          0    0               0         0         0   0    0           0  \n",
      "4          0    0               0         0         0   1    0           0  \n",
      "...      ...  ...             ...       ...       ...  ..  ...         ...  \n",
      "4995       0    0               0         0         0   1    0           0  \n",
      "4996       0    1               0         0         0   0    0           0  \n",
      "4997       0    0               0         0         0   0    0           0  \n",
      "4998       0    0               0         0         0   0    0           0  \n",
      "4999       0    0               0         0         0   0    0           0  \n",
      "\n",
      "[4000 rows x 3001 columns]\n",
      "(4000, 3001)\n",
      "(1000, 3001)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0     1     2     3     4     5     6     7     8     9    ...   990  \\\n",
      "0  1936   666  1966  1864   946   666  3787  3698  3596  2495  ...  2138   \n",
      "1  1998  1502  1838  1960  1027  1947  3396  1565   380  1991  ...  2116   \n",
      "2  1983  1947  1897  1924  1156  1502  2846  3716     0  3359  ...  2154   \n",
      "3  1721  1959  1863  1912    90  1211  2449   971    87  2309  ...  2168   \n",
      "4  1571  1211  1926  1968  1873  1959  2906  2305  2974  3775  ...  1201   \n",
      "5  1933  1759  1868  1866  1178   970  2913  1681   307  3295  ...  1549   \n",
      "6  1879   970  1958  1946   692   949  2845  1789  2979   480  ...  1462   \n",
      "\n",
      "    991   992   993   994   995   996   997   998   999  \n",
      "0   424  3498  2155  1775  2763  2661    30  2003  1241  \n",
      "1  1181  3045   299  2035  1944  3653  1893  2072  2063  \n",
      "2  3519  3139   877  3060  1979  1415  3423   120  2121  \n",
      "3  3864  3240   354  1683  3620  1357  2525  2080  1501  \n",
      "4  2038  2279  3594  1695  2629  1021  3214  3980  1489  \n",
      "5  1621  3244   379  1433  3252  2869  3213  1353  1397  \n",
      "6  1110  3135  2539  2079  1842  3247  3645  3822  1325  \n",
      "\n",
      "[7 rows x 1000 columns]\n",
      "   0    1    2    3    4    5    6    7    8    9    ...  990  991  992  993  \\\n",
      "0    0    1    0    0    0    1    0    0    0    0  ...    0    0    0    0   \n",
      "1    0    1    0    0    0    1    0    0    1    0  ...    0    1    0    0   \n",
      "2    0    1    0    0    0    1    0    0    0    0  ...    0    1    0    0   \n",
      "3    0    1    0    0    0    1    0    0    1    0  ...    0    0    0    0   \n",
      "4    0    1    0    0    1    1    0    0    0    0  ...    0    0    0    0   \n",
      "5    0    1    0    0    0    1    0    0    1    0  ...    0    0    0    0   \n",
      "6    0    1    0    0    1    1    0    0    0    0  ...    0    0    0    1   \n",
      "\n",
      "   994  995  996  997  998  999  \n",
      "0    0    0    0    0    0    0  \n",
      "1    0    0    0    0    0    0  \n",
      "2    1    0    1    1    0    0  \n",
      "3    0    0    0    1    0    0  \n",
      "4    0    0    0    0    0    0  \n",
      "5    0    0    1    0    0    0  \n",
      "6    0    0    0    0    0    0  \n",
      "\n",
      "[7 rows x 1000 columns]\n",
      "0      0\n",
      "1      1\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "995    0\n",
      "996    0\n",
      "997    0\n",
      "998    0\n",
      "999    0\n",
      "Name: 0, Length: 1000, dtype: int64\n",
      "     the  to  ect  and  for  of   a  you  hou  in  ...  jay  valued  lay  \\\n",
      "0      0   0    2    0    1   0   7    0    0   0  ...    0       0    0   \n",
      "1      2   1    1    2    2   2  25    0    0   2  ...    0       0    0   \n",
      "2      0   0    1    0    1   0   3    0    0   0  ...    0       0    0   \n",
      "3      0   0    1    0    1   0   4    0    0   0  ...    0       0    0   \n",
      "4      0   0    1    0    0   0   7    0    0   0  ...    0       0    0   \n",
      "..   ...  ..  ...  ...  ...  ..  ..  ...  ...  ..  ...  ...     ...  ...   \n",
      "995    0   1    2    0    0   0  14    0    1   4  ...    0       0    0   \n",
      "996    5   6    9    9    3   7  85    1    4  21  ...    0       0    0   \n",
      "997    5   1    1    2    2   5  30    2    0   3  ...    0       0    0   \n",
      "998    9   9    4    6    3   3  78    3    1   5  ...    0       0    0   \n",
      "999    0   0    1    0    1   0   5    0    0   0  ...    0       0    0   \n",
      "\n",
      "     infrastructure  military  allowing  ff  dry  Prediction  pred  \n",
      "0                 0         0         0   0    0           0     0  \n",
      "1                 0         0         0   2    0           1     1  \n",
      "2                 0         0         0   0    0           0     0  \n",
      "3                 0         0         0   0    0           0     0  \n",
      "4                 0         0         0   0    0           0     0  \n",
      "..              ...       ...       ...  ..  ...         ...   ...  \n",
      "995               0         0         0   0    0           0     0  \n",
      "996               0         0         0   1    0           0     0  \n",
      "997               0         0         0   2    0           0     0  \n",
      "998               0         0         0   0    0           0     0  \n",
      "999               0         0         0   0    0           0     0  \n",
      "\n",
      "[1000 rows x 3002 columns]\n",
      "[2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013\n",
      " 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 2025 2026 2027\n",
      " 2028 2029 2030 2031 2032 2033 2034 2035 2036 2037 2038 2039 2040 2041\n",
      " 2042 2043 2044 2045 2046 2047 2048 2049 2050 2051 2052 2053 2054 2055\n",
      " 2056 2057 2058 2059 2060 2061 2062 2063 2064 2065 2066 2067 2068 2069\n",
      " 2070 2071 2072 2073 2074 2075 2076 2077 2078 2079 2080 2081 2082 2083\n",
      " 2084 2085 2086 2087 2088 2089 2090 2091 2092 2093 2094 2095 2096 2097\n",
      " 2098 2099 2100 2101 2102 2103 2104 2105 2106 2107 2108 2109 2110 2111\n",
      " 2112 2113 2114 2115 2116 2117 2118 2119 2120 2121 2122 2123 2124 2125\n",
      " 2126 2127 2128 2129 2130 2131 2132 2133 2134 2135 2136 2137 2138 2139\n",
      " 2140 2141 2142 2143 2144 2145 2146 2147 2148 2149 2150 2151 2152 2153\n",
      " 2154 2155 2156 2157 2158 2159 2160 2161 2162 2163 2164 2165 2166 2167\n",
      " 2168 2169 2170 2171 2172 2173 2174 2175 2176 2177 2178 2179 2180 2181\n",
      " 2182 2183 2184 2185 2186 2187 2188 2189 2190 2191 2192 2193 2194 2195\n",
      " 2196 2197 2198 2199 2200 2201 2202 2203 2204 2205 2206 2207 2208 2209\n",
      " 2210 2211 2212 2213 2214 2215 2216 2217 2218 2219 2220 2221 2222 2223\n",
      " 2224 2225 2226 2227 2228 2229 2230 2231 2232 2233 2234 2235 2236 2237\n",
      " 2238 2239 2240 2241 2242 2243 2244 2245 2246 2247 2248 2249 2250 2251\n",
      " 2252 2253 2254 2255 2256 2257 2258 2259 2260 2261 2262 2263 2264 2265\n",
      " 2266 2267 2268 2269 2270 2271 2272 2273 2274 2275 2276 2277 2278 2279\n",
      " 2280 2281 2282 2283 2284 2285 2286 2287 2288 2289 2290 2291 2292 2293\n",
      " 2294 2295 2296 2297 2298 2299 2300 2301 2302 2303 2304 2305 2306 2307\n",
      " 2308 2309 2310 2311 2312 2313 2314 2315 2316 2317 2318 2319 2320 2321\n",
      " 2322 2323 2324 2325 2326 2327 2328 2329 2330 2331 2332 2333 2334 2335\n",
      " 2336 2337 2338 2339 2340 2341 2342 2343 2344 2345 2346 2347 2348 2349\n",
      " 2350 2351 2352 2353 2354 2355 2356 2357 2358 2359 2360 2361 2362 2363\n",
      " 2364 2365 2366 2367 2368 2369 2370 2371 2372 2373 2374 2375 2376 2377\n",
      " 2378 2379 2380 2381 2382 2383 2384 2385 2386 2387 2388 2389 2390 2391\n",
      " 2392 2393 2394 2395 2396 2397 2398 2399 2400 2401 2402 2403 2404 2405\n",
      " 2406 2407 2408 2409 2410 2411 2412 2413 2414 2415 2416 2417 2418 2419\n",
      " 2420 2421 2422 2423 2424 2425 2426 2427 2428 2429 2430 2431 2432 2433\n",
      " 2434 2435 2436 2437 2438 2439 2440 2441 2442 2443 2444 2445 2446 2447\n",
      " 2448 2449 2450 2451 2452 2453 2454 2455 2456 2457 2458 2459 2460 2461\n",
      " 2462 2463 2464 2465 2466 2467 2468 2469 2470 2471 2472 2473 2474 2475\n",
      " 2476 2477 2478 2479 2480 2481 2482 2483 2484 2485 2486 2487 2488 2489\n",
      " 2490 2491 2492 2493 2494 2495 2496 2497 2498 2499 2500 2501 2502 2503\n",
      " 2504 2505 2506 2507 2508 2509 2510 2511 2512 2513 2514 2515 2516 2517\n",
      " 2518 2519 2520 2521 2522 2523 2524 2525 2526 2527 2528 2529 2530 2531\n",
      " 2532 2533 2534 2535 2536 2537 2538 2539 2540 2541 2542 2543 2544 2545\n",
      " 2546 2547 2548 2549 2550 2551 2552 2553 2554 2555 2556 2557 2558 2559\n",
      " 2560 2561 2562 2563 2564 2565 2566 2567 2568 2569 2570 2571 2572 2573\n",
      " 2574 2575 2576 2577 2578 2579 2580 2581 2582 2583 2584 2585 2586 2587\n",
      " 2588 2589 2590 2591 2592 2593 2594 2595 2596 2597 2598 2599 2600 2601\n",
      " 2602 2603 2604 2605 2606 2607 2608 2609 2610 2611 2612 2613 2614 2615\n",
      " 2616 2617 2618 2619 2620 2621 2622 2623 2624 2625 2626 2627 2628 2629\n",
      " 2630 2631 2632 2633 2634 2635 2636 2637 2638 2639 2640 2641 2642 2643\n",
      " 2644 2645 2646 2647 2648 2649 2650 2651 2652 2653 2654 2655 2656 2657\n",
      " 2658 2659 2660 2661 2662 2663 2664 2665 2666 2667 2668 2669 2670 2671\n",
      " 2672 2673 2674 2675 2676 2677 2678 2679 2680 2681 2682 2683 2684 2685\n",
      " 2686 2687 2688 2689 2690 2691 2692 2693 2694 2695 2696 2697 2698 2699\n",
      " 2700 2701 2702 2703 2704 2705 2706 2707 2708 2709 2710 2711 2712 2713\n",
      " 2714 2715 2716 2717 2718 2719 2720 2721 2722 2723 2724 2725 2726 2727\n",
      " 2728 2729 2730 2731 2732 2733 2734 2735 2736 2737 2738 2739 2740 2741\n",
      " 2742 2743 2744 2745 2746 2747 2748 2749 2750 2751 2752 2753 2754 2755\n",
      " 2756 2757 2758 2759 2760 2761 2762 2763 2764 2765 2766 2767 2768 2769\n",
      " 2770 2771 2772 2773 2774 2775 2776 2777 2778 2779 2780 2781 2782 2783\n",
      " 2784 2785 2786 2787 2788 2789 2790 2791 2792 2793 2794 2795 2796 2797\n",
      " 2798 2799 2800 2801 2802 2803 2804 2805 2806 2807 2808 2809 2810 2811\n",
      " 2812 2813 2814 2815 2816 2817 2818 2819 2820 2821 2822 2823 2824 2825\n",
      " 2826 2827 2828 2829 2830 2831 2832 2833 2834 2835 2836 2837 2838 2839\n",
      " 2840 2841 2842 2843 2844 2845 2846 2847 2848 2849 2850 2851 2852 2853\n",
      " 2854 2855 2856 2857 2858 2859 2860 2861 2862 2863 2864 2865 2866 2867\n",
      " 2868 2869 2870 2871 2872 2873 2874 2875 2876 2877 2878 2879 2880 2881\n",
      " 2882 2883 2884 2885 2886 2887 2888 2889 2890 2891 2892 2893 2894 2895\n",
      " 2896 2897 2898 2899 2900 2901 2902 2903 2904 2905 2906 2907 2908 2909\n",
      " 2910 2911 2912 2913 2914 2915 2916 2917 2918 2919 2920 2921 2922 2923\n",
      " 2924 2925 2926 2927 2928 2929 2930 2931 2932 2933 2934 2935 2936 2937\n",
      " 2938 2939 2940 2941 2942 2943 2944 2945 2946 2947 2948 2949 2950 2951\n",
      " 2952 2953 2954 2955 2956 2957 2958 2959 2960 2961 2962 2963 2964 2965\n",
      " 2966 2967 2968 2969 2970 2971 2972 2973 2974 2975 2976 2977 2978 2979\n",
      " 2980 2981 2982 2983 2984 2985 2986 2987 2988 2989 2990 2991 2992 2993\n",
      " 2994 2995 2996 2997 2998 2999]\n",
      "     the  to  ect  and  for  of   a  you  hou  in  ...  valued  lay  \\\n",
      "0      0   0    2    0    1   0   7    0    0   0  ...       0    0   \n",
      "1      2   1    1    2    2   2  25    0    0   2  ...       0    0   \n",
      "2      0   0    1    0    1   0   3    0    0   0  ...       0    0   \n",
      "3      0   0    1    0    1   0   4    0    0   0  ...       0    0   \n",
      "4      0   0    1    0    0   0   7    0    0   0  ...       0    0   \n",
      "..   ...  ..  ...  ...  ...  ..  ..  ...  ...  ..  ...     ...  ...   \n",
      "995    0   1    2    0    0   0  14    0    1   4  ...       0    0   \n",
      "996    5   6    9    9    3   7  85    1    4  21  ...       0    0   \n",
      "997    5   1    1    2    2   5  30    2    0   3  ...       0    0   \n",
      "998    9   9    4    6    3   3  78    3    1   5  ...       0    0   \n",
      "999    0   0    1    0    1   0   5    0    0   0  ...       0    0   \n",
      "\n",
      "     infrastructure  military  allowing  ff  dry  Prediction  pred  true_label  \n",
      "0                 0         0         0   0    0           0     0           0  \n",
      "1                 0         0         0   2    0           1     1           1  \n",
      "2                 0         0         0   0    0           0     0           0  \n",
      "3                 0         0         0   0    0           0     0           0  \n",
      "4                 0         0         0   0    0           0     0           0  \n",
      "..              ...       ...       ...  ..  ...         ...   ...         ...  \n",
      "995               0         0         0   0    0           0     0           0  \n",
      "996               0         0         0   1    0           0     0           0  \n",
      "997               0         0         0   2    0           0     0           0  \n",
      "998               0         0         0   0    0           0     0           0  \n",
      "999               0         0         0   0    0           0     0           0  \n",
      "\n",
      "[1000 rows x 3003 columns]\n",
      "2000    0\n",
      "2001    1\n",
      "2002    0\n",
      "2003    0\n",
      "2004    0\n",
      "       ..\n",
      "2995    0\n",
      "2996    0\n",
      "2997    0\n",
      "2998    0\n",
      "2999    0\n",
      "Name: Prediction, Length: 1000, dtype: int64\n",
      "[0.875, 0.7556270096463023, 0.8274647887323944]\n",
      "      the  to  ect  and  for  of   a  you  hou  in  ...  connevey  jay  \\\n",
      "3000    0   2    2    0    1   0  27    0    0   6  ...         0    0   \n",
      "3001    3   2    1    1    2   2  13    0    0   4  ...         0    0   \n",
      "3002    0   0    1    0    1   0   2    0    0   0  ...         0    0   \n",
      "3003    9   9    4    6    3   3  78    3    1   5  ...         0    0   \n",
      "3004    4   2    2    1    3   1  33    0    1  12  ...         0    0   \n",
      "...   ...  ..  ...  ...  ...  ..  ..  ...  ...  ..  ...       ...  ...   \n",
      "3995    6   3   15    2    7   1  67    4    6   7  ...         0    0   \n",
      "3996    4   1    4    4    2   0  26    2    2   5  ...         0    0   \n",
      "3997    2   1    1    1    1   0   9    0    0   2  ...         0    0   \n",
      "3998   11   4    1    6    1   3  75    3    3   9  ...         0    0   \n",
      "3999    2   1    1    1    1   0   9    0    0   2  ...         0    0   \n",
      "\n",
      "      valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
      "3000       0    0               0         0         0   0    0           1  \n",
      "3001       0    0               0         0         0   1    0           0  \n",
      "3002       0    0               0         0         0   0    0           0  \n",
      "3003       0    0               0         0         0   0    0           0  \n",
      "3004       0    0               0         0         0   0    0           1  \n",
      "...      ...  ...             ...       ...       ...  ..  ...         ...  \n",
      "3995       0    0               0         0         0   2    0           0  \n",
      "3996       0    0               0         0         0   0    0           0  \n",
      "3997       0    0               0         0         0   0    0           0  \n",
      "3998       0    0               0         0         0   1    0           0  \n",
      "3999       0    0               0         0         0   0    0           0  \n",
      "\n",
      "[1000 rows x 3001 columns]\n",
      "      the  to  ect  and  for  of    a  you  hou  in  ...  connevey  jay  \\\n",
      "0       0   0    1    0    0   0    2    0    0   0  ...         0    0   \n",
      "1       8  13   24    6    6   2  102    1   27  18  ...         0    0   \n",
      "2       0   0    1    0    0   0    8    0    0   4  ...         0    0   \n",
      "3       0   5   22    0    5   1   51    2   10   1  ...         0    0   \n",
      "4       7   6   17    1    5   2   57    0    9   3  ...         0    0   \n",
      "...   ...  ..  ...  ...  ...  ..  ...  ...  ...  ..  ...       ...  ...   \n",
      "4995   20   6    3    1    1   1   34    0    0  15  ...         0    0   \n",
      "4996    0   7    1    0    0   0   20    1    1   0  ...         0    0   \n",
      "4997    6   8    1    3    2   1   64    7    1  16  ...         0    0   \n",
      "4998    8   6    2    5    6   1   51    4    0   4  ...         0    0   \n",
      "4999   13  12    3    7    6   4   96    9    1  10  ...         0    0   \n",
      "\n",
      "      valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
      "0          0    0               0         0         0   0    0           0  \n",
      "1          0    0               0         0         0   1    0           0  \n",
      "2          0    0               0         0         0   0    0           0  \n",
      "3          0    0               0         0         0   0    0           0  \n",
      "4          0    0               0         0         0   1    0           0  \n",
      "...      ...  ...             ...       ...       ...  ..  ...         ...  \n",
      "4995       0    0               0         0         0   1    0           0  \n",
      "4996       0    1               0         0         0   0    0           0  \n",
      "4997       0    0               0         0         0   0    0           0  \n",
      "4998       0    0               0         0         0   0    0           0  \n",
      "4999       0    0               0         0         0   0    0           0  \n",
      "\n",
      "[4000 rows x 3001 columns]\n",
      "(4000, 3001)\n",
      "(1000, 3001)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0     1     2     3     4     5     6     7     8     9    ...   990  \\\n",
      "0  2674  3695  2978   120  3491  2311  2628  2684  2510  3897  ...   872   \n",
      "1  1716  1594  2989  3980  3083   126  2680  3807   415  1731  ...   891   \n",
      "2  2751  1713  2981  2998  3081   550   490  1777   456  1402  ...  1656   \n",
      "3   102   750  2944  1353  1757   321   996   153  1587   839  ...  3912   \n",
      "4  2246   262  2921  2328  3174  1637   152  2987   127  1147  ...  3688   \n",
      "5  1351  3572  2827  2333   324  1438  1201  3732    36  2928  ...  1070   \n",
      "6  2598  1562  2891  3822  3123   668  2152  3987  3186   376  ...  1621   \n",
      "\n",
      "    991   992   993   994   995   996   997   998   999  \n",
      "0  2736  3194  2659  3194  2736   872   592  3001   592  \n",
      "1   747  3186  2364  3186   747   891   425  3802   425  \n",
      "2   241  2510  3306  2510   241  1656  2864  3967  2864  \n",
      "3  3018  3698  1230  3698  3018  3912  3961  2819  3961  \n",
      "4  1993  3762  2366  3762  1993  3688  3971   733  3971  \n",
      "5  3019  1587   198  1587  3019  1070   110  1777   110  \n",
      "6   590  3716  1449  3716   590  1621  3797  3940  3797  \n",
      "\n",
      "[7 rows x 1000 columns]\n",
      "   0    1    2    3    4    5    6    7    8    9    ...  990  991  992  993  \\\n",
      "0    0    0    0    0    0    0    1    0    1    1  ...    0    0    0    1   \n",
      "1    1    0    0    0    0    0    1    1    0    1  ...    0    0    0    1   \n",
      "2    1    0    0    0    0    0    0    1    0    0  ...    0    0    1    0   \n",
      "3    1    1    0    0    1    0    1    0    1    1  ...    1    0    0    1   \n",
      "4    1    0    0    0    1    0    1    1    0    1  ...    1    0    0    1   \n",
      "5    1    0    0    0    1    0    0    1    0    1  ...    0    0    1    1   \n",
      "6    0    0    0    0    1    0    1    1    0    1  ...    0    0    0    1   \n",
      "\n",
      "   994  995  996  997  998  999  \n",
      "0    0    0    0    0    0    0  \n",
      "1    0    0    0    0    1    0  \n",
      "2    1    0    0    0    0    0  \n",
      "3    0    0    1    0    0    0  \n",
      "4    0    0    1    0    1    0  \n",
      "5    1    0    0    0    1    0  \n",
      "6    0    0    0    0    0    0  \n",
      "\n",
      "[7 rows x 1000 columns]\n",
      "0      1\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      1\n",
      "      ..\n",
      "995    0\n",
      "996    0\n",
      "997    0\n",
      "998    0\n",
      "999    0\n",
      "Name: 0, Length: 1000, dtype: int64\n",
      "     the  to  ect  and  for  of   a  you  hou  in  ...  jay  valued  lay  \\\n",
      "0      0   2    2    0    1   0  27    0    0   6  ...    0       0    0   \n",
      "1      3   2    1    1    2   2  13    0    0   4  ...    0       0    0   \n",
      "2      0   0    1    0    1   0   2    0    0   0  ...    0       0    0   \n",
      "3      9   9    4    6    3   3  78    3    1   5  ...    0       0    0   \n",
      "4      4   2    2    1    3   1  33    0    1  12  ...    0       0    0   \n",
      "..   ...  ..  ...  ...  ...  ..  ..  ...  ...  ..  ...  ...     ...  ...   \n",
      "995    6   3   15    2    7   1  67    4    6   7  ...    0       0    0   \n",
      "996    4   1    4    4    2   0  26    2    2   5  ...    0       0    0   \n",
      "997    2   1    1    1    1   0   9    0    0   2  ...    0       0    0   \n",
      "998   11   4    1    6    1   3  75    3    3   9  ...    0       0    0   \n",
      "999    2   1    1    1    1   0   9    0    0   2  ...    0       0    0   \n",
      "\n",
      "     infrastructure  military  allowing  ff  dry  Prediction  pred  \n",
      "0                 0         0         0   0    0           1     1  \n",
      "1                 0         0         0   1    0           0     0  \n",
      "2                 0         0         0   0    0           0     0  \n",
      "3                 0         0         0   0    0           0     0  \n",
      "4                 0         0         0   0    0           1     1  \n",
      "..              ...       ...       ...  ..  ...         ...   ...  \n",
      "995               0         0         0   2    0           0     0  \n",
      "996               0         0         0   0    0           0     0  \n",
      "997               0         0         0   0    0           0     0  \n",
      "998               0         0         0   1    0           0     0  \n",
      "999               0         0         0   0    0           0     0  \n",
      "\n",
      "[1000 rows x 3002 columns]\n",
      "[3000 3001 3002 3003 3004 3005 3006 3007 3008 3009 3010 3011 3012 3013\n",
      " 3014 3015 3016 3017 3018 3019 3020 3021 3022 3023 3024 3025 3026 3027\n",
      " 3028 3029 3030 3031 3032 3033 3034 3035 3036 3037 3038 3039 3040 3041\n",
      " 3042 3043 3044 3045 3046 3047 3048 3049 3050 3051 3052 3053 3054 3055\n",
      " 3056 3057 3058 3059 3060 3061 3062 3063 3064 3065 3066 3067 3068 3069\n",
      " 3070 3071 3072 3073 3074 3075 3076 3077 3078 3079 3080 3081 3082 3083\n",
      " 3084 3085 3086 3087 3088 3089 3090 3091 3092 3093 3094 3095 3096 3097\n",
      " 3098 3099 3100 3101 3102 3103 3104 3105 3106 3107 3108 3109 3110 3111\n",
      " 3112 3113 3114 3115 3116 3117 3118 3119 3120 3121 3122 3123 3124 3125\n",
      " 3126 3127 3128 3129 3130 3131 3132 3133 3134 3135 3136 3137 3138 3139\n",
      " 3140 3141 3142 3143 3144 3145 3146 3147 3148 3149 3150 3151 3152 3153\n",
      " 3154 3155 3156 3157 3158 3159 3160 3161 3162 3163 3164 3165 3166 3167\n",
      " 3168 3169 3170 3171 3172 3173 3174 3175 3176 3177 3178 3179 3180 3181\n",
      " 3182 3183 3184 3185 3186 3187 3188 3189 3190 3191 3192 3193 3194 3195\n",
      " 3196 3197 3198 3199 3200 3201 3202 3203 3204 3205 3206 3207 3208 3209\n",
      " 3210 3211 3212 3213 3214 3215 3216 3217 3218 3219 3220 3221 3222 3223\n",
      " 3224 3225 3226 3227 3228 3229 3230 3231 3232 3233 3234 3235 3236 3237\n",
      " 3238 3239 3240 3241 3242 3243 3244 3245 3246 3247 3248 3249 3250 3251\n",
      " 3252 3253 3254 3255 3256 3257 3258 3259 3260 3261 3262 3263 3264 3265\n",
      " 3266 3267 3268 3269 3270 3271 3272 3273 3274 3275 3276 3277 3278 3279\n",
      " 3280 3281 3282 3283 3284 3285 3286 3287 3288 3289 3290 3291 3292 3293\n",
      " 3294 3295 3296 3297 3298 3299 3300 3301 3302 3303 3304 3305 3306 3307\n",
      " 3308 3309 3310 3311 3312 3313 3314 3315 3316 3317 3318 3319 3320 3321\n",
      " 3322 3323 3324 3325 3326 3327 3328 3329 3330 3331 3332 3333 3334 3335\n",
      " 3336 3337 3338 3339 3340 3341 3342 3343 3344 3345 3346 3347 3348 3349\n",
      " 3350 3351 3352 3353 3354 3355 3356 3357 3358 3359 3360 3361 3362 3363\n",
      " 3364 3365 3366 3367 3368 3369 3370 3371 3372 3373 3374 3375 3376 3377\n",
      " 3378 3379 3380 3381 3382 3383 3384 3385 3386 3387 3388 3389 3390 3391\n",
      " 3392 3393 3394 3395 3396 3397 3398 3399 3400 3401 3402 3403 3404 3405\n",
      " 3406 3407 3408 3409 3410 3411 3412 3413 3414 3415 3416 3417 3418 3419\n",
      " 3420 3421 3422 3423 3424 3425 3426 3427 3428 3429 3430 3431 3432 3433\n",
      " 3434 3435 3436 3437 3438 3439 3440 3441 3442 3443 3444 3445 3446 3447\n",
      " 3448 3449 3450 3451 3452 3453 3454 3455 3456 3457 3458 3459 3460 3461\n",
      " 3462 3463 3464 3465 3466 3467 3468 3469 3470 3471 3472 3473 3474 3475\n",
      " 3476 3477 3478 3479 3480 3481 3482 3483 3484 3485 3486 3487 3488 3489\n",
      " 3490 3491 3492 3493 3494 3495 3496 3497 3498 3499 3500 3501 3502 3503\n",
      " 3504 3505 3506 3507 3508 3509 3510 3511 3512 3513 3514 3515 3516 3517\n",
      " 3518 3519 3520 3521 3522 3523 3524 3525 3526 3527 3528 3529 3530 3531\n",
      " 3532 3533 3534 3535 3536 3537 3538 3539 3540 3541 3542 3543 3544 3545\n",
      " 3546 3547 3548 3549 3550 3551 3552 3553 3554 3555 3556 3557 3558 3559\n",
      " 3560 3561 3562 3563 3564 3565 3566 3567 3568 3569 3570 3571 3572 3573\n",
      " 3574 3575 3576 3577 3578 3579 3580 3581 3582 3583 3584 3585 3586 3587\n",
      " 3588 3589 3590 3591 3592 3593 3594 3595 3596 3597 3598 3599 3600 3601\n",
      " 3602 3603 3604 3605 3606 3607 3608 3609 3610 3611 3612 3613 3614 3615\n",
      " 3616 3617 3618 3619 3620 3621 3622 3623 3624 3625 3626 3627 3628 3629\n",
      " 3630 3631 3632 3633 3634 3635 3636 3637 3638 3639 3640 3641 3642 3643\n",
      " 3644 3645 3646 3647 3648 3649 3650 3651 3652 3653 3654 3655 3656 3657\n",
      " 3658 3659 3660 3661 3662 3663 3664 3665 3666 3667 3668 3669 3670 3671\n",
      " 3672 3673 3674 3675 3676 3677 3678 3679 3680 3681 3682 3683 3684 3685\n",
      " 3686 3687 3688 3689 3690 3691 3692 3693 3694 3695 3696 3697 3698 3699\n",
      " 3700 3701 3702 3703 3704 3705 3706 3707 3708 3709 3710 3711 3712 3713\n",
      " 3714 3715 3716 3717 3718 3719 3720 3721 3722 3723 3724 3725 3726 3727\n",
      " 3728 3729 3730 3731 3732 3733 3734 3735 3736 3737 3738 3739 3740 3741\n",
      " 3742 3743 3744 3745 3746 3747 3748 3749 3750 3751 3752 3753 3754 3755\n",
      " 3756 3757 3758 3759 3760 3761 3762 3763 3764 3765 3766 3767 3768 3769\n",
      " 3770 3771 3772 3773 3774 3775 3776 3777 3778 3779 3780 3781 3782 3783\n",
      " 3784 3785 3786 3787 3788 3789 3790 3791 3792 3793 3794 3795 3796 3797\n",
      " 3798 3799 3800 3801 3802 3803 3804 3805 3806 3807 3808 3809 3810 3811\n",
      " 3812 3813 3814 3815 3816 3817 3818 3819 3820 3821 3822 3823 3824 3825\n",
      " 3826 3827 3828 3829 3830 3831 3832 3833 3834 3835 3836 3837 3838 3839\n",
      " 3840 3841 3842 3843 3844 3845 3846 3847 3848 3849 3850 3851 3852 3853\n",
      " 3854 3855 3856 3857 3858 3859 3860 3861 3862 3863 3864 3865 3866 3867\n",
      " 3868 3869 3870 3871 3872 3873 3874 3875 3876 3877 3878 3879 3880 3881\n",
      " 3882 3883 3884 3885 3886 3887 3888 3889 3890 3891 3892 3893 3894 3895\n",
      " 3896 3897 3898 3899 3900 3901 3902 3903 3904 3905 3906 3907 3908 3909\n",
      " 3910 3911 3912 3913 3914 3915 3916 3917 3918 3919 3920 3921 3922 3923\n",
      " 3924 3925 3926 3927 3928 3929 3930 3931 3932 3933 3934 3935 3936 3937\n",
      " 3938 3939 3940 3941 3942 3943 3944 3945 3946 3947 3948 3949 3950 3951\n",
      " 3952 3953 3954 3955 3956 3957 3958 3959 3960 3961 3962 3963 3964 3965\n",
      " 3966 3967 3968 3969 3970 3971 3972 3973 3974 3975 3976 3977 3978 3979\n",
      " 3980 3981 3982 3983 3984 3985 3986 3987 3988 3989 3990 3991 3992 3993\n",
      " 3994 3995 3996 3997 3998 3999]\n",
      "     the  to  ect  and  for  of   a  you  hou  in  ...  valued  lay  \\\n",
      "0      0   2    2    0    1   0  27    0    0   6  ...       0    0   \n",
      "1      3   2    1    1    2   2  13    0    0   4  ...       0    0   \n",
      "2      0   0    1    0    1   0   2    0    0   0  ...       0    0   \n",
      "3      9   9    4    6    3   3  78    3    1   5  ...       0    0   \n",
      "4      4   2    2    1    3   1  33    0    1  12  ...       0    0   \n",
      "..   ...  ..  ...  ...  ...  ..  ..  ...  ...  ..  ...     ...  ...   \n",
      "995    6   3   15    2    7   1  67    4    6   7  ...       0    0   \n",
      "996    4   1    4    4    2   0  26    2    2   5  ...       0    0   \n",
      "997    2   1    1    1    1   0   9    0    0   2  ...       0    0   \n",
      "998   11   4    1    6    1   3  75    3    3   9  ...       0    0   \n",
      "999    2   1    1    1    1   0   9    0    0   2  ...       0    0   \n",
      "\n",
      "     infrastructure  military  allowing  ff  dry  Prediction  pred  true_label  \n",
      "0                 0         0         0   0    0           1     1           1  \n",
      "1                 0         0         0   1    0           0     0           0  \n",
      "2                 0         0         0   0    0           0     0           0  \n",
      "3                 0         0         0   0    0           0     0           0  \n",
      "4                 0         0         0   0    0           1     1           1  \n",
      "..              ...       ...       ...  ..  ...         ...   ...         ...  \n",
      "995               0         0         0   2    0           0     0           0  \n",
      "996               0         0         0   0    0           0     0           0  \n",
      "997               0         0         0   0    0           0     0           0  \n",
      "998               0         0         0   1    0           0     0           0  \n",
      "999               0         0         0   0    0           0     0           0  \n",
      "\n",
      "[1000 rows x 3003 columns]\n",
      "3000    1\n",
      "3001    0\n",
      "3002    0\n",
      "3003    0\n",
      "3004    1\n",
      "       ..\n",
      "3995    0\n",
      "3996    0\n",
      "3997    0\n",
      "3998    0\n",
      "3999    0\n",
      "Name: Prediction, Length: 1000, dtype: int64\n",
      "[0.874, 0.7781456953642384, 0.7993197278911565]\n",
      "      the  to  ect  and  for  of   a  you  hou  in  ...  connevey  jay  \\\n",
      "4000    0   2    2    0    0   1  40    1    0   4  ...         0    0   \n",
      "4001   11   4    1    6    1   3  75    3    3   9  ...         0    0   \n",
      "4002    0   5    2    0    2   0  18    0    0   4  ...         0    0   \n",
      "4003    0   0    1    0    0   0  22    0    0   9  ...         0    0   \n",
      "4004    0   0    1    0    1   0   3    0    0   0  ...         0    0   \n",
      "...   ...  ..  ...  ...  ...  ..  ..  ...  ...  ..  ...       ...  ...   \n",
      "4995   20   6    3    1    1   1  34    0    0  15  ...         0    0   \n",
      "4996    0   7    1    0    0   0  20    1    1   0  ...         0    0   \n",
      "4997    6   8    1    3    2   1  64    7    1  16  ...         0    0   \n",
      "4998    8   6    2    5    6   1  51    4    0   4  ...         0    0   \n",
      "4999   13  12    3    7    6   4  96    9    1  10  ...         0    0   \n",
      "\n",
      "      valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
      "4000       0    0               0         0         0   1    0           1  \n",
      "4001       0    0               0         0         0   1    0           0  \n",
      "4002       0    0               0         0         0   0    0           0  \n",
      "4003       0    0               0         0         0   0    0           1  \n",
      "4004       0    0               0         0         0   0    0           0  \n",
      "...      ...  ...             ...       ...       ...  ..  ...         ...  \n",
      "4995       0    0               0         0         0   1    0           0  \n",
      "4996       0    1               0         0         0   0    0           0  \n",
      "4997       0    0               0         0         0   0    0           0  \n",
      "4998       0    0               0         0         0   0    0           0  \n",
      "4999       0    0               0         0         0   0    0           0  \n",
      "\n",
      "[1000 rows x 3001 columns]\n",
      "      the  to  ect  and  for  of    a  you  hou  in  ...  connevey  jay  \\\n",
      "0       0   0    1    0    0   0    2    0    0   0  ...         0    0   \n",
      "1       8  13   24    6    6   2  102    1   27  18  ...         0    0   \n",
      "2       0   0    1    0    0   0    8    0    0   4  ...         0    0   \n",
      "3       0   5   22    0    5   1   51    2   10   1  ...         0    0   \n",
      "4       7   6   17    1    5   2   57    0    9   3  ...         0    0   \n",
      "...   ...  ..  ...  ...  ...  ..  ...  ...  ...  ..  ...       ...  ...   \n",
      "3995    6   3   15    2    7   1   67    4    6   7  ...         0    0   \n",
      "3996    4   1    4    4    2   0   26    2    2   5  ...         0    0   \n",
      "3997    2   1    1    1    1   0    9    0    0   2  ...         0    0   \n",
      "3998   11   4    1    6    1   3   75    3    3   9  ...         0    0   \n",
      "3999    2   1    1    1    1   0    9    0    0   2  ...         0    0   \n",
      "\n",
      "      valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
      "0          0    0               0         0         0   0    0           0  \n",
      "1          0    0               0         0         0   1    0           0  \n",
      "2          0    0               0         0         0   0    0           0  \n",
      "3          0    0               0         0         0   0    0           0  \n",
      "4          0    0               0         0         0   1    0           0  \n",
      "...      ...  ...             ...       ...       ...  ..  ...         ...  \n",
      "3995       0    0               0         0         0   2    0           0  \n",
      "3996       0    0               0         0         0   0    0           0  \n",
      "3997       0    0               0         0         0   0    0           0  \n",
      "3998       0    0               0         0         0   1    0           0  \n",
      "3999       0    0               0         0         0   0    0           0  \n",
      "\n",
      "[4000 rows x 3001 columns]\n",
      "(4000, 3001)\n",
      "(1000, 3001)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0     1     2     3     4     5     6     7     8     9    ...   990  \\\n",
      "0    68  3237  3682  3034  3809  3682  3809  3662  2523  3662  ...   789   \n",
      "1  3620  1777  3695  1722  3832  3695  3832   536  3145   536  ...  2586   \n",
      "2  2651  3998  3863  3320  3807  3863  3807  2674  1700  2674  ...    57   \n",
      "3  2563   733  3868  3123  3941  3868  3941  2760  2402  2760  ...  3892   \n",
      "4  3501  2819  3690  2513  3938  3690  3938  3303  2538  3303  ...   979   \n",
      "5   559  3396  3760  2941  3966  3760  3966   102  1449   102  ...  3228   \n",
      "6  2558  2342  3762  3109  3904  3762  3904  3098  2482  3098  ...  2932   \n",
      "\n",
      "    991   992   993   994   995   996   997   998   999  \n",
      "0   366  3381   767  3048  2138   450  2732  3766   405  \n",
      "1  1242  3772  1545   431   337  2415  1278  1104   654  \n",
      "2   657   323   822   289  3406  2637   952   928  3106  \n",
      "3  2839   289   221  3381  1831   681   323  1080  2121  \n",
      "4  1765  2518  3217  1278  3107  3387  2836  3304   389  \n",
      "5  1611   191  2708   568  2377  3277   191  3770   335  \n",
      "6  1817   461  3246  1366  2872  2361  3720   367   480  \n",
      "\n",
      "[7 rows x 1000 columns]\n",
      "   0    1    2    3    4    5    6    7    8    9    ...  990  991  992  993  \\\n",
      "0    1    1    0    1    0    0    0    0    0    0  ...    0    1    0    0   \n",
      "1    1    1    0    1    0    0    0    0    0    0  ...    0    1    1    0   \n",
      "2    1    0    0    1    0    0    0    0    1    0  ...    1    1    1    0   \n",
      "3    0    1    0    1    0    0    0    0    1    0  ...    1    1    1    0   \n",
      "4    1    0    0    1    0    0    0    1    1    1  ...    0    1    0    1   \n",
      "5    0    1    0    1    0    0    0    1    1    1  ...    0    1    1    1   \n",
      "6    0    0    0    1    0    0    0    0    1    0  ...    1    0    1    1   \n",
      "\n",
      "   994  995  996  997  998  999  \n",
      "0    1    0    1    1    0    0  \n",
      "1    1    0    1    0    0    0  \n",
      "2    1    0    1    1    0    1  \n",
      "3    0    0    1    1    0    1  \n",
      "4    0    0    1    1    0    0  \n",
      "5    1    0    1    1    0    0  \n",
      "6    1    0    1    0    0    0  \n",
      "\n",
      "[7 rows x 1000 columns]\n",
      "0      1\n",
      "1      1\n",
      "2      0\n",
      "3      1\n",
      "4      0\n",
      "      ..\n",
      "995    0\n",
      "996    1\n",
      "997    1\n",
      "998    0\n",
      "999    0\n",
      "Name: 0, Length: 1000, dtype: int64\n",
      "     the  to  ect  and  for  of   a  you  hou  in  ...  jay  valued  lay  \\\n",
      "0      0   2    2    0    0   1  40    1    0   4  ...    0       0    0   \n",
      "1     11   4    1    6    1   3  75    3    3   9  ...    0       0    0   \n",
      "2      0   5    2    0    2   0  18    0    0   4  ...    0       0    0   \n",
      "3      0   0    1    0    0   0  22    0    0   9  ...    0       0    0   \n",
      "4      0   0    1    0    1   0   3    0    0   0  ...    0       0    0   \n",
      "..   ...  ..  ...  ...  ...  ..  ..  ...  ...  ..  ...  ...     ...  ...   \n",
      "995   20   6    3    1    1   1  34    0    0  15  ...    0       0    0   \n",
      "996    0   7    1    0    0   0  20    1    1   0  ...    0       0    1   \n",
      "997    6   8    1    3    2   1  64    7    1  16  ...    0       0    0   \n",
      "998    8   6    2    5    6   1  51    4    0   4  ...    0       0    0   \n",
      "999   13  12    3    7    6   4  96    9    1  10  ...    0       0    0   \n",
      "\n",
      "     infrastructure  military  allowing  ff  dry  Prediction  pred  \n",
      "0                 0         0         0   1    0           1     1  \n",
      "1                 0         0         0   1    0           0     1  \n",
      "2                 0         0         0   0    0           0     0  \n",
      "3                 0         0         0   0    0           1     1  \n",
      "4                 0         0         0   0    0           0     0  \n",
      "..              ...       ...       ...  ..  ...         ...   ...  \n",
      "995               0         0         0   1    0           0     0  \n",
      "996               0         0         0   0    0           0     1  \n",
      "997               0         0         0   0    0           0     1  \n",
      "998               0         0         0   0    0           0     0  \n",
      "999               0         0         0   0    0           0     0  \n",
      "\n",
      "[1000 rows x 3002 columns]\n",
      "[4000 4001 4002 4003 4004 4005 4006 4007 4008 4009 4010 4011 4012 4013\n",
      " 4014 4015 4016 4017 4018 4019 4020 4021 4022 4023 4024 4025 4026 4027\n",
      " 4028 4029 4030 4031 4032 4033 4034 4035 4036 4037 4038 4039 4040 4041\n",
      " 4042 4043 4044 4045 4046 4047 4048 4049 4050 4051 4052 4053 4054 4055\n",
      " 4056 4057 4058 4059 4060 4061 4062 4063 4064 4065 4066 4067 4068 4069\n",
      " 4070 4071 4072 4073 4074 4075 4076 4077 4078 4079 4080 4081 4082 4083\n",
      " 4084 4085 4086 4087 4088 4089 4090 4091 4092 4093 4094 4095 4096 4097\n",
      " 4098 4099 4100 4101 4102 4103 4104 4105 4106 4107 4108 4109 4110 4111\n",
      " 4112 4113 4114 4115 4116 4117 4118 4119 4120 4121 4122 4123 4124 4125\n",
      " 4126 4127 4128 4129 4130 4131 4132 4133 4134 4135 4136 4137 4138 4139\n",
      " 4140 4141 4142 4143 4144 4145 4146 4147 4148 4149 4150 4151 4152 4153\n",
      " 4154 4155 4156 4157 4158 4159 4160 4161 4162 4163 4164 4165 4166 4167\n",
      " 4168 4169 4170 4171 4172 4173 4174 4175 4176 4177 4178 4179 4180 4181\n",
      " 4182 4183 4184 4185 4186 4187 4188 4189 4190 4191 4192 4193 4194 4195\n",
      " 4196 4197 4198 4199 4200 4201 4202 4203 4204 4205 4206 4207 4208 4209\n",
      " 4210 4211 4212 4213 4214 4215 4216 4217 4218 4219 4220 4221 4222 4223\n",
      " 4224 4225 4226 4227 4228 4229 4230 4231 4232 4233 4234 4235 4236 4237\n",
      " 4238 4239 4240 4241 4242 4243 4244 4245 4246 4247 4248 4249 4250 4251\n",
      " 4252 4253 4254 4255 4256 4257 4258 4259 4260 4261 4262 4263 4264 4265\n",
      " 4266 4267 4268 4269 4270 4271 4272 4273 4274 4275 4276 4277 4278 4279\n",
      " 4280 4281 4282 4283 4284 4285 4286 4287 4288 4289 4290 4291 4292 4293\n",
      " 4294 4295 4296 4297 4298 4299 4300 4301 4302 4303 4304 4305 4306 4307\n",
      " 4308 4309 4310 4311 4312 4313 4314 4315 4316 4317 4318 4319 4320 4321\n",
      " 4322 4323 4324 4325 4326 4327 4328 4329 4330 4331 4332 4333 4334 4335\n",
      " 4336 4337 4338 4339 4340 4341 4342 4343 4344 4345 4346 4347 4348 4349\n",
      " 4350 4351 4352 4353 4354 4355 4356 4357 4358 4359 4360 4361 4362 4363\n",
      " 4364 4365 4366 4367 4368 4369 4370 4371 4372 4373 4374 4375 4376 4377\n",
      " 4378 4379 4380 4381 4382 4383 4384 4385 4386 4387 4388 4389 4390 4391\n",
      " 4392 4393 4394 4395 4396 4397 4398 4399 4400 4401 4402 4403 4404 4405\n",
      " 4406 4407 4408 4409 4410 4411 4412 4413 4414 4415 4416 4417 4418 4419\n",
      " 4420 4421 4422 4423 4424 4425 4426 4427 4428 4429 4430 4431 4432 4433\n",
      " 4434 4435 4436 4437 4438 4439 4440 4441 4442 4443 4444 4445 4446 4447\n",
      " 4448 4449 4450 4451 4452 4453 4454 4455 4456 4457 4458 4459 4460 4461\n",
      " 4462 4463 4464 4465 4466 4467 4468 4469 4470 4471 4472 4473 4474 4475\n",
      " 4476 4477 4478 4479 4480 4481 4482 4483 4484 4485 4486 4487 4488 4489\n",
      " 4490 4491 4492 4493 4494 4495 4496 4497 4498 4499 4500 4501 4502 4503\n",
      " 4504 4505 4506 4507 4508 4509 4510 4511 4512 4513 4514 4515 4516 4517\n",
      " 4518 4519 4520 4521 4522 4523 4524 4525 4526 4527 4528 4529 4530 4531\n",
      " 4532 4533 4534 4535 4536 4537 4538 4539 4540 4541 4542 4543 4544 4545\n",
      " 4546 4547 4548 4549 4550 4551 4552 4553 4554 4555 4556 4557 4558 4559\n",
      " 4560 4561 4562 4563 4564 4565 4566 4567 4568 4569 4570 4571 4572 4573\n",
      " 4574 4575 4576 4577 4578 4579 4580 4581 4582 4583 4584 4585 4586 4587\n",
      " 4588 4589 4590 4591 4592 4593 4594 4595 4596 4597 4598 4599 4600 4601\n",
      " 4602 4603 4604 4605 4606 4607 4608 4609 4610 4611 4612 4613 4614 4615\n",
      " 4616 4617 4618 4619 4620 4621 4622 4623 4624 4625 4626 4627 4628 4629\n",
      " 4630 4631 4632 4633 4634 4635 4636 4637 4638 4639 4640 4641 4642 4643\n",
      " 4644 4645 4646 4647 4648 4649 4650 4651 4652 4653 4654 4655 4656 4657\n",
      " 4658 4659 4660 4661 4662 4663 4664 4665 4666 4667 4668 4669 4670 4671\n",
      " 4672 4673 4674 4675 4676 4677 4678 4679 4680 4681 4682 4683 4684 4685\n",
      " 4686 4687 4688 4689 4690 4691 4692 4693 4694 4695 4696 4697 4698 4699\n",
      " 4700 4701 4702 4703 4704 4705 4706 4707 4708 4709 4710 4711 4712 4713\n",
      " 4714 4715 4716 4717 4718 4719 4720 4721 4722 4723 4724 4725 4726 4727\n",
      " 4728 4729 4730 4731 4732 4733 4734 4735 4736 4737 4738 4739 4740 4741\n",
      " 4742 4743 4744 4745 4746 4747 4748 4749 4750 4751 4752 4753 4754 4755\n",
      " 4756 4757 4758 4759 4760 4761 4762 4763 4764 4765 4766 4767 4768 4769\n",
      " 4770 4771 4772 4773 4774 4775 4776 4777 4778 4779 4780 4781 4782 4783\n",
      " 4784 4785 4786 4787 4788 4789 4790 4791 4792 4793 4794 4795 4796 4797\n",
      " 4798 4799 4800 4801 4802 4803 4804 4805 4806 4807 4808 4809 4810 4811\n",
      " 4812 4813 4814 4815 4816 4817 4818 4819 4820 4821 4822 4823 4824 4825\n",
      " 4826 4827 4828 4829 4830 4831 4832 4833 4834 4835 4836 4837 4838 4839\n",
      " 4840 4841 4842 4843 4844 4845 4846 4847 4848 4849 4850 4851 4852 4853\n",
      " 4854 4855 4856 4857 4858 4859 4860 4861 4862 4863 4864 4865 4866 4867\n",
      " 4868 4869 4870 4871 4872 4873 4874 4875 4876 4877 4878 4879 4880 4881\n",
      " 4882 4883 4884 4885 4886 4887 4888 4889 4890 4891 4892 4893 4894 4895\n",
      " 4896 4897 4898 4899 4900 4901 4902 4903 4904 4905 4906 4907 4908 4909\n",
      " 4910 4911 4912 4913 4914 4915 4916 4917 4918 4919 4920 4921 4922 4923\n",
      " 4924 4925 4926 4927 4928 4929 4930 4931 4932 4933 4934 4935 4936 4937\n",
      " 4938 4939 4940 4941 4942 4943 4944 4945 4946 4947 4948 4949 4950 4951\n",
      " 4952 4953 4954 4955 4956 4957 4958 4959 4960 4961 4962 4963 4964 4965\n",
      " 4966 4967 4968 4969 4970 4971 4972 4973 4974 4975 4976 4977 4978 4979\n",
      " 4980 4981 4982 4983 4984 4985 4986 4987 4988 4989 4990 4991 4992 4993\n",
      " 4994 4995 4996 4997 4998 4999]\n",
      "     the  to  ect  and  for  of   a  you  hou  in  ...  valued  lay  \\\n",
      "0      0   2    2    0    0   1  40    1    0   4  ...       0    0   \n",
      "1     11   4    1    6    1   3  75    3    3   9  ...       0    0   \n",
      "2      0   5    2    0    2   0  18    0    0   4  ...       0    0   \n",
      "3      0   0    1    0    0   0  22    0    0   9  ...       0    0   \n",
      "4      0   0    1    0    1   0   3    0    0   0  ...       0    0   \n",
      "..   ...  ..  ...  ...  ...  ..  ..  ...  ...  ..  ...     ...  ...   \n",
      "995   20   6    3    1    1   1  34    0    0  15  ...       0    0   \n",
      "996    0   7    1    0    0   0  20    1    1   0  ...       0    1   \n",
      "997    6   8    1    3    2   1  64    7    1  16  ...       0    0   \n",
      "998    8   6    2    5    6   1  51    4    0   4  ...       0    0   \n",
      "999   13  12    3    7    6   4  96    9    1  10  ...       0    0   \n",
      "\n",
      "     infrastructure  military  allowing  ff  dry  Prediction  pred  true_label  \n",
      "0                 0         0         0   1    0           1     1           1  \n",
      "1                 0         0         0   1    0           0     1           0  \n",
      "2                 0         0         0   0    0           0     0           0  \n",
      "3                 0         0         0   0    0           1     1           1  \n",
      "4                 0         0         0   0    0           0     0           0  \n",
      "..              ...       ...       ...  ..  ...         ...   ...         ...  \n",
      "995               0         0         0   1    0           0     0           0  \n",
      "996               0         0         0   0    0           0     1           0  \n",
      "997               0         0         0   0    0           0     1           0  \n",
      "998               0         0         0   0    0           0     0           0  \n",
      "999               0         0         0   0    0           0     0           0  \n",
      "\n",
      "[1000 rows x 3003 columns]\n",
      "4000    1\n",
      "4001    0\n",
      "4002    0\n",
      "4003    1\n",
      "4004    0\n",
      "       ..\n",
      "4995    0\n",
      "4996    0\n",
      "4997    0\n",
      "4998    0\n",
      "4999    0\n",
      "Name: Prediction, Length: 1000, dtype: int64\n",
      "[0.779, 0.6145552560646901, 0.7450980392156863]\n"
     ]
    }
   ],
   "source": [
    "#q5 KNN with 1, 3, 5, 7 \n",
    "\n",
    "three_nn = run_five_fold(3)\n",
    "five_nn = run_five_fold(5)\n",
    "seven_nn = run_five_fold(7)\n",
    "ten_nn = run_five_fold(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "3f04fcef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    k  accuracy\n",
      "0   1    0.8332\n",
      "1   3    0.8416\n",
      "2   5    0.8408\n",
      "3   7    0.8462\n",
      "4  10    0.8556\n",
      "\\begin{tabular}{lrr}\n",
      "\\toprule\n",
      "{} &   k &  accuracy \\\\\n",
      "\\midrule\n",
      "0 &   1 &    0.8332 \\\\\n",
      "1 &   3 &    0.8416 \\\\\n",
      "2 &   5 &    0.8408 \\\\\n",
      "3 &   7 &    0.8462 \\\\\n",
      "4 &  10 &    0.8556 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b2/8cn96b9x6qz0b7b79dn_n_1h0000gn/T/ipykernel_13453/3857412837.py:7: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(agg_results.to_latex())\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agg_results = pd.DataFrame({'k': [1, 3, 5, 7, 10], 'accuracy': [np.mean(one_nn['accuracy']), np.mean(three_nn['accuracy']), np.mean(five_nn['accuracy']), np.mean(seven_nn['accuracy']), np.mean(ten_nn['accuracy'])]})\n",
    "print(agg_results)\n",
    "ax=agg_results.plot('k', 'accuracy', marker = 'o')\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_xlabel(\"k\")\n",
    "plt.savefig(\"./HW/HW3_KNN_results_plot.png\")\n",
    "print(agg_results.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "819ff192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 3001)\n",
      "(4000, 3001)\n",
      "(1000, 3001)\n"
     ]
    }
   ],
   "source": [
    "#q5 - logistic regression 5-NN on single split of training/testing \n",
    "spam = pd.read_csv(\"./HW/hw3Data/emails.csv\")\n",
    "spam = spam.drop(['Email No.'], axis = 1)\n",
    "print(spam.shape)\n",
    "q5_train = np.arange(0, 4000, 1)\n",
    "q5_test = np.arange(4000, 5000, 1)\n",
    "\n",
    "fiveknn = predict_KNN(spam.iloc[q5_train], spam.iloc[q5_test], 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "ff026234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-06 0\n",
      "1e-06 1\n",
      "1e-06 2\n",
      "1e-06 3\n",
      "1e-06 4\n",
      "1e-06 5\n",
      "1e-06 6\n",
      "1e-06 7\n",
      "1e-06 8\n",
      "1e-06 9\n",
      "1e-06 10\n",
      "1e-06 11\n",
      "1e-06 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b2/8cn96b9x6qz0b7b79dn_n_1h0000gn/T/ipykernel_13453/2633864594.py:26: RuntimeWarning: overflow encountered in exp\n",
      "  a = (1/(1+np.exp(-a)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-06 13\n",
      "1e-06 14\n",
      "1e-06 15\n",
      "1e-06 16\n",
      "1e-06 17\n",
      "1e-06 18\n",
      "1e-06 19\n",
      "1e-06 20\n",
      "1e-06 21\n",
      "1e-06 22\n",
      "1e-06 23\n",
      "1e-06 24\n",
      "1e-06 25\n",
      "1e-06 26\n",
      "1e-06 27\n",
      "1e-06 28\n",
      "1e-06 29\n",
      "1e-06 30\n",
      "1e-06 31\n",
      "1e-06 32\n",
      "1e-06 33\n",
      "1e-06 34\n",
      "1e-06 35\n",
      "1e-06 36\n",
      "1e-06 37\n",
      "1e-06 38\n",
      "1e-06 39\n",
      "1e-06 40\n",
      "1e-06 41\n",
      "1e-06 42\n",
      "1e-06 43\n",
      "1e-06 44\n",
      "1e-06 45\n",
      "1e-06 46\n",
      "1e-06 47\n",
      "1e-06 48\n",
      "1e-06 49\n",
      "1e-06 50\n",
      "1e-06 51\n",
      "1e-06 52\n",
      "1e-06 53\n",
      "1e-06 54\n",
      "1e-06 55\n",
      "1e-06 56\n",
      "1e-06 57\n",
      "1e-06 58\n",
      "1e-06 59\n",
      "1e-06 60\n",
      "1e-06 61\n",
      "1e-06 62\n",
      "1e-06 63\n",
      "1e-06 64\n",
      "1e-06 65\n",
      "1e-06 66\n",
      "1e-06 67\n",
      "1e-06 68\n",
      "1e-06 69\n",
      "1e-06 70\n",
      "1e-06 71\n",
      "1e-06 72\n",
      "1e-06 73\n",
      "1e-06 74\n",
      "1e-06 75\n",
      "1e-06 76\n",
      "1e-06 77\n",
      "1e-06 78\n",
      "1e-06 79\n",
      "1e-06 80\n",
      "1e-06 81\n",
      "1e-06 82\n",
      "1e-06 83\n",
      "1e-06 84\n",
      "1e-06 85\n",
      "1e-06 86\n",
      "1e-06 87\n",
      "1e-06 88\n",
      "1e-06 89\n",
      "1e-06 90\n",
      "1e-06 91\n",
      "1e-06 92\n",
      "1e-06 93\n",
      "1e-06 94\n",
      "1e-06 95\n",
      "1e-06 96\n",
      "1e-06 97\n",
      "1e-06 98\n",
      "1e-06 99\n",
      "1e-06 100\n",
      "1e-06 101\n",
      "1e-06 102\n",
      "1e-06 103\n",
      "1e-06 104\n",
      "1e-06 105\n",
      "1e-06 106\n",
      "1e-06 107\n",
      "1e-06 108\n",
      "1e-06 109\n",
      "1e-06 110\n",
      "1e-06 111\n",
      "1e-06 112\n",
      "1e-06 113\n",
      "1e-06 114\n",
      "1e-06 115\n",
      "1e-06 116\n",
      "1e-06 117\n",
      "1e-06 118\n",
      "1e-06 119\n",
      "1e-06 120\n",
      "1e-06 121\n",
      "1e-06 122\n",
      "1e-06 123\n",
      "1e-06 124\n",
      "1e-06 125\n",
      "1e-06 126\n",
      "1e-06 127\n",
      "1e-06 128\n",
      "1e-06 129\n",
      "1e-06 130\n",
      "1e-06 131\n",
      "1e-06 132\n",
      "1e-06 133\n",
      "1e-06 134\n",
      "1e-06 135\n",
      "1e-06 136\n",
      "1e-06 137\n",
      "1e-06 138\n",
      "1e-06 139\n",
      "1e-06 140\n",
      "1e-06 141\n",
      "1e-06 142\n",
      "1e-06 143\n",
      "1e-06 144\n",
      "1e-06 145\n",
      "1e-06 146\n",
      "1e-06 147\n",
      "1e-06 148\n",
      "1e-06 149\n",
      "1e-06 150\n",
      "1e-06 151\n",
      "1e-06 152\n",
      "1e-06 153\n",
      "1e-06 154\n",
      "1e-06 155\n",
      "1e-06 156\n",
      "1e-06 157\n",
      "1e-06 158\n",
      "1e-06 159\n",
      "1e-06 160\n",
      "1e-06 161\n",
      "1e-06 162\n",
      "1e-06 163\n",
      "1e-06 164\n",
      "1e-06 165\n",
      "1e-06 166\n",
      "1e-06 167\n",
      "1e-06 168\n",
      "1e-06 169\n",
      "1e-06 170\n",
      "1e-06 171\n",
      "1e-06 172\n",
      "1e-06 173\n",
      "1e-06 174\n",
      "1e-06 175\n",
      "1e-06 176\n",
      "1e-06 177\n",
      "1e-06 178\n",
      "1e-06 179\n",
      "1e-06 180\n",
      "1e-06 181\n",
      "1e-06 182\n",
      "1e-06 183\n",
      "1e-06 184\n",
      "1e-06 185\n",
      "1e-06 186\n",
      "1e-06 187\n",
      "1e-06 188\n",
      "1e-06 189\n",
      "1e-06 190\n",
      "1e-06 191\n",
      "1e-06 192\n",
      "1e-06 193\n",
      "1e-06 194\n",
      "1e-06 195\n",
      "1e-06 196\n",
      "1e-06 197\n",
      "1e-06 198\n",
      "1e-06 199\n",
      "1e-06 200\n",
      "1e-06 201\n",
      "1e-06 202\n",
      "1e-06 203\n",
      "1e-06 204\n",
      "1e-06 205\n",
      "1e-06 206\n",
      "1e-06 207\n",
      "1e-06 208\n",
      "1e-06 209\n",
      "1e-06 210\n",
      "1e-06 211\n",
      "1e-06 212\n",
      "1e-06 213\n",
      "1e-06 214\n",
      "1e-06 215\n",
      "1e-06 216\n",
      "1e-06 217\n",
      "1e-06 218\n",
      "1e-06 219\n",
      "1e-06 220\n",
      "1e-06 221\n",
      "1e-06 222\n",
      "1e-06 223\n",
      "1e-06 224\n",
      "1e-06 225\n",
      "1e-06 226\n",
      "1e-06 227\n",
      "1e-06 228\n",
      "1e-06 229\n",
      "1e-06 230\n",
      "1e-06 231\n",
      "1e-06 232\n",
      "1e-06 233\n",
      "1e-06 234\n",
      "1e-06 235\n",
      "1e-06 236\n",
      "1e-06 237\n",
      "1e-06 238\n",
      "1e-06 239\n",
      "1e-06 240\n",
      "1e-06 241\n",
      "1e-06 242\n",
      "1e-06 243\n",
      "1e-06 244\n",
      "1e-06 245\n",
      "1e-06 246\n",
      "1e-06 247\n",
      "1e-06 248\n",
      "1e-06 249\n",
      "1e-06 250\n",
      "1e-06 251\n",
      "1e-06 252\n",
      "1e-06 253\n",
      "1e-06 254\n",
      "1e-06 255\n",
      "1e-06 256\n",
      "1e-06 257\n",
      "1e-06 258\n",
      "1e-06 259\n",
      "1e-06 260\n",
      "1e-06 261\n",
      "1e-06 262\n",
      "1e-06 263\n",
      "1e-06 264\n",
      "1e-06 265\n",
      "1e-06 266\n",
      "1e-06 267\n",
      "1e-06 268\n",
      "1e-06 269\n",
      "1e-06 270\n",
      "1e-06 271\n",
      "1e-06 272\n",
      "1e-06 273\n",
      "1e-06 274\n",
      "1e-06 275\n",
      "1e-06 276\n",
      "1e-06 277\n",
      "1e-06 278\n",
      "1e-06 279\n",
      "1e-06 280\n",
      "1e-06 281\n",
      "1e-06 282\n",
      "1e-06 283\n",
      "1e-06 284\n",
      "1e-06 285\n",
      "1e-06 286\n",
      "1e-06 287\n",
      "1e-06 288\n",
      "1e-06 289\n",
      "1e-06 290\n",
      "1e-06 291\n",
      "1e-06 292\n",
      "1e-06 293\n",
      "1e-06 294\n",
      "1e-06 295\n",
      "1e-06 296\n",
      "1e-06 297\n",
      "1e-06 298\n",
      "1e-06 299\n",
      "1e-06 300\n",
      "1e-06 301\n",
      "1e-06 302\n",
      "1e-06 303\n",
      "1e-06 304\n",
      "1e-06 305\n",
      "1e-06 306\n",
      "1e-06 307\n",
      "1e-06 308\n",
      "1e-06 309\n",
      "1e-06 310\n",
      "1e-06 311\n",
      "1e-06 312\n",
      "1e-06 313\n",
      "1e-06 314\n",
      "1e-06 315\n",
      "1e-06 316\n",
      "1e-06 317\n",
      "1e-06 318\n",
      "1e-06 319\n",
      "1e-06 320\n",
      "1e-06 321\n",
      "1e-06 322\n",
      "1e-06 323\n",
      "1e-06 324\n",
      "1e-06 325\n",
      "1e-06 326\n",
      "1e-06 327\n",
      "1e-06 328\n",
      "1e-06 329\n",
      "1e-06 330\n",
      "1e-06 331\n",
      "1e-06 332\n",
      "1e-06 333\n",
      "1e-06 334\n",
      "1e-06 335\n",
      "1e-06 336\n",
      "1e-06 337\n",
      "1e-06 338\n",
      "1e-06 339\n",
      "1e-06 340\n",
      "1e-06 341\n",
      "1e-06 342\n",
      "1e-06 343\n",
      "1e-06 344\n",
      "1e-06 345\n",
      "1e-06 346\n",
      "1e-06 347\n",
      "1e-06 348\n",
      "1e-06 349\n",
      "1e-06 350\n",
      "1e-06 351\n",
      "1e-06 352\n",
      "1e-06 353\n",
      "1e-06 354\n",
      "1e-06 355\n",
      "1e-06 356\n",
      "1e-06 357\n",
      "1e-06 358\n",
      "1e-06 359\n",
      "1e-06 360\n",
      "1e-06 361\n",
      "1e-06 362\n",
      "1e-06 363\n",
      "1e-06 364\n",
      "1e-06 365\n",
      "1e-06 366\n",
      "1e-06 367\n",
      "1e-06 368\n",
      "1e-06 369\n",
      "1e-06 370\n",
      "1e-06 371\n",
      "1e-06 372\n",
      "1e-06 373\n",
      "1e-06 374\n",
      "1e-06 375\n",
      "1e-06 376\n",
      "1e-06 377\n",
      "1e-06 378\n",
      "1e-06 379\n",
      "1e-06 380\n",
      "1e-06 381\n",
      "1e-06 382\n",
      "1e-06 383\n",
      "1e-06 384\n",
      "1e-06 385\n",
      "1e-06 386\n",
      "1e-06 387\n",
      "1e-06 388\n",
      "1e-06 389\n",
      "1e-06 390\n",
      "1e-06 391\n",
      "1e-06 392\n",
      "1e-06 393\n",
      "1e-06 394\n",
      "1e-06 395\n",
      "1e-06 396\n",
      "1e-06 397\n",
      "1e-06 398\n",
      "1e-06 399\n",
      "1e-06 400\n",
      "1e-06 401\n",
      "1e-06 402\n",
      "1e-06 403\n",
      "1e-06 404\n",
      "1e-06 405\n",
      "1e-06 406\n",
      "1e-06 407\n",
      "1e-06 408\n",
      "1e-06 409\n",
      "1e-06 410\n",
      "1e-06 411\n",
      "1e-06 412\n",
      "1e-06 413\n",
      "1e-06 414\n",
      "1e-06 415\n",
      "1e-06 416\n",
      "1e-06 417\n",
      "1e-06 418\n",
      "1e-06 419\n",
      "1e-06 420\n",
      "1e-06 421\n",
      "1e-06 422\n",
      "1e-06 423\n",
      "1e-06 424\n",
      "1e-06 425\n",
      "1e-06 426\n",
      "1e-06 427\n",
      "1e-06 428\n",
      "1e-06 429\n",
      "1e-06 430\n",
      "1e-06 431\n",
      "1e-06 432\n",
      "1e-06 433\n",
      "1e-06 434\n",
      "1e-06 435\n",
      "1e-06 436\n",
      "1e-06 437\n",
      "1e-06 438\n",
      "1e-06 439\n",
      "1e-06 440\n",
      "1e-06 441\n",
      "1e-06 442\n",
      "1e-06 443\n",
      "1e-06 444\n",
      "1e-06 445\n",
      "1e-06 446\n",
      "1e-06 447\n",
      "1e-06 448\n",
      "1e-06 449\n",
      "1e-06 450\n",
      "1e-06 451\n",
      "1e-06 452\n",
      "1e-06 453\n",
      "1e-06 454\n",
      "1e-06 455\n",
      "1e-06 456\n",
      "1e-06 457\n",
      "1e-06 458\n",
      "1e-06 459\n",
      "1e-06 460\n",
      "1e-06 461\n",
      "1e-06 462\n",
      "1e-06 463\n",
      "1e-06 464\n",
      "1e-06 465\n",
      "1e-06 466\n",
      "1e-06 467\n",
      "1e-06 468\n",
      "1e-06 469\n",
      "1e-06 470\n",
      "1e-06 471\n",
      "1e-06 472\n",
      "1e-06 473\n",
      "1e-06 474\n",
      "1e-06 475\n",
      "1e-06 476\n",
      "1e-06 477\n",
      "1e-06 478\n",
      "1e-06 479\n",
      "1e-06 480\n",
      "1e-06 481\n",
      "1e-06 482\n",
      "1e-06 483\n",
      "1e-06 484\n",
      "1e-06 485\n",
      "1e-06 486\n",
      "1e-06 487\n",
      "1e-06 488\n",
      "1e-06 489\n",
      "1e-06 490\n",
      "1e-06 491\n",
      "1e-06 492\n",
      "1e-06 493\n",
      "1e-06 494\n",
      "1e-06 495\n",
      "1e-06 496\n",
      "1e-06 497\n",
      "1e-06 498\n",
      "1e-06 499\n",
      "1e-06 500\n",
      "1e-06 501\n",
      "1e-06 502\n",
      "1e-06 503\n",
      "1e-06 504\n",
      "1e-06 505\n",
      "1e-06 506\n",
      "1e-06 507\n",
      "1e-06 508\n",
      "1e-06 509\n",
      "1e-06 510\n",
      "1e-06 511\n",
      "1e-06 512\n",
      "1e-06 513\n",
      "1e-06 514\n",
      "1e-06 515\n",
      "1e-06 516\n",
      "1e-06 517\n",
      "1e-06 518\n",
      "1e-06 519\n",
      "1e-06 520\n",
      "1e-06 521\n",
      "1e-06 522\n",
      "1e-06 523\n",
      "1e-06 524\n",
      "1e-06 525\n",
      "1e-06 526\n",
      "1e-06 527\n",
      "1e-06 528\n",
      "1e-06 529\n",
      "1e-06 530\n",
      "1e-06 531\n",
      "1e-06 532\n",
      "1e-06 533\n",
      "1e-06 534\n",
      "1e-06 535\n",
      "1e-06 536\n",
      "1e-06 537\n",
      "1e-06 538\n",
      "1e-06 539\n",
      "1e-06 540\n",
      "1e-06 541\n",
      "1e-06 542\n",
      "1e-06 543\n",
      "1e-06 544\n",
      "1e-06 545\n",
      "1e-06 546\n",
      "1e-06 547\n",
      "1e-06 548\n",
      "1e-06 549\n",
      "1e-06 550\n",
      "1e-06 551\n",
      "1e-06 552\n",
      "1e-06 553\n",
      "1e-06 554\n",
      "1e-06 555\n",
      "1e-06 556\n",
      "1e-06 557\n",
      "1e-06 558\n",
      "1e-06 559\n",
      "1e-06 560\n",
      "1e-06 561\n",
      "1e-06 562\n",
      "1e-06 563\n",
      "1e-06 564\n",
      "1e-06 565\n",
      "1e-06 566\n",
      "1e-06 567\n",
      "1e-06 568\n",
      "1e-06 569\n",
      "1e-06 570\n",
      "1e-06 571\n",
      "1e-06 572\n",
      "1e-06 573\n",
      "1e-06 574\n",
      "1e-06 575\n",
      "1e-06 576\n",
      "1e-06 577\n",
      "1e-06 578\n",
      "1e-06 579\n",
      "1e-06 580\n",
      "1e-06 581\n",
      "1e-06 582\n",
      "1e-06 583\n",
      "1e-06 584\n",
      "1e-06 585\n",
      "1e-06 586\n",
      "1e-06 587\n",
      "1e-06 588\n",
      "1e-06 589\n",
      "1e-06 590\n",
      "1e-06 591\n",
      "1e-06 592\n",
      "1e-06 593\n",
      "1e-06 594\n",
      "1e-06 595\n",
      "1e-06 596\n",
      "1e-06 597\n",
      "1e-06 598\n",
      "1e-06 599\n",
      "1e-06 600\n",
      "1e-06 601\n",
      "1e-06 602\n",
      "1e-06 603\n",
      "1e-06 604\n",
      "1e-06 605\n",
      "1e-06 606\n",
      "1e-06 607\n",
      "1e-06 608\n",
      "1e-06 609\n",
      "1e-06 610\n",
      "1e-06 611\n",
      "1e-06 612\n",
      "1e-06 613\n",
      "1e-06 614\n",
      "1e-06 615\n",
      "1e-06 616\n",
      "1e-06 617\n",
      "1e-06 618\n",
      "1e-06 619\n",
      "1e-06 620\n",
      "1e-06 621\n",
      "1e-06 622\n",
      "1e-06 623\n",
      "1e-06 624\n",
      "1e-06 625\n",
      "1e-06 626\n",
      "1e-06 627\n",
      "1e-06 628\n",
      "1e-06 629\n",
      "1e-06 630\n",
      "1e-06 631\n",
      "1e-06 632\n",
      "1e-06 633\n",
      "1e-06 634\n",
      "1e-06 635\n",
      "1e-06 636\n",
      "1e-06 637\n",
      "1e-06 638\n",
      "1e-06 639\n",
      "1e-06 640\n",
      "1e-06 641\n",
      "1e-06 642\n",
      "1e-06 643\n",
      "1e-06 644\n",
      "1e-06 645\n",
      "1e-06 646\n",
      "1e-06 647\n",
      "1e-06 648\n",
      "1e-06 649\n",
      "1e-06 650\n",
      "1e-06 651\n",
      "1e-06 652\n",
      "1e-06 653\n",
      "1e-06 654\n",
      "1e-06 655\n",
      "1e-06 656\n",
      "1e-06 657\n",
      "1e-06 658\n",
      "1e-06 659\n",
      "1e-06 660\n",
      "1e-06 661\n",
      "1e-06 662\n",
      "1e-06 663\n",
      "1e-06 664\n",
      "1e-06 665\n",
      "1e-06 666\n",
      "1e-06 667\n",
      "1e-06 668\n",
      "1e-06 669\n",
      "1e-06 670\n",
      "1e-06 671\n",
      "1e-06 672\n",
      "1e-06 673\n",
      "1e-06 674\n",
      "1e-06 675\n",
      "1e-06 676\n",
      "1e-06 677\n",
      "1e-06 678\n",
      "1e-06 679\n",
      "1e-06 680\n",
      "1e-06 681\n",
      "1e-06 682\n",
      "1e-06 683\n",
      "1e-06 684\n",
      "1e-06 685\n",
      "1e-06 686\n",
      "1e-06 687\n",
      "1e-06 688\n",
      "1e-06 689\n",
      "1e-06 690\n",
      "1e-06 691\n",
      "1e-06 692\n",
      "1e-06 693\n",
      "1e-06 694\n",
      "1e-06 695\n",
      "1e-06 696\n",
      "1e-06 697\n",
      "1e-06 698\n",
      "1e-06 699\n",
      "1e-06 700\n",
      "1e-06 701\n",
      "1e-06 702\n",
      "1e-06 703\n",
      "1e-06 704\n",
      "1e-06 705\n",
      "1e-06 706\n",
      "1e-06 707\n",
      "1e-06 708\n",
      "1e-06 709\n",
      "1e-06 710\n",
      "1e-06 711\n",
      "1e-06 712\n",
      "1e-06 713\n",
      "1e-06 714\n",
      "1e-06 715\n",
      "1e-06 716\n",
      "1e-06 717\n",
      "1e-06 718\n",
      "1e-06 719\n",
      "1e-06 720\n",
      "1e-06 721\n",
      "1e-06 722\n",
      "1e-06 723\n",
      "1e-06 724\n",
      "1e-06 725\n",
      "1e-06 726\n",
      "1e-06 727\n",
      "1e-06 728\n",
      "1e-06 729\n",
      "1e-06 730\n",
      "1e-06 731\n",
      "1e-06 732\n",
      "1e-06 733\n",
      "1e-06 734\n",
      "1e-06 735\n",
      "1e-06 736\n",
      "1e-06 737\n",
      "1e-06 738\n",
      "1e-06 739\n",
      "1e-06 740\n",
      "1e-06 741\n",
      "1e-06 742\n",
      "1e-06 743\n",
      "1e-06 744\n",
      "1e-06 745\n",
      "1e-06 746\n",
      "1e-06 747\n",
      "1e-06 748\n",
      "1e-06 749\n",
      "1e-06 750\n",
      "1e-06 751\n",
      "1e-06 752\n",
      "1e-06 753\n",
      "1e-06 754\n",
      "1e-06 755\n",
      "1e-06 756\n",
      "1e-06 757\n",
      "1e-06 758\n",
      "1e-06 759\n",
      "1e-06 760\n",
      "1e-06 761\n",
      "1e-06 762\n",
      "1e-06 763\n",
      "1e-06 764\n",
      "1e-06 765\n",
      "1e-06 766\n",
      "1e-06 767\n",
      "1e-06 768\n",
      "1e-06 769\n",
      "1e-06 770\n",
      "1e-06 771\n",
      "1e-06 772\n",
      "1e-06 773\n",
      "1e-06 774\n",
      "1e-06 775\n",
      "1e-06 776\n",
      "1e-06 777\n",
      "1e-06 778\n",
      "1e-06 779\n",
      "1e-06 780\n",
      "1e-06 781\n",
      "1e-06 782\n",
      "1e-06 783\n",
      "1e-06 784\n",
      "1e-06 785\n",
      "1e-06 786\n",
      "1e-06 787\n",
      "1e-06 788\n",
      "1e-06 789\n",
      "1e-06 790\n",
      "1e-06 791\n",
      "1e-06 792\n",
      "1e-06 793\n",
      "1e-06 794\n",
      "1e-06 795\n",
      "1e-06 796\n",
      "1e-06 797\n",
      "1e-06 798\n",
      "1e-06 799\n",
      "1e-06 800\n",
      "1e-06 801\n",
      "1e-06 802\n",
      "1e-06 803\n",
      "1e-06 804\n",
      "1e-06 805\n",
      "1e-06 806\n",
      "1e-06 807\n",
      "1e-06 808\n",
      "1e-06 809\n",
      "1e-06 810\n",
      "1e-06 811\n",
      "1e-06 812\n",
      "1e-06 813\n",
      "1e-06 814\n",
      "1e-06 815\n",
      "1e-06 816\n",
      "1e-06 817\n",
      "1e-06 818\n",
      "1e-06 819\n",
      "1e-06 820\n",
      "1e-06 821\n",
      "1e-06 822\n",
      "1e-06 823\n",
      "1e-06 824\n",
      "1e-06 825\n",
      "1e-06 826\n",
      "1e-06 827\n",
      "1e-06 828\n",
      "1e-06 829\n",
      "1e-06 830\n",
      "1e-06 831\n",
      "1e-06 832\n",
      "1e-06 833\n",
      "1e-06 834\n",
      "1e-06 835\n",
      "1e-06 836\n",
      "1e-06 837\n",
      "1e-06 838\n",
      "1e-06 839\n",
      "1e-06 840\n",
      "1e-06 841\n",
      "1e-06 842\n",
      "1e-06 843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-06 844\n",
      "1e-06 845\n",
      "1e-06 846\n",
      "1e-06 847\n",
      "1e-06 848\n",
      "1e-06 849\n",
      "1e-06 850\n",
      "1e-06 851\n",
      "1e-06 852\n",
      "1e-06 853\n",
      "1e-06 854\n",
      "1e-06 855\n",
      "1e-06 856\n",
      "1e-06 857\n",
      "1e-06 858\n",
      "1e-06 859\n",
      "1e-06 860\n",
      "1e-06 861\n",
      "1e-06 862\n",
      "1e-06 863\n",
      "1e-06 864\n",
      "1e-06 865\n",
      "1e-06 866\n",
      "1e-06 867\n",
      "1e-06 868\n",
      "1e-06 869\n",
      "1e-06 870\n",
      "1e-06 871\n",
      "1e-06 872\n",
      "1e-06 873\n",
      "1e-06 874\n",
      "1e-06 875\n",
      "1e-06 876\n",
      "1e-06 877\n",
      "1e-06 878\n",
      "1e-06 879\n",
      "1e-06 880\n",
      "1e-06 881\n",
      "1e-06 882\n",
      "1e-06 883\n",
      "1e-06 884\n",
      "1e-06 885\n",
      "1e-06 886\n",
      "1e-06 887\n",
      "1e-06 888\n",
      "1e-06 889\n",
      "1e-06 890\n",
      "1e-06 891\n",
      "1e-06 892\n",
      "1e-06 893\n",
      "1e-06 894\n",
      "1e-06 895\n",
      "1e-06 896\n",
      "1e-06 897\n",
      "1e-06 898\n",
      "1e-06 899\n",
      "1e-06 900\n",
      "1e-06 901\n",
      "1e-06 902\n",
      "1e-06 903\n",
      "1e-06 904\n",
      "1e-06 905\n",
      "1e-06 906\n",
      "1e-06 907\n",
      "1e-06 908\n",
      "1e-06 909\n",
      "1e-06 910\n",
      "1e-06 911\n",
      "1e-06 912\n",
      "1e-06 913\n",
      "1e-06 914\n",
      "1e-06 915\n",
      "1e-06 916\n",
      "1e-06 917\n",
      "1e-06 918\n",
      "1e-06 919\n",
      "1e-06 920\n",
      "1e-06 921\n",
      "1e-06 922\n",
      "1e-06 923\n",
      "1e-06 924\n",
      "1e-06 925\n",
      "1e-06 926\n",
      "1e-06 927\n",
      "1e-06 928\n",
      "1e-06 929\n",
      "1e-06 930\n",
      "1e-06 931\n",
      "1e-06 932\n",
      "1e-06 933\n",
      "1e-06 934\n",
      "1e-06 935\n",
      "1e-06 936\n",
      "1e-06 937\n",
      "1e-06 938\n",
      "1e-06 939\n",
      "1e-06 940\n",
      "1e-06 941\n",
      "1e-06 942\n",
      "1e-06 943\n",
      "1e-06 944\n",
      "1e-06 945\n",
      "1e-06 946\n",
      "1e-06 947\n",
      "1e-06 948\n",
      "1e-06 949\n",
      "1e-06 950\n",
      "1e-06 951\n",
      "1e-06 952\n",
      "1e-06 953\n",
      "1e-06 954\n",
      "1e-06 955\n",
      "1e-06 956\n",
      "1e-06 957\n",
      "1e-06 958\n",
      "1e-06 959\n",
      "1e-06 960\n",
      "1e-06 961\n",
      "1e-06 962\n",
      "1e-06 963\n",
      "1e-06 964\n",
      "1e-06 965\n",
      "1e-06 966\n",
      "1e-06 967\n",
      "1e-06 968\n",
      "1e-06 969\n",
      "1e-06 970\n",
      "1e-06 971\n",
      "1e-06 972\n",
      "1e-06 973\n",
      "1e-06 974\n",
      "1e-06 975\n",
      "1e-06 976\n",
      "1e-06 977\n",
      "1e-06 978\n",
      "1e-06 979\n",
      "1e-06 980\n",
      "1e-06 981\n",
      "1e-06 982\n",
      "1e-06 983\n",
      "1e-06 984\n",
      "1e-06 985\n",
      "1e-06 986\n",
      "1e-06 987\n",
      "1e-06 988\n",
      "1e-06 989\n",
      "1e-06 990\n",
      "1e-06 991\n",
      "1e-06 992\n",
      "1e-06 993\n",
      "1e-06 994\n",
      "1e-06 995\n",
      "1e-06 996\n",
      "1e-06 997\n",
      "1e-06 998\n",
      "1e-06 999\n",
      "1e-06 1000\n",
      "1e-06 1001\n",
      "1e-06 1002\n",
      "1e-06 1003\n",
      "1e-06 1004\n",
      "1e-06 1005\n",
      "1e-06 1006\n",
      "1e-06 1007\n",
      "1e-06 1008\n",
      "1e-06 1009\n",
      "1e-06 1010\n",
      "1e-06 1011\n",
      "1e-06 1012\n",
      "1e-06 1013\n",
      "1e-06 1014\n",
      "1e-06 1015\n",
      "1e-06 1016\n",
      "1e-06 1017\n",
      "1e-06 1018\n",
      "1e-06 1019\n",
      "1e-06 1020\n",
      "1e-06 1021\n",
      "1e-06 1022\n",
      "1e-06 1023\n",
      "1e-06 1024\n",
      "1e-06 1025\n",
      "1e-06 1026\n",
      "1e-06 1027\n",
      "1e-06 1028\n",
      "1e-06 1029\n",
      "1e-06 1030\n",
      "1e-06 1031\n",
      "1e-06 1032\n",
      "1e-06 1033\n",
      "1e-06 1034\n",
      "1e-06 1035\n",
      "1e-06 1036\n",
      "1e-06 1037\n",
      "1e-06 1038\n",
      "1e-06 1039\n",
      "1e-06 1040\n",
      "1e-06 1041\n",
      "1e-06 1042\n",
      "1e-06 1043\n",
      "1e-06 1044\n",
      "1e-06 1045\n",
      "1e-06 1046\n",
      "1e-06 1047\n",
      "1e-06 1048\n",
      "1e-06 1049\n",
      "1e-06 1050\n",
      "1e-06 1051\n",
      "1e-06 1052\n",
      "1e-06 1053\n",
      "1e-06 1054\n",
      "1e-06 1055\n",
      "1e-06 1056\n",
      "1e-06 1057\n",
      "1e-06 1058\n",
      "1e-06 1059\n",
      "1e-06 1060\n",
      "1e-06 1061\n",
      "1e-06 1062\n",
      "1e-06 1063\n",
      "1e-06 1064\n",
      "1e-06 1065\n",
      "1e-06 1066\n",
      "1e-06 1067\n",
      "1e-06 1068\n",
      "1e-06 1069\n",
      "1e-06 1070\n",
      "1e-06 1071\n",
      "1e-06 1072\n",
      "1e-06 1073\n",
      "1e-06 1074\n",
      "1e-06 1075\n",
      "1e-06 1076\n",
      "1e-06 1077\n",
      "1e-06 1078\n",
      "1e-06 1079\n",
      "1e-06 1080\n",
      "1e-06 1081\n",
      "1e-06 1082\n",
      "1e-06 1083\n",
      "1e-06 1084\n",
      "1e-06 1085\n",
      "1e-06 1086\n",
      "1e-06 1087\n",
      "1e-06 1088\n",
      "1e-06 1089\n",
      "1e-06 1090\n",
      "1e-06 1091\n",
      "1e-06 1092\n",
      "1e-06 1093\n",
      "1e-06 1094\n",
      "1e-06 1095\n",
      "1e-06 1096\n",
      "1e-06 1097\n",
      "1e-06 1098\n",
      "1e-06 1099\n",
      "1e-06 1100\n",
      "1e-06 1101\n",
      "1e-06 1102\n",
      "1e-06 1103\n",
      "1e-06 1104\n",
      "1e-06 1105\n",
      "1e-06 1106\n",
      "1e-06 1107\n",
      "1e-06 1108\n",
      "1e-06 1109\n",
      "1e-06 1110\n",
      "1e-06 1111\n",
      "1e-06 1112\n",
      "1e-06 1113\n",
      "1e-06 1114\n",
      "1e-06 1115\n",
      "1e-06 1116\n",
      "1e-06 1117\n",
      "1e-06 1118\n",
      "1e-06 1119\n",
      "1e-06 1120\n",
      "1e-06 1121\n",
      "1e-06 1122\n",
      "1e-06 1123\n",
      "1e-06 1124\n",
      "1e-06 1125\n",
      "1e-06 1126\n",
      "1e-06 1127\n",
      "1e-06 1128\n",
      "1e-06 1129\n",
      "1e-06 1130\n",
      "1e-06 1131\n",
      "1e-06 1132\n",
      "1e-06 1133\n",
      "1e-06 1134\n",
      "1e-06 1135\n",
      "1e-06 1136\n",
      "1e-06 1137\n",
      "1e-06 1138\n",
      "1e-06 1139\n",
      "1e-06 1140\n",
      "1e-06 1141\n",
      "1e-06 1142\n",
      "1e-06 1143\n",
      "1e-06 1144\n",
      "1e-06 1145\n",
      "1e-06 1146\n",
      "1e-06 1147\n",
      "1e-06 1148\n",
      "1e-06 1149\n",
      "1e-06 1150\n",
      "1e-06 1151\n",
      "1e-06 1152\n",
      "1e-06 1153\n",
      "1e-06 1154\n",
      "1e-06 1155\n",
      "1e-06 1156\n",
      "1e-06 1157\n",
      "1e-06 1158\n",
      "1e-06 1159\n",
      "1e-06 1160\n",
      "1e-06 1161\n",
      "1e-06 1162\n",
      "1e-06 1163\n",
      "1e-06 1164\n",
      "1e-06 1165\n",
      "1e-06 1166\n",
      "1e-06 1167\n",
      "1e-06 1168\n",
      "1e-06 1169\n",
      "1e-06 1170\n",
      "1e-06 1171\n",
      "1e-06 1172\n",
      "1e-06 1173\n",
      "1e-06 1174\n",
      "1e-06 1175\n",
      "1e-06 1176\n",
      "1e-06 1177\n",
      "1e-06 1178\n",
      "1e-06 1179\n",
      "1e-06 1180\n",
      "1e-06 1181\n",
      "1e-06 1182\n",
      "1e-06 1183\n",
      "1e-06 1184\n",
      "1e-06 1185\n",
      "1e-06 1186\n",
      "1e-06 1187\n",
      "1e-06 1188\n",
      "1e-06 1189\n",
      "1e-06 1190\n",
      "1e-06 1191\n",
      "1e-06 1192\n",
      "1e-06 1193\n",
      "1e-06 1194\n",
      "1e-06 1195\n",
      "1e-06 1196\n",
      "1e-06 1197\n",
      "1e-06 1198\n",
      "1e-06 1199\n",
      "1e-06 1200\n",
      "1e-06 1201\n",
      "1e-06 1202\n",
      "1e-06 1203\n",
      "1e-06 1204\n",
      "1e-06 1205\n",
      "1e-06 1206\n",
      "1e-06 1207\n",
      "1e-06 1208\n",
      "1e-06 1209\n",
      "1e-06 1210\n",
      "1e-06 1211\n",
      "1e-06 1212\n",
      "1e-06 1213\n",
      "1e-06 1214\n",
      "1e-06 1215\n",
      "1e-06 1216\n",
      "1e-06 1217\n",
      "1e-06 1218\n",
      "1e-06 1219\n",
      "1e-06 1220\n",
      "1e-06 1221\n",
      "1e-06 1222\n",
      "1e-06 1223\n",
      "1e-06 1224\n",
      "1e-06 1225\n",
      "1e-06 1226\n",
      "1e-06 1227\n",
      "1e-06 1228\n",
      "1e-06 1229\n",
      "1e-06 1230\n",
      "1e-06 1231\n",
      "1e-06 1232\n",
      "1e-06 1233\n",
      "1e-06 1234\n",
      "1e-06 1235\n",
      "1e-06 1236\n",
      "1e-06 1237\n",
      "1e-06 1238\n",
      "1e-06 1239\n",
      "1e-06 1240\n",
      "1e-06 1241\n",
      "1e-06 1242\n",
      "1e-06 1243\n",
      "1e-06 1244\n",
      "1e-06 1245\n",
      "1e-06 1246\n",
      "1e-06 1247\n",
      "1e-06 1248\n",
      "1e-06 1249\n",
      "1e-06 1250\n",
      "1e-06 1251\n",
      "1e-06 1252\n",
      "1e-06 1253\n",
      "1e-06 1254\n",
      "1e-06 1255\n",
      "1e-06 1256\n",
      "1e-06 1257\n",
      "1e-06 1258\n",
      "1e-06 1259\n",
      "1e-06 1260\n",
      "1e-06 1261\n",
      "1e-06 1262\n",
      "1e-06 1263\n",
      "1e-06 1264\n",
      "1e-06 1265\n",
      "1e-06 1266\n",
      "1e-06 1267\n",
      "1e-06 1268\n",
      "1e-06 1269\n",
      "1e-06 1270\n",
      "1e-06 1271\n",
      "1e-06 1272\n",
      "1e-06 1273\n",
      "1e-06 1274\n",
      "1e-06 1275\n",
      "1e-06 1276\n",
      "1e-06 1277\n",
      "1e-06 1278\n",
      "1e-06 1279\n",
      "1e-06 1280\n",
      "1e-06 1281\n",
      "1e-06 1282\n",
      "1e-06 1283\n",
      "1e-06 1284\n",
      "1e-06 1285\n",
      "1e-06 1286\n",
      "1e-06 1287\n",
      "1e-06 1288\n",
      "1e-06 1289\n",
      "1e-06 1290\n",
      "1e-06 1291\n",
      "1e-06 1292\n",
      "1e-06 1293\n",
      "1e-06 1294\n",
      "1e-06 1295\n",
      "1e-06 1296\n",
      "1e-06 1297\n",
      "1e-06 1298\n",
      "1e-06 1299\n",
      "1e-06 1300\n",
      "1e-06 1301\n",
      "1e-06 1302\n",
      "1e-06 1303\n",
      "1e-06 1304\n",
      "1e-06 1305\n",
      "1e-06 1306\n",
      "1e-06 1307\n",
      "1e-06 1308\n",
      "1e-06 1309\n",
      "1e-06 1310\n",
      "1e-06 1311\n",
      "1e-06 1312\n",
      "1e-06 1313\n",
      "1e-06 1314\n",
      "1e-06 1315\n",
      "1e-06 1316\n",
      "1e-06 1317\n",
      "1e-06 1318\n",
      "1e-06 1319\n",
      "1e-06 1320\n",
      "1e-06 1321\n",
      "1e-06 1322\n",
      "1e-06 1323\n",
      "1e-06 1324\n",
      "1e-06 1325\n",
      "1e-06 1326\n",
      "1e-06 1327\n",
      "1e-06 1328\n",
      "1e-06 1329\n",
      "1e-06 1330\n",
      "1e-06 1331\n",
      "1e-06 1332\n",
      "1e-06 1333\n",
      "1e-06 1334\n",
      "1e-06 1335\n",
      "1e-06 1336\n",
      "1e-06 1337\n",
      "1e-06 1338\n",
      "1e-06 1339\n",
      "1e-06 1340\n",
      "1e-06 1341\n",
      "1e-06 1342\n",
      "1e-06 1343\n",
      "1e-06 1344\n",
      "1e-06 1345\n",
      "1e-06 1346\n",
      "1e-06 1347\n",
      "1e-06 1348\n",
      "1e-06 1349\n",
      "1e-06 1350\n",
      "1e-06 1351\n",
      "1e-06 1352\n",
      "1e-06 1353\n",
      "1e-06 1354\n",
      "1e-06 1355\n",
      "1e-06 1356\n",
      "1e-06 1357\n",
      "1e-06 1358\n",
      "1e-06 1359\n",
      "1e-06 1360\n",
      "1e-06 1361\n",
      "1e-06 1362\n",
      "1e-06 1363\n",
      "1e-06 1364\n",
      "1e-06 1365\n",
      "1e-06 1366\n",
      "1e-06 1367\n",
      "1e-06 1368\n",
      "1e-06 1369\n",
      "1e-06 1370\n",
      "1e-06 1371\n",
      "1e-06 1372\n",
      "1e-06 1373\n",
      "1e-06 1374\n",
      "1e-06 1375\n",
      "1e-06 1376\n",
      "1e-06 1377\n",
      "1e-06 1378\n",
      "1e-06 1379\n",
      "1e-06 1380\n",
      "1e-06 1381\n",
      "1e-06 1382\n",
      "1e-06 1383\n",
      "1e-06 1384\n",
      "1e-06 1385\n",
      "1e-06 1386\n",
      "1e-06 1387\n",
      "1e-06 1388\n",
      "1e-06 1389\n",
      "1e-06 1390\n",
      "1e-06 1391\n",
      "1e-06 1392\n",
      "1e-06 1393\n",
      "1e-06 1394\n",
      "1e-06 1395\n",
      "1e-06 1396\n",
      "1e-06 1397\n",
      "1e-06 1398\n",
      "1e-06 1399\n",
      "1e-06 1400\n",
      "1e-06 1401\n",
      "1e-06 1402\n",
      "1e-06 1403\n",
      "1e-06 1404\n",
      "1e-06 1405\n",
      "1e-06 1406\n",
      "1e-06 1407\n",
      "1e-06 1408\n",
      "1e-06 1409\n",
      "1e-06 1410\n",
      "1e-06 1411\n",
      "1e-06 1412\n",
      "1e-06 1413\n",
      "1e-06 1414\n",
      "1e-06 1415\n",
      "1e-06 1416\n",
      "1e-06 1417\n",
      "1e-06 1418\n",
      "1e-06 1419\n",
      "1e-06 1420\n",
      "1e-06 1421\n",
      "1e-06 1422\n",
      "1e-06 1423\n",
      "1e-06 1424\n",
      "1e-06 1425\n",
      "1e-06 1426\n",
      "1e-06 1427\n",
      "1e-06 1428\n",
      "1e-06 1429\n",
      "1e-06 1430\n",
      "1e-06 1431\n",
      "1e-06 1432\n",
      "1e-06 1433\n",
      "1e-06 1434\n",
      "1e-06 1435\n",
      "1e-06 1436\n",
      "1e-06 1437\n",
      "1e-06 1438\n",
      "1e-06 1439\n",
      "1e-06 1440\n",
      "1e-06 1441\n",
      "1e-06 1442\n",
      "1e-06 1443\n",
      "1e-06 1444\n",
      "1e-06 1445\n",
      "1e-06 1446\n",
      "1e-06 1447\n",
      "1e-06 1448\n",
      "1e-06 1449\n",
      "1e-06 1450\n",
      "1e-06 1451\n",
      "1e-06 1452\n",
      "1e-06 1453\n",
      "1e-06 1454\n",
      "1e-06 1455\n",
      "1e-06 1456\n",
      "1e-06 1457\n",
      "1e-06 1458\n",
      "1e-06 1459\n",
      "1e-06 1460\n",
      "1e-06 1461\n",
      "1e-06 1462\n",
      "1e-06 1463\n",
      "1e-06 1464\n",
      "1e-06 1465\n",
      "1e-06 1466\n",
      "1e-06 1467\n",
      "1e-06 1468\n",
      "1e-06 1469\n",
      "1e-06 1470\n",
      "1e-06 1471\n",
      "1e-06 1472\n",
      "1e-06 1473\n",
      "1e-06 1474\n",
      "1e-06 1475\n",
      "1e-06 1476\n",
      "1e-06 1477\n",
      "1e-06 1478\n",
      "1e-06 1479\n",
      "1e-06 1480\n",
      "1e-06 1481\n",
      "1e-06 1482\n",
      "1e-06 1483\n",
      "1e-06 1484\n",
      "1e-06 1485\n",
      "1e-06 1486\n",
      "1e-06 1487\n",
      "1e-06 1488\n",
      "1e-06 1489\n",
      "1e-06 1490\n",
      "1e-06 1491\n",
      "1e-06 1492\n",
      "1e-06 1493\n",
      "1e-06 1494\n",
      "1e-06 1495\n",
      "1e-06 1496\n",
      "1e-06 1497\n",
      "1e-06 1498\n",
      "1e-06 1499\n",
      "1e-06 1500\n",
      "1e-06 1501\n",
      "1e-06 1502\n",
      "1e-06 1503\n",
      "1e-06 1504\n",
      "1e-06 1505\n",
      "1e-06 1506\n",
      "1e-06 1507\n",
      "1e-06 1508\n",
      "1e-06 1509\n",
      "1e-06 1510\n",
      "1e-06 1511\n",
      "1e-06 1512\n",
      "1e-06 1513\n",
      "1e-06 1514\n",
      "1e-06 1515\n",
      "1e-06 1516\n",
      "1e-06 1517\n",
      "1e-06 1518\n",
      "1e-06 1519\n",
      "1e-06 1520\n",
      "1e-06 1521\n",
      "1e-06 1522\n",
      "1e-06 1523\n",
      "1e-06 1524\n",
      "1e-06 1525\n",
      "1e-06 1526\n",
      "1e-06 1527\n",
      "1e-06 1528\n",
      "1e-06 1529\n",
      "1e-06 1530\n",
      "1e-06 1531\n",
      "1e-06 1532\n",
      "1e-06 1533\n",
      "1e-06 1534\n",
      "1e-06 1535\n",
      "1e-06 1536\n",
      "1e-06 1537\n",
      "1e-06 1538\n",
      "1e-06 1539\n",
      "1e-06 1540\n",
      "1e-06 1541\n",
      "1e-06 1542\n",
      "1e-06 1543\n",
      "1e-06 1544\n",
      "1e-06 1545\n",
      "1e-06 1546\n",
      "1e-06 1547\n",
      "1e-06 1548\n",
      "1e-06 1549\n",
      "1e-06 1550\n",
      "1e-06 1551\n",
      "1e-06 1552\n",
      "1e-06 1553\n",
      "1e-06 1554\n",
      "1e-06 1555\n",
      "1e-06 1556\n",
      "1e-06 1557\n",
      "1e-06 1558\n",
      "1e-06 1559\n",
      "1e-06 1560\n",
      "1e-06 1561\n",
      "1e-06 1562\n",
      "1e-06 1563\n",
      "1e-06 1564\n",
      "1e-06 1565\n",
      "1e-06 1566\n",
      "1e-06 1567\n",
      "1e-06 1568\n",
      "1e-06 1569\n",
      "1e-06 1570\n",
      "1e-06 1571\n",
      "1e-06 1572\n",
      "1e-06 1573\n",
      "1e-06 1574\n",
      "1e-06 1575\n",
      "1e-06 1576\n",
      "1e-06 1577\n",
      "1e-06 1578\n",
      "1e-06 1579\n",
      "1e-06 1580\n",
      "1e-06 1581\n",
      "1e-06 1582\n",
      "1e-06 1583\n",
      "1e-06 1584\n",
      "1e-06 1585\n",
      "1e-06 1586\n",
      "1e-06 1587\n",
      "1e-06 1588\n",
      "1e-06 1589\n",
      "1e-06 1590\n",
      "1e-06 1591\n",
      "1e-06 1592\n",
      "1e-06 1593\n",
      "1e-06 1594\n",
      "1e-06 1595\n",
      "1e-06 1596\n",
      "1e-06 1597\n",
      "1e-06 1598\n",
      "1e-06 1599\n",
      "1e-06 1600\n",
      "1e-06 1601\n",
      "1e-06 1602\n",
      "1e-06 1603\n",
      "1e-06 1604\n",
      "1e-06 1605\n",
      "1e-06 1606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-06 1607\n",
      "1e-06 1608\n",
      "1e-06 1609\n",
      "1e-06 1610\n",
      "1e-06 1611\n",
      "1e-06 1612\n",
      "1e-06 1613\n",
      "1e-06 1614\n",
      "1e-06 1615\n",
      "1e-06 1616\n",
      "1e-06 1617\n",
      "1e-06 1618\n",
      "1e-06 1619\n",
      "1e-06 1620\n",
      "1e-06 1621\n",
      "1e-06 1622\n",
      "1e-06 1623\n",
      "1e-06 1624\n",
      "1e-06 1625\n",
      "1e-06 1626\n",
      "1e-06 1627\n",
      "1e-06 1628\n",
      "1e-06 1629\n",
      "1e-06 1630\n",
      "1e-06 1631\n",
      "1e-06 1632\n",
      "1e-06 1633\n",
      "1e-06 1634\n",
      "1e-06 1635\n",
      "1e-06 1636\n",
      "1e-06 1637\n",
      "1e-06 1638\n",
      "1e-06 1639\n",
      "1e-06 1640\n",
      "1e-06 1641\n",
      "1e-06 1642\n",
      "1e-06 1643\n",
      "1e-06 1644\n",
      "1e-06 1645\n",
      "1e-06 1646\n",
      "1e-06 1647\n",
      "1e-06 1648\n",
      "1e-06 1649\n",
      "1e-06 1650\n",
      "1e-06 1651\n",
      "1e-06 1652\n",
      "1e-06 1653\n",
      "1e-06 1654\n",
      "1e-06 1655\n",
      "1e-06 1656\n",
      "1e-06 1657\n",
      "1e-06 1658\n",
      "1e-06 1659\n",
      "1e-06 1660\n",
      "1e-06 1661\n",
      "1e-06 1662\n",
      "1e-06 1663\n",
      "1e-06 1664\n",
      "1e-06 1665\n",
      "1e-06 1666\n",
      "1e-06 1667\n",
      "1e-06 1668\n",
      "1e-06 1669\n",
      "1e-06 1670\n",
      "1e-06 1671\n",
      "1e-06 1672\n",
      "1e-06 1673\n",
      "1e-06 1674\n",
      "1e-06 1675\n",
      "1e-06 1676\n",
      "1e-06 1677\n",
      "1e-06 1678\n",
      "1e-06 1679\n",
      "1e-06 1680\n",
      "1e-06 1681\n",
      "1e-06 1682\n",
      "1e-06 1683\n",
      "1e-06 1684\n",
      "1e-06 1685\n",
      "1e-06 1686\n",
      "1e-06 1687\n",
      "1e-06 1688\n",
      "1e-06 1689\n",
      "1e-06 1690\n",
      "1e-06 1691\n",
      "1e-06 1692\n",
      "1e-06 1693\n",
      "1e-06 1694\n",
      "1e-06 1695\n",
      "1e-06 1696\n",
      "1e-06 1697\n",
      "1e-06 1698\n",
      "1e-06 1699\n",
      "1e-06 1700\n",
      "1e-06 1701\n",
      "1e-06 1702\n",
      "1e-06 1703\n",
      "1e-06 1704\n",
      "1e-06 1705\n",
      "1e-06 1706\n",
      "1e-06 1707\n",
      "1e-06 1708\n",
      "1e-06 1709\n",
      "1e-06 1710\n",
      "1e-06 1711\n",
      "1e-06 1712\n",
      "1e-06 1713\n",
      "1e-06 1714\n",
      "1e-06 1715\n",
      "1e-06 1716\n",
      "1e-06 1717\n",
      "1e-06 1718\n",
      "1e-06 1719\n",
      "1e-06 1720\n",
      "1e-06 1721\n",
      "1e-06 1722\n",
      "1e-06 1723\n",
      "1e-06 1724\n",
      "1e-06 1725\n",
      "1e-06 1726\n",
      "1e-06 1727\n",
      "1e-06 1728\n",
      "1e-06 1729\n",
      "1e-06 1730\n",
      "1e-06 1731\n",
      "1e-06 1732\n",
      "1e-06 1733\n",
      "1e-06 1734\n",
      "1e-06 1735\n",
      "1e-06 1736\n",
      "1e-06 1737\n",
      "1e-06 1738\n",
      "1e-06 1739\n",
      "1e-06 1740\n",
      "1e-06 1741\n",
      "1e-06 1742\n",
      "1e-06 1743\n",
      "1e-06 1744\n",
      "1e-06 1745\n",
      "1e-06 1746\n",
      "1e-06 1747\n",
      "1e-06 1748\n",
      "1e-06 1749\n",
      "1e-06 1750\n",
      "1e-06 1751\n",
      "1e-06 1752\n",
      "1e-06 1753\n",
      "1e-06 1754\n",
      "1e-06 1755\n",
      "1e-06 1756\n",
      "1e-06 1757\n",
      "1e-06 1758\n",
      "1e-06 1759\n",
      "1e-06 1760\n",
      "1e-06 1761\n",
      "1e-06 1762\n",
      "1e-06 1763\n",
      "1e-06 1764\n",
      "1e-06 1765\n",
      "1e-06 1766\n",
      "1e-06 1767\n",
      "1e-06 1768\n",
      "1e-06 1769\n",
      "1e-06 1770\n",
      "1e-06 1771\n",
      "1e-06 1772\n",
      "1e-06 1773\n",
      "1e-06 1774\n",
      "1e-06 1775\n",
      "1e-06 1776\n",
      "1e-06 1777\n",
      "1e-06 1778\n",
      "1e-06 1779\n",
      "1e-06 1780\n",
      "1e-06 1781\n",
      "1e-06 1782\n",
      "1e-06 1783\n",
      "1e-06 1784\n",
      "1e-06 1785\n",
      "1e-06 1786\n",
      "1e-06 1787\n",
      "1e-06 1788\n",
      "1e-06 1789\n",
      "1e-06 1790\n",
      "1e-06 1791\n",
      "1e-06 1792\n",
      "1e-06 1793\n",
      "1e-06 1794\n",
      "1e-06 1795\n",
      "1e-06 1796\n",
      "1e-06 1797\n",
      "1e-06 1798\n",
      "1e-06 1799\n",
      "1e-06 1800\n",
      "1e-06 1801\n",
      "1e-06 1802\n",
      "1e-06 1803\n",
      "1e-06 1804\n",
      "1e-06 1805\n",
      "1e-06 1806\n",
      "1e-06 1807\n",
      "1e-06 1808\n",
      "1e-06 1809\n",
      "1e-06 1810\n",
      "1e-06 1811\n",
      "1e-06 1812\n",
      "1e-06 1813\n",
      "1e-06 1814\n",
      "1e-06 1815\n",
      "1e-06 1816\n",
      "1e-06 1817\n",
      "1e-06 1818\n",
      "1e-06 1819\n",
      "1e-06 1820\n",
      "1e-06 1821\n",
      "1e-06 1822\n",
      "1e-06 1823\n",
      "1e-06 1824\n",
      "1e-06 1825\n",
      "1e-06 1826\n",
      "1e-06 1827\n",
      "1e-06 1828\n",
      "1e-06 1829\n",
      "1e-06 1830\n",
      "1e-06 1831\n",
      "1e-06 1832\n",
      "1e-06 1833\n",
      "1e-06 1834\n",
      "1e-06 1835\n",
      "1e-06 1836\n",
      "1e-06 1837\n",
      "1e-06 1838\n",
      "1e-06 1839\n",
      "1e-06 1840\n",
      "1e-06 1841\n",
      "1e-06 1842\n",
      "1e-06 1843\n",
      "1e-06 1844\n",
      "1e-06 1845\n",
      "1e-06 1846\n",
      "1e-06 1847\n",
      "1e-06 1848\n",
      "1e-06 1849\n",
      "1e-06 1850\n",
      "1e-06 1851\n",
      "1e-06 1852\n",
      "1e-06 1853\n",
      "1e-06 1854\n",
      "1e-06 1855\n",
      "1e-06 1856\n",
      "1e-06 1857\n",
      "1e-06 1858\n",
      "1e-06 1859\n",
      "1e-06 1860\n",
      "1e-06 1861\n",
      "1e-06 1862\n",
      "1e-06 1863\n",
      "1e-06 1864\n",
      "1e-06 1865\n",
      "1e-06 1866\n",
      "1e-06 1867\n",
      "1e-06 1868\n",
      "1e-06 1869\n",
      "1e-06 1870\n",
      "1e-06 1871\n",
      "1e-06 1872\n",
      "1e-06 1873\n",
      "1e-06 1874\n",
      "1e-06 1875\n",
      "1e-06 1876\n",
      "1e-06 1877\n",
      "1e-06 1878\n",
      "1e-06 1879\n",
      "1e-06 1880\n",
      "1e-06 1881\n",
      "1e-06 1882\n",
      "1e-06 1883\n",
      "1e-06 1884\n",
      "1e-06 1885\n",
      "1e-06 1886\n",
      "1e-06 1887\n",
      "1e-06 1888\n",
      "1e-06 1889\n",
      "1e-06 1890\n",
      "1e-06 1891\n",
      "1e-06 1892\n",
      "1e-06 1893\n",
      "1e-06 1894\n",
      "1e-06 1895\n",
      "1e-06 1896\n",
      "1e-06 1897\n",
      "1e-06 1898\n",
      "1e-06 1899\n",
      "1e-06 1900\n",
      "1e-06 1901\n",
      "1e-06 1902\n",
      "1e-06 1903\n",
      "1e-06 1904\n",
      "1e-06 1905\n",
      "1e-06 1906\n",
      "1e-06 1907\n",
      "1e-06 1908\n",
      "1e-06 1909\n",
      "1e-06 1910\n",
      "1e-06 1911\n",
      "1e-06 1912\n",
      "1e-06 1913\n",
      "1e-06 1914\n",
      "1e-06 1915\n",
      "1e-06 1916\n",
      "1e-06 1917\n",
      "1e-06 1918\n",
      "1e-06 1919\n",
      "1e-06 1920\n",
      "1e-06 1921\n",
      "1e-06 1922\n",
      "1e-06 1923\n",
      "1e-06 1924\n",
      "1e-06 1925\n",
      "1e-06 1926\n",
      "1e-06 1927\n",
      "1e-06 1928\n",
      "1e-06 1929\n",
      "1e-06 1930\n",
      "1e-06 1931\n",
      "1e-06 1932\n",
      "1e-06 1933\n",
      "1e-06 1934\n",
      "1e-06 1935\n",
      "1e-06 1936\n",
      "1e-06 1937\n",
      "1e-06 1938\n",
      "1e-06 1939\n",
      "1e-06 1940\n",
      "1e-06 1941\n",
      "1e-06 1942\n",
      "1e-06 1943\n",
      "1e-06 1944\n",
      "1e-06 1945\n",
      "1e-06 1946\n",
      "1e-06 1947\n",
      "1e-06 1948\n",
      "1e-06 1949\n",
      "1e-06 1950\n",
      "1e-06 1951\n",
      "1e-06 1952\n",
      "1e-06 1953\n",
      "1e-06 1954\n",
      "1e-06 1955\n",
      "1e-06 1956\n",
      "1e-06 1957\n",
      "1e-06 1958\n",
      "1e-06 1959\n",
      "1e-06 1960\n",
      "1e-06 1961\n",
      "1e-06 1962\n",
      "1e-06 1963\n",
      "1e-06 1964\n",
      "1e-06 1965\n",
      "1e-06 1966\n",
      "1e-06 1967\n",
      "1e-06 1968\n",
      "1e-06 1969\n",
      "1e-06 1970\n",
      "1e-06 1971\n",
      "1e-06 1972\n",
      "1e-06 1973\n",
      "1e-06 1974\n",
      "1e-06 1975\n",
      "1e-06 1976\n",
      "1e-06 1977\n",
      "1e-06 1978\n",
      "1e-06 1979\n",
      "1e-06 1980\n",
      "1e-06 1981\n",
      "1e-06 1982\n",
      "1e-06 1983\n",
      "1e-06 1984\n",
      "1e-06 1985\n",
      "1e-06 1986\n",
      "1e-06 1987\n",
      "1e-06 1988\n",
      "1e-06 1989\n",
      "1e-06 1990\n",
      "1e-06 1991\n",
      "1e-06 1992\n",
      "1e-06 1993\n",
      "1e-06 1994\n",
      "1e-06 1995\n",
      "1e-06 1996\n",
      "1e-06 1997\n",
      "1e-06 1998\n",
      "1e-06 1999\n",
      "1e-06 2000\n",
      "1e-06 2001\n",
      "1e-06 2002\n",
      "1e-06 2003\n",
      "1e-06 2004\n",
      "1e-06 2005\n",
      "1e-06 2006\n",
      "1e-06 2007\n",
      "1e-06 2008\n",
      "1e-06 2009\n",
      "1e-06 2010\n",
      "1e-06 2011\n",
      "1e-06 2012\n",
      "1e-06 2013\n",
      "1e-06 2014\n",
      "1e-06 2015\n",
      "1e-06 2016\n",
      "1e-06 2017\n",
      "1e-06 2018\n",
      "1e-06 2019\n",
      "1e-06 2020\n",
      "1e-06 2021\n",
      "1e-06 2022\n",
      "1e-06 2023\n",
      "1e-06 2024\n",
      "1e-06 2025\n",
      "1e-06 2026\n",
      "1e-06 2027\n",
      "1e-06 2028\n",
      "1e-06 2029\n",
      "1e-06 2030\n",
      "1e-06 2031\n",
      "1e-06 2032\n",
      "1e-06 2033\n",
      "1e-06 2034\n",
      "1e-06 2035\n",
      "1e-06 2036\n",
      "1e-06 2037\n",
      "1e-06 2038\n",
      "1e-06 2039\n",
      "1e-06 2040\n",
      "1e-06 2041\n",
      "1e-06 2042\n",
      "1e-06 2043\n",
      "1e-06 2044\n",
      "1e-06 2045\n",
      "1e-06 2046\n",
      "1e-06 2047\n",
      "1e-06 2048\n",
      "1e-06 2049\n",
      "1e-06 2050\n",
      "1e-06 2051\n",
      "1e-06 2052\n",
      "1e-06 2053\n",
      "1e-06 2054\n",
      "1e-06 2055\n",
      "1e-06 2056\n",
      "1e-06 2057\n",
      "1e-06 2058\n",
      "1e-06 2059\n",
      "1e-06 2060\n",
      "1e-06 2061\n",
      "1e-06 2062\n",
      "1e-06 2063\n",
      "1e-06 2064\n",
      "1e-06 2065\n",
      "1e-06 2066\n",
      "1e-06 2067\n",
      "1e-06 2068\n",
      "1e-06 2069\n",
      "1e-06 2070\n",
      "1e-06 2071\n",
      "1e-06 2072\n",
      "1e-06 2073\n",
      "1e-06 2074\n",
      "1e-06 2075\n",
      "1e-06 2076\n",
      "1e-06 2077\n",
      "1e-06 2078\n",
      "1e-06 2079\n",
      "1e-06 2080\n",
      "1e-06 2081\n",
      "1e-06 2082\n",
      "1e-06 2083\n",
      "1e-06 2084\n",
      "1e-06 2085\n",
      "1e-06 2086\n",
      "1e-06 2087\n",
      "1e-06 2088\n",
      "1e-06 2089\n",
      "1e-06 2090\n",
      "1e-06 2091\n",
      "1e-06 2092\n",
      "1e-06 2093\n",
      "1e-06 2094\n",
      "1e-06 2095\n",
      "1e-06 2096\n",
      "1e-06 2097\n",
      "1e-06 2098\n",
      "1e-06 2099\n",
      "1e-06 2100\n",
      "1e-06 2101\n",
      "1e-06 2102\n",
      "1e-06 2103\n",
      "1e-06 2104\n",
      "1e-06 2105\n",
      "1e-06 2106\n",
      "1e-06 2107\n",
      "1e-06 2108\n",
      "1e-06 2109\n",
      "1e-06 2110\n",
      "1e-06 2111\n",
      "1e-06 2112\n",
      "1e-06 2113\n",
      "1e-06 2114\n",
      "1e-06 2115\n",
      "1e-06 2116\n",
      "1e-06 2117\n",
      "1e-06 2118\n",
      "1e-06 2119\n",
      "1e-06 2120\n",
      "1e-06 2121\n",
      "1e-06 2122\n",
      "1e-06 2123\n",
      "1e-06 2124\n",
      "1e-06 2125\n",
      "1e-06 2126\n",
      "1e-06 2127\n",
      "1e-06 2128\n",
      "1e-06 2129\n",
      "1e-06 2130\n",
      "1e-06 2131\n",
      "1e-06 2132\n",
      "1e-06 2133\n",
      "1e-06 2134\n",
      "1e-06 2135\n",
      "1e-06 2136\n",
      "1e-06 2137\n",
      "1e-06 2138\n",
      "1e-06 2139\n",
      "1e-06 2140\n",
      "1e-06 2141\n",
      "1e-06 2142\n",
      "1e-06 2143\n",
      "1e-06 2144\n",
      "1e-06 2145\n",
      "1e-06 2146\n",
      "1e-06 2147\n",
      "1e-06 2148\n",
      "1e-06 2149\n",
      "1e-06 2150\n",
      "1e-06 2151\n",
      "1e-06 2152\n",
      "1e-06 2153\n",
      "1e-06 2154\n",
      "1e-06 2155\n",
      "1e-06 2156\n",
      "1e-06 2157\n",
      "1e-06 2158\n",
      "1e-06 2159\n",
      "1e-06 2160\n",
      "1e-06 2161\n",
      "1e-06 2162\n",
      "1e-06 2163\n",
      "1e-06 2164\n",
      "1e-06 2165\n",
      "1e-06 2166\n",
      "1e-06 2167\n",
      "1e-06 2168\n",
      "1e-06 2169\n",
      "1e-06 2170\n",
      "1e-06 2171\n",
      "1e-06 2172\n",
      "1e-06 2173\n",
      "1e-06 2174\n",
      "1e-06 2175\n",
      "1e-06 2176\n",
      "1e-06 2177\n",
      "1e-06 2178\n",
      "1e-06 2179\n",
      "1e-06 2180\n",
      "1e-06 2181\n",
      "1e-06 2182\n",
      "1e-06 2183\n",
      "1e-06 2184\n",
      "1e-06 2185\n",
      "1e-06 2186\n",
      "1e-06 2187\n",
      "1e-06 2188\n",
      "1e-06 2189\n",
      "1e-06 2190\n",
      "1e-06 2191\n",
      "1e-06 2192\n",
      "1e-06 2193\n",
      "1e-06 2194\n",
      "1e-06 2195\n",
      "1e-06 2196\n",
      "1e-06 2197\n",
      "1e-06 2198\n",
      "1e-06 2199\n",
      "1e-06 2200\n",
      "1e-06 2201\n",
      "1e-06 2202\n",
      "1e-06 2203\n",
      "1e-06 2204\n",
      "1e-06 2205\n",
      "1e-06 2206\n",
      "1e-06 2207\n",
      "1e-06 2208\n",
      "1e-06 2209\n",
      "1e-06 2210\n",
      "1e-06 2211\n",
      "1e-06 2212\n",
      "1e-06 2213\n",
      "1e-06 2214\n",
      "1e-06 2215\n",
      "1e-06 2216\n",
      "1e-06 2217\n",
      "1e-06 2218\n",
      "1e-06 2219\n",
      "1e-06 2220\n",
      "1e-06 2221\n",
      "1e-06 2222\n",
      "1e-06 2223\n",
      "1e-06 2224\n",
      "1e-06 2225\n",
      "1e-06 2226\n",
      "1e-06 2227\n",
      "1e-06 2228\n",
      "1e-06 2229\n",
      "1e-06 2230\n",
      "1e-06 2231\n",
      "1e-06 2232\n",
      "1e-06 2233\n",
      "1e-06 2234\n",
      "1e-06 2235\n",
      "1e-06 2236\n",
      "1e-06 2237\n",
      "1e-06 2238\n",
      "1e-06 2239\n",
      "1e-06 2240\n",
      "1e-06 2241\n",
      "1e-06 2242\n",
      "1e-06 2243\n",
      "1e-06 2244\n",
      "1e-06 2245\n",
      "1e-06 2246\n",
      "1e-06 2247\n",
      "1e-06 2248\n",
      "1e-06 2249\n",
      "1e-06 2250\n",
      "1e-06 2251\n",
      "1e-06 2252\n",
      "1e-06 2253\n",
      "1e-06 2254\n",
      "1e-06 2255\n",
      "1e-06 2256\n",
      "1e-06 2257\n",
      "1e-06 2258\n",
      "1e-06 2259\n",
      "1e-06 2260\n",
      "1e-06 2261\n",
      "1e-06 2262\n",
      "1e-06 2263\n",
      "1e-06 2264\n",
      "1e-06 2265\n",
      "1e-06 2266\n",
      "1e-06 2267\n",
      "1e-06 2268\n",
      "1e-06 2269\n",
      "1e-06 2270\n",
      "1e-06 2271\n",
      "1e-06 2272\n",
      "1e-06 2273\n",
      "1e-06 2274\n",
      "1e-06 2275\n",
      "1e-06 2276\n",
      "1e-06 2277\n",
      "1e-06 2278\n",
      "1e-06 2279\n",
      "1e-06 2280\n",
      "1e-06 2281\n",
      "1e-06 2282\n",
      "1e-06 2283\n",
      "1e-06 2284\n",
      "1e-06 2285\n",
      "1e-06 2286\n",
      "1e-06 2287\n",
      "1e-06 2288\n",
      "1e-06 2289\n",
      "1e-06 2290\n",
      "1e-06 2291\n",
      "1e-06 2292\n",
      "1e-06 2293\n",
      "1e-06 2294\n",
      "1e-06 2295\n",
      "1e-06 2296\n",
      "1e-06 2297\n",
      "1e-06 2298\n",
      "1e-06 2299\n",
      "1e-06 2300\n",
      "1e-06 2301\n",
      "1e-06 2302\n",
      "1e-06 2303\n",
      "1e-06 2304\n",
      "1e-06 2305\n",
      "1e-06 2306\n",
      "1e-06 2307\n",
      "1e-06 2308\n",
      "1e-06 2309\n",
      "1e-06 2310\n",
      "1e-06 2311\n",
      "1e-06 2312\n",
      "1e-06 2313\n",
      "1e-06 2314\n",
      "1e-06 2315\n",
      "1e-06 2316\n",
      "1e-06 2317\n",
      "1e-06 2318\n",
      "1e-06 2319\n",
      "1e-06 2320\n",
      "1e-06 2321\n",
      "1e-06 2322\n",
      "1e-06 2323\n",
      "1e-06 2324\n",
      "1e-06 2325\n",
      "1e-06 2326\n",
      "1e-06 2327\n",
      "1e-06 2328\n",
      "1e-06 2329\n",
      "1e-06 2330\n",
      "1e-06 2331\n",
      "1e-06 2332\n",
      "1e-06 2333\n",
      "1e-06 2334\n",
      "1e-06 2335\n",
      "1e-06 2336\n",
      "1e-06 2337\n",
      "1e-06 2338\n",
      "1e-06 2339\n",
      "1e-06 2340\n",
      "1e-06 2341\n",
      "1e-06 2342\n",
      "1e-06 2343\n",
      "1e-06 2344\n",
      "1e-06 2345\n",
      "1e-06 2346\n",
      "1e-06 2347\n",
      "1e-06 2348\n",
      "1e-06 2349\n",
      "1e-06 2350\n",
      "1e-06 2351\n",
      "1e-06 2352\n",
      "1e-06 2353\n",
      "1e-06 2354\n",
      "1e-06 2355\n",
      "1e-06 2356\n",
      "1e-06 2357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-06 2358\n",
      "1e-06 2359\n",
      "1e-06 2360\n",
      "1e-06 2361\n",
      "1e-06 2362\n",
      "1e-06 2363\n",
      "1e-06 2364\n",
      "1e-06 2365\n",
      "1e-06 2366\n",
      "1e-06 2367\n",
      "1e-06 2368\n",
      "1e-06 2369\n",
      "1e-06 2370\n",
      "1e-06 2371\n",
      "1e-06 2372\n",
      "1e-06 2373\n",
      "1e-06 2374\n",
      "1e-06 2375\n",
      "1e-06 2376\n",
      "1e-06 2377\n",
      "1e-06 2378\n",
      "1e-06 2379\n",
      "1e-06 2380\n",
      "1e-06 2381\n",
      "1e-06 2382\n",
      "1e-06 2383\n",
      "1e-06 2384\n",
      "1e-06 2385\n",
      "1e-06 2386\n",
      "1e-06 2387\n",
      "1e-06 2388\n",
      "1e-06 2389\n",
      "1e-06 2390\n",
      "1e-06 2391\n",
      "1e-06 2392\n",
      "1e-06 2393\n",
      "1e-06 2394\n",
      "1e-06 2395\n",
      "1e-06 2396\n",
      "1e-06 2397\n",
      "1e-06 2398\n",
      "1e-06 2399\n",
      "1e-06 2400\n",
      "1e-06 2401\n",
      "1e-06 2402\n",
      "1e-06 2403\n",
      "1e-06 2404\n",
      "1e-06 2405\n",
      "1e-06 2406\n",
      "1e-06 2407\n",
      "1e-06 2408\n",
      "1e-06 2409\n",
      "1e-06 2410\n",
      "1e-06 2411\n",
      "1e-06 2412\n",
      "1e-06 2413\n",
      "1e-06 2414\n",
      "1e-06 2415\n",
      "1e-06 2416\n",
      "1e-06 2417\n",
      "1e-06 2418\n",
      "1e-06 2419\n",
      "1e-06 2420\n",
      "1e-06 2421\n",
      "1e-06 2422\n",
      "1e-06 2423\n",
      "1e-06 2424\n",
      "1e-06 2425\n",
      "1e-06 2426\n",
      "1e-06 2427\n",
      "1e-06 2428\n",
      "1e-06 2429\n",
      "1e-06 2430\n",
      "1e-06 2431\n",
      "1e-06 2432\n",
      "1e-06 2433\n",
      "1e-06 2434\n",
      "1e-06 2435\n",
      "1e-06 2436\n",
      "1e-06 2437\n",
      "1e-06 2438\n",
      "1e-06 2439\n",
      "1e-06 2440\n",
      "1e-06 2441\n",
      "1e-06 2442\n",
      "1e-06 2443\n",
      "1e-06 2444\n",
      "1e-06 2445\n",
      "1e-06 2446\n",
      "1e-06 2447\n",
      "1e-06 2448\n",
      "1e-06 2449\n",
      "1e-06 2450\n",
      "1e-06 2451\n",
      "1e-06 2452\n",
      "1e-06 2453\n",
      "1e-06 2454\n",
      "1e-06 2455\n",
      "1e-06 2456\n",
      "1e-06 2457\n",
      "1e-06 2458\n",
      "1e-06 2459\n",
      "1e-06 2460\n",
      "1e-06 2461\n",
      "1e-06 2462\n",
      "1e-06 2463\n",
      "1e-06 2464\n",
      "1e-06 2465\n",
      "1e-06 2466\n",
      "1e-06 2467\n",
      "1e-06 2468\n",
      "1e-06 2469\n",
      "1e-06 2470\n",
      "1e-06 2471\n",
      "1e-06 2472\n",
      "1e-06 2473\n",
      "1e-06 2474\n",
      "1e-06 2475\n",
      "1e-06 2476\n",
      "1e-06 2477\n",
      "1e-06 2478\n",
      "1e-06 2479\n",
      "1e-06 2480\n",
      "1e-06 2481\n",
      "1e-06 2482\n",
      "1e-06 2483\n",
      "1e-06 2484\n",
      "1e-06 2485\n",
      "1e-06 2486\n",
      "1e-06 2487\n",
      "1e-06 2488\n",
      "1e-06 2489\n",
      "1e-06 2490\n",
      "1e-06 2491\n",
      "1e-06 2492\n",
      "1e-06 2493\n",
      "1e-06 2494\n",
      "1e-06 2495\n",
      "1e-06 2496\n",
      "1e-06 2497\n",
      "1e-06 2498\n",
      "1e-06 2499\n",
      "1e-06 2500\n",
      "1e-06 2501\n",
      "1e-06 2502\n",
      "1e-06 2503\n",
      "1e-06 2504\n",
      "1e-06 2505\n",
      "1e-06 2506\n",
      "1e-06 2507\n",
      "1e-06 2508\n",
      "1e-06 2509\n",
      "1e-06 2510\n",
      "1e-06 2511\n",
      "1e-06 2512\n",
      "1e-06 2513\n",
      "1e-06 2514\n",
      "1e-06 2515\n",
      "1e-06 2516\n",
      "1e-06 2517\n",
      "1e-06 2518\n",
      "1e-06 2519\n",
      "1e-06 2520\n",
      "1e-06 2521\n",
      "1e-06 2522\n",
      "1e-06 2523\n",
      "1e-06 2524\n",
      "1e-06 2525\n",
      "1e-06 2526\n",
      "1e-06 2527\n",
      "1e-06 2528\n",
      "1e-06 2529\n",
      "1e-06 2530\n",
      "1e-06 2531\n",
      "1e-06 2532\n",
      "1e-06 2533\n",
      "1e-06 2534\n",
      "1e-06 2535\n",
      "1e-06 2536\n",
      "1e-06 2537\n",
      "1e-06 2538\n",
      "1e-06 2539\n",
      "1e-06 2540\n",
      "1e-06 2541\n",
      "1e-06 2542\n",
      "1e-06 2543\n",
      "1e-06 2544\n",
      "1e-06 2545\n",
      "1e-06 2546\n",
      "1e-06 2547\n",
      "1e-06 2548\n",
      "1e-06 2549\n",
      "1e-06 2550\n",
      "1e-06 2551\n",
      "1e-06 2552\n",
      "1e-06 2553\n",
      "1e-06 2554\n",
      "1e-06 2555\n",
      "1e-06 2556\n",
      "1e-06 2557\n",
      "1e-06 2558\n",
      "1e-06 2559\n",
      "1e-06 2560\n",
      "1e-06 2561\n",
      "1e-06 2562\n",
      "1e-06 2563\n",
      "1e-06 2564\n",
      "1e-06 2565\n",
      "1e-06 2566\n",
      "1e-06 2567\n",
      "1e-06 2568\n",
      "1e-06 2569\n",
      "1e-06 2570\n",
      "1e-06 2571\n",
      "1e-06 2572\n",
      "1e-06 2573\n",
      "1e-06 2574\n",
      "1e-06 2575\n",
      "1e-06 2576\n",
      "1e-06 2577\n",
      "1e-06 2578\n",
      "1e-06 2579\n",
      "1e-06 2580\n",
      "1e-06 2581\n",
      "1e-06 2582\n",
      "1e-06 2583\n",
      "1e-06 2584\n",
      "1e-06 2585\n",
      "1e-06 2586\n",
      "1e-06 2587\n",
      "1e-06 2588\n",
      "1e-06 2589\n",
      "1e-06 2590\n",
      "1e-06 2591\n",
      "1e-06 2592\n",
      "1e-06 2593\n",
      "1e-06 2594\n",
      "1e-06 2595\n",
      "1e-06 2596\n",
      "1e-06 2597\n",
      "1e-06 2598\n",
      "1e-06 2599\n",
      "1e-06 2600\n",
      "1e-06 2601\n",
      "1e-06 2602\n",
      "1e-06 2603\n",
      "1e-06 2604\n",
      "1e-06 2605\n",
      "1e-06 2606\n",
      "1e-06 2607\n",
      "1e-06 2608\n",
      "1e-06 2609\n",
      "1e-06 2610\n",
      "1e-06 2611\n",
      "1e-06 2612\n",
      "1e-06 2613\n",
      "1e-06 2614\n",
      "1e-06 2615\n",
      "1e-06 2616\n",
      "1e-06 2617\n",
      "1e-06 2618\n",
      "1e-06 2619\n",
      "1e-06 2620\n",
      "1e-06 2621\n",
      "1e-06 2622\n",
      "1e-06 2623\n",
      "1e-06 2624\n",
      "1e-06 2625\n",
      "1e-06 2626\n",
      "1e-06 2627\n",
      "1e-06 2628\n",
      "1e-06 2629\n",
      "1e-06 2630\n",
      "1e-06 2631\n",
      "1e-06 2632\n",
      "1e-06 2633\n",
      "1e-06 2634\n",
      "1e-06 2635\n",
      "1e-06 2636\n",
      "1e-06 2637\n",
      "1e-06 2638\n",
      "1e-06 2639\n",
      "1e-06 2640\n",
      "1e-06 2641\n",
      "1e-06 2642\n",
      "1e-06 2643\n",
      "1e-06 2644\n",
      "1e-06 2645\n",
      "1e-06 2646\n",
      "1e-06 2647\n",
      "1e-06 2648\n",
      "1e-06 2649\n",
      "1e-06 2650\n",
      "1e-06 2651\n",
      "1e-06 2652\n",
      "1e-06 2653\n",
      "1e-06 2654\n",
      "1e-06 2655\n",
      "1e-06 2656\n",
      "1e-06 2657\n",
      "1e-06 2658\n",
      "1e-06 2659\n",
      "1e-06 2660\n",
      "1e-06 2661\n",
      "1e-06 2662\n",
      "1e-06 2663\n",
      "1e-06 2664\n",
      "1e-06 2665\n",
      "1e-06 2666\n",
      "1e-06 2667\n",
      "1e-06 2668\n",
      "1e-06 2669\n",
      "1e-06 2670\n",
      "1e-06 2671\n",
      "1e-06 2672\n",
      "1e-06 2673\n",
      "1e-06 2674\n",
      "1e-06 2675\n",
      "1e-06 2676\n",
      "1e-06 2677\n",
      "1e-06 2678\n",
      "1e-06 2679\n",
      "1e-06 2680\n",
      "1e-06 2681\n",
      "1e-06 2682\n",
      "1e-06 2683\n",
      "1e-06 2684\n",
      "1e-06 2685\n",
      "1e-06 2686\n",
      "1e-06 2687\n",
      "1e-06 2688\n",
      "1e-06 2689\n",
      "1e-06 2690\n",
      "1e-06 2691\n",
      "1e-06 2692\n",
      "1e-06 2693\n",
      "1e-06 2694\n",
      "1e-06 2695\n",
      "1e-06 2696\n",
      "1e-06 2697\n",
      "1e-06 2698\n",
      "1e-06 2699\n",
      "1e-06 2700\n",
      "1e-06 2701\n",
      "1e-06 2702\n",
      "1e-06 2703\n",
      "1e-06 2704\n",
      "1e-06 2705\n",
      "1e-06 2706\n",
      "1e-06 2707\n",
      "1e-06 2708\n",
      "1e-06 2709\n",
      "1e-06 2710\n",
      "1e-06 2711\n",
      "1e-06 2712\n",
      "1e-06 2713\n",
      "1e-06 2714\n",
      "1e-06 2715\n",
      "1e-06 2716\n",
      "1e-06 2717\n",
      "1e-06 2718\n",
      "1e-06 2719\n",
      "1e-06 2720\n",
      "1e-06 2721\n",
      "1e-06 2722\n",
      "1e-06 2723\n",
      "1e-06 2724\n",
      "1e-06 2725\n",
      "1e-06 2726\n",
      "1e-06 2727\n",
      "1e-06 2728\n",
      "1e-06 2729\n",
      "1e-06 2730\n",
      "1e-06 2731\n",
      "1e-06 2732\n",
      "1e-06 2733\n",
      "1e-06 2734\n",
      "1e-06 2735\n",
      "1e-06 2736\n",
      "1e-06 2737\n",
      "1e-06 2738\n",
      "1e-06 2739\n",
      "1e-06 2740\n",
      "1e-06 2741\n",
      "1e-06 2742\n",
      "1e-06 2743\n",
      "1e-06 2744\n",
      "1e-06 2745\n",
      "1e-06 2746\n",
      "1e-06 2747\n",
      "1e-06 2748\n",
      "1e-06 2749\n",
      "1e-06 2750\n",
      "1e-06 2751\n",
      "1e-06 2752\n",
      "1e-06 2753\n",
      "1e-06 2754\n",
      "1e-06 2755\n",
      "1e-06 2756\n",
      "1e-06 2757\n",
      "1e-06 2758\n",
      "1e-06 2759\n",
      "1e-06 2760\n",
      "1e-06 2761\n",
      "1e-06 2762\n",
      "1e-06 2763\n",
      "1e-06 2764\n",
      "1e-06 2765\n",
      "1e-06 2766\n",
      "1e-06 2767\n",
      "1e-06 2768\n",
      "1e-06 2769\n",
      "1e-06 2770\n",
      "1e-06 2771\n",
      "1e-06 2772\n",
      "1e-06 2773\n",
      "1e-06 2774\n",
      "1e-06 2775\n",
      "1e-06 2776\n",
      "1e-06 2777\n",
      "1e-06 2778\n",
      "1e-06 2779\n",
      "1e-06 2780\n",
      "1e-06 2781\n",
      "1e-06 2782\n",
      "1e-06 2783\n",
      "1e-06 2784\n",
      "1e-06 2785\n",
      "1e-06 2786\n",
      "1e-06 2787\n",
      "1e-06 2788\n",
      "1e-06 2789\n",
      "1e-06 2790\n",
      "1e-06 2791\n",
      "1e-06 2792\n",
      "1e-06 2793\n",
      "1e-06 2794\n",
      "1e-06 2795\n",
      "1e-06 2796\n",
      "1e-06 2797\n",
      "1e-06 2798\n",
      "1e-06 2799\n",
      "1e-06 2800\n",
      "1e-06 2801\n",
      "1e-06 2802\n",
      "1e-06 2803\n",
      "1e-06 2804\n",
      "1e-06 2805\n",
      "1e-06 2806\n",
      "1e-06 2807\n",
      "1e-06 2808\n",
      "1e-06 2809\n",
      "1e-06 2810\n",
      "1e-06 2811\n",
      "1e-06 2812\n",
      "1e-06 2813\n",
      "1e-06 2814\n",
      "1e-06 2815\n",
      "1e-06 2816\n",
      "1e-06 2817\n",
      "1e-06 2818\n",
      "1e-06 2819\n",
      "1e-06 2820\n",
      "1e-06 2821\n",
      "1e-06 2822\n",
      "1e-06 2823\n",
      "1e-06 2824\n",
      "1e-06 2825\n",
      "1e-06 2826\n",
      "1e-06 2827\n",
      "1e-06 2828\n",
      "1e-06 2829\n",
      "1e-06 2830\n",
      "1e-06 2831\n",
      "1e-06 2832\n",
      "1e-06 2833\n",
      "1e-06 2834\n",
      "1e-06 2835\n",
      "1e-06 2836\n",
      "1e-06 2837\n",
      "1e-06 2838\n",
      "1e-06 2839\n",
      "1e-06 2840\n",
      "1e-06 2841\n",
      "1e-06 2842\n",
      "1e-06 2843\n",
      "1e-06 2844\n",
      "1e-06 2845\n",
      "1e-06 2846\n",
      "1e-06 2847\n",
      "1e-06 2848\n",
      "1e-06 2849\n",
      "1e-06 2850\n",
      "1e-06 2851\n",
      "1e-06 2852\n",
      "1e-06 2853\n",
      "1e-06 2854\n",
      "1e-06 2855\n",
      "1e-06 2856\n",
      "1e-06 2857\n",
      "1e-06 2858\n",
      "1e-06 2859\n",
      "1e-06 2860\n",
      "1e-06 2861\n",
      "1e-06 2862\n",
      "1e-06 2863\n",
      "1e-06 2864\n",
      "1e-06 2865\n",
      "1e-06 2866\n",
      "1e-06 2867\n",
      "1e-06 2868\n",
      "1e-06 2869\n",
      "1e-06 2870\n",
      "1e-06 2871\n",
      "1e-06 2872\n",
      "1e-06 2873\n",
      "1e-06 2874\n",
      "1e-06 2875\n",
      "1e-06 2876\n",
      "1e-06 2877\n",
      "1e-06 2878\n",
      "1e-06 2879\n",
      "1e-06 2880\n",
      "1e-06 2881\n",
      "1e-06 2882\n",
      "1e-06 2883\n",
      "1e-06 2884\n",
      "1e-06 2885\n",
      "1e-06 2886\n",
      "1e-06 2887\n",
      "1e-06 2888\n",
      "1e-06 2889\n",
      "1e-06 2890\n",
      "1e-06 2891\n",
      "1e-06 2892\n",
      "1e-06 2893\n",
      "1e-06 2894\n",
      "1e-06 2895\n",
      "1e-06 2896\n",
      "1e-06 2897\n",
      "1e-06 2898\n",
      "1e-06 2899\n",
      "1e-06 2900\n",
      "1e-06 2901\n",
      "1e-06 2902\n",
      "1e-06 2903\n",
      "1e-06 2904\n",
      "1e-06 2905\n",
      "1e-06 2906\n",
      "1e-06 2907\n",
      "1e-06 2908\n",
      "1e-06 2909\n",
      "1e-06 2910\n",
      "1e-06 2911\n",
      "1e-06 2912\n",
      "1e-06 2913\n",
      "1e-06 2914\n",
      "1e-06 2915\n",
      "1e-06 2916\n",
      "1e-06 2917\n",
      "1e-06 2918\n",
      "1e-06 2919\n",
      "1e-06 2920\n",
      "1e-06 2921\n",
      "1e-06 2922\n",
      "1e-06 2923\n",
      "1e-06 2924\n",
      "1e-06 2925\n",
      "1e-06 2926\n",
      "1e-06 2927\n",
      "1e-06 2928\n",
      "1e-06 2929\n",
      "1e-06 2930\n",
      "1e-06 2931\n",
      "1e-06 2932\n",
      "1e-06 2933\n",
      "1e-06 2934\n",
      "1e-06 2935\n",
      "1e-06 2936\n",
      "1e-06 2937\n",
      "1e-06 2938\n",
      "1e-06 2939\n",
      "1e-06 2940\n",
      "1e-06 2941\n",
      "1e-06 2942\n",
      "1e-06 2943\n",
      "1e-06 2944\n",
      "1e-06 2945\n",
      "1e-06 2946\n",
      "1e-06 2947\n",
      "1e-06 2948\n",
      "1e-06 2949\n",
      "1e-06 2950\n",
      "1e-06 2951\n",
      "1e-06 2952\n",
      "1e-06 2953\n",
      "1e-06 2954\n",
      "1e-06 2955\n",
      "1e-06 2956\n",
      "1e-06 2957\n",
      "1e-06 2958\n",
      "1e-06 2959\n",
      "1e-06 2960\n",
      "1e-06 2961\n",
      "1e-06 2962\n",
      "1e-06 2963\n",
      "1e-06 2964\n",
      "1e-06 2965\n",
      "1e-06 2966\n",
      "1e-06 2967\n",
      "1e-06 2968\n",
      "1e-06 2969\n",
      "1e-06 2970\n",
      "1e-06 2971\n",
      "1e-06 2972\n",
      "1e-06 2973\n",
      "1e-06 2974\n",
      "1e-06 2975\n",
      "1e-06 2976\n",
      "1e-06 2977\n",
      "1e-06 2978\n",
      "1e-06 2979\n",
      "1e-06 2980\n",
      "1e-06 2981\n",
      "1e-06 2982\n",
      "1e-06 2983\n",
      "1e-06 2984\n",
      "1e-06 2985\n",
      "1e-06 2986\n",
      "1e-06 2987\n",
      "1e-06 2988\n",
      "1e-06 2989\n",
      "1e-06 2990\n",
      "1e-06 2991\n",
      "1e-06 2992\n",
      "1e-06 2993\n",
      "1e-06 2994\n",
      "1e-06 2995\n",
      "1e-06 2996\n",
      "1e-06 2997\n",
      "1e-06 2998\n",
      "1e-06 2999\n",
      "1e-06 3000\n",
      "1e-06 3001\n",
      "1e-06 3002\n",
      "1e-06 3003\n",
      "1e-06 3004\n",
      "1e-06 3005\n",
      "1e-06 3006\n",
      "1e-06 3007\n",
      "1e-06 3008\n",
      "1e-06 3009\n",
      "1e-06 3010\n",
      "1e-06 3011\n",
      "1e-06 3012\n",
      "1e-06 3013\n",
      "1e-06 3014\n",
      "1e-06 3015\n",
      "1e-06 3016\n",
      "1e-06 3017\n",
      "1e-06 3018\n",
      "1e-06 3019\n",
      "1e-06 3020\n",
      "1e-06 3021\n",
      "1e-06 3022\n",
      "1e-06 3023\n",
      "1e-06 3024\n",
      "1e-06 3025\n",
      "1e-06 3026\n",
      "1e-06 3027\n",
      "1e-06 3028\n",
      "1e-06 3029\n",
      "1e-06 3030\n",
      "1e-06 3031\n",
      "1e-06 3032\n",
      "1e-06 3033\n",
      "1e-06 3034\n",
      "1e-06 3035\n",
      "1e-06 3036\n",
      "1e-06 3037\n",
      "1e-06 3038\n",
      "1e-06 3039\n",
      "1e-06 3040\n",
      "1e-06 3041\n",
      "1e-06 3042\n",
      "1e-06 3043\n",
      "1e-06 3044\n",
      "1e-06 3045\n",
      "1e-06 3046\n",
      "1e-06 3047\n",
      "1e-06 3048\n",
      "1e-06 3049\n",
      "1e-06 3050\n",
      "1e-06 3051\n",
      "1e-06 3052\n",
      "1e-06 3053\n",
      "1e-06 3054\n",
      "1e-06 3055\n",
      "1e-06 3056\n",
      "1e-06 3057\n",
      "1e-06 3058\n",
      "1e-06 3059\n",
      "1e-06 3060\n",
      "1e-06 3061\n",
      "1e-06 3062\n",
      "1e-06 3063\n",
      "1e-06 3064\n",
      "1e-06 3065\n",
      "1e-06 3066\n",
      "1e-06 3067\n",
      "1e-06 3068\n",
      "1e-06 3069\n",
      "1e-06 3070\n",
      "1e-06 3071\n",
      "1e-06 3072\n",
      "1e-06 3073\n",
      "1e-06 3074\n",
      "1e-06 3075\n",
      "1e-06 3076\n",
      "1e-06 3077\n",
      "1e-06 3078\n",
      "1e-06 3079\n",
      "1e-06 3080\n",
      "1e-06 3081\n",
      "1e-06 3082\n",
      "1e-06 3083\n",
      "1e-06 3084\n",
      "1e-06 3085\n",
      "1e-06 3086\n",
      "1e-06 3087\n",
      "1e-06 3088\n",
      "1e-06 3089\n",
      "1e-06 3090\n",
      "1e-06 3091\n",
      "1e-06 3092\n",
      "1e-06 3093\n",
      "1e-06 3094\n",
      "1e-06 3095\n",
      "1e-06 3096\n",
      "1e-06 3097\n",
      "1e-06 3098\n",
      "1e-06 3099\n",
      "1e-06 3100\n",
      "1e-06 3101\n",
      "1e-06 3102\n",
      "1e-06 3103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-06 3104\n",
      "1e-06 3105\n",
      "1e-06 3106\n",
      "1e-06 3107\n",
      "1e-06 3108\n",
      "1e-06 3109\n",
      "1e-06 3110\n",
      "1e-06 3111\n",
      "1e-06 3112\n",
      "1e-06 3113\n",
      "1e-06 3114\n",
      "1e-06 3115\n",
      "1e-06 3116\n",
      "1e-06 3117\n",
      "1e-06 3118\n",
      "1e-06 3119\n",
      "1e-06 3120\n",
      "1e-06 3121\n",
      "1e-06 3122\n",
      "1e-06 3123\n",
      "1e-06 3124\n",
      "1e-06 3125\n",
      "1e-06 3126\n",
      "1e-06 3127\n",
      "1e-06 3128\n",
      "1e-06 3129\n",
      "1e-06 3130\n",
      "1e-06 3131\n",
      "1e-06 3132\n",
      "1e-06 3133\n",
      "1e-06 3134\n",
      "1e-06 3135\n",
      "1e-06 3136\n",
      "1e-06 3137\n",
      "1e-06 3138\n",
      "1e-06 3139\n",
      "1e-06 3140\n",
      "1e-06 3141\n",
      "1e-06 3142\n",
      "1e-06 3143\n",
      "1e-06 3144\n",
      "1e-06 3145\n",
      "1e-06 3146\n",
      "1e-06 3147\n",
      "1e-06 3148\n",
      "1e-06 3149\n",
      "1e-06 3150\n",
      "1e-06 3151\n",
      "1e-06 3152\n",
      "1e-06 3153\n",
      "1e-06 3154\n",
      "1e-06 3155\n",
      "1e-06 3156\n",
      "1e-06 3157\n",
      "1e-06 3158\n",
      "1e-06 3159\n",
      "1e-06 3160\n",
      "1e-06 3161\n",
      "1e-06 3162\n",
      "1e-06 3163\n",
      "1e-06 3164\n",
      "1e-06 3165\n",
      "1e-06 3166\n",
      "1e-06 3167\n",
      "1e-06 3168\n",
      "1e-06 3169\n",
      "1e-06 3170\n",
      "1e-06 3171\n",
      "1e-06 3172\n",
      "1e-06 3173\n",
      "1e-06 3174\n",
      "1e-06 3175\n",
      "1e-06 3176\n",
      "1e-06 3177\n",
      "1e-06 3178\n",
      "1e-06 3179\n",
      "1e-06 3180\n",
      "1e-06 3181\n",
      "1e-06 3182\n",
      "1e-06 3183\n",
      "1e-06 3184\n",
      "1e-06 3185\n",
      "1e-06 3186\n",
      "1e-06 3187\n",
      "1e-06 3188\n",
      "1e-06 3189\n",
      "1e-06 3190\n",
      "1e-06 3191\n",
      "1e-06 3192\n",
      "1e-06 3193\n",
      "1e-06 3194\n",
      "1e-06 3195\n",
      "1e-06 3196\n",
      "1e-06 3197\n",
      "1e-06 3198\n",
      "1e-06 3199\n",
      "1e-06 3200\n",
      "1e-06 3201\n",
      "1e-06 3202\n",
      "1e-06 3203\n",
      "1e-06 3204\n",
      "1e-06 3205\n",
      "1e-06 3206\n",
      "1e-06 3207\n",
      "1e-06 3208\n",
      "1e-06 3209\n",
      "1e-06 3210\n",
      "1e-06 3211\n",
      "1e-06 3212\n",
      "1e-06 3213\n",
      "1e-06 3214\n",
      "1e-06 3215\n",
      "1e-06 3216\n",
      "1e-06 3217\n",
      "1e-06 3218\n",
      "1e-06 3219\n",
      "1e-06 3220\n",
      "1e-06 3221\n",
      "1e-06 3222\n",
      "1e-06 3223\n",
      "1e-06 3224\n",
      "1e-06 3225\n",
      "1e-06 3226\n",
      "1e-06 3227\n",
      "1e-06 3228\n",
      "1e-06 3229\n",
      "1e-06 3230\n",
      "1e-06 3231\n",
      "1e-06 3232\n",
      "1e-06 3233\n",
      "1e-06 3234\n",
      "1e-06 3235\n",
      "1e-06 3236\n",
      "1e-06 3237\n",
      "1e-06 3238\n",
      "1e-06 3239\n",
      "1e-06 3240\n",
      "1e-06 3241\n",
      "1e-06 3242\n",
      "1e-06 3243\n",
      "1e-06 3244\n",
      "1e-06 3245\n",
      "1e-06 3246\n",
      "1e-06 3247\n",
      "1e-06 3248\n",
      "1e-06 3249\n",
      "1e-06 3250\n",
      "1e-06 3251\n",
      "1e-06 3252\n",
      "1e-06 3253\n",
      "1e-06 3254\n",
      "1e-06 3255\n",
      "1e-06 3256\n",
      "1e-06 3257\n",
      "1e-06 3258\n",
      "1e-06 3259\n",
      "1e-06 3260\n",
      "1e-06 3261\n",
      "1e-06 3262\n",
      "1e-06 3263\n",
      "1e-06 3264\n",
      "1e-06 3265\n",
      "1e-06 3266\n",
      "1e-06 3267\n",
      "1e-06 3268\n",
      "1e-06 3269\n",
      "1e-06 3270\n",
      "1e-06 3271\n",
      "1e-06 3272\n",
      "1e-06 3273\n",
      "1e-06 3274\n",
      "1e-06 3275\n",
      "1e-06 3276\n",
      "1e-06 3277\n",
      "1e-06 3278\n",
      "1e-06 3279\n",
      "1e-06 3280\n",
      "1e-06 3281\n",
      "1e-06 3282\n",
      "1e-06 3283\n",
      "1e-06 3284\n",
      "1e-06 3285\n",
      "1e-06 3286\n",
      "1e-06 3287\n",
      "1e-06 3288\n",
      "1e-06 3289\n",
      "1e-06 3290\n",
      "1e-06 3291\n",
      "1e-06 3292\n",
      "1e-06 3293\n",
      "1e-06 3294\n",
      "1e-06 3295\n",
      "1e-06 3296\n",
      "1e-06 3297\n",
      "1e-06 3298\n",
      "1e-06 3299\n",
      "1e-06 3300\n",
      "1e-06 3301\n",
      "1e-06 3302\n",
      "1e-06 3303\n",
      "1e-06 3304\n",
      "1e-06 3305\n",
      "1e-06 3306\n",
      "1e-06 3307\n",
      "1e-06 3308\n",
      "1e-06 3309\n",
      "1e-06 3310\n",
      "1e-06 3311\n",
      "1e-06 3312\n",
      "1e-06 3313\n",
      "1e-06 3314\n",
      "1e-06 3315\n",
      "1e-06 3316\n",
      "1e-06 3317\n",
      "1e-06 3318\n",
      "1e-06 3319\n",
      "1e-06 3320\n",
      "1e-06 3321\n",
      "1e-06 3322\n",
      "1e-06 3323\n",
      "1e-06 3324\n",
      "1e-06 3325\n",
      "1e-06 3326\n",
      "1e-06 3327\n",
      "1e-06 3328\n",
      "1e-06 3329\n",
      "1e-06 3330\n",
      "1e-06 3331\n",
      "1e-06 3332\n",
      "1e-06 3333\n",
      "1e-06 3334\n",
      "1e-06 3335\n",
      "1e-06 3336\n",
      "1e-06 3337\n",
      "1e-06 3338\n",
      "1e-06 3339\n",
      "1e-06 3340\n",
      "1e-06 3341\n",
      "1e-06 3342\n",
      "1e-06 3343\n",
      "1e-06 3344\n",
      "1e-06 3345\n",
      "1e-06 3346\n",
      "1e-06 3347\n",
      "1e-06 3348\n",
      "1e-06 3349\n",
      "1e-06 3350\n",
      "1e-06 3351\n",
      "1e-06 3352\n",
      "1e-06 3353\n",
      "1e-06 3354\n",
      "1e-06 3355\n",
      "1e-06 3356\n",
      "1e-06 3357\n",
      "1e-06 3358\n",
      "1e-06 3359\n",
      "1e-06 3360\n",
      "1e-06 3361\n",
      "1e-06 3362\n",
      "1e-06 3363\n",
      "1e-06 3364\n",
      "1e-06 3365\n",
      "1e-06 3366\n",
      "1e-06 3367\n",
      "1e-06 3368\n",
      "1e-06 3369\n",
      "1e-06 3370\n",
      "1e-06 3371\n",
      "1e-06 3372\n",
      "1e-06 3373\n",
      "1e-06 3374\n",
      "1e-06 3375\n",
      "1e-06 3376\n",
      "1e-06 3377\n",
      "1e-06 3378\n",
      "1e-06 3379\n",
      "1e-06 3380\n",
      "1e-06 3381\n",
      "1e-06 3382\n",
      "1e-06 3383\n",
      "1e-06 3384\n",
      "1e-06 3385\n",
      "1e-06 3386\n",
      "1e-06 3387\n",
      "1e-06 3388\n",
      "1e-06 3389\n",
      "1e-06 3390\n",
      "1e-06 3391\n",
      "1e-06 3392\n",
      "1e-06 3393\n",
      "1e-06 3394\n",
      "1e-06 3395\n",
      "1e-06 3396\n",
      "1e-06 3397\n",
      "1e-06 3398\n",
      "1e-06 3399\n",
      "1e-06 3400\n",
      "1e-06 3401\n",
      "1e-06 3402\n",
      "1e-06 3403\n",
      "1e-06 3404\n",
      "1e-06 3405\n",
      "1e-06 3406\n",
      "1e-06 3407\n",
      "1e-06 3408\n",
      "1e-06 3409\n",
      "1e-06 3410\n",
      "1e-06 3411\n",
      "1e-06 3412\n",
      "1e-06 3413\n",
      "1e-06 3414\n",
      "1e-06 3415\n",
      "1e-06 3416\n",
      "1e-06 3417\n",
      "1e-06 3418\n",
      "1e-06 3419\n",
      "1e-06 3420\n",
      "1e-06 3421\n",
      "1e-06 3422\n",
      "1e-06 3423\n",
      "1e-06 3424\n",
      "1e-06 3425\n",
      "1e-06 3426\n",
      "1e-06 3427\n",
      "1e-06 3428\n",
      "1e-06 3429\n",
      "1e-06 3430\n",
      "1e-06 3431\n",
      "1e-06 3432\n",
      "1e-06 3433\n",
      "1e-06 3434\n",
      "1e-06 3435\n",
      "1e-06 3436\n",
      "1e-06 3437\n",
      "1e-06 3438\n",
      "1e-06 3439\n",
      "1e-06 3440\n",
      "1e-06 3441\n",
      "1e-06 3442\n",
      "1e-06 3443\n",
      "1e-06 3444\n",
      "1e-06 3445\n",
      "1e-06 3446\n",
      "1e-06 3447\n",
      "1e-06 3448\n",
      "1e-06 3449\n",
      "1e-06 3450\n",
      "1e-06 3451\n",
      "1e-06 3452\n",
      "1e-06 3453\n",
      "1e-06 3454\n",
      "1e-06 3455\n",
      "1e-06 3456\n",
      "1e-06 3457\n",
      "1e-06 3458\n",
      "1e-06 3459\n",
      "1e-06 3460\n",
      "1e-06 3461\n",
      "1e-06 3462\n",
      "1e-06 3463\n",
      "1e-06 3464\n",
      "1e-06 3465\n",
      "1e-06 3466\n",
      "1e-06 3467\n",
      "1e-06 3468\n",
      "1e-06 3469\n",
      "1e-06 3470\n",
      "1e-06 3471\n",
      "1e-06 3472\n",
      "1e-06 3473\n",
      "1e-06 3474\n",
      "1e-06 3475\n",
      "1e-06 3476\n",
      "1e-06 3477\n",
      "1e-06 3478\n",
      "1e-06 3479\n",
      "1e-06 3480\n",
      "1e-06 3481\n",
      "1e-06 3482\n",
      "1e-06 3483\n",
      "1e-06 3484\n",
      "1e-06 3485\n",
      "1e-06 3486\n",
      "1e-06 3487\n",
      "1e-06 3488\n",
      "1e-06 3489\n",
      "1e-06 3490\n",
      "1e-06 3491\n",
      "1e-06 3492\n",
      "1e-06 3493\n",
      "1e-06 3494\n",
      "1e-06 3495\n",
      "1e-06 3496\n",
      "1e-06 3497\n",
      "1e-06 3498\n",
      "1e-06 3499\n",
      "1e-06 3500\n",
      "1e-06 3501\n",
      "1e-06 3502\n",
      "1e-06 3503\n",
      "1e-06 3504\n",
      "1e-06 3505\n",
      "1e-06 3506\n",
      "1e-06 3507\n",
      "1e-06 3508\n",
      "1e-06 3509\n",
      "1e-06 3510\n",
      "1e-06 3511\n",
      "1e-06 3512\n",
      "1e-06 3513\n",
      "1e-06 3514\n",
      "1e-06 3515\n",
      "1e-06 3516\n",
      "1e-06 3517\n",
      "1e-06 3518\n",
      "1e-06 3519\n",
      "1e-06 3520\n",
      "1e-06 3521\n",
      "1e-06 3522\n",
      "1e-06 3523\n",
      "1e-06 3524\n",
      "1e-06 3525\n",
      "1e-06 3526\n",
      "1e-06 3527\n",
      "1e-06 3528\n",
      "1e-06 3529\n",
      "1e-06 3530\n",
      "1e-06 3531\n",
      "1e-06 3532\n",
      "1e-06 3533\n",
      "1e-06 3534\n",
      "1e-06 3535\n",
      "1e-06 3536\n",
      "1e-06 3537\n",
      "1e-06 3538\n",
      "1e-06 3539\n",
      "1e-06 3540\n",
      "1e-06 3541\n",
      "1e-06 3542\n",
      "1e-06 3543\n",
      "1e-06 3544\n",
      "1e-06 3545\n",
      "1e-06 3546\n",
      "1e-06 3547\n",
      "1e-06 3548\n",
      "1e-06 3549\n",
      "1e-06 3550\n",
      "1e-06 3551\n",
      "1e-06 3552\n",
      "1e-06 3553\n",
      "1e-06 3554\n",
      "1e-06 3555\n",
      "1e-06 3556\n",
      "1e-06 3557\n",
      "1e-06 3558\n",
      "1e-06 3559\n",
      "1e-06 3560\n",
      "1e-06 3561\n",
      "1e-06 3562\n",
      "1e-06 3563\n",
      "1e-06 3564\n",
      "1e-06 3565\n",
      "1e-06 3566\n",
      "1e-06 3567\n",
      "1e-06 3568\n",
      "1e-06 3569\n",
      "1e-06 3570\n",
      "1e-06 3571\n",
      "1e-06 3572\n",
      "1e-06 3573\n",
      "1e-06 3574\n",
      "1e-06 3575\n",
      "1e-06 3576\n",
      "1e-06 3577\n",
      "1e-06 3578\n",
      "1e-06 3579\n",
      "1e-06 3580\n",
      "1e-06 3581\n",
      "1e-06 3582\n",
      "1e-06 3583\n",
      "1e-06 3584\n",
      "1e-06 3585\n",
      "1e-06 3586\n",
      "1e-06 3587\n",
      "1e-06 3588\n",
      "1e-06 3589\n",
      "1e-06 3590\n",
      "1e-06 3591\n",
      "1e-06 3592\n",
      "1e-06 3593\n",
      "1e-06 3594\n",
      "1e-06 3595\n",
      "1e-06 3596\n",
      "1e-06 3597\n",
      "1e-06 3598\n",
      "1e-06 3599\n",
      "1e-06 3600\n",
      "1e-06 3601\n",
      "1e-06 3602\n",
      "1e-06 3603\n",
      "1e-06 3604\n",
      "1e-06 3605\n",
      "1e-06 3606\n",
      "1e-06 3607\n",
      "1e-06 3608\n",
      "1e-06 3609\n",
      "1e-06 3610\n",
      "1e-06 3611\n",
      "1e-06 3612\n",
      "1e-06 3613\n",
      "1e-06 3614\n",
      "1e-06 3615\n",
      "1e-06 3616\n",
      "1e-06 3617\n",
      "1e-06 3618\n",
      "1e-06 3619\n",
      "1e-06 3620\n",
      "1e-06 3621\n",
      "1e-06 3622\n",
      "1e-06 3623\n",
      "1e-06 3624\n",
      "1e-06 3625\n",
      "1e-06 3626\n",
      "1e-06 3627\n",
      "1e-06 3628\n",
      "1e-06 3629\n",
      "1e-06 3630\n",
      "1e-06 3631\n",
      "1e-06 3632\n",
      "1e-06 3633\n",
      "1e-06 3634\n",
      "1e-06 3635\n",
      "1e-06 3636\n",
      "1e-06 3637\n",
      "1e-06 3638\n",
      "1e-06 3639\n",
      "1e-06 3640\n",
      "1e-06 3641\n",
      "1e-06 3642\n",
      "1e-06 3643\n",
      "1e-06 3644\n",
      "1e-06 3645\n",
      "1e-06 3646\n",
      "1e-06 3647\n",
      "1e-06 3648\n",
      "1e-06 3649\n",
      "1e-06 3650\n",
      "1e-06 3651\n",
      "1e-06 3652\n",
      "1e-06 3653\n",
      "1e-06 3654\n",
      "1e-06 3655\n",
      "1e-06 3656\n",
      "1e-06 3657\n",
      "1e-06 3658\n",
      "1e-06 3659\n",
      "1e-06 3660\n",
      "1e-06 3661\n",
      "1e-06 3662\n",
      "1e-06 3663\n",
      "1e-06 3664\n",
      "1e-06 3665\n",
      "1e-06 3666\n",
      "1e-06 3667\n",
      "1e-06 3668\n",
      "1e-06 3669\n",
      "1e-06 3670\n",
      "1e-06 3671\n",
      "1e-06 3672\n",
      "1e-06 3673\n",
      "1e-06 3674\n",
      "1e-06 3675\n",
      "1e-06 3676\n",
      "1e-06 3677\n",
      "1e-06 3678\n",
      "1e-06 3679\n",
      "1e-06 3680\n",
      "1e-06 3681\n",
      "1e-06 3682\n",
      "1e-06 3683\n",
      "1e-06 3684\n",
      "1e-06 3685\n",
      "1e-06 3686\n",
      "1e-06 3687\n",
      "1e-06 3688\n",
      "1e-06 3689\n",
      "1e-06 3690\n",
      "1e-06 3691\n",
      "1e-06 3692\n",
      "1e-06 3693\n",
      "1e-06 3694\n",
      "1e-06 3695\n",
      "1e-06 3696\n",
      "1e-06 3697\n",
      "1e-06 3698\n",
      "1e-06 3699\n",
      "1e-06 3700\n",
      "1e-06 3701\n",
      "1e-06 3702\n",
      "1e-06 3703\n",
      "1e-06 3704\n",
      "1e-06 3705\n",
      "1e-06 3706\n",
      "1e-06 3707\n",
      "1e-06 3708\n",
      "1e-06 3709\n",
      "1e-06 3710\n",
      "1e-06 3711\n",
      "1e-06 3712\n",
      "1e-06 3713\n",
      "1e-06 3714\n",
      "1e-06 3715\n",
      "1e-06 3716\n",
      "1e-06 3717\n",
      "1e-06 3718\n",
      "1e-06 3719\n",
      "1e-06 3720\n",
      "1e-06 3721\n",
      "1e-06 3722\n",
      "1e-06 3723\n",
      "1e-06 3724\n",
      "1e-06 3725\n",
      "1e-06 3726\n",
      "1e-06 3727\n",
      "1e-06 3728\n",
      "1e-06 3729\n",
      "1e-06 3730\n",
      "1e-06 3731\n",
      "1e-06 3732\n",
      "1e-06 3733\n",
      "1e-06 3734\n",
      "1e-06 3735\n",
      "1e-06 3736\n",
      "1e-06 3737\n",
      "1e-06 3738\n",
      "1e-06 3739\n",
      "1e-06 3740\n",
      "1e-06 3741\n",
      "1e-06 3742\n",
      "1e-06 3743\n",
      "1e-06 3744\n",
      "1e-06 3745\n",
      "1e-06 3746\n",
      "1e-06 3747\n",
      "1e-06 3748\n",
      "1e-06 3749\n",
      "1e-06 3750\n",
      "1e-06 3751\n",
      "1e-06 3752\n",
      "1e-06 3753\n",
      "1e-06 3754\n",
      "1e-06 3755\n",
      "1e-06 3756\n",
      "1e-06 3757\n",
      "1e-06 3758\n",
      "1e-06 3759\n",
      "1e-06 3760\n",
      "1e-06 3761\n",
      "1e-06 3762\n",
      "1e-06 3763\n",
      "1e-06 3764\n",
      "1e-06 3765\n",
      "1e-06 3766\n",
      "1e-06 3767\n",
      "1e-06 3768\n",
      "1e-06 3769\n",
      "1e-06 3770\n",
      "1e-06 3771\n",
      "1e-06 3772\n",
      "1e-06 3773\n",
      "1e-06 3774\n",
      "1e-06 3775\n",
      "1e-06 3776\n",
      "1e-06 3777\n",
      "1e-06 3778\n",
      "1e-06 3779\n",
      "1e-06 3780\n",
      "1e-06 3781\n",
      "1e-06 3782\n",
      "1e-06 3783\n",
      "1e-06 3784\n",
      "1e-06 3785\n",
      "1e-06 3786\n",
      "1e-06 3787\n",
      "1e-06 3788\n",
      "1e-06 3789\n",
      "1e-06 3790\n",
      "1e-06 3791\n",
      "1e-06 3792\n",
      "1e-06 3793\n",
      "1e-06 3794\n",
      "1e-06 3795\n",
      "1e-06 3796\n",
      "1e-06 3797\n",
      "1e-06 3798\n",
      "1e-06 3799\n",
      "1e-06 3800\n",
      "1e-06 3801\n",
      "1e-06 3802\n",
      "1e-06 3803\n",
      "1e-06 3804\n",
      "1e-06 3805\n",
      "1e-06 3806\n",
      "1e-06 3807\n",
      "1e-06 3808\n",
      "1e-06 3809\n",
      "1e-06 3810\n",
      "1e-06 3811\n",
      "1e-06 3812\n",
      "1e-06 3813\n",
      "1e-06 3814\n",
      "1e-06 3815\n",
      "1e-06 3816\n",
      "1e-06 3817\n",
      "1e-06 3818\n",
      "1e-06 3819\n",
      "1e-06 3820\n",
      "1e-06 3821\n",
      "1e-06 3822\n",
      "1e-06 3823\n",
      "1e-06 3824\n",
      "1e-06 3825\n",
      "1e-06 3826\n",
      "1e-06 3827\n",
      "1e-06 3828\n",
      "1e-06 3829\n",
      "1e-06 3830\n",
      "1e-06 3831\n",
      "1e-06 3832\n",
      "1e-06 3833\n",
      "1e-06 3834\n",
      "1e-06 3835\n",
      "1e-06 3836\n",
      "1e-06 3837\n",
      "1e-06 3838\n",
      "1e-06 3839\n",
      "1e-06 3840\n",
      "1e-06 3841\n",
      "1e-06 3842\n",
      "1e-06 3843\n",
      "1e-06 3844\n",
      "1e-06 3845\n",
      "1e-06 3846\n",
      "1e-06 3847\n",
      "1e-06 3848\n",
      "1e-06 3849\n",
      "1e-06 3850\n",
      "1e-06 3851\n",
      "1e-06 3852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-06 3853\n",
      "1e-06 3854\n",
      "1e-06 3855\n",
      "1e-06 3856\n",
      "1e-06 3857\n",
      "1e-06 3858\n",
      "1e-06 3859\n",
      "1e-06 3860\n",
      "1e-06 3861\n",
      "1e-06 3862\n",
      "1e-06 3863\n",
      "1e-06 3864\n",
      "1e-06 3865\n",
      "1e-06 3866\n",
      "1e-06 3867\n",
      "1e-06 3868\n",
      "1e-06 3869\n",
      "1e-06 3870\n",
      "1e-06 3871\n",
      "1e-06 3872\n",
      "1e-06 3873\n",
      "1e-06 3874\n",
      "1e-06 3875\n",
      "1e-06 3876\n",
      "1e-06 3877\n",
      "1e-06 3878\n",
      "1e-06 3879\n",
      "1e-06 3880\n",
      "1e-06 3881\n",
      "1e-06 3882\n",
      "1e-06 3883\n",
      "1e-06 3884\n",
      "1e-06 3885\n",
      "1e-06 3886\n",
      "1e-06 3887\n",
      "1e-06 3888\n",
      "1e-06 3889\n",
      "1e-06 3890\n",
      "1e-06 3891\n",
      "1e-06 3892\n",
      "1e-06 3893\n",
      "1e-06 3894\n",
      "1e-06 3895\n",
      "1e-06 3896\n",
      "1e-06 3897\n",
      "1e-06 3898\n",
      "1e-06 3899\n",
      "1e-06 3900\n",
      "1e-06 3901\n",
      "1e-06 3902\n",
      "1e-06 3903\n",
      "1e-06 3904\n",
      "1e-06 3905\n",
      "1e-06 3906\n",
      "1e-06 3907\n",
      "1e-06 3908\n",
      "1e-06 3909\n",
      "1e-06 3910\n",
      "1e-06 3911\n",
      "1e-06 3912\n",
      "1e-06 3913\n",
      "1e-06 3914\n",
      "1e-06 3915\n",
      "1e-06 3916\n",
      "1e-06 3917\n",
      "1e-06 3918\n",
      "1e-06 3919\n",
      "1e-06 3920\n",
      "1e-06 3921\n",
      "1e-06 3922\n",
      "1e-06 3923\n",
      "1e-06 3924\n",
      "1e-06 3925\n",
      "1e-06 3926\n",
      "1e-06 3927\n",
      "1e-06 3928\n",
      "1e-06 3929\n",
      "1e-06 3930\n",
      "1e-06 3931\n",
      "1e-06 3932\n",
      "1e-06 3933\n",
      "1e-06 3934\n",
      "1e-06 3935\n",
      "1e-06 3936\n",
      "1e-06 3937\n",
      "1e-06 3938\n",
      "1e-06 3939\n",
      "1e-06 3940\n",
      "1e-06 3941\n",
      "1e-06 3942\n",
      "1e-06 3943\n",
      "1e-06 3944\n",
      "1e-06 3945\n",
      "1e-06 3946\n",
      "1e-06 3947\n",
      "1e-06 3948\n",
      "1e-06 3949\n",
      "1e-06 3950\n",
      "1e-06 3951\n",
      "1e-06 3952\n",
      "1e-06 3953\n",
      "1e-06 3954\n",
      "1e-06 3955\n",
      "1e-06 3956\n",
      "1e-06 3957\n",
      "1e-06 3958\n",
      "1e-06 3959\n",
      "1e-06 3960\n",
      "1e-06 3961\n",
      "1e-06 3962\n",
      "1e-06 3963\n",
      "1e-06 3964\n",
      "1e-06 3965\n",
      "1e-06 3966\n",
      "1e-06 3967\n",
      "1e-06 3968\n",
      "1e-06 3969\n",
      "1e-06 3970\n",
      "1e-06 3971\n",
      "1e-06 3972\n",
      "1e-06 3973\n",
      "1e-06 3974\n",
      "1e-06 3975\n",
      "1e-06 3976\n",
      "1e-06 3977\n",
      "1e-06 3978\n",
      "1e-06 3979\n",
      "1e-06 3980\n",
      "1e-06 3981\n",
      "1e-06 3982\n",
      "1e-06 3983\n",
      "1e-06 3984\n",
      "1e-06 3985\n",
      "1e-06 3986\n",
      "1e-06 3987\n",
      "1e-06 3988\n",
      "1e-06 3989\n",
      "1e-06 3990\n",
      "1e-06 3991\n",
      "1e-06 3992\n",
      "1e-06 3993\n",
      "1e-06 3994\n",
      "1e-06 3995\n",
      "1e-06 3996\n",
      "1e-06 3997\n",
      "1e-06 3998\n",
      "1e-06 3999\n",
      "1e-06 4000\n",
      "1e-06 4001\n",
      "1e-06 4002\n",
      "1e-06 4003\n",
      "1e-06 4004\n",
      "1e-06 4005\n",
      "1e-06 4006\n",
      "1e-06 4007\n",
      "1e-06 4008\n",
      "1e-06 4009\n",
      "1e-06 4010\n",
      "1e-06 4011\n",
      "1e-06 4012\n",
      "1e-06 4013\n",
      "1e-06 4014\n",
      "1e-06 4015\n",
      "1e-06 4016\n",
      "1e-06 4017\n",
      "1e-06 4018\n",
      "1e-06 4019\n",
      "1e-06 4020\n",
      "1e-06 4021\n",
      "1e-06 4022\n",
      "1e-06 4023\n",
      "1e-06 4024\n",
      "1e-06 4025\n",
      "1e-06 4026\n",
      "1e-06 4027\n",
      "1e-06 4028\n",
      "1e-06 4029\n",
      "1e-06 4030\n",
      "1e-06 4031\n",
      "1e-06 4032\n",
      "1e-06 4033\n",
      "1e-06 4034\n",
      "1e-06 4035\n",
      "1e-06 4036\n",
      "1e-06 4037\n",
      "1e-06 4038\n",
      "1e-06 4039\n",
      "1e-06 4040\n",
      "1e-06 4041\n",
      "1e-06 4042\n",
      "1e-06 4043\n",
      "1e-06 4044\n",
      "1e-06 4045\n",
      "1e-06 4046\n",
      "1e-06 4047\n",
      "1e-06 4048\n",
      "1e-06 4049\n",
      "1e-06 4050\n",
      "1e-06 4051\n",
      "1e-06 4052\n",
      "1e-06 4053\n",
      "1e-06 4054\n",
      "1e-06 4055\n",
      "1e-06 4056\n",
      "1e-06 4057\n",
      "1e-06 4058\n",
      "1e-06 4059\n",
      "1e-06 4060\n",
      "1e-06 4061\n",
      "1e-06 4062\n",
      "1e-06 4063\n",
      "1e-06 4064\n",
      "1e-06 4065\n",
      "1e-06 4066\n",
      "1e-06 4067\n",
      "1e-06 4068\n",
      "1e-06 4069\n",
      "1e-06 4070\n",
      "1e-06 4071\n",
      "1e-06 4072\n",
      "1e-06 4073\n",
      "1e-06 4074\n",
      "1e-06 4075\n",
      "1e-06 4076\n",
      "1e-06 4077\n",
      "1e-06 4078\n",
      "1e-06 4079\n",
      "1e-06 4080\n",
      "1e-06 4081\n",
      "1e-06 4082\n",
      "1e-06 4083\n",
      "1e-06 4084\n",
      "1e-06 4085\n",
      "1e-06 4086\n",
      "1e-06 4087\n",
      "1e-06 4088\n",
      "1e-06 4089\n",
      "1e-06 4090\n",
      "1e-06 4091\n",
      "1e-06 4092\n",
      "1e-06 4093\n",
      "1e-06 4094\n",
      "1e-06 4095\n",
      "1e-06 4096\n",
      "1e-06 4097\n",
      "1e-06 4098\n",
      "1e-06 4099\n",
      "1e-06 4100\n",
      "1e-06 4101\n",
      "1e-06 4102\n",
      "1e-06 4103\n",
      "1e-06 4104\n",
      "1e-06 4105\n",
      "1e-06 4106\n",
      "1e-06 4107\n",
      "1e-06 4108\n",
      "1e-06 4109\n",
      "1e-06 4110\n",
      "1e-06 4111\n",
      "1e-06 4112\n",
      "1e-06 4113\n",
      "1e-06 4114\n",
      "1e-06 4115\n",
      "1e-06 4116\n",
      "1e-06 4117\n",
      "1e-06 4118\n",
      "1e-06 4119\n",
      "1e-06 4120\n",
      "1e-06 4121\n",
      "1e-06 4122\n",
      "1e-06 4123\n",
      "1e-06 4124\n",
      "1e-06 4125\n",
      "1e-06 4126\n",
      "1e-06 4127\n",
      "1e-06 4128\n",
      "1e-06 4129\n",
      "1e-06 4130\n",
      "1e-06 4131\n",
      "1e-06 4132\n",
      "1e-06 4133\n",
      "1e-06 4134\n",
      "1e-06 4135\n",
      "1e-06 4136\n",
      "1e-06 4137\n",
      "1e-06 4138\n",
      "1e-06 4139\n",
      "1e-06 4140\n",
      "1e-06 4141\n",
      "1e-06 4142\n",
      "1e-06 4143\n",
      "1e-06 4144\n",
      "1e-06 4145\n",
      "1e-06 4146\n",
      "1e-06 4147\n",
      "1e-06 4148\n",
      "1e-06 4149\n",
      "1e-06 4150\n",
      "1e-06 4151\n",
      "1e-06 4152\n",
      "1e-06 4153\n",
      "1e-06 4154\n",
      "1e-06 4155\n",
      "1e-06 4156\n",
      "1e-06 4157\n",
      "1e-06 4158\n",
      "1e-06 4159\n",
      "1e-06 4160\n",
      "1e-06 4161\n",
      "1e-06 4162\n",
      "1e-06 4163\n",
      "1e-06 4164\n",
      "1e-06 4165\n",
      "1e-06 4166\n",
      "1e-06 4167\n",
      "1e-06 4168\n",
      "1e-06 4169\n",
      "1e-06 4170\n",
      "1e-06 4171\n",
      "1e-06 4172\n",
      "1e-06 4173\n",
      "1e-06 4174\n",
      "1e-06 4175\n",
      "1e-06 4176\n",
      "1e-06 4177\n",
      "1e-06 4178\n",
      "1e-06 4179\n",
      "1e-06 4180\n",
      "1e-06 4181\n",
      "1e-06 4182\n",
      "1e-06 4183\n",
      "1e-06 4184\n",
      "1e-06 4185\n",
      "1e-06 4186\n",
      "1e-06 4187\n",
      "1e-06 4188\n",
      "1e-06 4189\n",
      "1e-06 4190\n",
      "1e-06 4191\n",
      "1e-06 4192\n",
      "1e-06 4193\n",
      "1e-06 4194\n",
      "1e-06 4195\n",
      "1e-06 4196\n",
      "1e-06 4197\n",
      "1e-06 4198\n",
      "1e-06 4199\n",
      "1e-06 4200\n",
      "1e-06 4201\n",
      "1e-06 4202\n",
      "1e-06 4203\n",
      "1e-06 4204\n",
      "1e-06 4205\n",
      "1e-06 4206\n",
      "1e-06 4207\n",
      "1e-06 4208\n",
      "1e-06 4209\n",
      "1e-06 4210\n",
      "1e-06 4211\n",
      "1e-06 4212\n",
      "1e-06 4213\n",
      "1e-06 4214\n",
      "1e-06 4215\n",
      "1e-06 4216\n",
      "1e-06 4217\n",
      "1e-06 4218\n",
      "1e-06 4219\n",
      "1e-06 4220\n",
      "1e-06 4221\n",
      "1e-06 4222\n",
      "1e-06 4223\n",
      "1e-06 4224\n",
      "1e-06 4225\n",
      "1e-06 4226\n",
      "1e-06 4227\n",
      "1e-06 4228\n",
      "1e-06 4229\n",
      "1e-06 4230\n",
      "1e-06 4231\n",
      "1e-06 4232\n",
      "1e-06 4233\n",
      "1e-06 4234\n",
      "1e-06 4235\n",
      "1e-06 4236\n",
      "1e-06 4237\n",
      "1e-06 4238\n",
      "1e-06 4239\n",
      "1e-06 4240\n",
      "1e-06 4241\n",
      "1e-06 4242\n",
      "1e-06 4243\n",
      "1e-06 4244\n",
      "1e-06 4245\n",
      "1e-06 4246\n",
      "1e-06 4247\n",
      "1e-06 4248\n",
      "1e-06 4249\n",
      "1e-06 4250\n",
      "1e-06 4251\n",
      "1e-06 4252\n",
      "1e-06 4253\n",
      "1e-06 4254\n",
      "1e-06 4255\n",
      "1e-06 4256\n",
      "1e-06 4257\n",
      "1e-06 4258\n",
      "1e-06 4259\n",
      "1e-06 4260\n",
      "1e-06 4261\n",
      "1e-06 4262\n",
      "1e-06 4263\n",
      "1e-06 4264\n",
      "1e-06 4265\n",
      "1e-06 4266\n",
      "1e-06 4267\n",
      "1e-06 4268\n",
      "1e-06 4269\n",
      "1e-06 4270\n",
      "1e-06 4271\n",
      "1e-06 4272\n",
      "1e-06 4273\n",
      "1e-06 4274\n",
      "1e-06 4275\n",
      "1e-06 4276\n",
      "1e-06 4277\n",
      "1e-06 4278\n",
      "1e-06 4279\n",
      "1e-06 4280\n",
      "1e-06 4281\n",
      "1e-06 4282\n",
      "1e-06 4283\n",
      "1e-06 4284\n",
      "1e-06 4285\n",
      "1e-06 4286\n",
      "1e-06 4287\n",
      "1e-06 4288\n",
      "1e-06 4289\n",
      "1e-06 4290\n",
      "1e-06 4291\n",
      "1e-06 4292\n",
      "1e-06 4293\n",
      "1e-06 4294\n",
      "1e-06 4295\n",
      "1e-06 4296\n",
      "1e-06 4297\n",
      "1e-06 4298\n",
      "1e-06 4299\n",
      "1e-06 4300\n",
      "1e-06 4301\n",
      "1e-06 4302\n",
      "1e-06 4303\n",
      "1e-06 4304\n",
      "1e-06 4305\n",
      "1e-06 4306\n",
      "1e-06 4307\n",
      "1e-06 4308\n",
      "1e-06 4309\n",
      "1e-06 4310\n",
      "1e-06 4311\n",
      "1e-06 4312\n",
      "1e-06 4313\n",
      "1e-06 4314\n",
      "1e-06 4315\n",
      "1e-06 4316\n",
      "1e-06 4317\n",
      "1e-06 4318\n",
      "1e-06 4319\n",
      "1e-06 4320\n",
      "1e-06 4321\n",
      "1e-06 4322\n",
      "1e-06 4323\n",
      "1e-06 4324\n",
      "1e-06 4325\n",
      "1e-06 4326\n",
      "1e-06 4327\n",
      "1e-06 4328\n",
      "1e-06 4329\n",
      "1e-06 4330\n",
      "1e-06 4331\n",
      "1e-06 4332\n",
      "1e-06 4333\n",
      "1e-06 4334\n",
      "1e-06 4335\n",
      "1e-06 4336\n",
      "1e-06 4337\n",
      "1e-06 4338\n",
      "1e-06 4339\n",
      "1e-06 4340\n",
      "1e-06 4341\n",
      "1e-06 4342\n",
      "1e-06 4343\n",
      "1e-06 4344\n",
      "1e-06 4345\n",
      "1e-06 4346\n",
      "1e-06 4347\n",
      "1e-06 4348\n",
      "1e-06 4349\n",
      "1e-06 4350\n",
      "1e-06 4351\n",
      "1e-06 4352\n",
      "1e-06 4353\n",
      "1e-06 4354\n",
      "1e-06 4355\n",
      "1e-06 4356\n",
      "1e-06 4357\n",
      "1e-06 4358\n",
      "1e-06 4359\n",
      "1e-06 4360\n",
      "1e-06 4361\n",
      "1e-06 4362\n",
      "1e-06 4363\n",
      "1e-06 4364\n",
      "1e-06 4365\n",
      "1e-06 4366\n",
      "1e-06 4367\n",
      "1e-06 4368\n",
      "1e-06 4369\n",
      "1e-06 4370\n",
      "1e-06 4371\n",
      "1e-06 4372\n",
      "1e-06 4373\n",
      "1e-06 4374\n",
      "1e-06 4375\n",
      "1e-06 4376\n",
      "1e-06 4377\n",
      "1e-06 4378\n",
      "1e-06 4379\n",
      "1e-06 4380\n",
      "1e-06 4381\n",
      "1e-06 4382\n",
      "1e-06 4383\n",
      "1e-06 4384\n",
      "1e-06 4385\n",
      "1e-06 4386\n",
      "1e-06 4387\n",
      "1e-06 4388\n",
      "1e-06 4389\n",
      "1e-06 4390\n",
      "1e-06 4391\n",
      "1e-06 4392\n",
      "1e-06 4393\n",
      "1e-06 4394\n",
      "1e-06 4395\n",
      "1e-06 4396\n",
      "1e-06 4397\n",
      "1e-06 4398\n",
      "1e-06 4399\n",
      "1e-06 4400\n",
      "1e-06 4401\n",
      "1e-06 4402\n",
      "1e-06 4403\n",
      "1e-06 4404\n",
      "1e-06 4405\n",
      "1e-06 4406\n",
      "1e-06 4407\n",
      "1e-06 4408\n",
      "1e-06 4409\n",
      "1e-06 4410\n",
      "1e-06 4411\n",
      "1e-06 4412\n",
      "1e-06 4413\n",
      "1e-06 4414\n",
      "1e-06 4415\n",
      "1e-06 4416\n",
      "1e-06 4417\n",
      "1e-06 4418\n",
      "1e-06 4419\n",
      "1e-06 4420\n",
      "1e-06 4421\n",
      "1e-06 4422\n",
      "1e-06 4423\n",
      "1e-06 4424\n",
      "1e-06 4425\n",
      "1e-06 4426\n",
      "1e-06 4427\n",
      "1e-06 4428\n",
      "1e-06 4429\n",
      "1e-06 4430\n",
      "1e-06 4431\n",
      "1e-06 4432\n",
      "1e-06 4433\n",
      "1e-06 4434\n",
      "1e-06 4435\n",
      "1e-06 4436\n",
      "1e-06 4437\n",
      "1e-06 4438\n",
      "1e-06 4439\n",
      "1e-06 4440\n",
      "1e-06 4441\n",
      "1e-06 4442\n",
      "1e-06 4443\n",
      "1e-06 4444\n",
      "1e-06 4445\n",
      "1e-06 4446\n",
      "1e-06 4447\n",
      "1e-06 4448\n",
      "1e-06 4449\n",
      "1e-06 4450\n",
      "1e-06 4451\n",
      "1e-06 4452\n",
      "1e-06 4453\n",
      "1e-06 4454\n",
      "1e-06 4455\n",
      "1e-06 4456\n",
      "1e-06 4457\n",
      "1e-06 4458\n",
      "1e-06 4459\n",
      "1e-06 4460\n",
      "1e-06 4461\n",
      "1e-06 4462\n",
      "1e-06 4463\n",
      "1e-06 4464\n",
      "1e-06 4465\n",
      "1e-06 4466\n",
      "1e-06 4467\n",
      "1e-06 4468\n",
      "1e-06 4469\n",
      "1e-06 4470\n",
      "1e-06 4471\n",
      "1e-06 4472\n",
      "1e-06 4473\n",
      "1e-06 4474\n",
      "1e-06 4475\n",
      "1e-06 4476\n",
      "1e-06 4477\n",
      "1e-06 4478\n",
      "1e-06 4479\n",
      "1e-06 4480\n",
      "1e-06 4481\n",
      "1e-06 4482\n",
      "1e-06 4483\n",
      "1e-06 4484\n",
      "1e-06 4485\n",
      "1e-06 4486\n",
      "1e-06 4487\n",
      "1e-06 4488\n",
      "1e-06 4489\n",
      "1e-06 4490\n",
      "1e-06 4491\n",
      "1e-06 4492\n",
      "1e-06 4493\n",
      "1e-06 4494\n",
      "1e-06 4495\n",
      "1e-06 4496\n",
      "1e-06 4497\n",
      "1e-06 4498\n",
      "1e-06 4499\n",
      "1e-06 4500\n",
      "1e-06 4501\n",
      "1e-06 4502\n",
      "1e-06 4503\n",
      "1e-06 4504\n",
      "1e-06 4505\n",
      "1e-06 4506\n",
      "1e-06 4507\n",
      "1e-06 4508\n",
      "1e-06 4509\n",
      "1e-06 4510\n",
      "1e-06 4511\n",
      "1e-06 4512\n",
      "1e-06 4513\n",
      "1e-06 4514\n",
      "1e-06 4515\n",
      "1e-06 4516\n",
      "1e-06 4517\n",
      "1e-06 4518\n",
      "1e-06 4519\n",
      "1e-06 4520\n",
      "1e-06 4521\n",
      "1e-06 4522\n",
      "1e-06 4523\n",
      "1e-06 4524\n",
      "1e-06 4525\n",
      "1e-06 4526\n",
      "1e-06 4527\n",
      "1e-06 4528\n",
      "1e-06 4529\n",
      "1e-06 4530\n",
      "1e-06 4531\n",
      "1e-06 4532\n",
      "1e-06 4533\n",
      "1e-06 4534\n",
      "1e-06 4535\n",
      "1e-06 4536\n",
      "1e-06 4537\n",
      "1e-06 4538\n",
      "1e-06 4539\n",
      "1e-06 4540\n",
      "1e-06 4541\n",
      "1e-06 4542\n",
      "1e-06 4543\n",
      "1e-06 4544\n",
      "1e-06 4545\n",
      "1e-06 4546\n",
      "1e-06 4547\n",
      "1e-06 4548\n",
      "1e-06 4549\n",
      "1e-06 4550\n",
      "1e-06 4551\n",
      "1e-06 4552\n",
      "1e-06 4553\n",
      "1e-06 4554\n",
      "1e-06 4555\n",
      "1e-06 4556\n",
      "1e-06 4557\n",
      "1e-06 4558\n",
      "1e-06 4559\n",
      "1e-06 4560\n",
      "1e-06 4561\n",
      "1e-06 4562\n",
      "1e-06 4563\n",
      "1e-06 4564\n",
      "1e-06 4565\n",
      "1e-06 4566\n",
      "1e-06 4567\n",
      "1e-06 4568\n",
      "1e-06 4569\n",
      "1e-06 4570\n",
      "1e-06 4571\n",
      "1e-06 4572\n",
      "1e-06 4573\n",
      "1e-06 4574\n",
      "1e-06 4575\n",
      "1e-06 4576\n",
      "1e-06 4577\n",
      "1e-06 4578\n",
      "1e-06 4579\n",
      "1e-06 4580\n",
      "1e-06 4581\n",
      "1e-06 4582\n",
      "1e-06 4583\n",
      "1e-06 4584\n",
      "1e-06 4585\n",
      "1e-06 4586\n",
      "1e-06 4587\n",
      "1e-06 4588\n",
      "1e-06 4589\n",
      "1e-06 4590\n",
      "1e-06 4591\n",
      "1e-06 4592\n",
      "1e-06 4593\n",
      "1e-06 4594\n",
      "1e-06 4595\n",
      "1e-06 4596\n",
      "1e-06 4597\n",
      "1e-06 4598\n",
      "1e-06 4599\n",
      "1e-06 4600\n",
      "1e-06 4601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-06 4602\n",
      "1e-06 4603\n",
      "1e-06 4604\n",
      "1e-06 4605\n",
      "1e-06 4606\n",
      "1e-06 4607\n",
      "1e-06 4608\n",
      "1e-06 4609\n",
      "1e-06 4610\n",
      "1e-06 4611\n",
      "1e-06 4612\n",
      "1e-06 4613\n",
      "1e-06 4614\n",
      "1e-06 4615\n",
      "1e-06 4616\n",
      "1e-06 4617\n",
      "1e-06 4618\n",
      "1e-06 4619\n",
      "1e-06 4620\n",
      "1e-06 4621\n",
      "1e-06 4622\n",
      "1e-06 4623\n",
      "1e-06 4624\n",
      "1e-06 4625\n",
      "1e-06 4626\n",
      "1e-06 4627\n",
      "1e-06 4628\n",
      "1e-06 4629\n",
      "1e-06 4630\n",
      "1e-06 4631\n",
      "1e-06 4632\n",
      "1e-06 4633\n",
      "1e-06 4634\n",
      "1e-06 4635\n",
      "1e-06 4636\n",
      "1e-06 4637\n",
      "1e-06 4638\n",
      "1e-06 4639\n",
      "1e-06 4640\n",
      "1e-06 4641\n",
      "1e-06 4642\n",
      "1e-06 4643\n",
      "1e-06 4644\n",
      "1e-06 4645\n",
      "1e-06 4646\n",
      "1e-06 4647\n",
      "1e-06 4648\n",
      "1e-06 4649\n",
      "1e-06 4650\n",
      "1e-06 4651\n",
      "1e-06 4652\n",
      "1e-06 4653\n",
      "1e-06 4654\n",
      "1e-06 4655\n",
      "1e-06 4656\n",
      "1e-06 4657\n",
      "1e-06 4658\n",
      "1e-06 4659\n",
      "1e-06 4660\n",
      "1e-06 4661\n",
      "1e-06 4662\n",
      "1e-06 4663\n",
      "1e-06 4664\n",
      "1e-06 4665\n",
      "1e-06 4666\n",
      "1e-06 4667\n",
      "1e-06 4668\n",
      "1e-06 4669\n",
      "1e-06 4670\n",
      "1e-06 4671\n",
      "1e-06 4672\n",
      "1e-06 4673\n",
      "1e-06 4674\n",
      "1e-06 4675\n",
      "1e-06 4676\n",
      "1e-06 4677\n",
      "1e-06 4678\n",
      "1e-06 4679\n",
      "1e-06 4680\n",
      "1e-06 4681\n",
      "1e-06 4682\n",
      "1e-06 4683\n",
      "1e-06 4684\n",
      "1e-06 4685\n",
      "1e-06 4686\n",
      "1e-06 4687\n",
      "1e-06 4688\n",
      "1e-06 4689\n",
      "1e-06 4690\n",
      "1e-06 4691\n",
      "1e-06 4692\n",
      "1e-06 4693\n",
      "1e-06 4694\n",
      "1e-06 4695\n",
      "1e-06 4696\n",
      "1e-06 4697\n",
      "1e-06 4698\n",
      "1e-06 4699\n",
      "1e-06 4700\n",
      "1e-06 4701\n",
      "1e-06 4702\n",
      "1e-06 4703\n",
      "1e-06 4704\n",
      "1e-06 4705\n",
      "1e-06 4706\n",
      "1e-06 4707\n",
      "1e-06 4708\n",
      "1e-06 4709\n",
      "1e-06 4710\n",
      "1e-06 4711\n",
      "1e-06 4712\n",
      "1e-06 4713\n",
      "1e-06 4714\n",
      "1e-06 4715\n",
      "1e-06 4716\n",
      "1e-06 4717\n",
      "1e-06 4718\n",
      "1e-06 4719\n",
      "1e-06 4720\n",
      "1e-06 4721\n",
      "1e-06 4722\n",
      "1e-06 4723\n",
      "1e-06 4724\n",
      "1e-06 4725\n",
      "1e-06 4726\n",
      "1e-06 4727\n",
      "1e-06 4728\n",
      "1e-06 4729\n",
      "1e-06 4730\n",
      "1e-06 4731\n",
      "1e-06 4732\n",
      "1e-06 4733\n",
      "1e-06 4734\n",
      "1e-06 4735\n",
      "1e-06 4736\n",
      "1e-06 4737\n",
      "1e-06 4738\n",
      "1e-06 4739\n",
      "1e-06 4740\n",
      "1e-06 4741\n",
      "1e-06 4742\n",
      "1e-06 4743\n",
      "1e-06 4744\n",
      "1e-06 4745\n",
      "1e-06 4746\n",
      "1e-06 4747\n",
      "1e-06 4748\n",
      "1e-06 4749\n",
      "1e-06 4750\n",
      "1e-06 4751\n",
      "1e-06 4752\n",
      "1e-06 4753\n",
      "1e-06 4754\n",
      "1e-06 4755\n",
      "1e-06 4756\n",
      "1e-06 4757\n",
      "1e-06 4758\n",
      "1e-06 4759\n",
      "1e-06 4760\n",
      "1e-06 4761\n",
      "1e-06 4762\n",
      "1e-06 4763\n",
      "1e-06 4764\n",
      "1e-06 4765\n",
      "1e-06 4766\n",
      "1e-06 4767\n",
      "1e-06 4768\n",
      "1e-06 4769\n",
      "1e-06 4770\n",
      "1e-06 4771\n",
      "1e-06 4772\n",
      "1e-06 4773\n",
      "1e-06 4774\n",
      "1e-06 4775\n",
      "1e-06 4776\n",
      "1e-06 4777\n",
      "1e-06 4778\n",
      "1e-06 4779\n",
      "1e-06 4780\n",
      "1e-06 4781\n",
      "1e-06 4782\n",
      "1e-06 4783\n",
      "1e-06 4784\n",
      "1e-06 4785\n",
      "1e-06 4786\n",
      "1e-06 4787\n",
      "1e-06 4788\n",
      "1e-06 4789\n",
      "1e-06 4790\n",
      "1e-06 4791\n",
      "1e-06 4792\n",
      "1e-06 4793\n",
      "1e-06 4794\n",
      "1e-06 4795\n",
      "1e-06 4796\n",
      "1e-06 4797\n",
      "1e-06 4798\n",
      "1e-06 4799\n",
      "1e-06 4800\n",
      "1e-06 4801\n",
      "1e-06 4802\n",
      "1e-06 4803\n",
      "1e-06 4804\n",
      "1e-06 4805\n",
      "1e-06 4806\n",
      "1e-06 4807\n",
      "1e-06 4808\n",
      "1e-06 4809\n",
      "1e-06 4810\n",
      "1e-06 4811\n",
      "1e-06 4812\n",
      "1e-06 4813\n",
      "1e-06 4814\n",
      "1e-06 4815\n",
      "1e-06 4816\n",
      "1e-06 4817\n",
      "1e-06 4818\n",
      "1e-06 4819\n",
      "1e-06 4820\n",
      "1e-06 4821\n",
      "1e-06 4822\n",
      "1e-06 4823\n",
      "1e-06 4824\n",
      "1e-06 4825\n",
      "1e-06 4826\n",
      "1e-06 4827\n",
      "1e-06 4828\n",
      "1e-06 4829\n",
      "1e-06 4830\n",
      "1e-06 4831\n",
      "1e-06 4832\n",
      "1e-06 4833\n",
      "1e-06 4834\n",
      "1e-06 4835\n",
      "1e-06 4836\n",
      "1e-06 4837\n",
      "1e-06 4838\n",
      "1e-06 4839\n",
      "1e-06 4840\n",
      "1e-06 4841\n",
      "1e-06 4842\n",
      "1e-06 4843\n",
      "1e-06 4844\n",
      "1e-06 4845\n",
      "1e-06 4846\n",
      "1e-06 4847\n",
      "1e-06 4848\n",
      "1e-06 4849\n",
      "1e-06 4850\n",
      "1e-06 4851\n",
      "1e-06 4852\n",
      "1e-06 4853\n",
      "1e-06 4854\n",
      "1e-06 4855\n",
      "1e-06 4856\n",
      "1e-06 4857\n",
      "1e-06 4858\n",
      "1e-06 4859\n",
      "1e-06 4860\n",
      "1e-06 4861\n",
      "1e-06 4862\n",
      "1e-06 4863\n",
      "1e-06 4864\n",
      "1e-06 4865\n",
      "1e-06 4866\n",
      "1e-06 4867\n",
      "1e-06 4868\n",
      "1e-06 4869\n",
      "1e-06 4870\n",
      "1e-06 4871\n",
      "1e-06 4872\n",
      "1e-06 4873\n",
      "1e-06 4874\n",
      "1e-06 4875\n",
      "1e-06 4876\n",
      "1e-06 4877\n",
      "1e-06 4878\n",
      "1e-06 4879\n",
      "1e-06 4880\n",
      "1e-06 4881\n",
      "1e-06 4882\n",
      "1e-06 4883\n",
      "1e-06 4884\n",
      "1e-06 4885\n",
      "1e-06 4886\n",
      "1e-06 4887\n",
      "1e-06 4888\n",
      "1e-06 4889\n",
      "1e-06 4890\n",
      "1e-06 4891\n",
      "1e-06 4892\n",
      "1e-06 4893\n",
      "1e-06 4894\n",
      "1e-06 4895\n",
      "1e-06 4896\n",
      "1e-06 4897\n",
      "1e-06 4898\n",
      "1e-06 4899\n",
      "1e-06 4900\n",
      "1e-06 4901\n",
      "1e-06 4902\n",
      "1e-06 4903\n",
      "1e-06 4904\n",
      "1e-06 4905\n",
      "1e-06 4906\n",
      "1e-06 4907\n",
      "1e-06 4908\n",
      "1e-06 4909\n",
      "1e-06 4910\n",
      "1e-06 4911\n",
      "1e-06 4912\n",
      "1e-06 4913\n",
      "1e-06 4914\n",
      "1e-06 4915\n",
      "1e-06 4916\n",
      "1e-06 4917\n",
      "1e-06 4918\n",
      "1e-06 4919\n",
      "1e-06 4920\n",
      "1e-06 4921\n",
      "1e-06 4922\n",
      "1e-06 4923\n",
      "1e-06 4924\n",
      "1e-06 4925\n",
      "1e-06 4926\n",
      "1e-06 4927\n",
      "1e-06 4928\n",
      "1e-06 4929\n",
      "1e-06 4930\n",
      "1e-06 4931\n",
      "1e-06 4932\n",
      "1e-06 4933\n",
      "1e-06 4934\n",
      "1e-06 4935\n",
      "1e-06 4936\n",
      "1e-06 4937\n",
      "1e-06 4938\n",
      "1e-06 4939\n",
      "1e-06 4940\n",
      "1e-06 4941\n",
      "1e-06 4942\n",
      "1e-06 4943\n",
      "1e-06 4944\n",
      "1e-06 4945\n",
      "1e-06 4946\n",
      "1e-06 4947\n",
      "1e-06 4948\n",
      "1e-06 4949\n",
      "1e-06 4950\n",
      "1e-06 4951\n",
      "1e-06 4952\n",
      "1e-06 4953\n",
      "1e-06 4954\n",
      "1e-06 4955\n",
      "1e-06 4956\n",
      "1e-06 4957\n",
      "1e-06 4958\n",
      "1e-06 4959\n",
      "1e-06 4960\n",
      "1e-06 4961\n",
      "1e-06 4962\n",
      "1e-06 4963\n",
      "1e-06 4964\n",
      "1e-06 4965\n",
      "1e-06 4966\n",
      "1e-06 4967\n",
      "1e-06 4968\n",
      "1e-06 4969\n",
      "1e-06 4970\n",
      "1e-06 4971\n",
      "1e-06 4972\n",
      "1e-06 4973\n",
      "1e-06 4974\n",
      "1e-06 4975\n",
      "1e-06 4976\n",
      "1e-06 4977\n",
      "1e-06 4978\n",
      "1e-06 4979\n",
      "1e-06 4980\n",
      "1e-06 4981\n",
      "1e-06 4982\n",
      "1e-06 4983\n",
      "1e-06 4984\n",
      "1e-06 4985\n",
      "1e-06 4986\n",
      "1e-06 4987\n",
      "1e-06 4988\n",
      "1e-06 4989\n",
      "1e-06 4990\n",
      "1e-06 4991\n",
      "1e-06 4992\n",
      "1e-06 4993\n",
      "1e-06 4994\n",
      "1e-06 4995\n",
      "1e-06 4996\n",
      "1e-06 4997\n",
      "1e-06 4998\n",
      "1e-06 4999\n",
      "0.015790421052631582 0\n",
      "0.015790421052631582 1\n",
      "0.015790421052631582 2\n",
      "0.015790421052631582 3\n",
      "0.015790421052631582 4\n",
      "0.015790421052631582 5\n",
      "0.015790421052631582 6\n",
      "0.03157984210526316 0\n",
      "0.03157984210526316 1\n",
      "0.03157984210526316 2\n",
      "0.04736926315789475 0\n",
      "0.04736926315789475 1\n",
      "0.04736926315789475 2\n",
      "0.06315868421052633 0\n",
      "0.06315868421052633 1\n",
      "0.06315868421052633 2\n",
      "0.0789481052631579 0\n",
      "0.0789481052631579 1\n",
      "0.0789481052631579 2\n",
      "0.0947375263157895 0\n",
      "0.0947375263157895 1\n",
      "0.0947375263157895 2\n",
      "0.0947375263157895 3\n",
      "0.0947375263157895 4\n",
      "0.0947375263157895 5\n",
      "0.0947375263157895 6\n",
      "0.0947375263157895 7\n",
      "0.0947375263157895 8\n",
      "0.0947375263157895 9\n",
      "0.0947375263157895 10\n",
      "0.0947375263157895 11\n",
      "0.0947375263157895 12\n",
      "0.0947375263157895 13\n",
      "0.0947375263157895 14\n",
      "0.0947375263157895 15\n",
      "0.0947375263157895 16\n",
      "0.0947375263157895 17\n",
      "0.0947375263157895 18\n",
      "0.0947375263157895 19\n",
      "0.0947375263157895 20\n",
      "0.0947375263157895 21\n",
      "0.0947375263157895 22\n",
      "0.0947375263157895 23\n",
      "0.0947375263157895 24\n",
      "0.0947375263157895 25\n",
      "0.0947375263157895 26\n",
      "0.0947375263157895 27\n",
      "0.0947375263157895 28\n",
      "0.0947375263157895 29\n",
      "0.0947375263157895 30\n",
      "0.0947375263157895 31\n",
      "0.0947375263157895 32\n",
      "0.0947375263157895 33\n",
      "0.0947375263157895 34\n",
      "0.0947375263157895 35\n",
      "0.0947375263157895 36\n",
      "0.0947375263157895 37\n",
      "0.0947375263157895 38\n",
      "0.0947375263157895 39\n",
      "0.0947375263157895 40\n",
      "0.0947375263157895 41\n",
      "0.0947375263157895 42\n",
      "0.0947375263157895 43\n",
      "0.0947375263157895 44\n",
      "0.0947375263157895 45\n",
      "0.0947375263157895 46\n",
      "0.0947375263157895 47\n",
      "0.0947375263157895 48\n",
      "0.0947375263157895 49\n",
      "0.0947375263157895 50\n",
      "0.0947375263157895 51\n",
      "0.0947375263157895 52\n",
      "0.0947375263157895 53\n",
      "0.0947375263157895 54\n",
      "0.0947375263157895 55\n",
      "0.0947375263157895 56\n",
      "0.0947375263157895 57\n",
      "0.0947375263157895 58\n",
      "0.0947375263157895 59\n",
      "0.0947375263157895 60\n",
      "0.0947375263157895 61\n",
      "0.0947375263157895 62\n",
      "0.0947375263157895 63\n",
      "0.0947375263157895 64\n",
      "0.0947375263157895 65\n",
      "0.0947375263157895 66\n",
      "0.0947375263157895 67\n",
      "0.0947375263157895 68\n",
      "0.0947375263157895 69\n",
      "0.0947375263157895 70\n",
      "0.0947375263157895 71\n",
      "0.0947375263157895 72\n",
      "0.0947375263157895 73\n",
      "0.0947375263157895 74\n",
      "0.0947375263157895 75\n",
      "0.0947375263157895 76\n",
      "0.0947375263157895 77\n",
      "0.0947375263157895 78\n",
      "0.0947375263157895 79\n",
      "0.0947375263157895 80\n",
      "0.0947375263157895 81\n",
      "0.0947375263157895 82\n",
      "0.0947375263157895 83\n",
      "0.0947375263157895 84\n",
      "0.0947375263157895 85\n",
      "0.0947375263157895 86\n",
      "0.0947375263157895 87\n",
      "0.0947375263157895 88\n",
      "0.0947375263157895 89\n",
      "0.0947375263157895 90\n",
      "0.0947375263157895 91\n",
      "0.0947375263157895 92\n",
      "0.0947375263157895 93\n",
      "0.0947375263157895 94\n",
      "0.0947375263157895 95\n",
      "0.0947375263157895 96\n",
      "0.0947375263157895 97\n",
      "0.0947375263157895 98\n",
      "0.0947375263157895 99\n",
      "0.0947375263157895 100\n",
      "0.0947375263157895 101\n",
      "0.0947375263157895 102\n",
      "0.0947375263157895 103\n",
      "0.0947375263157895 104\n",
      "0.0947375263157895 105\n",
      "0.0947375263157895 106\n",
      "0.0947375263157895 107\n",
      "0.0947375263157895 108\n",
      "0.0947375263157895 109\n",
      "0.0947375263157895 110\n",
      "0.0947375263157895 111\n",
      "0.0947375263157895 112\n",
      "0.0947375263157895 113\n",
      "0.0947375263157895 114\n",
      "0.0947375263157895 115\n",
      "0.0947375263157895 116\n",
      "0.0947375263157895 117\n",
      "0.0947375263157895 118\n",
      "0.0947375263157895 119\n",
      "0.0947375263157895 120\n",
      "0.0947375263157895 121\n",
      "0.0947375263157895 122\n",
      "0.0947375263157895 123\n",
      "0.0947375263157895 124\n",
      "0.0947375263157895 125\n",
      "0.0947375263157895 126\n",
      "0.0947375263157895 127\n",
      "0.0947375263157895 128\n",
      "0.0947375263157895 129\n",
      "0.0947375263157895 130\n",
      "0.0947375263157895 131\n",
      "0.0947375263157895 132\n",
      "0.0947375263157895 133\n",
      "0.0947375263157895 134\n",
      "0.0947375263157895 135\n",
      "0.0947375263157895 136\n",
      "0.0947375263157895 137\n",
      "0.0947375263157895 138\n",
      "0.0947375263157895 139\n",
      "0.0947375263157895 140\n",
      "0.0947375263157895 141\n",
      "0.0947375263157895 142\n",
      "0.0947375263157895 143\n",
      "0.0947375263157895 144\n",
      "0.0947375263157895 145\n",
      "0.0947375263157895 146\n",
      "0.0947375263157895 147\n",
      "0.0947375263157895 148\n",
      "0.0947375263157895 149\n",
      "0.0947375263157895 150\n",
      "0.0947375263157895 151\n",
      "0.0947375263157895 152\n",
      "0.0947375263157895 153\n",
      "0.0947375263157895 154\n",
      "0.0947375263157895 155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0947375263157895 156\n",
      "0.0947375263157895 157\n",
      "0.0947375263157895 158\n",
      "0.0947375263157895 159\n",
      "0.0947375263157895 160\n",
      "0.0947375263157895 161\n",
      "0.0947375263157895 162\n",
      "0.0947375263157895 163\n",
      "0.0947375263157895 164\n",
      "0.0947375263157895 165\n",
      "0.0947375263157895 166\n",
      "0.0947375263157895 167\n",
      "0.0947375263157895 168\n",
      "0.0947375263157895 169\n",
      "0.0947375263157895 170\n",
      "0.0947375263157895 171\n",
      "0.0947375263157895 172\n",
      "0.0947375263157895 173\n",
      "0.0947375263157895 174\n",
      "0.0947375263157895 175\n",
      "0.0947375263157895 176\n",
      "0.0947375263157895 177\n",
      "0.0947375263157895 178\n",
      "0.0947375263157895 179\n",
      "0.0947375263157895 180\n",
      "0.0947375263157895 181\n",
      "0.0947375263157895 182\n",
      "0.0947375263157895 183\n",
      "0.0947375263157895 184\n",
      "0.0947375263157895 185\n",
      "0.0947375263157895 186\n",
      "0.0947375263157895 187\n",
      "0.0947375263157895 188\n",
      "0.0947375263157895 189\n",
      "0.0947375263157895 190\n",
      "0.0947375263157895 191\n",
      "0.0947375263157895 192\n",
      "0.0947375263157895 193\n",
      "0.0947375263157895 194\n",
      "0.0947375263157895 195\n",
      "0.0947375263157895 196\n",
      "0.0947375263157895 197\n",
      "0.0947375263157895 198\n",
      "0.0947375263157895 199\n",
      "0.0947375263157895 200\n",
      "0.0947375263157895 201\n",
      "0.0947375263157895 202\n",
      "0.0947375263157895 203\n",
      "0.0947375263157895 204\n",
      "0.0947375263157895 205\n",
      "0.0947375263157895 206\n",
      "0.0947375263157895 207\n",
      "0.0947375263157895 208\n",
      "0.0947375263157895 209\n",
      "0.0947375263157895 210\n",
      "0.0947375263157895 211\n",
      "0.0947375263157895 212\n",
      "0.0947375263157895 213\n",
      "0.0947375263157895 214\n",
      "0.0947375263157895 215\n",
      "0.0947375263157895 216\n",
      "0.0947375263157895 217\n",
      "0.0947375263157895 218\n",
      "0.0947375263157895 219\n",
      "0.0947375263157895 220\n",
      "0.0947375263157895 221\n",
      "0.0947375263157895 222\n",
      "0.0947375263157895 223\n",
      "0.0947375263157895 224\n",
      "0.0947375263157895 225\n",
      "0.0947375263157895 226\n",
      "0.0947375263157895 227\n",
      "0.0947375263157895 228\n",
      "0.0947375263157895 229\n",
      "0.0947375263157895 230\n",
      "0.0947375263157895 231\n",
      "0.0947375263157895 232\n",
      "0.0947375263157895 233\n",
      "0.0947375263157895 234\n",
      "0.0947375263157895 235\n",
      "0.0947375263157895 236\n",
      "0.0947375263157895 237\n",
      "0.0947375263157895 238\n",
      "0.0947375263157895 239\n",
      "0.0947375263157895 240\n",
      "0.0947375263157895 241\n",
      "0.0947375263157895 242\n",
      "0.0947375263157895 243\n",
      "0.0947375263157895 244\n",
      "0.0947375263157895 245\n",
      "0.0947375263157895 246\n",
      "0.0947375263157895 247\n",
      "0.0947375263157895 248\n",
      "0.0947375263157895 249\n",
      "0.0947375263157895 250\n",
      "0.0947375263157895 251\n",
      "0.0947375263157895 252\n",
      "0.0947375263157895 253\n",
      "0.0947375263157895 254\n",
      "0.0947375263157895 255\n",
      "0.0947375263157895 256\n",
      "0.0947375263157895 257\n",
      "0.0947375263157895 258\n",
      "0.0947375263157895 259\n",
      "0.0947375263157895 260\n",
      "0.0947375263157895 261\n",
      "0.0947375263157895 262\n",
      "0.0947375263157895 263\n",
      "0.0947375263157895 264\n",
      "0.0947375263157895 265\n",
      "0.0947375263157895 266\n",
      "0.0947375263157895 267\n",
      "0.0947375263157895 268\n",
      "0.0947375263157895 269\n",
      "0.0947375263157895 270\n",
      "0.0947375263157895 271\n",
      "0.0947375263157895 272\n",
      "0.0947375263157895 273\n",
      "0.0947375263157895 274\n",
      "0.0947375263157895 275\n",
      "0.0947375263157895 276\n",
      "0.0947375263157895 277\n",
      "0.0947375263157895 278\n",
      "0.0947375263157895 279\n",
      "0.0947375263157895 280\n",
      "0.0947375263157895 281\n",
      "0.0947375263157895 282\n",
      "0.0947375263157895 283\n",
      "0.0947375263157895 284\n",
      "0.0947375263157895 285\n",
      "0.0947375263157895 286\n",
      "0.0947375263157895 287\n",
      "0.0947375263157895 288\n",
      "0.0947375263157895 289\n",
      "0.0947375263157895 290\n",
      "0.0947375263157895 291\n",
      "0.0947375263157895 292\n",
      "0.0947375263157895 293\n",
      "0.0947375263157895 294\n",
      "0.0947375263157895 295\n",
      "0.0947375263157895 296\n",
      "0.0947375263157895 297\n",
      "0.0947375263157895 298\n",
      "0.0947375263157895 299\n",
      "0.0947375263157895 300\n",
      "0.0947375263157895 301\n",
      "0.0947375263157895 302\n",
      "0.0947375263157895 303\n",
      "0.0947375263157895 304\n",
      "0.0947375263157895 305\n",
      "0.0947375263157895 306\n",
      "0.0947375263157895 307\n",
      "0.0947375263157895 308\n",
      "0.0947375263157895 309\n",
      "0.0947375263157895 310\n",
      "0.0947375263157895 311\n",
      "0.0947375263157895 312\n",
      "0.0947375263157895 313\n",
      "0.0947375263157895 314\n",
      "0.0947375263157895 315\n",
      "0.0947375263157895 316\n",
      "0.0947375263157895 317\n",
      "0.0947375263157895 318\n",
      "0.0947375263157895 319\n",
      "0.0947375263157895 320\n",
      "0.0947375263157895 321\n",
      "0.0947375263157895 322\n",
      "0.0947375263157895 323\n",
      "0.0947375263157895 324\n",
      "0.0947375263157895 325\n",
      "0.0947375263157895 326\n",
      "0.0947375263157895 327\n",
      "0.0947375263157895 328\n",
      "0.0947375263157895 329\n",
      "0.0947375263157895 330\n",
      "0.0947375263157895 331\n",
      "0.0947375263157895 332\n",
      "0.0947375263157895 333\n",
      "0.0947375263157895 334\n",
      "0.0947375263157895 335\n",
      "0.0947375263157895 336\n",
      "0.0947375263157895 337\n",
      "0.0947375263157895 338\n",
      "0.0947375263157895 339\n",
      "0.0947375263157895 340\n",
      "0.0947375263157895 341\n",
      "0.0947375263157895 342\n",
      "0.0947375263157895 343\n",
      "0.0947375263157895 344\n",
      "0.0947375263157895 345\n",
      "0.0947375263157895 346\n",
      "0.0947375263157895 347\n",
      "0.0947375263157895 348\n",
      "0.0947375263157895 349\n",
      "0.0947375263157895 350\n",
      "0.0947375263157895 351\n",
      "0.0947375263157895 352\n",
      "0.0947375263157895 353\n",
      "0.0947375263157895 354\n",
      "0.0947375263157895 355\n",
      "0.0947375263157895 356\n",
      "0.0947375263157895 357\n",
      "0.0947375263157895 358\n",
      "0.0947375263157895 359\n",
      "0.0947375263157895 360\n",
      "0.0947375263157895 361\n",
      "0.0947375263157895 362\n",
      "0.0947375263157895 363\n",
      "0.0947375263157895 364\n",
      "0.0947375263157895 365\n",
      "0.0947375263157895 366\n",
      "0.0947375263157895 367\n",
      "0.0947375263157895 368\n",
      "0.0947375263157895 369\n",
      "0.0947375263157895 370\n",
      "0.0947375263157895 371\n",
      "0.0947375263157895 372\n",
      "0.0947375263157895 373\n",
      "0.0947375263157895 374\n",
      "0.0947375263157895 375\n",
      "0.0947375263157895 376\n",
      "0.0947375263157895 377\n",
      "0.0947375263157895 378\n",
      "0.0947375263157895 379\n",
      "0.0947375263157895 380\n",
      "0.0947375263157895 381\n",
      "0.0947375263157895 382\n",
      "0.0947375263157895 383\n",
      "0.0947375263157895 384\n",
      "0.0947375263157895 385\n",
      "0.0947375263157895 386\n",
      "0.0947375263157895 387\n",
      "0.0947375263157895 388\n",
      "0.0947375263157895 389\n",
      "0.0947375263157895 390\n",
      "0.0947375263157895 391\n",
      "0.0947375263157895 392\n",
      "0.0947375263157895 393\n",
      "0.0947375263157895 394\n",
      "0.0947375263157895 395\n",
      "0.0947375263157895 396\n",
      "0.0947375263157895 397\n",
      "0.0947375263157895 398\n",
      "0.0947375263157895 399\n",
      "0.0947375263157895 400\n",
      "0.0947375263157895 401\n",
      "0.0947375263157895 402\n",
      "0.0947375263157895 403\n",
      "0.0947375263157895 404\n",
      "0.0947375263157895 405\n",
      "0.0947375263157895 406\n",
      "0.0947375263157895 407\n",
      "0.0947375263157895 408\n",
      "0.0947375263157895 409\n",
      "0.0947375263157895 410\n",
      "0.0947375263157895 411\n",
      "0.0947375263157895 412\n",
      "0.0947375263157895 413\n",
      "0.0947375263157895 414\n",
      "0.0947375263157895 415\n",
      "0.0947375263157895 416\n",
      "0.0947375263157895 417\n",
      "0.0947375263157895 418\n",
      "0.0947375263157895 419\n",
      "0.0947375263157895 420\n",
      "0.0947375263157895 421\n",
      "0.0947375263157895 422\n",
      "0.0947375263157895 423\n",
      "0.0947375263157895 424\n",
      "0.0947375263157895 425\n",
      "0.0947375263157895 426\n",
      "0.0947375263157895 427\n",
      "0.0947375263157895 428\n",
      "0.0947375263157895 429\n",
      "0.0947375263157895 430\n",
      "0.0947375263157895 431\n",
      "0.0947375263157895 432\n",
      "0.0947375263157895 433\n",
      "0.0947375263157895 434\n",
      "0.0947375263157895 435\n",
      "0.0947375263157895 436\n",
      "0.0947375263157895 437\n",
      "0.0947375263157895 438\n",
      "0.0947375263157895 439\n",
      "0.0947375263157895 440\n",
      "0.0947375263157895 441\n",
      "0.0947375263157895 442\n",
      "0.0947375263157895 443\n",
      "0.0947375263157895 444\n",
      "0.0947375263157895 445\n",
      "0.0947375263157895 446\n",
      "0.0947375263157895 447\n",
      "0.0947375263157895 448\n",
      "0.0947375263157895 449\n",
      "0.0947375263157895 450\n",
      "0.0947375263157895 451\n",
      "0.0947375263157895 452\n",
      "0.0947375263157895 453\n",
      "0.0947375263157895 454\n",
      "0.0947375263157895 455\n",
      "0.0947375263157895 456\n",
      "0.0947375263157895 457\n",
      "0.0947375263157895 458\n",
      "0.0947375263157895 459\n",
      "0.0947375263157895 460\n",
      "0.0947375263157895 461\n",
      "0.0947375263157895 462\n",
      "0.0947375263157895 463\n",
      "0.0947375263157895 464\n",
      "0.0947375263157895 465\n",
      "0.0947375263157895 466\n",
      "0.0947375263157895 467\n",
      "0.0947375263157895 468\n",
      "0.0947375263157895 469\n",
      "0.0947375263157895 470\n",
      "0.0947375263157895 471\n",
      "0.0947375263157895 472\n",
      "0.0947375263157895 473\n",
      "0.0947375263157895 474\n",
      "0.0947375263157895 475\n",
      "0.0947375263157895 476\n",
      "0.0947375263157895 477\n",
      "0.0947375263157895 478\n",
      "0.0947375263157895 479\n",
      "0.0947375263157895 480\n",
      "0.0947375263157895 481\n",
      "0.0947375263157895 482\n",
      "0.0947375263157895 483\n",
      "0.0947375263157895 484\n",
      "0.0947375263157895 485\n",
      "0.0947375263157895 486\n",
      "0.0947375263157895 487\n",
      "0.0947375263157895 488\n",
      "0.0947375263157895 489\n",
      "0.0947375263157895 490\n",
      "0.0947375263157895 491\n",
      "0.0947375263157895 492\n",
      "0.0947375263157895 493\n",
      "0.0947375263157895 494\n",
      "0.0947375263157895 495\n",
      "0.0947375263157895 496\n",
      "0.0947375263157895 497\n",
      "0.0947375263157895 498\n",
      "0.0947375263157895 499\n",
      "0.0947375263157895 500\n",
      "0.0947375263157895 501\n",
      "0.0947375263157895 502\n",
      "0.0947375263157895 503\n",
      "0.0947375263157895 504\n",
      "0.0947375263157895 505\n",
      "0.0947375263157895 506\n",
      "0.0947375263157895 507\n",
      "0.0947375263157895 508\n",
      "0.0947375263157895 509\n",
      "0.0947375263157895 510\n",
      "0.0947375263157895 511\n",
      "0.0947375263157895 512\n",
      "0.0947375263157895 513\n",
      "0.0947375263157895 514\n",
      "0.0947375263157895 515\n",
      "0.0947375263157895 516\n",
      "0.0947375263157895 517\n",
      "0.0947375263157895 518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0947375263157895 519\n",
      "0.0947375263157895 520\n",
      "0.0947375263157895 521\n",
      "0.0947375263157895 522\n",
      "0.0947375263157895 523\n",
      "0.0947375263157895 524\n",
      "0.0947375263157895 525\n",
      "0.0947375263157895 526\n",
      "0.0947375263157895 527\n",
      "0.0947375263157895 528\n",
      "0.0947375263157895 529\n",
      "0.0947375263157895 530\n",
      "0.0947375263157895 531\n",
      "0.0947375263157895 532\n",
      "0.0947375263157895 533\n",
      "0.0947375263157895 534\n",
      "0.0947375263157895 535\n",
      "0.0947375263157895 536\n",
      "0.0947375263157895 537\n",
      "0.0947375263157895 538\n",
      "0.0947375263157895 539\n",
      "0.0947375263157895 540\n",
      "0.0947375263157895 541\n",
      "0.0947375263157895 542\n",
      "0.0947375263157895 543\n",
      "0.0947375263157895 544\n",
      "0.0947375263157895 545\n",
      "0.0947375263157895 546\n",
      "0.0947375263157895 547\n",
      "0.0947375263157895 548\n",
      "0.0947375263157895 549\n",
      "0.0947375263157895 550\n",
      "0.0947375263157895 551\n",
      "0.0947375263157895 552\n",
      "0.0947375263157895 553\n",
      "0.0947375263157895 554\n",
      "0.0947375263157895 555\n",
      "0.0947375263157895 556\n",
      "0.0947375263157895 557\n",
      "0.0947375263157895 558\n",
      "0.0947375263157895 559\n",
      "0.0947375263157895 560\n",
      "0.0947375263157895 561\n",
      "0.0947375263157895 562\n",
      "0.0947375263157895 563\n",
      "0.0947375263157895 564\n",
      "0.0947375263157895 565\n",
      "0.0947375263157895 566\n",
      "0.0947375263157895 567\n",
      "0.0947375263157895 568\n",
      "0.0947375263157895 569\n",
      "0.0947375263157895 570\n",
      "0.0947375263157895 571\n",
      "0.0947375263157895 572\n",
      "0.0947375263157895 573\n",
      "0.0947375263157895 574\n",
      "0.0947375263157895 575\n",
      "0.0947375263157895 576\n",
      "0.0947375263157895 577\n",
      "0.0947375263157895 578\n",
      "0.0947375263157895 579\n",
      "0.0947375263157895 580\n",
      "0.0947375263157895 581\n",
      "0.0947375263157895 582\n",
      "0.0947375263157895 583\n",
      "0.0947375263157895 584\n",
      "0.0947375263157895 585\n",
      "0.0947375263157895 586\n",
      "0.0947375263157895 587\n",
      "0.0947375263157895 588\n",
      "0.0947375263157895 589\n",
      "0.0947375263157895 590\n",
      "0.0947375263157895 591\n",
      "0.0947375263157895 592\n",
      "0.0947375263157895 593\n",
      "0.0947375263157895 594\n",
      "0.0947375263157895 595\n",
      "0.0947375263157895 596\n",
      "0.0947375263157895 597\n",
      "0.0947375263157895 598\n",
      "0.0947375263157895 599\n",
      "0.0947375263157895 600\n",
      "0.0947375263157895 601\n",
      "0.0947375263157895 602\n",
      "0.0947375263157895 603\n",
      "0.0947375263157895 604\n",
      "0.0947375263157895 605\n",
      "0.0947375263157895 606\n",
      "0.0947375263157895 607\n",
      "0.0947375263157895 608\n",
      "0.0947375263157895 609\n",
      "0.0947375263157895 610\n",
      "0.0947375263157895 611\n",
      "0.0947375263157895 612\n",
      "0.0947375263157895 613\n",
      "0.0947375263157895 614\n",
      "0.0947375263157895 615\n",
      "0.0947375263157895 616\n",
      "0.0947375263157895 617\n",
      "0.0947375263157895 618\n",
      "0.0947375263157895 619\n",
      "0.0947375263157895 620\n",
      "0.0947375263157895 621\n",
      "0.0947375263157895 622\n",
      "0.0947375263157895 623\n",
      "0.0947375263157895 624\n",
      "0.0947375263157895 625\n",
      "0.0947375263157895 626\n",
      "0.0947375263157895 627\n",
      "0.0947375263157895 628\n",
      "0.0947375263157895 629\n",
      "0.0947375263157895 630\n",
      "0.0947375263157895 631\n",
      "0.0947375263157895 632\n",
      "0.0947375263157895 633\n",
      "0.0947375263157895 634\n",
      "0.0947375263157895 635\n",
      "0.0947375263157895 636\n",
      "0.0947375263157895 637\n",
      "0.0947375263157895 638\n",
      "0.0947375263157895 639\n",
      "0.0947375263157895 640\n",
      "0.0947375263157895 641\n",
      "0.0947375263157895 642\n",
      "0.0947375263157895 643\n",
      "0.0947375263157895 644\n",
      "0.0947375263157895 645\n",
      "0.0947375263157895 646\n",
      "0.0947375263157895 647\n",
      "0.0947375263157895 648\n",
      "0.0947375263157895 649\n",
      "0.0947375263157895 650\n",
      "0.0947375263157895 651\n",
      "0.11052694736842107 0\n",
      "0.11052694736842107 1\n",
      "0.11052694736842107 2\n",
      "0.11052694736842107 3\n",
      "0.11052694736842107 4\n",
      "0.11052694736842107 5\n",
      "0.12631636842105265 0\n",
      "0.12631636842105265 1\n",
      "0.12631636842105265 2\n",
      "0.12631636842105265 3\n",
      "0.12631636842105265 4\n",
      "0.12631636842105265 5\n",
      "0.12631636842105265 6\n",
      "0.12631636842105265 7\n",
      "0.12631636842105265 8\n",
      "0.12631636842105265 9\n",
      "0.12631636842105265 10\n",
      "0.12631636842105265 11\n",
      "0.12631636842105265 12\n",
      "0.14210578947368424 0\n",
      "0.14210578947368424 1\n",
      "0.14210578947368424 2\n",
      "0.14210578947368424 3\n",
      "0.1578952105263158 0\n",
      "0.1578952105263158 1\n",
      "0.1578952105263158 2\n",
      "0.1578952105263158 3\n",
      "0.1578952105263158 4\n",
      "0.1578952105263158 5\n",
      "0.1578952105263158 6\n",
      "0.1578952105263158 7\n",
      "0.1578952105263158 8\n",
      "0.1578952105263158 9\n",
      "0.1578952105263158 10\n",
      "0.1578952105263158 11\n",
      "0.1578952105263158 12\n",
      "0.1578952105263158 13\n",
      "0.1578952105263158 14\n",
      "0.1578952105263158 15\n",
      "0.1578952105263158 16\n",
      "0.1578952105263158 17\n",
      "0.1578952105263158 18\n",
      "0.1578952105263158 19\n",
      "0.1578952105263158 20\n",
      "0.1578952105263158 21\n",
      "0.1578952105263158 22\n",
      "0.1578952105263158 23\n",
      "0.1578952105263158 24\n",
      "0.1578952105263158 25\n",
      "0.1578952105263158 26\n",
      "0.1578952105263158 27\n",
      "0.1578952105263158 28\n",
      "0.1578952105263158 29\n",
      "0.1578952105263158 30\n",
      "0.1578952105263158 31\n",
      "0.1578952105263158 32\n",
      "0.1578952105263158 33\n",
      "0.1578952105263158 34\n",
      "0.1578952105263158 35\n",
      "0.1578952105263158 36\n",
      "0.1578952105263158 37\n",
      "0.1578952105263158 38\n",
      "0.1578952105263158 39\n",
      "0.1578952105263158 40\n",
      "0.1578952105263158 41\n",
      "0.1578952105263158 42\n",
      "0.1578952105263158 43\n",
      "0.1578952105263158 44\n",
      "0.1578952105263158 45\n",
      "0.1578952105263158 46\n",
      "0.1578952105263158 47\n",
      "0.1578952105263158 48\n",
      "0.1578952105263158 49\n",
      "0.1578952105263158 50\n",
      "0.1578952105263158 51\n",
      "0.1578952105263158 52\n",
      "0.1578952105263158 53\n",
      "0.1578952105263158 54\n",
      "0.1578952105263158 55\n",
      "0.1578952105263158 56\n",
      "0.1578952105263158 57\n",
      "0.1578952105263158 58\n",
      "0.1578952105263158 59\n",
      "0.1578952105263158 60\n",
      "0.1578952105263158 61\n",
      "0.1578952105263158 62\n",
      "0.1578952105263158 63\n",
      "0.1578952105263158 64\n",
      "0.1578952105263158 65\n",
      "0.1578952105263158 66\n",
      "0.1578952105263158 67\n",
      "0.1578952105263158 68\n",
      "0.1578952105263158 69\n",
      "0.1578952105263158 70\n",
      "0.1578952105263158 71\n",
      "0.1578952105263158 72\n",
      "0.1578952105263158 73\n",
      "0.1578952105263158 74\n",
      "0.1578952105263158 75\n",
      "0.1578952105263158 76\n",
      "0.1578952105263158 77\n",
      "0.1578952105263158 78\n",
      "0.1578952105263158 79\n",
      "0.1578952105263158 80\n",
      "0.1578952105263158 81\n",
      "0.1578952105263158 82\n",
      "0.1578952105263158 83\n",
      "0.1578952105263158 84\n",
      "0.1578952105263158 85\n",
      "0.1578952105263158 86\n",
      "0.1578952105263158 87\n",
      "0.1578952105263158 88\n",
      "0.1578952105263158 89\n",
      "0.1578952105263158 90\n",
      "0.1578952105263158 91\n",
      "0.1578952105263158 92\n",
      "0.1578952105263158 93\n",
      "0.1578952105263158 94\n",
      "0.1578952105263158 95\n",
      "0.1578952105263158 96\n",
      "0.1578952105263158 97\n",
      "0.1578952105263158 98\n",
      "0.1578952105263158 99\n",
      "0.1578952105263158 100\n",
      "0.1578952105263158 101\n",
      "0.1578952105263158 102\n",
      "0.1578952105263158 103\n",
      "0.1578952105263158 104\n",
      "0.1578952105263158 105\n",
      "0.1578952105263158 106\n",
      "0.1578952105263158 107\n",
      "0.1578952105263158 108\n",
      "0.1578952105263158 109\n",
      "0.1578952105263158 110\n",
      "0.1578952105263158 111\n",
      "0.1578952105263158 112\n",
      "0.1578952105263158 113\n",
      "0.1578952105263158 114\n",
      "0.1578952105263158 115\n",
      "0.1578952105263158 116\n",
      "0.1578952105263158 117\n",
      "0.1578952105263158 118\n",
      "0.1578952105263158 119\n",
      "0.1578952105263158 120\n",
      "0.1578952105263158 121\n",
      "0.1578952105263158 122\n",
      "0.1578952105263158 123\n",
      "0.1578952105263158 124\n",
      "0.1578952105263158 125\n",
      "0.1578952105263158 126\n",
      "0.1578952105263158 127\n",
      "0.1578952105263158 128\n",
      "0.1578952105263158 129\n",
      "0.1578952105263158 130\n",
      "0.1578952105263158 131\n",
      "0.1578952105263158 132\n",
      "0.1578952105263158 133\n",
      "0.1578952105263158 134\n",
      "0.1578952105263158 135\n",
      "0.1578952105263158 136\n",
      "0.1578952105263158 137\n",
      "0.1578952105263158 138\n",
      "0.1578952105263158 139\n",
      "0.1578952105263158 140\n",
      "0.1578952105263158 141\n",
      "0.1578952105263158 142\n",
      "0.1578952105263158 143\n",
      "0.1578952105263158 144\n",
      "0.1578952105263158 145\n",
      "0.1578952105263158 146\n",
      "0.1578952105263158 147\n",
      "0.1578952105263158 148\n",
      "0.1578952105263158 149\n",
      "0.1578952105263158 150\n",
      "0.1578952105263158 151\n",
      "0.1578952105263158 152\n",
      "0.1578952105263158 153\n",
      "0.1578952105263158 154\n",
      "0.1578952105263158 155\n",
      "0.1578952105263158 156\n",
      "0.1578952105263158 157\n",
      "0.1578952105263158 158\n",
      "0.1578952105263158 159\n",
      "0.1578952105263158 160\n",
      "0.1578952105263158 161\n",
      "0.1578952105263158 162\n",
      "0.1578952105263158 163\n",
      "0.1578952105263158 164\n",
      "0.1578952105263158 165\n",
      "0.1578952105263158 166\n",
      "0.1578952105263158 167\n",
      "0.1578952105263158 168\n",
      "0.1578952105263158 169\n",
      "0.1578952105263158 170\n",
      "0.1578952105263158 171\n",
      "0.1578952105263158 172\n",
      "0.1578952105263158 173\n",
      "0.1578952105263158 174\n",
      "0.1578952105263158 175\n",
      "0.1578952105263158 176\n",
      "0.1578952105263158 177\n",
      "0.1578952105263158 178\n",
      "0.1578952105263158 179\n",
      "0.1578952105263158 180\n",
      "0.1578952105263158 181\n",
      "0.1578952105263158 182\n",
      "0.1578952105263158 183\n",
      "0.1578952105263158 184\n",
      "0.1578952105263158 185\n",
      "0.1578952105263158 186\n",
      "0.1578952105263158 187\n",
      "0.1578952105263158 188\n",
      "0.1578952105263158 189\n",
      "0.1578952105263158 190\n",
      "0.1578952105263158 191\n",
      "0.1578952105263158 192\n",
      "0.1578952105263158 193\n",
      "0.1578952105263158 194\n",
      "0.1578952105263158 195\n",
      "0.1578952105263158 196\n",
      "0.1578952105263158 197\n",
      "0.1578952105263158 198\n",
      "0.1578952105263158 199\n",
      "0.1578952105263158 200\n",
      "0.1578952105263158 201\n",
      "0.1578952105263158 202\n",
      "0.1578952105263158 203\n",
      "0.1578952105263158 204\n",
      "0.1578952105263158 205\n",
      "0.1578952105263158 206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1578952105263158 207\n",
      "0.1578952105263158 208\n",
      "0.1578952105263158 209\n",
      "0.1578952105263158 210\n",
      "0.1578952105263158 211\n",
      "0.1578952105263158 212\n",
      "0.1578952105263158 213\n",
      "0.1578952105263158 214\n",
      "0.1578952105263158 215\n",
      "0.1578952105263158 216\n",
      "0.1578952105263158 217\n",
      "0.1578952105263158 218\n",
      "0.1578952105263158 219\n",
      "0.1578952105263158 220\n",
      "0.1578952105263158 221\n",
      "0.1578952105263158 222\n",
      "0.1578952105263158 223\n",
      "0.1578952105263158 224\n",
      "0.1578952105263158 225\n",
      "0.1578952105263158 226\n",
      "0.1578952105263158 227\n",
      "0.1578952105263158 228\n",
      "0.1578952105263158 229\n",
      "0.1578952105263158 230\n",
      "0.1578952105263158 231\n",
      "0.1578952105263158 232\n",
      "0.1578952105263158 233\n",
      "0.1578952105263158 234\n",
      "0.1578952105263158 235\n",
      "0.1578952105263158 236\n",
      "0.1578952105263158 237\n",
      "0.1578952105263158 238\n",
      "0.1578952105263158 239\n",
      "0.1578952105263158 240\n",
      "0.1578952105263158 241\n",
      "0.1578952105263158 242\n",
      "0.1578952105263158 243\n",
      "0.1578952105263158 244\n",
      "0.1578952105263158 245\n",
      "0.1578952105263158 246\n",
      "0.1578952105263158 247\n",
      "0.1578952105263158 248\n",
      "0.1578952105263158 249\n",
      "0.1578952105263158 250\n",
      "0.1578952105263158 251\n",
      "0.1578952105263158 252\n",
      "0.1578952105263158 253\n",
      "0.1578952105263158 254\n",
      "0.1578952105263158 255\n",
      "0.1578952105263158 256\n",
      "0.1578952105263158 257\n",
      "0.1578952105263158 258\n",
      "0.1578952105263158 259\n",
      "0.1578952105263158 260\n",
      "0.1578952105263158 261\n",
      "0.1578952105263158 262\n",
      "0.1578952105263158 263\n",
      "0.1578952105263158 264\n",
      "0.1578952105263158 265\n",
      "0.1578952105263158 266\n",
      "0.1578952105263158 267\n",
      "0.1578952105263158 268\n",
      "0.1578952105263158 269\n",
      "0.1578952105263158 270\n",
      "0.1578952105263158 271\n",
      "0.1578952105263158 272\n",
      "0.1578952105263158 273\n",
      "0.1578952105263158 274\n",
      "0.1578952105263158 275\n",
      "0.1578952105263158 276\n",
      "0.1578952105263158 277\n",
      "0.1578952105263158 278\n",
      "0.1578952105263158 279\n",
      "0.1578952105263158 280\n",
      "0.1578952105263158 281\n",
      "0.1578952105263158 282\n",
      "0.1578952105263158 283\n",
      "0.1578952105263158 284\n",
      "0.1578952105263158 285\n",
      "0.1578952105263158 286\n",
      "0.1578952105263158 287\n",
      "0.1578952105263158 288\n",
      "0.1578952105263158 289\n",
      "0.1578952105263158 290\n",
      "0.1578952105263158 291\n",
      "0.1578952105263158 292\n",
      "0.1578952105263158 293\n",
      "0.1578952105263158 294\n",
      "0.1578952105263158 295\n",
      "0.1578952105263158 296\n",
      "0.1578952105263158 297\n",
      "0.1578952105263158 298\n",
      "0.1578952105263158 299\n",
      "0.1578952105263158 300\n",
      "0.1578952105263158 301\n",
      "0.1578952105263158 302\n",
      "0.1578952105263158 303\n",
      "0.1578952105263158 304\n",
      "0.1578952105263158 305\n",
      "0.1578952105263158 306\n",
      "0.1578952105263158 307\n",
      "0.1578952105263158 308\n",
      "0.1578952105263158 309\n",
      "0.1578952105263158 310\n",
      "0.1578952105263158 311\n",
      "0.1578952105263158 312\n",
      "0.1578952105263158 313\n",
      "0.1578952105263158 314\n",
      "0.1578952105263158 315\n",
      "0.1578952105263158 316\n",
      "0.1578952105263158 317\n",
      "0.1578952105263158 318\n",
      "0.1578952105263158 319\n",
      "0.1578952105263158 320\n",
      "0.1578952105263158 321\n",
      "0.1578952105263158 322\n",
      "0.1578952105263158 323\n",
      "0.1578952105263158 324\n",
      "0.1578952105263158 325\n",
      "0.1578952105263158 326\n",
      "0.1578952105263158 327\n",
      "0.1578952105263158 328\n",
      "0.1578952105263158 329\n",
      "0.1578952105263158 330\n",
      "0.1578952105263158 331\n",
      "0.1578952105263158 332\n",
      "0.1578952105263158 333\n",
      "0.1578952105263158 334\n",
      "0.1578952105263158 335\n",
      "0.1578952105263158 336\n",
      "0.1578952105263158 337\n",
      "0.1578952105263158 338\n",
      "0.1578952105263158 339\n",
      "0.1578952105263158 340\n",
      "0.1578952105263158 341\n",
      "0.1578952105263158 342\n",
      "0.1578952105263158 343\n",
      "0.1578952105263158 344\n",
      "0.1578952105263158 345\n",
      "0.1578952105263158 346\n",
      "0.1578952105263158 347\n",
      "0.1578952105263158 348\n",
      "0.1578952105263158 349\n",
      "0.1578952105263158 350\n",
      "0.1578952105263158 351\n",
      "0.1578952105263158 352\n",
      "0.1578952105263158 353\n",
      "0.1578952105263158 354\n",
      "0.1578952105263158 355\n",
      "0.1578952105263158 356\n",
      "0.1578952105263158 357\n",
      "0.1578952105263158 358\n",
      "0.1578952105263158 359\n",
      "0.1578952105263158 360\n",
      "0.1578952105263158 361\n",
      "0.1578952105263158 362\n",
      "0.1578952105263158 363\n",
      "0.1578952105263158 364\n",
      "0.1736846315789474 0\n",
      "0.1736846315789474 1\n",
      "0.1736846315789474 2\n",
      "0.1736846315789474 3\n",
      "0.1736846315789474 4\n",
      "0.1736846315789474 5\n",
      "0.1736846315789474 6\n",
      "0.1736846315789474 7\n",
      "0.1736846315789474 8\n",
      "0.1736846315789474 9\n",
      "0.1736846315789474 10\n",
      "0.1736846315789474 11\n",
      "0.1736846315789474 12\n",
      "0.1736846315789474 13\n",
      "0.1736846315789474 14\n",
      "0.1736846315789474 15\n",
      "0.1736846315789474 16\n",
      "0.1736846315789474 17\n",
      "0.1736846315789474 18\n",
      "0.1736846315789474 19\n",
      "0.1736846315789474 20\n",
      "0.1736846315789474 21\n",
      "0.1736846315789474 22\n",
      "0.1736846315789474 23\n",
      "0.1736846315789474 24\n",
      "0.1736846315789474 25\n",
      "0.1736846315789474 26\n",
      "0.1736846315789474 27\n",
      "0.1736846315789474 28\n",
      "0.1736846315789474 29\n",
      "0.1736846315789474 30\n",
      "0.1736846315789474 31\n",
      "0.1736846315789474 32\n",
      "0.1736846315789474 33\n",
      "0.1736846315789474 34\n",
      "0.1736846315789474 35\n",
      "0.1736846315789474 36\n",
      "0.1736846315789474 37\n",
      "0.1736846315789474 38\n",
      "0.1736846315789474 39\n",
      "0.1736846315789474 40\n",
      "0.1736846315789474 41\n",
      "0.1736846315789474 42\n",
      "0.1736846315789474 43\n",
      "0.1736846315789474 44\n",
      "0.1736846315789474 45\n",
      "0.1736846315789474 46\n",
      "0.1736846315789474 47\n",
      "0.1736846315789474 48\n",
      "0.1736846315789474 49\n",
      "0.1736846315789474 50\n",
      "0.1736846315789474 51\n",
      "0.1736846315789474 52\n",
      "0.1736846315789474 53\n",
      "0.1736846315789474 54\n",
      "0.1736846315789474 55\n",
      "0.1736846315789474 56\n",
      "0.1736846315789474 57\n",
      "0.1736846315789474 58\n",
      "0.1736846315789474 59\n",
      "0.1736846315789474 60\n",
      "0.1736846315789474 61\n",
      "0.1736846315789474 62\n",
      "0.1736846315789474 63\n",
      "0.1736846315789474 64\n",
      "0.1736846315789474 65\n",
      "0.1736846315789474 66\n",
      "0.1736846315789474 67\n",
      "0.1736846315789474 68\n",
      "0.1736846315789474 69\n",
      "0.1736846315789474 70\n",
      "0.1736846315789474 71\n",
      "0.1736846315789474 72\n",
      "0.1736846315789474 73\n",
      "0.1736846315789474 74\n",
      "0.1736846315789474 75\n",
      "0.1736846315789474 76\n",
      "0.1736846315789474 77\n",
      "0.1736846315789474 78\n",
      "0.1736846315789474 79\n",
      "0.1736846315789474 80\n",
      "0.1736846315789474 81\n",
      "0.1736846315789474 82\n",
      "0.1736846315789474 83\n",
      "0.1736846315789474 84\n",
      "0.1736846315789474 85\n",
      "0.1736846315789474 86\n",
      "0.1736846315789474 87\n",
      "0.1736846315789474 88\n",
      "0.1736846315789474 89\n",
      "0.1736846315789474 90\n",
      "0.1736846315789474 91\n",
      "0.1736846315789474 92\n",
      "0.1736846315789474 93\n",
      "0.1736846315789474 94\n",
      "0.1736846315789474 95\n",
      "0.1736846315789474 96\n",
      "0.1736846315789474 97\n",
      "0.1736846315789474 98\n",
      "0.1736846315789474 99\n",
      "0.1736846315789474 100\n",
      "0.1736846315789474 101\n",
      "0.1736846315789474 102\n",
      "0.1736846315789474 103\n",
      "0.1736846315789474 104\n",
      "0.1736846315789474 105\n",
      "0.1736846315789474 106\n",
      "0.1736846315789474 107\n",
      "0.1736846315789474 108\n",
      "0.1736846315789474 109\n",
      "0.1736846315789474 110\n",
      "0.1736846315789474 111\n",
      "0.1736846315789474 112\n",
      "0.1736846315789474 113\n",
      "0.1736846315789474 114\n",
      "0.1736846315789474 115\n",
      "0.1736846315789474 116\n",
      "0.1736846315789474 117\n",
      "0.1736846315789474 118\n",
      "0.1736846315789474 119\n",
      "0.1736846315789474 120\n",
      "0.1736846315789474 121\n",
      "0.1736846315789474 122\n",
      "0.1736846315789474 123\n",
      "0.1736846315789474 124\n",
      "0.1736846315789474 125\n",
      "0.1736846315789474 126\n",
      "0.1736846315789474 127\n",
      "0.1736846315789474 128\n",
      "0.1736846315789474 129\n",
      "0.1736846315789474 130\n",
      "0.1736846315789474 131\n",
      "0.1736846315789474 132\n",
      "0.1736846315789474 133\n",
      "0.1736846315789474 134\n",
      "0.1736846315789474 135\n",
      "0.1736846315789474 136\n",
      "0.1736846315789474 137\n",
      "0.1736846315789474 138\n",
      "0.1736846315789474 139\n",
      "0.1736846315789474 140\n",
      "0.1736846315789474 141\n",
      "0.1736846315789474 142\n",
      "0.1736846315789474 143\n",
      "0.1736846315789474 144\n",
      "0.1736846315789474 145\n",
      "0.1736846315789474 146\n",
      "0.1736846315789474 147\n",
      "0.1736846315789474 148\n",
      "0.1736846315789474 149\n",
      "0.1736846315789474 150\n",
      "0.1736846315789474 151\n",
      "0.1736846315789474 152\n",
      "0.1736846315789474 153\n",
      "0.1736846315789474 154\n",
      "0.1736846315789474 155\n",
      "0.1736846315789474 156\n",
      "0.1736846315789474 157\n",
      "0.1736846315789474 158\n",
      "0.1736846315789474 159\n",
      "0.1736846315789474 160\n",
      "0.1736846315789474 161\n",
      "0.1736846315789474 162\n",
      "0.1736846315789474 163\n",
      "0.1736846315789474 164\n",
      "0.1736846315789474 165\n",
      "0.1736846315789474 166\n",
      "0.1736846315789474 167\n",
      "0.1736846315789474 168\n",
      "0.1736846315789474 169\n",
      "0.1736846315789474 170\n",
      "0.1736846315789474 171\n",
      "0.1736846315789474 172\n",
      "0.1736846315789474 173\n",
      "0.1736846315789474 174\n",
      "0.1736846315789474 175\n",
      "0.1736846315789474 176\n",
      "0.1736846315789474 177\n",
      "0.1736846315789474 178\n",
      "0.1736846315789474 179\n",
      "0.1736846315789474 180\n",
      "0.1736846315789474 181\n",
      "0.1736846315789474 182\n",
      "0.1736846315789474 183\n",
      "0.1736846315789474 184\n",
      "0.1736846315789474 185\n",
      "0.1736846315789474 186\n",
      "0.1736846315789474 187\n",
      "0.1736846315789474 188\n",
      "0.1736846315789474 189\n",
      "0.1736846315789474 190\n",
      "0.1736846315789474 191\n",
      "0.1736846315789474 192\n",
      "0.1736846315789474 193\n",
      "0.1736846315789474 194\n",
      "0.1736846315789474 195\n",
      "0.1736846315789474 196\n",
      "0.1736846315789474 197\n",
      "0.1736846315789474 198\n",
      "0.1736846315789474 199\n",
      "0.1736846315789474 200\n",
      "0.1736846315789474 201\n",
      "0.1736846315789474 202\n",
      "0.1736846315789474 203\n",
      "0.1736846315789474 204\n",
      "0.1736846315789474 205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1736846315789474 206\n",
      "0.1736846315789474 207\n",
      "0.1736846315789474 208\n",
      "0.1736846315789474 209\n",
      "0.1736846315789474 210\n",
      "0.1736846315789474 211\n",
      "0.1736846315789474 212\n",
      "0.1736846315789474 213\n",
      "0.1736846315789474 214\n",
      "0.1736846315789474 215\n",
      "0.1736846315789474 216\n",
      "0.1736846315789474 217\n",
      "0.1736846315789474 218\n",
      "0.1736846315789474 219\n",
      "0.1736846315789474 220\n",
      "0.1736846315789474 221\n",
      "0.1736846315789474 222\n",
      "0.1736846315789474 223\n",
      "0.1736846315789474 224\n",
      "0.1736846315789474 225\n",
      "0.1736846315789474 226\n",
      "0.1736846315789474 227\n",
      "0.1736846315789474 228\n",
      "0.1736846315789474 229\n",
      "0.1736846315789474 230\n",
      "0.1736846315789474 231\n",
      "0.1736846315789474 232\n",
      "0.1736846315789474 233\n",
      "0.1736846315789474 234\n",
      "0.1736846315789474 235\n",
      "0.1736846315789474 236\n",
      "0.1736846315789474 237\n",
      "0.1736846315789474 238\n",
      "0.1736846315789474 239\n",
      "0.1736846315789474 240\n",
      "0.1736846315789474 241\n",
      "0.1736846315789474 242\n",
      "0.1736846315789474 243\n",
      "0.1736846315789474 244\n",
      "0.1736846315789474 245\n",
      "0.1736846315789474 246\n",
      "0.1736846315789474 247\n",
      "0.1736846315789474 248\n",
      "0.1736846315789474 249\n",
      "0.1736846315789474 250\n",
      "0.189474052631579 0\n",
      "0.189474052631579 1\n",
      "0.189474052631579 2\n",
      "0.189474052631579 3\n",
      "0.189474052631579 4\n",
      "0.189474052631579 5\n",
      "0.189474052631579 6\n",
      "0.189474052631579 7\n",
      "0.189474052631579 8\n",
      "0.189474052631579 9\n",
      "0.189474052631579 10\n",
      "0.189474052631579 11\n",
      "0.189474052631579 12\n",
      "0.189474052631579 13\n",
      "0.189474052631579 14\n",
      "0.189474052631579 15\n",
      "0.189474052631579 16\n",
      "0.189474052631579 17\n",
      "0.189474052631579 18\n",
      "0.189474052631579 19\n",
      "0.189474052631579 20\n",
      "0.189474052631579 21\n",
      "0.189474052631579 22\n",
      "0.189474052631579 23\n",
      "0.189474052631579 24\n",
      "0.189474052631579 25\n",
      "0.189474052631579 26\n",
      "0.189474052631579 27\n",
      "0.189474052631579 28\n",
      "0.189474052631579 29\n",
      "0.189474052631579 30\n",
      "0.189474052631579 31\n",
      "0.189474052631579 32\n",
      "0.189474052631579 33\n",
      "0.189474052631579 34\n",
      "0.189474052631579 35\n",
      "0.189474052631579 36\n",
      "0.189474052631579 37\n",
      "0.189474052631579 38\n",
      "0.189474052631579 39\n",
      "0.189474052631579 40\n",
      "0.189474052631579 41\n",
      "0.189474052631579 42\n",
      "0.189474052631579 43\n",
      "0.189474052631579 44\n",
      "0.189474052631579 45\n",
      "0.189474052631579 46\n",
      "0.189474052631579 47\n",
      "0.189474052631579 48\n",
      "0.189474052631579 49\n",
      "0.189474052631579 50\n",
      "0.189474052631579 51\n",
      "0.189474052631579 52\n",
      "0.189474052631579 53\n",
      "0.189474052631579 54\n",
      "0.189474052631579 55\n",
      "0.189474052631579 56\n",
      "0.20526347368421055 0\n",
      "0.20526347368421055 1\n",
      "0.20526347368421055 2\n",
      "0.20526347368421055 3\n",
      "0.22105289473684214 0\n",
      "0.22105289473684214 1\n",
      "0.2368423157894737 0\n",
      "0.2368423157894737 1\n",
      "0.2368423157894737 2\n",
      "0.2368423157894737 3\n",
      "0.2368423157894737 4\n",
      "0.2368423157894737 5\n",
      "0.2368423157894737 6\n",
      "0.2368423157894737 7\n",
      "0.25263173684210527 0\n",
      "0.25263173684210527 1\n",
      "0.25263173684210527 2\n",
      "0.26842115789473686 0\n",
      "0.28421057894736845 0\n",
      "0.28421057894736845 1\n",
      "0.28421057894736845 2\n",
      "0.28421057894736845 3\n",
      "0.28421057894736845 4\n",
      "0.28421057894736845 5\n",
      "0.28421057894736845 6\n",
      "0.28421057894736845 7\n",
      "0.28421057894736845 8\n",
      "0.28421057894736845 9\n",
      "0.28421057894736845 10\n",
      "0.28421057894736845 11\n",
      "0.28421057894736845 12\n",
      "0.28421057894736845 13\n",
      "0.28421057894736845 14\n",
      "0.28421057894736845 15\n",
      "0.28421057894736845 16\n",
      "0.28421057894736845 17\n",
      "0.28421057894736845 18\n",
      "0.28421057894736845 19\n",
      "0.28421057894736845 20\n",
      "0.28421057894736845 21\n",
      "0.28421057894736845 22\n",
      "0.28421057894736845 23\n",
      "0.28421057894736845 24\n",
      "0.28421057894736845 25\n",
      "0.28421057894736845 26\n",
      "0.28421057894736845 27\n",
      "0.28421057894736845 28\n",
      "0.28421057894736845 29\n",
      "0.28421057894736845 30\n",
      "0.28421057894736845 31\n",
      "0.28421057894736845 32\n",
      "0.28421057894736845 33\n",
      "0.28421057894736845 34\n",
      "0.28421057894736845 35\n",
      "0.28421057894736845 36\n",
      "0.28421057894736845 37\n",
      "0.28421057894736845 38\n",
      "0.28421057894736845 39\n",
      "0.28421057894736845 40\n",
      "0.28421057894736845 41\n",
      "0.28421057894736845 42\n",
      "0.28421057894736845 43\n",
      "0.28421057894736845 44\n",
      "0.28421057894736845 45\n",
      "0.28421057894736845 46\n",
      "0.28421057894736845 47\n",
      "0.28421057894736845 48\n",
      "0.28421057894736845 49\n",
      "0.28421057894736845 50\n",
      "0.28421057894736845 51\n",
      "0.28421057894736845 52\n",
      "0.28421057894736845 53\n",
      "0.28421057894736845 54\n",
      "0.28421057894736845 55\n",
      "0.28421057894736845 56\n",
      "0.28421057894736845 57\n",
      "0.28421057894736845 58\n",
      "0.28421057894736845 59\n",
      "0.28421057894736845 60\n",
      "0.28421057894736845 61\n",
      "0.28421057894736845 62\n",
      "0.28421057894736845 63\n",
      "0.28421057894736845 64\n",
      "0.28421057894736845 65\n",
      "0.28421057894736845 66\n",
      "0.28421057894736845 67\n",
      "0.28421057894736845 68\n",
      "0.28421057894736845 69\n",
      "0.28421057894736845 70\n",
      "0.28421057894736845 71\n",
      "0.28421057894736845 72\n",
      "0.28421057894736845 73\n",
      "0.28421057894736845 74\n",
      "0.28421057894736845 75\n",
      "0.28421057894736845 76\n",
      "0.28421057894736845 77\n",
      "0.28421057894736845 78\n",
      "0.28421057894736845 79\n",
      "0.28421057894736845 80\n",
      "0.28421057894736845 81\n",
      "0.28421057894736845 82\n",
      "0.28421057894736845 83\n",
      "0.28421057894736845 84\n",
      "0.28421057894736845 85\n",
      "0.28421057894736845 86\n",
      "0.28421057894736845 87\n",
      "0.28421057894736845 88\n",
      "0.28421057894736845 89\n",
      "0.28421057894736845 90\n",
      "0.28421057894736845 91\n",
      "0.28421057894736845 92\n",
      "0.28421057894736845 93\n",
      "0.28421057894736845 94\n",
      "0.28421057894736845 95\n",
      "0.28421057894736845 96\n",
      "0.28421057894736845 97\n",
      "0.28421057894736845 98\n",
      "0.28421057894736845 99\n",
      "0.28421057894736845 100\n",
      "0.28421057894736845 101\n",
      "0.28421057894736845 102\n",
      "0.28421057894736845 103\n",
      "0.28421057894736845 104\n",
      "0.28421057894736845 105\n",
      "0.28421057894736845 106\n",
      "0.28421057894736845 107\n",
      "0.28421057894736845 108\n",
      "0.28421057894736845 109\n",
      "0.28421057894736845 110\n",
      "0.28421057894736845 111\n",
      "0.28421057894736845 112\n",
      "0.28421057894736845 113\n",
      "0.28421057894736845 114\n",
      "0.28421057894736845 115\n",
      "0.28421057894736845 116\n",
      "0.28421057894736845 117\n",
      "0.28421057894736845 118\n",
      "0.28421057894736845 119\n",
      "0.28421057894736845 120\n",
      "0.28421057894736845 121\n",
      "0.28421057894736845 122\n",
      "0.28421057894736845 123\n",
      "0.28421057894736845 124\n",
      "0.28421057894736845 125\n",
      "0.28421057894736845 126\n",
      "0.28421057894736845 127\n",
      "0.28421057894736845 128\n",
      "0.3 0\n",
      "0.3 1\n",
      "0.3 2\n",
      "0.3 3\n",
      "0.3 4\n",
      "0.3 5\n",
      "0.3 6\n",
      "0.3 7\n",
      "0.3 8\n",
      "0.3 9\n",
      "0.3 10\n",
      "0.3 11\n",
      "0.3 12\n",
      "0.3 13\n",
      "0.3 14\n",
      "0.3 15\n",
      "0.3 16\n",
      "0.3 17\n",
      "0.3 18\n",
      "0.3 19\n",
      "0.3 20\n",
      "0.3 21\n",
      "0.3 22\n",
      "0.3 23\n",
      "0.3 24\n",
      "0.3 25\n",
      "0.3 26\n",
      "0.3 27\n",
      "0.3 28\n",
      "0.3 29\n",
      "0.3 30\n",
      "0.3 31\n",
      "0.3 32\n",
      "0.3 33\n",
      "0.3 34\n",
      "0.3 35\n",
      "0.3 36\n",
      "0.3 37\n",
      "0.3 38\n",
      "0.3 39\n",
      "0.3 40\n",
      "0.3 41\n",
      "0.3 42\n",
      "0.3 43\n",
      "0.3 44\n",
      "0.3 45\n",
      "0.3 46\n",
      "0.3 47\n",
      "0.3 48\n",
      "0.3 49\n",
      "0.3 50\n",
      "0.3 51\n",
      "0.3 52\n",
      "0.3 53\n",
      "0.3 54\n",
      "0.3 55\n",
      "0.3 56\n",
      "0.3 57\n",
      "0.3 58\n",
      "0.3 59\n",
      "0.3 60\n",
      "0.3 61\n",
      "0.3 62\n",
      "0.3 63\n",
      "0.3 64\n",
      "0.3 65\n",
      "0.3 66\n",
      "0.3 67\n",
      "0.3 68\n",
      "0.3 69\n",
      "0.3 70\n",
      "0.3 71\n",
      "0.3 72\n",
      "0.3 73\n",
      "0.3 74\n",
      "0.3 75\n",
      "0.3 76\n",
      "0.3 77\n",
      "0.3 78\n",
      "0.3 79\n",
      "0.3 80\n",
      "0.3 81\n",
      "0.3 82\n",
      "0.3 83\n",
      "0.3 84\n",
      "0.3 85\n",
      "0.3 86\n",
      "0.3 87\n",
      "0.3 88\n",
      "0.3 89\n",
      "     pred  true_label\n",
      "0     1.0           1\n",
      "1     0.0           0\n",
      "2     0.0           0\n",
      "3     1.0           1\n",
      "4     0.0           0\n",
      "..    ...         ...\n",
      "995   0.0           0\n",
      "996   1.0           0\n",
      "997   1.0           0\n",
      "998   0.0           0\n",
      "999   0.0           0\n",
      "\n",
      "[1000 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b2/8cn96b9x6qz0b7b79dn_n_1h0000gn/T/ipykernel_13453/2633864594.py:50: RuntimeWarning: overflow encountered in exp\n",
      "  test_pred = 1/(1+np.exp(-test_a))\n"
     ]
    }
   ],
   "source": [
    "lr, lr_preds = logistic_regression(q5_test, np.delete(all_index, q5_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "a6960242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.846393456518054\n",
      "0.8155289973818538\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sklearn as sk\n",
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = sk.metrics.roc_curve(fiveknn['Prediction'], fiveknn['pred'], pos_label=1)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(fpr, tpr, marker = 'o', label = 'KNN, k = 5, AUC: 0.846')\n",
    "\n",
    "\n",
    "fpr, tpr, thresholds = sk.metrics.roc_curve(fiveknn['Prediction'], lr_preds, pos_label=1)\n",
    "ax.plot(fpr, tpr, marker = 'o', label = 'Logistic regression, AUC: 0.816')\n",
    "ax.set_ylabel(\"TPR\")\n",
    "ax.set_xlabel(\"FPR\")\n",
    "fig.legend()\n",
    "print(sk.metrics.roc_auc_score(fiveknn['Prediction'], fiveknn['pred']))\n",
    "print(sk.metrics.roc_auc_score(fiveknn['Prediction'], lr_preds))\n",
    "plt.savefig(\"./HW/HW3_roc_curve.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
